{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook implements the BOW model with Ordinal Output Categories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib as plt \n",
    "import glob\n",
    "from importlib import reload\n",
    "\n",
    "import os, sys, re, json, time, datetime, shutil\n",
    "from common import utils, constants, spell\n",
    "\n",
    "import tensorflow as tf\n",
    "import tripadvisor_ds\n",
    "import visualization\n",
    "\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except ModuleNotFoundError:\n",
    "    import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load tripadvisor data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "reload(tripadvisor_ds)\n",
    "\n",
    "input_length = 500\n",
    "max_bytes = 2**31 - 1\n",
    "\n",
    "data_file = 'data/tripadvisor_ds.pkl'\n",
    "\n",
    "if os.path.isfile(data_file):\n",
    "\n",
    "    bytes_in = bytearray(0)\n",
    "    input_size = os.path.getsize(data_file)\n",
    "    with open(data_file, 'rb') as f_in:\n",
    "        for _ in range(0, input_size, max_bytes):\n",
    "            bytes_in += f_in.read(max_bytes)\n",
    "    ds = pickle.loads(bytes_in)\n",
    "        \n",
    "else:\n",
    "    ds = tripadvisor_ds.TripAdvisor_DS().process(input_length=input_length)\n",
    "    ds.save(data_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------\n",
    "# convert the output to Ordinal Categories \n",
    "# 2-star rating: [0,0,0]\n",
    "# 3-star rating: [1,0,0]\n",
    "# 4-star rating: [1,1,0]\n",
    "# 5-star rating: [1,1,1]\n",
    "# -----------------------------------------\n",
    "\n",
    "ds.get_ord_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    413463\n",
       "2    231827\n",
       "1    106079\n",
       "0     90053\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.DataFrame({'rating': ds.train_labels})\n",
    "labels.rating.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set model parameters \n",
    "model_params = dict(V=ds.vocab.size, \n",
    "                    embed_dim=100, \n",
    "                    num_classes=len(ds.target_labels),\n",
    "                    encoder_type='bow', \n",
    "                    hidden_dims=[1024, 64], \n",
    "                    input_length=input_length,\n",
    "                    lr=0.0001, \n",
    "                    optimizer='adam', \n",
    "                    beta=0.00001)\n",
    "                    \n",
    "train_params = dict(batch_size=64, \n",
    "                    total_epochs=20, \n",
    "                    eval_every=2)\n",
    "\n",
    "\n",
    "summary_params = dict(chkpt_dir=\"./tmp/266_bow_ord\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# setup tensorboard \n",
    "\n",
    "if os.path.isdir(summary_params['chkpt_dir']):\n",
    "    shutil.rmtree(summary_params['chkpt_dir'])\n",
    "\n",
    "def variable_summaries(var):\n",
    "    \"\"\"Attach a lot of summaries to a Tensor (for TensorBoard visualization).\"\"\"\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean', mean)\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "        tf.summary.scalar('stddev', stddev)\n",
    "        tf.summary.scalar('max', tf.reduce_max(var))\n",
    "        tf.summary.scalar('min', tf.reduce_min(var))\n",
    "        tf.summary.histogram('histogram', var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def embedding_layer(ids_, V, embed_dim, init_scale=0.001):\n",
    "    \n",
    "    # prepare vocabulary  \n",
    "    W_embed_ = tf.get_variable(\"W_embed\", shape=[V, embed_dim], \\\n",
    "                               initializer=tf.random_uniform_initializer(-init_scale, init_scale), \\\n",
    "                               trainable=True)\n",
    "        \n",
    "    # look up word embedding \n",
    "    xs_ = tf.nn.embedding_lookup(W_embed_, ids_, name=\"embed_x\")\n",
    "        \n",
    "    return xs_\n",
    "\n",
    "def fully_connected_layers(h0_, hidden_dims, activation=tf.nn.relu,\n",
    "                           dropout_rate=0, is_training=False):\n",
    "    h_ = h0_\n",
    "    for i, hdim in enumerate(hidden_dims):\n",
    "        h_ = tf.layers.dense(h_, hdim, activation=activation, name=(\"Hidden_%d\"%i))\n",
    "        if dropout_rate > 0:\n",
    "            h_ = tf.layers.dropout(h_, rate=dropout_rate, training=is_training )\n",
    "\n",
    "    return h_\n",
    "\n",
    "def softmax_output_layer(h_, labels_, num_classes):\n",
    "    \n",
    "    W_out_ = tf.get_variable(\"W_out\",  shape=[h_.get_shape().as_list()[1], num_classes], \\\n",
    "                               initializer=tf.random_normal_initializer())\n",
    "    b_out_ = tf.get_variable(\"b_out\", shape=[num_classes])\n",
    "\n",
    "    logits_ = tf.add(tf.matmul(h_, W_out_), b_out_)\n",
    "        \n",
    "    if labels_ is None:\n",
    "        return None, logits_\n",
    "    \n",
    "    with tf.variable_scope(\"Softmax_Layer\"):\n",
    "\n",
    "        softmax_ = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels_, logits=logits_)\n",
    "        \n",
    "        loss_ = tf.reduce_mean(softmax_)\n",
    "    \n",
    "    return loss_, logits_\n",
    "\n",
    "\n",
    "def sigmoid_output_layer(h_, labels_, num_classes):\n",
    "    \n",
    "    W_out_ = tf.get_variable(\"W_out\",  shape=[h_.get_shape().as_list()[1], num_classes], \\\n",
    "                               initializer=tf.random_normal_initializer())\n",
    "    b_out_ = tf.get_variable(\"b_out\", shape=[num_classes])\n",
    "\n",
    "    logits_ = tf.add(tf.matmul(h_, W_out_), b_out_)\n",
    "        \n",
    "    if labels_ is None:\n",
    "        return None, logits_\n",
    "    \n",
    "    with tf.variable_scope(\"Sigmoid_Layer\"):\n",
    "        \n",
    "        sigmoid_ = tf.nn.sigmoid(logits_)\n",
    "        \n",
    "        loss_ = num_classes * tf.reduce_mean(tf.squared_difference( labels_, sigmoid_))\n",
    "        \n",
    "    return loss_, logits_\n",
    "\n",
    "\n",
    "def BOW(ids_, V, embed_dim, hidden_dims, dropout_rate=0, is_training=None):\n",
    "    assert is_training is not None, \"is_training must be explicitly set to True or False\"\n",
    "\n",
    "    with tf.variable_scope(\"Embedding_Layer\"):\n",
    "        xs_ = embedding_layer(ids_, V, embed_dim)\n",
    "     \n",
    "    sum_xs_ = tf.reduce_sum(xs_, 1)\n",
    "\n",
    "    h_ = fully_connected_layers(sum_xs_, hidden_dims, \\\n",
    "                           dropout_rate=dropout_rate, is_training=is_training)\n",
    "    return h_, xs_\n",
    "\n",
    "\n",
    "def conv_net(ids_, V, embed_dim, filter_sizes, num_filters, hidden_dims, input_length, dropout_rate=0, is_training=None):\n",
    "\n",
    "    assert is_training is not None, \"is_training must be explicitly set to True or False\"\n",
    "\n",
    "    with tf.variable_scope(\"Embedding_Layer\"):\n",
    "        xs_ = embedding_layer(ids_, V, embed_dim)\n",
    "\n",
    "    xs_ = tf.expand_dims(xs_, -1)\n",
    "        \n",
    "    pooled_outputs_ = []\n",
    "    for _, filter_size in enumerate(filter_sizes):\n",
    "        with tf.name_scope(\"Conv_MaxPool_%d\"%filter_size):\n",
    "            \n",
    "            # Convolution Layer\n",
    "            filter_shape = [filter_size, embed_dim, 1, num_filters]\n",
    "            W_ = tf.Variable(tf.truncated_normal(filter_shape, stddev=0.1), name=\"W\")\n",
    "            b_ = tf.Variable(tf.constant(0.1, shape=[num_filters]), name=\"b\")\n",
    "            conv_ = tf.nn.conv2d(\n",
    "                xs_,\n",
    "                W_,\n",
    "                strides=[1, 1, 1, 1],\n",
    "                padding=\"VALID\",\n",
    "                name=\"conv\")\n",
    "            \n",
    "            # Activation\n",
    "            h_ = tf.nn.relu(tf.nn.bias_add(conv_, b_), name=\"relu\")\n",
    "            \n",
    "            # Maxpooling \n",
    "            pooled_ = tf.nn.max_pool(\n",
    "                h_,\n",
    "                ksize=[1, input_length - filter_size + 1, 1, 1],\n",
    "                strides=[1, 1, 1, 1],\n",
    "                padding='VALID',\n",
    "                name=\"pool\")\n",
    "            pooled_outputs_.append(pooled_)\n",
    "            \n",
    "            variable_summaries(pooled_)\n",
    "\n",
    "    # Combine all the pooled features and flatten it\n",
    "    num_filters_total = num_filters * len(filter_sizes)\n",
    "    h_ = tf.concat(pooled_outputs_, 3)\n",
    "    h_ = tf.reshape(h_, [-1, num_filters_total])\n",
    "    \n",
    "    # fully connected layers\n",
    "    with tf.variable_scope(\"FC_Layer\"):\n",
    "        h_ = fully_connected_layers(h_, hidden_dims, is_training = is_training)\n",
    "\n",
    "    return h_, xs_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph() \n",
    "\n",
    "X = tf.placeholder(tf.int32, [None, input_length], name='input_x')\n",
    "Y = tf.placeholder(tf.float32, [None, 3], name='input_y')\n",
    "    \n",
    "if model_params['encoder_type'] == 'bow':\n",
    "    h_, xs_ = BOW(X, model_params['V'], \n",
    "                      model_params['embed_dim'],  \n",
    "                      model_params['hidden_dims'],\n",
    "                      is_training=True)\n",
    "\n",
    "\n",
    "with tf.variable_scope(\"Output_Layer\"):\n",
    "    loss_, logits_ = sigmoid_output_layer(h_, Y, model_params['num_classes'] -1)\n",
    "    \n",
    "\n",
    "with tf.name_scope(\"Prediction\"):\n",
    "    pred_proba_ = tf.nn.sigmoid(logits_, name=\"pred_proba\")\n",
    "    \n",
    "    pred_max_ = tf.reduce_sum(tf.cast(tf.great(pred_proba_ ,0.5), tf.int32), axis = 1, name=\"pred_max\")\n",
    "    \n",
    "    predictions_dict = {\"proba\": pred_proba_, \"max\": pred_max_}\n",
    "\n",
    "with tf.variable_scope(\"Regularization\"):\n",
    "    l2_penalty_ = tf.nn.l2_loss(xs_)  # l2 loss on embeddings\n",
    "    for var_ in tf.trainable_variables():\n",
    "        if \"Embedding_Layer\" in var_.name:\n",
    "            continue\n",
    "        l2_penalty_ += tf.nn.l2_loss(var_)\n",
    "    l2_penalty_ *= model_params['beta']  # scale by regularization strength\n",
    "    tf.summary.scalar('l2_penalty', l2_penalty_)\n",
    "    regularized_loss_ = loss_ + l2_penalty_\n",
    "    tf.summary.scalar('regularized_loss', regularized_loss_)\n",
    "\n",
    "with tf.variable_scope(\"Training\"):\n",
    "    if model_params['optimizer'] == 'adagrad':\n",
    "        optimizer_ = tf.train.AdagradOptimizer(model_params['lr'])\n",
    "    elif  model_params['optimizer'] == 'adam':\n",
    "        optimizer_ = tf.train.AdamOptimizer(model_params['lr'])\n",
    "    else:\n",
    "        optimizer_ = tf.train.GradientDescentOptimizer(model_params['lr'])\n",
    "    train_op_ = optimizer_.minimize(regularized_loss_,\n",
    "                    global_step=tf.train.get_global_step())\n",
    "\n",
    "\n",
    "with tf.name_scope(\"Evaluation\"):\n",
    "\n",
    "    correct_pred_ = tf.equal(tf.cast(pred_max_, tf.int32), tf.cast(tf.reduce_sum(Y, 1), tf.int32))\n",
    "    accuracy_ = tf.reduce_mean(tf.cast(correct_pred_, tf.float32))\n",
    "\n",
    "    tf.summary.scalar('loss', loss_)\n",
    "    tf.summary.scalar('accuracy', accuracy_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorboard --logdir=./tmp/266_cnn_20181207-2305/train\n",
      "tensorboard --logdir=./tmp/266_cnn_20181207-2305/test\n",
      "1,600 examples, moving-average loss 0.54, train accuracy 0.39\n",
      "3,200 examples, moving-average loss 0.45, train accuracy 0.45\n",
      "4,800 examples, moving-average loss 0.38, train accuracy 0.50\n",
      "6,400 examples, moving-average loss 0.34, train accuracy 0.53\n",
      "8,000 examples, moving-average loss 0.32, train accuracy 0.54\n",
      "9,600 examples, moving-average loss 0.30, train accuracy 0.56\n",
      "11,200 examples, moving-average loss 0.29, train accuracy 0.57\n",
      "12,800 examples, moving-average loss 0.28, train accuracy 0.59\n",
      "14,400 examples, moving-average loss 0.27, train accuracy 0.60\n",
      "16,000 examples, moving-average loss 0.28, train accuracy 0.60\n",
      "17,600 examples, moving-average loss 0.27, train accuracy 0.61\n",
      "19,200 examples, moving-average loss 0.27, train accuracy 0.62\n",
      "20,800 examples, moving-average loss 0.29, train accuracy 0.62\n",
      "22,400 examples, moving-average loss 0.29, train accuracy 0.62\n",
      "24,000 examples, moving-average loss 0.28, train accuracy 0.62\n",
      "25,600 examples, moving-average loss 0.28, train accuracy 0.63\n",
      "27,200 examples, moving-average loss 0.28, train accuracy 0.63\n",
      "28,800 examples, moving-average loss 0.27, train accuracy 0.63\n",
      "30,400 examples, moving-average loss 0.27, train accuracy 0.63\n",
      "32,000 examples, moving-average loss 0.26, train accuracy 0.64\n",
      "33,600 examples, moving-average loss 0.26, train accuracy 0.64\n",
      "35,200 examples, moving-average loss 0.26, train accuracy 0.64\n",
      "36,800 examples, moving-average loss 0.26, train accuracy 0.64\n",
      "38,400 examples, moving-average loss 0.25, train accuracy 0.64\n",
      "40,000 examples, moving-average loss 0.25, train accuracy 0.65\n",
      "41,600 examples, moving-average loss 0.27, train accuracy 0.65\n",
      "43,200 examples, moving-average loss 0.27, train accuracy 0.65\n",
      "44,800 examples, moving-average loss 0.27, train accuracy 0.65\n",
      "46,400 examples, moving-average loss 0.24, train accuracy 0.65\n",
      "48,000 examples, moving-average loss 0.24, train accuracy 0.65\n",
      "49,600 examples, moving-average loss 0.25, train accuracy 0.66\n",
      "51,200 examples, moving-average loss 0.24, train accuracy 0.66\n",
      "52,800 examples, moving-average loss 0.27, train accuracy 0.66\n",
      "54,400 examples, moving-average loss 0.26, train accuracy 0.66\n",
      "56,000 examples, moving-average loss 0.26, train accuracy 0.66\n",
      "57,600 examples, moving-average loss 0.24, train accuracy 0.66\n",
      "59,200 examples, moving-average loss 0.25, train accuracy 0.66\n",
      "60,800 examples, moving-average loss 0.25, train accuracy 0.66\n",
      "62,400 examples, moving-average loss 0.26, train accuracy 0.66\n",
      "64,000 examples, moving-average loss 0.27, train accuracy 0.66\n",
      "65,600 examples, moving-average loss 0.25, train accuracy 0.67\n",
      "67,200 examples, moving-average loss 0.24, train accuracy 0.67\n",
      "68,800 examples, moving-average loss 0.23, train accuracy 0.67\n",
      "70,400 examples, moving-average loss 0.25, train accuracy 0.67\n",
      "72,000 examples, moving-average loss 0.24, train accuracy 0.67\n",
      "73,600 examples, moving-average loss 0.25, train accuracy 0.67\n",
      "75,200 examples, moving-average loss 0.26, train accuracy 0.67\n",
      "76,800 examples, moving-average loss 0.24, train accuracy 0.67\n",
      "78,400 examples, moving-average loss 0.24, train accuracy 0.67\n",
      "80,000 examples, moving-average loss 0.25, train accuracy 0.67\n",
      "81,600 examples, moving-average loss 0.24, train accuracy 0.67\n",
      "83,200 examples, moving-average loss 0.25, train accuracy 0.67\n",
      "84,800 examples, moving-average loss 0.25, train accuracy 0.67\n",
      "86,400 examples, moving-average loss 0.24, train accuracy 0.67\n",
      "88,000 examples, moving-average loss 0.24, train accuracy 0.67\n",
      "89,600 examples, moving-average loss 0.23, train accuracy 0.67\n",
      "91,200 examples, moving-average loss 0.22, train accuracy 0.67\n",
      "92,800 examples, moving-average loss 0.24, train accuracy 0.68\n",
      "94,400 examples, moving-average loss 0.26, train accuracy 0.68\n",
      "96,000 examples, moving-average loss 0.26, train accuracy 0.68\n",
      "97,600 examples, moving-average loss 0.27, train accuracy 0.68\n",
      "99,200 examples, moving-average loss 0.25, train accuracy 0.68\n",
      "100,800 examples, moving-average loss 0.25, train accuracy 0.68\n",
      "102,400 examples, moving-average loss 0.25, train accuracy 0.68\n",
      "104,000 examples, moving-average loss 0.24, train accuracy 0.68\n",
      "105,600 examples, moving-average loss 0.26, train accuracy 0.68\n",
      "107,200 examples, moving-average loss 0.24, train accuracy 0.68\n",
      "108,800 examples, moving-average loss 0.25, train accuracy 0.68\n",
      "110,400 examples, moving-average loss 0.24, train accuracy 0.68\n",
      "112,000 examples, moving-average loss 0.26, train accuracy 0.68\n",
      "113,600 examples, moving-average loss 0.26, train accuracy 0.68\n",
      "115,200 examples, moving-average loss 0.26, train accuracy 0.68\n",
      "116,800 examples, moving-average loss 0.24, train accuracy 0.68\n",
      "118,400 examples, moving-average loss 0.24, train accuracy 0.68\n",
      "120,000 examples, moving-average loss 0.25, train accuracy 0.68\n",
      "121,600 examples, moving-average loss 0.24, train accuracy 0.68\n",
      "123,200 examples, moving-average loss 0.24, train accuracy 0.68\n",
      "124,800 examples, moving-average loss 0.24, train accuracy 0.68\n",
      "126,400 examples, moving-average loss 0.24, train accuracy 0.68\n",
      "128,000 examples, moving-average loss 0.24, train accuracy 0.68\n",
      "129,600 examples, moving-average loss 0.25, train accuracy 0.68\n",
      "131,200 examples, moving-average loss 0.25, train accuracy 0.68\n",
      "132,800 examples, moving-average loss 0.25, train accuracy 0.68\n",
      "134,400 examples, moving-average loss 0.25, train accuracy 0.68\n",
      "136,000 examples, moving-average loss 0.26, train accuracy 0.68\n",
      "137,600 examples, moving-average loss 0.24, train accuracy 0.68\n",
      "139,200 examples, moving-average loss 0.23, train accuracy 0.68\n",
      "140,800 examples, moving-average loss 0.24, train accuracy 0.68\n",
      "142,400 examples, moving-average loss 0.23, train accuracy 0.68\n",
      "144,000 examples, moving-average loss 0.25, train accuracy 0.68\n",
      "145,600 examples, moving-average loss 0.24, train accuracy 0.68\n",
      "147,200 examples, moving-average loss 0.24, train accuracy 0.68\n",
      "148,800 examples, moving-average loss 0.25, train accuracy 0.68\n",
      "150,400 examples, moving-average loss 0.25, train accuracy 0.68\n",
      "152,000 examples, moving-average loss 0.24, train accuracy 0.68\n",
      "153,600 examples, moving-average loss 0.25, train accuracy 0.68\n",
      "155,200 examples, moving-average loss 0.25, train accuracy 0.68\n",
      "156,800 examples, moving-average loss 0.25, train accuracy 0.68\n",
      "158,400 examples, moving-average loss 0.25, train accuracy 0.68\n",
      "160,000 examples, moving-average loss 0.23, train accuracy 0.68\n",
      "161,600 examples, moving-average loss 0.24, train accuracy 0.68\n",
      "163,200 examples, moving-average loss 0.24, train accuracy 0.69\n",
      "164,800 examples, moving-average loss 0.25, train accuracy 0.69\n",
      "166,400 examples, moving-average loss 0.25, train accuracy 0.69\n",
      "168,000 examples, moving-average loss 0.26, train accuracy 0.69\n",
      "169,600 examples, moving-average loss 0.24, train accuracy 0.69\n",
      "171,200 examples, moving-average loss 0.24, train accuracy 0.69\n",
      "172,800 examples, moving-average loss 0.26, train accuracy 0.69\n",
      "174,400 examples, moving-average loss 0.26, train accuracy 0.69\n",
      "176,000 examples, moving-average loss 0.23, train accuracy 0.69\n",
      "177,600 examples, moving-average loss 0.25, train accuracy 0.69\n",
      "179,200 examples, moving-average loss 0.23, train accuracy 0.69\n",
      "180,800 examples, moving-average loss 0.25, train accuracy 0.69\n",
      "182,400 examples, moving-average loss 0.24, train accuracy 0.69\n",
      "184,000 examples, moving-average loss 0.26, train accuracy 0.69\n",
      "185,600 examples, moving-average loss 0.25, train accuracy 0.69\n",
      "187,200 examples, moving-average loss 0.24, train accuracy 0.69\n",
      "188,800 examples, moving-average loss 0.24, train accuracy 0.69\n",
      "190,400 examples, moving-average loss 0.25, train accuracy 0.69\n",
      "192,000 examples, moving-average loss 0.24, train accuracy 0.69\n",
      "193,600 examples, moving-average loss 0.24, train accuracy 0.69\n",
      "195,200 examples, moving-average loss 0.23, train accuracy 0.69\n",
      "196,800 examples, moving-average loss 0.24, train accuracy 0.69\n",
      "198,400 examples, moving-average loss 0.25, train accuracy 0.69\n",
      "200,000 examples, moving-average loss 0.24, train accuracy 0.69\n",
      "201,600 examples, moving-average loss 0.23, train accuracy 0.69\n",
      "203,200 examples, moving-average loss 0.25, train accuracy 0.69\n",
      "204,800 examples, moving-average loss 0.24, train accuracy 0.69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206,400 examples, moving-average loss 0.24, train accuracy 0.69\n",
      "208,000 examples, moving-average loss 0.24, train accuracy 0.69\n",
      "209,600 examples, moving-average loss 0.23, train accuracy 0.69\n",
      "211,200 examples, moving-average loss 0.25, train accuracy 0.69\n",
      "212,800 examples, moving-average loss 0.23, train accuracy 0.69\n",
      "214,400 examples, moving-average loss 0.24, train accuracy 0.69\n",
      "216,000 examples, moving-average loss 0.25, train accuracy 0.69\n",
      "217,600 examples, moving-average loss 0.24, train accuracy 0.69\n",
      "219,200 examples, moving-average loss 0.24, train accuracy 0.69\n",
      "220,800 examples, moving-average loss 0.24, train accuracy 0.69\n",
      "222,400 examples, moving-average loss 0.23, train accuracy 0.69\n",
      "224,000 examples, moving-average loss 0.24, train accuracy 0.69\n",
      "225,600 examples, moving-average loss 0.24, train accuracy 0.69\n",
      "227,200 examples, moving-average loss 0.24, train accuracy 0.69\n",
      "228,800 examples, moving-average loss 0.24, train accuracy 0.69\n",
      "230,400 examples, moving-average loss 0.24, train accuracy 0.69\n",
      "232,000 examples, moving-average loss 0.23, train accuracy 0.69\n",
      "233,600 examples, moving-average loss 0.23, train accuracy 0.69\n",
      "235,200 examples, moving-average loss 0.25, train accuracy 0.69\n",
      "236,800 examples, moving-average loss 0.24, train accuracy 0.69\n",
      "238,400 examples, moving-average loss 0.24, train accuracy 0.69\n",
      "240,000 examples, moving-average loss 0.22, train accuracy 0.69\n",
      "241,600 examples, moving-average loss 0.22, train accuracy 0.69\n",
      "243,200 examples, moving-average loss 0.22, train accuracy 0.69\n",
      "244,800 examples, moving-average loss 0.25, train accuracy 0.69\n",
      "246,400 examples, moving-average loss 0.22, train accuracy 0.69\n",
      "248,000 examples, moving-average loss 0.23, train accuracy 0.69\n",
      "249,600 examples, moving-average loss 0.25, train accuracy 0.69\n",
      "251,200 examples, moving-average loss 0.25, train accuracy 0.69\n",
      "252,800 examples, moving-average loss 0.24, train accuracy 0.69\n",
      "254,400 examples, moving-average loss 0.22, train accuracy 0.69\n",
      "256,000 examples, moving-average loss 0.23, train accuracy 0.69\n",
      "257,600 examples, moving-average loss 0.25, train accuracy 0.69\n",
      "259,200 examples, moving-average loss 0.22, train accuracy 0.69\n",
      "260,800 examples, moving-average loss 0.23, train accuracy 0.69\n",
      "262,400 examples, moving-average loss 0.25, train accuracy 0.69\n",
      "264,000 examples, moving-average loss 0.23, train accuracy 0.69\n",
      "265,600 examples, moving-average loss 0.24, train accuracy 0.69\n",
      "267,200 examples, moving-average loss 0.23, train accuracy 0.69\n",
      "268,800 examples, moving-average loss 0.22, train accuracy 0.69\n",
      "270,400 examples, moving-average loss 0.24, train accuracy 0.69\n",
      "272,000 examples, moving-average loss 0.23, train accuracy 0.69\n",
      "273,600 examples, moving-average loss 0.22, train accuracy 0.69\n",
      "275,200 examples, moving-average loss 0.24, train accuracy 0.69\n",
      "276,800 examples, moving-average loss 0.24, train accuracy 0.69\n",
      "278,400 examples, moving-average loss 0.24, train accuracy 0.69\n",
      "280,000 examples, moving-average loss 0.25, train accuracy 0.69\n",
      "281,600 examples, moving-average loss 0.23, train accuracy 0.69\n",
      "283,200 examples, moving-average loss 0.24, train accuracy 0.69\n",
      "284,800 examples, moving-average loss 0.25, train accuracy 0.69\n",
      "286,400 examples, moving-average loss 0.23, train accuracy 0.69\n",
      "288,000 examples, moving-average loss 0.23, train accuracy 0.69\n",
      "289,600 examples, moving-average loss 0.24, train accuracy 0.69\n",
      "291,200 examples, moving-average loss 0.24, train accuracy 0.69\n",
      "292,800 examples, moving-average loss 0.24, train accuracy 0.69\n",
      "294,400 examples, moving-average loss 0.25, train accuracy 0.69\n",
      "296,000 examples, moving-average loss 0.24, train accuracy 0.69\n",
      "297,600 examples, moving-average loss 0.23, train accuracy 0.69\n",
      "299,200 examples, moving-average loss 0.22, train accuracy 0.69\n",
      "300,800 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "302,400 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "304,000 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "305,600 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "307,200 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "308,800 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "310,400 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "312,000 examples, moving-average loss 0.25, train accuracy 0.70\n",
      "313,600 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "315,200 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "316,800 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "318,400 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "320,000 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "321,600 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "323,200 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "324,800 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "326,400 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "328,000 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "329,600 examples, moving-average loss 0.25, train accuracy 0.70\n",
      "331,200 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "332,800 examples, moving-average loss 0.25, train accuracy 0.70\n",
      "334,400 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "336,000 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "337,600 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "339,200 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "340,800 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "342,400 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "344,000 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "345,600 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "347,200 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "348,800 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "350,400 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "352,000 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "353,600 examples, moving-average loss 0.25, train accuracy 0.70\n",
      "355,200 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "356,800 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "358,400 examples, moving-average loss 0.25, train accuracy 0.70\n",
      "360,000 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "361,600 examples, moving-average loss 0.25, train accuracy 0.70\n",
      "363,200 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "364,800 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "366,400 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "368,000 examples, moving-average loss 0.25, train accuracy 0.70\n",
      "369,600 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "371,200 examples, moving-average loss 0.25, train accuracy 0.70\n",
      "372,800 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "374,400 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "376,000 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "377,600 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "379,200 examples, moving-average loss 0.25, train accuracy 0.70\n",
      "380,800 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "382,400 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "384,000 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "385,600 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "387,200 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "388,800 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "390,400 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "392,000 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "393,600 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "395,200 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "396,800 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "398,400 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "400,000 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "401,600 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "403,200 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "404,800 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "406,400 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "408,000 examples, moving-average loss 0.25, train accuracy 0.70\n",
      "409,600 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "411,200 examples, moving-average loss 0.22, train accuracy 0.70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "412,800 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "414,400 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "416,000 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "417,600 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "419,200 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "420,800 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "422,400 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "424,000 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "425,600 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "427,200 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "428,800 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "430,400 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "432,000 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "433,600 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "435,200 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "436,800 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "438,400 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "440,000 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "441,600 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "443,200 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "444,800 examples, moving-average loss 0.25, train accuracy 0.70\n",
      "446,400 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "448,000 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "449,600 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "451,200 examples, moving-average loss 0.25, train accuracy 0.70\n",
      "452,800 examples, moving-average loss 0.25, train accuracy 0.70\n",
      "454,400 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "456,000 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "457,600 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "459,200 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "460,800 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "462,400 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "464,000 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "465,600 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "467,200 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "468,800 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "470,400 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "472,000 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "473,600 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "475,200 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "476,800 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "478,400 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "480,000 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "481,600 examples, moving-average loss 0.25, train accuracy 0.70\n",
      "483,200 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "484,800 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "486,400 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "488,000 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "489,600 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "491,200 examples, moving-average loss 0.25, train accuracy 0.70\n",
      "492,800 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "494,400 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "496,000 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "497,600 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "499,200 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "500,800 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "502,400 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "504,000 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "505,600 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "507,200 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "508,800 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "510,400 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "512,000 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "513,600 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "515,200 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "516,800 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "518,400 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "520,000 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "521,600 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "523,200 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "524,800 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "526,400 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "528,000 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "529,600 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "531,200 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "532,800 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "534,400 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "536,000 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "537,600 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "539,200 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "540,800 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "542,400 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "544,000 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "545,600 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "547,200 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "548,800 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "550,400 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "552,000 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "553,600 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "555,200 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "556,800 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "558,400 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "560,000 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "561,600 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "563,200 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "564,800 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "566,400 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "568,000 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "569,600 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "571,200 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "572,800 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "574,400 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "576,000 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "577,600 examples, moving-average loss 0.25, train accuracy 0.70\n",
      "579,200 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "580,800 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "582,400 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "584,000 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "585,600 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "587,200 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "588,800 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "590,400 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "592,000 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "593,600 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "595,200 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "596,800 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "598,400 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "600,000 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "601,600 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "603,200 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "604,800 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "606,400 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "608,000 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "609,600 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "611,200 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "612,800 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "614,400 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "616,000 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "617,600 examples, moving-average loss 0.23, train accuracy 0.70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "619,200 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "620,800 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "622,400 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "624,000 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "625,600 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "627,200 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "628,800 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "630,400 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "632,000 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "633,600 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "635,200 examples, moving-average loss 0.21, train accuracy 0.70\n",
      "636,800 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "638,400 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "640,000 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "641,600 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "643,200 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "644,800 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "646,400 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "648,000 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "649,600 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "651,200 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "652,800 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "654,400 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "656,000 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "657,600 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "659,200 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "660,800 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "662,400 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "664,000 examples, moving-average loss 0.25, train accuracy 0.70\n",
      "665,600 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "667,200 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "668,800 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "670,400 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "672,000 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "673,600 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "675,200 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "676,800 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "678,400 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "680,000 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "681,600 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "683,200 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "684,800 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "686,400 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "688,000 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "689,600 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "691,200 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "692,800 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "694,400 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "696,000 examples, moving-average loss 0.21, train accuracy 0.70\n",
      "697,600 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "699,200 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "700,800 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "702,400 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "704,000 examples, moving-average loss 0.25, train accuracy 0.70\n",
      "705,600 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "707,200 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "708,800 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "710,400 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "712,000 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "713,600 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "715,200 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "716,800 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "718,400 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "720,000 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "721,600 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "723,200 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "724,800 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "726,400 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "728,000 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "729,600 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "731,200 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "732,800 examples, moving-average loss 0.25, train accuracy 0.70\n",
      "734,400 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "736,000 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "737,600 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "739,200 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "740,800 examples, moving-average loss 0.21, train accuracy 0.70\n",
      "742,400 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "744,000 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "745,600 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "747,200 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "748,800 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "750,400 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "752,000 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "753,600 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "755,200 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "756,800 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "758,400 examples, moving-average loss 0.24, train accuracy 0.70\n",
      "760,000 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "761,600 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "763,200 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "764,800 examples, moving-average loss 0.25, train accuracy 0.70\n",
      "766,400 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "768,000 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "769,600 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "771,200 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "772,800 examples, moving-average loss 0.21, train accuracy 0.70\n",
      "774,400 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "776,000 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "777,600 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "779,200 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "780,800 examples, moving-average loss 0.23, train accuracy 0.70\n",
      "782,400 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "784,000 examples, moving-average loss 0.21, train accuracy 0.71\n",
      "785,600 examples, moving-average loss 0.23, train accuracy 0.71\n",
      "787,200 examples, moving-average loss 0.24, train accuracy 0.71\n",
      "788,800 examples, moving-average loss 0.23, train accuracy 0.71\n",
      "790,400 examples, moving-average loss 0.23, train accuracy 0.71\n",
      "792,000 examples, moving-average loss 0.24, train accuracy 0.71\n",
      "793,600 examples, moving-average loss 0.24, train accuracy 0.71\n",
      "795,200 examples, moving-average loss 0.22, train accuracy 0.71\n",
      "796,800 examples, moving-average loss 0.23, train accuracy 0.71\n",
      "798,400 examples, moving-average loss 0.24, train accuracy 0.71\n",
      "800,000 examples, moving-average loss 0.24, train accuracy 0.71\n",
      "801,600 examples, moving-average loss 0.23, train accuracy 0.71\n",
      "803,200 examples, moving-average loss 0.22, train accuracy 0.71\n",
      "804,800 examples, moving-average loss 0.23, train accuracy 0.71\n",
      "806,400 examples, moving-average loss 0.23, train accuracy 0.71\n",
      "808,000 examples, moving-average loss 0.21, train accuracy 0.71\n",
      "809,600 examples, moving-average loss 0.24, train accuracy 0.71\n",
      "811,200 examples, moving-average loss 0.23, train accuracy 0.71\n",
      "812,800 examples, moving-average loss 0.23, train accuracy 0.71\n",
      "814,400 examples, moving-average loss 0.22, train accuracy 0.71\n",
      "816,000 examples, moving-average loss 0.24, train accuracy 0.71\n",
      "817,600 examples, moving-average loss 0.23, train accuracy 0.71\n",
      "819,200 examples, moving-average loss 0.23, train accuracy 0.71\n",
      "820,800 examples, moving-average loss 0.23, train accuracy 0.71\n",
      "822,400 examples, moving-average loss 0.23, train accuracy 0.71\n",
      "824,000 examples, moving-average loss 0.23, train accuracy 0.71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "825,600 examples, moving-average loss 0.23, train accuracy 0.71\n",
      "827,200 examples, moving-average loss 0.24, train accuracy 0.71\n",
      "828,800 examples, moving-average loss 0.22, train accuracy 0.71\n",
      "830,400 examples, moving-average loss 0.23, train accuracy 0.71\n",
      "832,000 examples, moving-average loss 0.23, train accuracy 0.71\n",
      "833,600 examples, moving-average loss 0.22, train accuracy 0.71\n",
      "835,200 examples, moving-average loss 0.21, train accuracy 0.71\n",
      "836,800 examples, moving-average loss 0.22, train accuracy 0.71\n",
      "838,400 examples, moving-average loss 0.22, train accuracy 0.71\n",
      "840,000 examples, moving-average loss 0.21, train accuracy 0.71\n",
      "Completed 0 epoch in 0:12:31\n",
      "Train accurary:0.70570\n",
      "Validate accuracy:0.71522\n",
      "841,550 examples, moving-average loss 0.23, train accuracy 0.47\n",
      "843,150 examples, moving-average loss 0.22, train accuracy 0.67\n",
      "844,750 examples, moving-average loss 0.22, train accuracy 0.70\n",
      "846,350 examples, moving-average loss 0.22, train accuracy 0.71\n",
      "847,950 examples, moving-average loss 0.22, train accuracy 0.71\n",
      "849,550 examples, moving-average loss 0.22, train accuracy 0.71\n",
      "851,150 examples, moving-average loss 0.23, train accuracy 0.71\n",
      "852,750 examples, moving-average loss 0.22, train accuracy 0.71\n",
      "854,350 examples, moving-average loss 0.22, train accuracy 0.71\n",
      "855,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "857,550 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "859,150 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "860,750 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "862,350 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "863,950 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "865,550 examples, moving-average loss 0.20, train accuracy 0.72\n",
      "867,150 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "868,750 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "870,350 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "871,950 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "873,550 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "875,150 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "876,750 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "878,350 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "879,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "881,550 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "883,150 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "884,750 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "886,350 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "887,950 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "889,550 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "891,150 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "892,750 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "894,350 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "895,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "897,550 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "899,150 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "900,750 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "902,350 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "903,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "905,550 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "907,150 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "908,750 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "910,350 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "911,950 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "913,550 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "915,150 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "916,750 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "918,350 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "919,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "921,550 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "923,150 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "924,750 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "926,350 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "927,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "929,550 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "931,150 examples, moving-average loss 0.20, train accuracy 0.72\n",
      "932,750 examples, moving-average loss 0.20, train accuracy 0.72\n",
      "934,350 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "935,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "937,550 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "939,150 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "940,750 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "942,350 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "943,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "945,550 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "947,150 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "948,750 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "950,350 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "951,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "953,550 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "955,150 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "956,750 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "958,350 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "959,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "961,550 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "963,150 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "964,750 examples, moving-average loss 0.24, train accuracy 0.72\n",
      "966,350 examples, moving-average loss 0.24, train accuracy 0.72\n",
      "967,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "969,550 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "971,150 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "972,750 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "974,350 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "975,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "977,550 examples, moving-average loss 0.24, train accuracy 0.72\n",
      "979,150 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "980,750 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "982,350 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "983,950 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "985,550 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "987,150 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "988,750 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "990,350 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "991,950 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "993,550 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "995,150 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "996,750 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "998,350 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "999,950 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,001,550 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,003,150 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,004,750 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,006,350 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,007,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,009,550 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,011,150 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,012,750 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,014,350 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,015,950 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,017,550 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,019,150 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,020,750 examples, moving-average loss 0.20, train accuracy 0.72\n",
      "1,022,350 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,023,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,025,550 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,027,150 examples, moving-average loss 0.22, train accuracy 0.72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,028,750 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,030,350 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,031,950 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,033,550 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,035,150 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,036,750 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,038,350 examples, moving-average loss 0.24, train accuracy 0.72\n",
      "1,039,950 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,041,550 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,043,150 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,044,750 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,046,350 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,047,950 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,049,550 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,051,150 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,052,750 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,054,350 examples, moving-average loss 0.20, train accuracy 0.72\n",
      "1,055,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,057,550 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,059,150 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,060,750 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,062,350 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,063,950 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,065,550 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,067,150 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,068,750 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,070,350 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,071,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,073,550 examples, moving-average loss 0.20, train accuracy 0.72\n",
      "1,075,150 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,076,750 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,078,350 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,079,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,081,550 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,083,150 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,084,750 examples, moving-average loss 0.20, train accuracy 0.72\n",
      "1,086,350 examples, moving-average loss 0.24, train accuracy 0.72\n",
      "1,087,950 examples, moving-average loss 0.20, train accuracy 0.72\n",
      "1,089,550 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,091,150 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,092,750 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,094,350 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,095,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,097,550 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,099,150 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,100,750 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,102,350 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,103,950 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,105,550 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,107,150 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,108,750 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,110,350 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,111,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,113,550 examples, moving-average loss 0.20, train accuracy 0.72\n",
      "1,115,150 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,116,750 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,118,350 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,119,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,121,550 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,123,150 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,124,750 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,126,350 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,127,950 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,129,550 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,131,150 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,132,750 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,134,350 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,135,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,137,550 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,139,150 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,140,750 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,142,350 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,143,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,145,550 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,147,150 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,148,750 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,150,350 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,151,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,153,550 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,155,150 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,156,750 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,158,350 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,159,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,161,550 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,163,150 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,164,750 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,166,350 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,167,950 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,169,550 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,171,150 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,172,750 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,174,350 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,175,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,177,550 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,179,150 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,180,750 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,182,350 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,183,950 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,185,550 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,187,150 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,188,750 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,190,350 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,191,950 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,193,550 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,195,150 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,196,750 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,198,350 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,199,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,201,550 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,203,150 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,204,750 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,206,350 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,207,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,209,550 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,211,150 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,212,750 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,214,350 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,215,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,217,550 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,219,150 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,220,750 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,222,350 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,223,950 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,225,550 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,227,150 examples, moving-average loss 0.22, train accuracy 0.72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,228,750 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,230,350 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,231,950 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,233,550 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,235,150 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,236,750 examples, moving-average loss 0.20, train accuracy 0.72\n",
      "1,238,350 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,239,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,241,550 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,243,150 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,244,750 examples, moving-average loss 0.20, train accuracy 0.72\n",
      "1,246,350 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,247,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,249,550 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,251,150 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,252,750 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,254,350 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,255,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,257,550 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,259,150 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,260,750 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,262,350 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,263,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,265,550 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,267,150 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,268,750 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,270,350 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,271,950 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,273,550 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,275,150 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,276,750 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,278,350 examples, moving-average loss 0.20, train accuracy 0.72\n",
      "1,279,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,281,550 examples, moving-average loss 0.20, train accuracy 0.72\n",
      "1,283,150 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,284,750 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,286,350 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,287,950 examples, moving-average loss 0.20, train accuracy 0.72\n",
      "1,289,550 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,291,150 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,292,750 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,294,350 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,295,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,297,550 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,299,150 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,300,750 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,302,350 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,303,950 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,305,550 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,307,150 examples, moving-average loss 0.20, train accuracy 0.72\n",
      "1,308,750 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,310,350 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,311,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,313,550 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,315,150 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,316,750 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,318,350 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,319,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,321,550 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,323,150 examples, moving-average loss 0.24, train accuracy 0.72\n",
      "1,324,750 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,326,350 examples, moving-average loss 0.20, train accuracy 0.72\n",
      "1,327,950 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,329,550 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,331,150 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,332,750 examples, moving-average loss 0.24, train accuracy 0.72\n",
      "1,334,350 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,335,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,337,550 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,339,150 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,340,750 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,342,350 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,343,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,345,550 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,347,150 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,348,750 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,350,350 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,351,950 examples, moving-average loss 0.20, train accuracy 0.72\n",
      "1,353,550 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,355,150 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,356,750 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,358,350 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,359,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,361,550 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,363,150 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,364,750 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,366,350 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,367,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,369,550 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,371,150 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,372,750 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,374,350 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,375,950 examples, moving-average loss 0.20, train accuracy 0.72\n",
      "1,377,550 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,379,150 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,380,750 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,382,350 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,383,950 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,385,550 examples, moving-average loss 0.20, train accuracy 0.72\n",
      "1,387,150 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,388,750 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,390,350 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,391,950 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,393,550 examples, moving-average loss 0.20, train accuracy 0.72\n",
      "1,395,150 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,396,750 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,398,350 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,399,950 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,401,550 examples, moving-average loss 0.20, train accuracy 0.72\n",
      "1,403,150 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,404,750 examples, moving-average loss 0.20, train accuracy 0.72\n",
      "1,406,350 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,407,950 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,409,550 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,411,150 examples, moving-average loss 0.20, train accuracy 0.72\n",
      "1,412,750 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,414,350 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,415,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,417,550 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,419,150 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,420,750 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,422,350 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,423,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,425,550 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,427,150 examples, moving-average loss 0.22, train accuracy 0.72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,428,750 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,430,350 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,431,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,433,550 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,435,150 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,436,750 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,438,350 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,439,950 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,441,550 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,443,150 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,444,750 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,446,350 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,447,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,449,550 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,451,150 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,452,750 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,454,350 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,455,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,457,550 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,459,150 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,460,750 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,462,350 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,463,950 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,465,550 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,467,150 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,468,750 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,470,350 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,471,950 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,473,550 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,475,150 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,476,750 examples, moving-average loss 0.20, train accuracy 0.72\n",
      "1,478,350 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,479,950 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,481,550 examples, moving-average loss 0.20, train accuracy 0.72\n",
      "1,483,150 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,484,750 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,486,350 examples, moving-average loss 0.20, train accuracy 0.72\n",
      "1,487,950 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,489,550 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,491,150 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,492,750 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,494,350 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,495,950 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,497,550 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,499,150 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,500,750 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,502,350 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,503,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,505,550 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,507,150 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,508,750 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,510,350 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,511,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,513,550 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,515,150 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,516,750 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,518,350 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,519,950 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,521,550 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,523,150 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,524,750 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,526,350 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,527,950 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,529,550 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,531,150 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,532,750 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,534,350 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,535,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,537,550 examples, moving-average loss 0.20, train accuracy 0.72\n",
      "1,539,150 examples, moving-average loss 0.20, train accuracy 0.72\n",
      "1,540,750 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,542,350 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,543,950 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,545,550 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,547,150 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,548,750 examples, moving-average loss 0.20, train accuracy 0.72\n",
      "1,550,350 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,551,950 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,553,550 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,555,150 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,556,750 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,558,350 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,559,950 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,561,550 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,563,150 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,564,750 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,566,350 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,567,950 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,569,550 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,571,150 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,572,750 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,574,350 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,575,950 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,577,550 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,579,150 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,580,750 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,582,350 examples, moving-average loss 0.20, train accuracy 0.72\n",
      "1,583,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,585,550 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,587,150 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,588,750 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,590,350 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,591,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,593,550 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,595,150 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,596,750 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,598,350 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,599,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,601,550 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,603,150 examples, moving-average loss 0.20, train accuracy 0.72\n",
      "1,604,750 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,606,350 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,607,950 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,609,550 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,611,150 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,612,750 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,614,350 examples, moving-average loss 0.20, train accuracy 0.72\n",
      "1,615,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,617,550 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,619,150 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,620,750 examples, moving-average loss 0.20, train accuracy 0.72\n",
      "1,622,350 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,623,950 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,625,550 examples, moving-average loss 0.20, train accuracy 0.72\n",
      "1,627,150 examples, moving-average loss 0.22, train accuracy 0.72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,628,750 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,630,350 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,631,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,633,550 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,635,150 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,636,750 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,638,350 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,639,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,641,550 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,643,150 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,644,750 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,646,350 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,647,950 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,649,550 examples, moving-average loss 0.20, train accuracy 0.72\n",
      "1,651,150 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,652,750 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,654,350 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,655,950 examples, moving-average loss 0.20, train accuracy 0.72\n",
      "1,657,550 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,659,150 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,660,750 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,662,350 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,663,950 examples, moving-average loss 0.23, train accuracy 0.72\n",
      "1,665,550 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,667,150 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,668,750 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,670,350 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,671,950 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,673,550 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,675,150 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,676,750 examples, moving-average loss 0.20, train accuracy 0.72\n",
      "1,678,350 examples, moving-average loss 0.20, train accuracy 0.72\n",
      "1,679,950 examples, moving-average loss 0.20, train accuracy 0.72\n",
      "1,681,550 examples, moving-average loss 0.20, train accuracy 0.72\n",
      "Completed 1 epoch in 0:12:41\n",
      "Train accurary:0.72476\n",
      "Validate accuracy:0.71891\n",
      "1,683,100 examples, moving-average loss 0.22, train accuracy 0.58\n",
      "1,684,700 examples, moving-average loss 0.21, train accuracy 0.69\n",
      "1,686,300 examples, moving-average loss 0.21, train accuracy 0.71\n",
      "1,687,900 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,689,500 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,691,100 examples, moving-average loss 0.20, train accuracy 0.72\n",
      "1,692,700 examples, moving-average loss 0.22, train accuracy 0.72\n",
      "1,694,300 examples, moving-average loss 0.20, train accuracy 0.72\n",
      "1,695,900 examples, moving-average loss 0.21, train accuracy 0.72\n",
      "1,697,500 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,699,100 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,700,700 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,702,300 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "1,703,900 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,705,500 examples, moving-average loss 0.23, train accuracy 0.73\n",
      "1,707,100 examples, moving-average loss 0.19, train accuracy 0.73\n",
      "1,708,700 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,710,300 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "1,711,900 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,713,500 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "1,715,100 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,716,700 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,718,300 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,719,900 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "1,721,500 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,723,100 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "1,724,700 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "1,726,300 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,727,900 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "1,729,500 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "1,731,100 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "1,732,700 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,734,300 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "1,735,900 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "1,737,500 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,739,100 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "1,740,700 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,742,300 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,743,900 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "1,745,500 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,747,100 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "1,748,700 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,750,300 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "1,751,900 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,753,500 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,755,100 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "1,756,700 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,758,300 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "1,759,900 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,761,500 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "1,763,100 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "1,764,700 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "1,766,300 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,767,900 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "1,769,500 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "1,771,100 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "1,772,700 examples, moving-average loss 0.19, train accuracy 0.73\n",
      "1,774,300 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "1,775,900 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,777,500 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "1,779,100 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,780,700 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "1,782,300 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "1,783,900 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,785,500 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,787,100 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "1,788,700 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "1,790,300 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,791,900 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "1,793,500 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,795,100 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "1,796,700 examples, moving-average loss 0.23, train accuracy 0.73\n",
      "1,798,300 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "1,799,900 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "1,801,500 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "1,803,100 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "1,804,700 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,806,300 examples, moving-average loss 0.23, train accuracy 0.73\n",
      "1,807,900 examples, moving-average loss 0.23, train accuracy 0.73\n",
      "1,809,500 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "1,811,100 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,812,700 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,814,300 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,815,900 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "1,817,500 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,819,100 examples, moving-average loss 0.23, train accuracy 0.73\n",
      "1,820,700 examples, moving-average loss 0.19, train accuracy 0.73\n",
      "1,822,300 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "1,823,900 examples, moving-average loss 0.20, train accuracy 0.73\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,825,500 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,827,100 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,828,700 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "1,830,300 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,831,900 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,833,500 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,835,100 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "1,836,700 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,838,300 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,839,900 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,841,500 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,843,100 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "1,844,700 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,846,300 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,847,900 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "1,849,500 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,851,100 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "1,852,700 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "1,854,300 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "1,855,900 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,857,500 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "1,859,100 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "1,860,700 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,862,300 examples, moving-average loss 0.19, train accuracy 0.73\n",
      "1,863,900 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,865,500 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,867,100 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,868,700 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,870,300 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,871,900 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,873,500 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,875,100 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,876,700 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,878,300 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "1,879,900 examples, moving-average loss 0.23, train accuracy 0.73\n",
      "1,881,500 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,883,100 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "1,884,700 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "1,886,300 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,887,900 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "1,889,500 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "1,891,100 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "1,892,700 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "1,894,300 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,895,900 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "1,897,500 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,899,100 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "1,900,700 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,902,300 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,903,900 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "1,905,500 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "1,907,100 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,908,700 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,910,300 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,911,900 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,913,500 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,915,100 examples, moving-average loss 0.19, train accuracy 0.73\n",
      "1,916,700 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "1,918,300 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "1,919,900 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,921,500 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "1,923,100 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "1,924,700 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,926,300 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "1,927,900 examples, moving-average loss 0.23, train accuracy 0.73\n",
      "1,929,500 examples, moving-average loss 0.19, train accuracy 0.73\n",
      "1,931,100 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,932,700 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,934,300 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "1,935,900 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,937,500 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,939,100 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "1,940,700 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,942,300 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "1,943,900 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,945,500 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,947,100 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "1,948,700 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "1,950,300 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "1,951,900 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "1,953,500 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,955,100 examples, moving-average loss 0.19, train accuracy 0.73\n",
      "1,956,700 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "1,958,300 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,959,900 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "1,961,500 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,963,100 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,964,700 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,966,300 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "1,967,900 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,969,500 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,971,100 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,972,700 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,974,300 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,975,900 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,977,500 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,979,100 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,980,700 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,982,300 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "1,983,900 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,985,500 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,987,100 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "1,988,700 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,990,300 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,991,900 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "1,993,500 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "1,995,100 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "1,996,700 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "1,998,300 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "1,999,900 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "2,001,500 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "2,003,100 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "2,004,700 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,006,300 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "2,007,900 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "2,009,500 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "2,011,100 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "2,012,700 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,014,300 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,015,900 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "2,017,500 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,019,100 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,020,700 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "2,022,300 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,023,900 examples, moving-average loss 0.22, train accuracy 0.73\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,025,500 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "2,027,100 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,028,700 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,030,300 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,031,900 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,033,500 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,035,100 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,036,700 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "2,038,300 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,039,900 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,041,500 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,043,100 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,044,700 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "2,046,300 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "2,047,900 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,049,500 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,051,100 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "2,052,700 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,054,300 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,055,900 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,057,500 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,059,100 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "2,060,700 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "2,062,300 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "2,063,900 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,065,500 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,067,100 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "2,068,700 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,070,300 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,071,900 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,073,500 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "2,075,100 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "2,076,700 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,078,300 examples, moving-average loss 0.19, train accuracy 0.73\n",
      "2,079,900 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,081,500 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "2,083,100 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,084,700 examples, moving-average loss 0.19, train accuracy 0.73\n",
      "2,086,300 examples, moving-average loss 0.19, train accuracy 0.73\n",
      "2,087,900 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "2,089,500 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "2,091,100 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,092,700 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "2,094,300 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,095,900 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "2,097,500 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,099,100 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "2,100,700 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "2,102,300 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,103,900 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,105,500 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,107,100 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,108,700 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "2,110,300 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,111,900 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "2,113,500 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "2,115,100 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,116,700 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,118,300 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "2,119,900 examples, moving-average loss 0.19, train accuracy 0.73\n",
      "2,121,500 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,123,100 examples, moving-average loss 0.19, train accuracy 0.73\n",
      "2,124,700 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,126,300 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,127,900 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,129,500 examples, moving-average loss 0.19, train accuracy 0.73\n",
      "2,131,100 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,132,700 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "2,134,300 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "2,135,900 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "2,137,500 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "2,139,100 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "2,140,700 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "2,142,300 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,143,900 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,145,500 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,147,100 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "2,148,700 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "2,150,300 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "2,151,900 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,153,500 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "2,155,100 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,156,700 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,158,300 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,159,900 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "2,161,500 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "2,163,100 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "2,164,700 examples, moving-average loss 0.23, train accuracy 0.73\n",
      "2,166,300 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,167,900 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "2,169,500 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "2,171,100 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,172,700 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,174,300 examples, moving-average loss 0.23, train accuracy 0.73\n",
      "2,175,900 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,177,500 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,179,100 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,180,700 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,182,300 examples, moving-average loss 0.23, train accuracy 0.73\n",
      "2,183,900 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,185,500 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,187,100 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,188,700 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,190,300 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "2,191,900 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "2,193,500 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "2,195,100 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,196,700 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,198,300 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,199,900 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,201,500 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,203,100 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,204,700 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,206,300 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "2,207,900 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,209,500 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "2,211,100 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,212,700 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,214,300 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "2,215,900 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,217,500 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "2,219,100 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,220,700 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "2,222,300 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,223,900 examples, moving-average loss 0.22, train accuracy 0.73\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,225,500 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "2,227,100 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "2,228,700 examples, moving-average loss 0.19, train accuracy 0.73\n",
      "2,230,300 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "2,231,900 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "2,233,500 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "2,235,100 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "2,236,700 examples, moving-average loss 0.23, train accuracy 0.73\n",
      "2,238,300 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "2,239,900 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,241,500 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,243,100 examples, moving-average loss 0.19, train accuracy 0.73\n",
      "2,244,700 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,246,300 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "2,247,900 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "2,249,500 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "2,251,100 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,252,700 examples, moving-average loss 0.19, train accuracy 0.74\n",
      "2,254,300 examples, moving-average loss 0.22, train accuracy 0.74\n",
      "2,255,900 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,257,500 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,259,100 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,260,700 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,262,300 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "2,263,900 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,265,500 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,267,100 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,268,700 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "2,270,300 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,271,900 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,273,500 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,275,100 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,276,700 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "2,278,300 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "2,279,900 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,281,500 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "2,283,100 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "2,284,700 examples, moving-average loss 0.23, train accuracy 0.73\n",
      "2,286,300 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "2,287,900 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,289,500 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,291,100 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,292,700 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "2,294,300 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "2,295,900 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,297,500 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "2,299,100 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "2,300,700 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,302,300 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "2,303,900 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,305,500 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,307,100 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "2,308,700 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,310,300 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,311,900 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "2,313,500 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,315,100 examples, moving-average loss 0.22, train accuracy 0.73\n",
      "2,316,700 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,318,300 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,319,900 examples, moving-average loss 0.22, train accuracy 0.74\n",
      "2,321,500 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,323,100 examples, moving-average loss 0.19, train accuracy 0.74\n",
      "2,324,700 examples, moving-average loss 0.22, train accuracy 0.74\n",
      "2,326,300 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,327,900 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,329,500 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,331,100 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,332,700 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,334,300 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,335,900 examples, moving-average loss 0.19, train accuracy 0.74\n",
      "2,337,500 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,339,100 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,340,700 examples, moving-average loss 0.22, train accuracy 0.74\n",
      "2,342,300 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,343,900 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,345,500 examples, moving-average loss 0.22, train accuracy 0.74\n",
      "2,347,100 examples, moving-average loss 0.22, train accuracy 0.74\n",
      "2,348,700 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,350,300 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,351,900 examples, moving-average loss 0.22, train accuracy 0.74\n",
      "2,353,500 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,355,100 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,356,700 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,358,300 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,359,900 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,361,500 examples, moving-average loss 0.22, train accuracy 0.74\n",
      "2,363,100 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,364,700 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,366,300 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,367,900 examples, moving-average loss 0.22, train accuracy 0.74\n",
      "2,369,500 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,371,100 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,372,700 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,374,300 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,375,900 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,377,500 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,379,100 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,380,700 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,382,300 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,383,900 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,385,500 examples, moving-average loss 0.22, train accuracy 0.74\n",
      "2,387,100 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,388,700 examples, moving-average loss 0.22, train accuracy 0.74\n",
      "2,390,300 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,391,900 examples, moving-average loss 0.22, train accuracy 0.74\n",
      "2,393,500 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,395,100 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,396,700 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,398,300 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,399,900 examples, moving-average loss 0.22, train accuracy 0.74\n",
      "2,401,500 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,403,100 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,404,700 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,406,300 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,407,900 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,409,500 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,411,100 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,412,700 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,414,300 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,415,900 examples, moving-average loss 0.22, train accuracy 0.74\n",
      "2,417,500 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,419,100 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,420,700 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,422,300 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,423,900 examples, moving-average loss 0.20, train accuracy 0.74\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,425,500 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,427,100 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,428,700 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,430,300 examples, moving-average loss 0.22, train accuracy 0.74\n",
      "2,431,900 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,433,500 examples, moving-average loss 0.22, train accuracy 0.74\n",
      "2,435,100 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,436,700 examples, moving-average loss 0.22, train accuracy 0.74\n",
      "2,438,300 examples, moving-average loss 0.19, train accuracy 0.74\n",
      "2,439,900 examples, moving-average loss 0.19, train accuracy 0.74\n",
      "2,441,500 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,443,100 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,444,700 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,446,300 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,447,900 examples, moving-average loss 0.22, train accuracy 0.74\n",
      "2,449,500 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,451,100 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,452,700 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,454,300 examples, moving-average loss 0.22, train accuracy 0.74\n",
      "2,455,900 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,457,500 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,459,100 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,460,700 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,462,300 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,463,900 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,465,500 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,467,100 examples, moving-average loss 0.19, train accuracy 0.74\n",
      "2,468,700 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,470,300 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,471,900 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,473,500 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,475,100 examples, moving-average loss 0.22, train accuracy 0.74\n",
      "2,476,700 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,478,300 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,479,900 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,481,500 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,483,100 examples, moving-average loss 0.22, train accuracy 0.74\n",
      "2,484,700 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,486,300 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,487,900 examples, moving-average loss 0.22, train accuracy 0.74\n",
      "2,489,500 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,491,100 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,492,700 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,494,300 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,495,900 examples, moving-average loss 0.22, train accuracy 0.74\n",
      "2,497,500 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,499,100 examples, moving-average loss 0.22, train accuracy 0.74\n",
      "2,500,700 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,502,300 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,503,900 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,505,500 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,507,100 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,508,700 examples, moving-average loss 0.22, train accuracy 0.74\n",
      "2,510,300 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,511,900 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,513,500 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,515,100 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,516,700 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,518,300 examples, moving-average loss 0.19, train accuracy 0.74\n",
      "2,519,900 examples, moving-average loss 0.19, train accuracy 0.74\n",
      "2,521,500 examples, moving-average loss 0.19, train accuracy 0.74\n",
      "2,523,100 examples, moving-average loss 0.19, train accuracy 0.74\n",
      "Completed 2 epoch in 0:12:43\n",
      "Train accurary:0.73578\n",
      "Validate accuracy:0.71710\n",
      "2,524,650 examples, moving-average loss 0.22, train accuracy 0.61\n",
      "2,526,250 examples, moving-average loss 0.20, train accuracy 0.71\n",
      "2,527,850 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "2,529,450 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,531,050 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,532,650 examples, moving-average loss 0.20, train accuracy 0.73\n",
      "2,534,250 examples, moving-average loss 0.21, train accuracy 0.73\n",
      "2,535,850 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,537,450 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,539,050 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,540,650 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,542,250 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,543,850 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,545,450 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,547,050 examples, moving-average loss 0.22, train accuracy 0.74\n",
      "2,548,650 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,550,250 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,551,850 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,553,450 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,555,050 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,556,650 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,558,250 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,559,850 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,561,450 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,563,050 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,564,650 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,566,250 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,567,850 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,569,450 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,571,050 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,572,650 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,574,250 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,575,850 examples, moving-average loss 0.19, train accuracy 0.74\n",
      "2,577,450 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,579,050 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,580,650 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,582,250 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,583,850 examples, moving-average loss 0.21, train accuracy 0.74\n",
      "2,585,450 examples, moving-average loss 0.20, train accuracy 0.74\n",
      "2,587,050 examples, moving-average loss 0.21, train accuracy 0.74\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-141-5a2ddc86fb7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         summary, batch_loss, _, batch_accuracy, pred_proba, pred_max = sess.run(\n\u001b[0;32m---> 41\u001b[0;31m             [merged, regularized_loss_, train_op_, accuracy_, pred_proba_, pred_max_], feed_dict={X: bx, Y: by})\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m#print(pred_proba)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1276\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# start session\n",
    "sess = tf.Session()\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "# Tensorboard - Visualize graph \n",
    "merged = tf.summary.merge_all()\n",
    "train_writer = tf.summary.FileWriter(summary_params['chkpt_dir'] + '/train', sess.graph)\n",
    "test_writer = tf.summary.FileWriter(summary_params['chkpt_dir'] + '/test')\n",
    "\n",
    "print(\"tensorboard --logdir={}/train\".format(summary_params['chkpt_dir']))\n",
    "print(\"tensorboard --logdir={}/test\".format(summary_params['chkpt_dir']))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "init_l = tf.local_variables_initializer()\n",
    "\n",
    "# Run the initializer\n",
    "sess.run(init)\n",
    "sess.run(init_l)\n",
    "\n",
    "total_batches = 0\n",
    "total_examples = 0\n",
    "total_loss = 0\n",
    "loss_ema = np.log(2)  # track exponential-moving-average of loss\n",
    "ema_decay = np.exp(-1/10)  # decay parameter for moving average = np.exp(-1/history_length)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(train_params['total_epochs']):\n",
    "    t0 = time.time()\n",
    "\n",
    "    train_batches = 1\n",
    "    train_accuracy = 0.0\n",
    "    \n",
    "    for (bx, by) in utils.multi_batch_generator(train_params['batch_size'], \\\n",
    "                                        ds.padded_train_features, ds.train_ord_labels):\n",
    "\n",
    "        summary, batch_loss, _, batch_accuracy, pred_proba, pred_max = sess.run(\n",
    "            [merged, regularized_loss_, train_op_, accuracy_, pred_proba_, pred_max_], feed_dict={X: bx, Y: by})\n",
    "        \n",
    "        #print(pred_proba)\n",
    "        #print(pred_max)\n",
    "        \n",
    "        train_batches +=1\n",
    "        train_accuracy += batch_accuracy\n",
    "        \n",
    "        # Compute some statistics\n",
    "        total_batches += 1\n",
    "        total_examples += len(bx)\n",
    "        total_loss += batch_loss * len(bx)  # re-scale, since batch loss is mean\n",
    "\n",
    "        # Compute moving average to smooth out noisy per-batch loss\n",
    "        loss_ema = ema_decay * loss_ema + (1 - ema_decay) * batch_loss\n",
    "        \n",
    "        if (total_batches % 25 == 0):\n",
    "            print(\"{:5,} examples, moving-average loss {:.2f}, train accuracy {:.2f}\"\\\n",
    "                  .format(total_examples, loss_ema, train_accuracy/train_batches))    \n",
    "            \n",
    "        train_writer.add_summary(summary, total_batches)\n",
    "\n",
    "    print(\"Completed {} epoch in {:s}\".format(i, utils.pretty_timedelta(since=t0)))\n",
    "    \n",
    "    train_accuracy = train_accuracy/train_batches\n",
    "    print(\"Train accurary:{:.5f}\".format(train_accuracy))\n",
    "    \n",
    "    \n",
    "    # run the validation dataset \n",
    "    validate_batches = 1\n",
    "    validate_accuracy = 0.0\n",
    "    for (vx, vy) in utils.multi_batch_generator(train_params['batch_size'], \\\n",
    "                                            ds.padded_validate_features, ds.validate_ord_labels):\n",
    "\n",
    "        summary, batch_accuracy = sess.run([merged, accuracy_], feed_dict={X: vx, Y: vy})\n",
    "\n",
    "        validate_batches +=1\n",
    "        validate_accuracy += batch_accuracy\n",
    "\n",
    "        test_writer.add_summary(summary, total_batches + validate_batches)\n",
    "\n",
    "    validate_accuracy = validate_accuracy/validate_batches\n",
    "    print(\"Validate accuracy:{:.5f}\".format(validate_accuracy))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:0.7119574175981375\n"
     ]
    }
   ],
   "source": [
    "test_batches = 1\n",
    "test_accuracy = 0.0\n",
    "test_pred_y = []\n",
    "\n",
    "for (tx, ty) in utils.multi_batch_generator(train_params['batch_size'], \\\n",
    "                                        ds.padded_test_features, ds.test_ord_labels):\n",
    "\n",
    "    batch_accuracy, pred_max = sess.run([accuracy_, pred_max_], feed_dict={X: tx, Y: ty})\n",
    "\n",
    "    test_batches +=1\n",
    "    test_accuracy += batch_accuracy\n",
    "    test_pred_y.append(pred_max.tolist())\n",
    "\n",
    "test_accuracy = test_accuracy/test_batches\n",
    "print(\"Test accuracy:{}\".format(test_accuracy))\n",
    "\n",
    "pred_y = [y for x in test_pred_y for y in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7718,  2946,   257,    35],\n",
       "       [ 1593,  7844,  3351,   243],\n",
       "       [  224,  3233, 16614,  8606],\n",
       "       [   65,   561,  8754, 41835]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(ds.test_labels, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#op = sess.graph.get_operations()\n",
    "#[m.values() for m in op]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
