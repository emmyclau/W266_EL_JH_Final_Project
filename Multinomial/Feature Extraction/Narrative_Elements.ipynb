{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook extracts features of narrative elements that we’ve defined from our hypotheses to use as predictors in a logistic regression model to understand element importance. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# General libraries.\n",
    "import re\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import nltk\n",
    "from apyori import apriori\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import wordnet \n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from collections import Counter\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import TripAdvisor dataset (currently one csv file from each city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(247637, 19)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = ['reviews/Chicago_Illinois_1.csv', 'reviews/Las_Vegas_Nevada_1.csv', \\\n",
    "            'reviews/New_York_City_New_York_1.csv', 'reviews/San_Francisco_California_1.csv']\n",
    "\n",
    "data = pd.DataFrame()\n",
    "for path in filepath:\n",
    "    df = pd.read_csv(path)\n",
    "    df['city'] = path.split('/')[1]\n",
    "    data = data.append(df)\n",
    "data.shape #247,637 rows, 19 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data.isnull().sum()\n",
    "del data['neighborhood'] #remove column given 80+% null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Make sure every sentence ends in a period and every review is split into sentences\n",
    "#for cases such as {961, 869, 871, 809, 717, 494, 911, 720, 818, 340, 634, 310, 442, 990}\n",
    "#data['review_body'] = data['review_body']+'.'\n",
    "data['review_body'] = [x.split('.') for x in data['review_body']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import LIWC scores for each csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(247637, 45)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath_LIWC = ['reviews/LIWC_scores_Chicago_Illinois_1.csv', 'reviews/LIWC_scores_Las_Vegas_Nevada_1.csv', \\\n",
    "            'reviews/LIWC_scores_New_York_City_New_York_1.csv', 'reviews/LIWC_scores_San_Francisco_California_1.csv']\n",
    "consciousness = pd.DataFrame()\n",
    "for path in filepath_LIWC:\n",
    "    d = pd.read_csv(path)\n",
    "    d['city'] = path.split('/')[1]\n",
    "    consciousness = consciousness.append(d)\n",
    "\n",
    "consciousness.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(247637, 27)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop redundant columns from dataframe\n",
    "consciousness.drop(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q',\n",
    "                   'R'], axis=1, inplace=True)\n",
    "consciousness.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in NRC Emotion Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('NRC-Emotion-Lexicon-Wordlevel-v0.92.csv', 'r') as f:\n",
    "    df = pd.read_csv(f, delimiter='\\t',\n",
    "                     header=0,\n",
    "                     names=['word', 'emotion', 'relation'])\n",
    "\n",
    "# Create lists of emotion words\n",
    "#(anger, fear, anticipation, trust, surprise, sadness, joy, and disgust)\n",
    "anticipation = list(df[(df['emotion']=='anticipation') & (df['relation']!=0)]['word'])\n",
    "anger = list(df[(df['emotion']=='anger') & (df['relation']!=0)]['word'])\n",
    "fear = list(df[(df['emotion']=='fear') & (df['relation']!=0)]['word'])\n",
    "trust = list(df[(df['emotion']=='trust') & (df['relation']!=0)]['word'])\n",
    "surprise = list(df[(df['emotion']=='surprise') & (df['relation']!=0)]['word'])\n",
    "sadness = list(df[(df['emotion']=='sadness') & (df['relation']!=0)]['word'])\n",
    "joy = list(df[(df['emotion']=='joy') & (df['relation']!=0)]['word'])\n",
    "disgust = list(df[(df['emotion']=='disgust') & (df['relation']!=0)]['word'])\n",
    "neg_NRC = list(df[(df['emotion']=='negative') & (df['relation']!=0)]['word'])\n",
    "pos_NRC = list(df[(df['emotion']=='positive') & (df['relation']!=0)]['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 839 anticipation words.\n",
      "There are 1247 anger words.\n",
      "There are 1476 fear words.\n",
      "There are 1231 trust words\n",
      "There are 534 surprise words\n",
      "There are 1191 sadness words\n",
      "There are 689 joy words\n",
      "There are 1058 disgust words\n",
      "There are 3324 negative words\n",
      "There are 2312 positive words\n"
     ]
    }
   ],
   "source": [
    "print('There are ' + str(len(anticipation)) + ' anticipation words.')\n",
    "print('There are ' + str(len(anger)) + ' anger words.')\n",
    "print('There are ' + str(len(fear)) + ' fear words.')\n",
    "print('There are ' + str(len(trust)) + ' trust words')\n",
    "print('There are ' + str(len(surprise)) + ' surprise words')\n",
    "print('There are ' + str(len(sadness)) + ' sadness words')\n",
    "print('There are ' + str(len(joy)) + ' joy words')\n",
    "print('There are ' + str(len(disgust)) + ' disgust words')\n",
    "print('There are ' + str(len(neg_NRC)) + ' negative words')\n",
    "print('There are ' + str(len(pos_NRC)) + ' positive words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tokenize and tag each sentence in review with part of speech tags.\n",
    "all_sent = []\n",
    "for item in data['review_body']:\n",
    "    tagged_sent = []\n",
    "    for sent in item:\n",
    "        tokenized = nltk.word_tokenize(sent)\n",
    "        tagged=nltk.pos_tag(tokenized)\n",
    "        tagged_sent.append(tagged)\n",
    "    all_sent.append(tagged_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"tagged_sent.csv\", 'w', newline='') as myfile:\n",
    "    wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "    wr.writerow(all_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features\n",
    "Feature details: https://docs.google.com/document/d/1xbN-xf9eeJsqsfqzynQt1KcV51cy0TLiaX3lAP8evBE/edit?usp=sharing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews = []\n",
    "sentences = []\n",
    "# Initiate empty list for subjectivity features\n",
    "nouns = []\n",
    "adj = []\n",
    "comparatives = []\n",
    "superlatives = []\n",
    "adverbs = []\n",
    "word_count = []\n",
    "ne = []\n",
    "tense = []\n",
    "polarity = []\n",
    "dt = []\n",
    "\n",
    "# Initiate empty list for trauma narrative features\n",
    "past_tense = []\n",
    "first_person_plural = []\n",
    "third_person_prn=[]\n",
    "negative_words = []\n",
    "positive_words = []\n",
    "\n",
    "# Initiate empty list for TextBlob scores\n",
    "subjectivity = []\n",
    "polarity2 = []\n",
    "\n",
    "# Initiate empty list for NRC Emotion / Plutchik’s scale of emotion\n",
    "tot_anger = []\n",
    "tot_fear = []\n",
    "tot_anticipation = []\n",
    "tot_trust = []\n",
    "tot_surprise = []\n",
    "tot_sadness = []\n",
    "tot_joy = []\n",
    "tot_disgust = []\n",
    "tot_neg_NRC = []\n",
    "tot_pos_NRC = []\n",
    "\n",
    "untagged_sent = []\n",
    "count=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for rev in all_sent:\n",
    "    count+=1\n",
    "    #print(rev)\n",
    "    for sent in rev:\n",
    "        if len(sent)==0:\n",
    "            pass\n",
    "        else:\n",
    "            #print(sent)\n",
    "            reviews.append(count)\n",
    "            # Append sentence\n",
    "            sentences.append(sent)\n",
    "            # Get word count\n",
    "            word_count.append(len(sent))\n",
    "\n",
    "            counts = Counter(x[1] for x in sent)\n",
    "            total_nouns = counts['NN'] + counts['NNS'] + counts['NNP'] + counts['NNPS']\n",
    "            nouns.append(total_nouns)\n",
    "            #print('total nouns: ' + str(total_nouns))\n",
    "\n",
    "            total_adj = counts['JJ'] + counts['JJR'] + counts['JJS']\n",
    "            adj.append(total_adj)\n",
    "            #print('total adj: ' + str(total_adj))\n",
    "\n",
    "            total_comparatives = counts['JJR']\n",
    "            comparatives.append(total_comparatives)\n",
    "            #print('total comparatives: ' + str(total_comparatives))\n",
    "\n",
    "            total_superlatives = counts['JJS']\n",
    "            superlatives.append(total_superlatives)\n",
    "            #print('total superlatives: ' + str(total_superlatives))\n",
    "\n",
    "            total_adv = counts['RB']+ counts['RBR'] + counts['RBS']\n",
    "            adverbs.append(total_adv)\n",
    "            #print('total adv: ' + str(total_adv))\n",
    "            \n",
    "            # Get named entities\n",
    "            ne_tree =  nltk.ne_chunk(sent)\n",
    "            ne_list = list(ne_tree)\n",
    "            counts_ne = Counter(list(ne_list[i])[0][1] for i in range(len(ne_list)) \\\n",
    "                                if type(ne_list[i]) is nltk.tree.Tree)\n",
    "            total_ne = counts_ne['NNP']\n",
    "            ne.append(total_ne)\n",
    "            \n",
    "            count_future = counts['MD']\n",
    "            #print('future words: ' + str(count_future))\n",
    "            count_present = counts['VBP'] + counts['VBG'] + counts['VBZ']\n",
    "            #print('present words: ' + str(count_present))\n",
    "            count_past = counts['VBD'] + counts ['VBN']\n",
    "            past_tense.append(count_past)\n",
    "            #print('past words: ' + str(count_past))\n",
    "            # Get max count from future, present, and past, and use as tense of sentence.\n",
    "            tense_count = max(count_future, count_present, count_past)\n",
    "            #print('max: ' + str(tense_count))\n",
    "            if tense_count == count_future:\n",
    "                tense.append('future')\n",
    "                #print('this sentence is written in future tense')\n",
    "            elif tense_count == count_present:\n",
    "                tense.append('present')\n",
    "                #print('this sentence is written in present tense')\n",
    "            else:\n",
    "                tense.append('past')\n",
    "                #print('this sentence is written in past tense')\n",
    "            \n",
    "            # CD represents cardinal numbers\n",
    "            count_dt = counts['CD']\n",
    "            dt.append(count_dt)\n",
    "            #print('total digits: ' + str(count_dt))\n",
    "            \n",
    "            count_fp = Counter(x[0] for x in sent if x[0] in ['we','us','our'])\n",
    "            first_person_plural.append(sum(count_fp.values()))\n",
    "            #print('total first person pronoun words: ' + str(sum(count_fp.values())))\n",
    "            \n",
    "            count_tp = Counter(x[0] for x in sent if x[0] in ['he','she','it','him','her','his','hers','its','they',\\\n",
    "                                                              'them','their','theirs'])            \n",
    "            third_person_prn.append(sum(count_tp.values()))\n",
    "            \n",
    "            # Determine polarity of sentence. Count the number of words from SentiWordNet \n",
    "            # (having either nonzero positive polarity score or nonzero negative polarity score) \n",
    "            # present in a sentence\n",
    "            sent_pos = 0\n",
    "            sent_neg = 0\n",
    "            for word in sent:\n",
    "                #print(word)\n",
    "                pos_list = []\n",
    "                neg_list = []\n",
    "                # Get word synonyms\n",
    "                syns = wordnet.synsets(word[0])\n",
    "                if syns == []:\n",
    "                    pass\n",
    "                else:\n",
    "                    # Append all polarity scores for each word and take the max positive and negative\n",
    "                    # to use as overall word polarity. \n",
    "                    for s in syns:\n",
    "                        #print(s.name)\n",
    "                        swn_synset =swn.senti_synset(s.name())\n",
    "                        pos_list.append(swn_synset.pos_score())\n",
    "                        neg_list.append(swn_synset.neg_score())\n",
    "                        #print('Positive: ' + str(pos_list))\n",
    "                        #print('Negative: ' + str(neg_list))\n",
    "                    word_pos = max(pos_list)\n",
    "                    #print('Positive max: ' + str(word_pos))\n",
    "                    word_neg = max(neg_list)\n",
    "                    #print('Negative max: ' + str(word_neg))\n",
    "                    if word_pos > word_neg:\n",
    "                        sent_pos +=1\n",
    "                    if word_neg > word_pos:\n",
    "                        sent_neg +=1\n",
    "            negative_words.append(sent_neg)\n",
    "            positive_words.append(sent_pos)\n",
    "            # Sum up number of positive and negative words in sentence\n",
    "            total_polarity = sent_pos+sent_neg\n",
    "            polarity.append(total_polarity)\n",
    "            \n",
    "            # NRC Emotions: anger, fear, anticipation, trust, surprise, sadness, joy, and disgust\n",
    "            count_ant = Counter(x[0] for x in sent if x[0] in anticipation)\n",
    "            tot_anticipation.append(sum(count_ant.values()))\n",
    "            count_anger = Counter(x[0] for x in sent if x[0] in anger)\n",
    "            tot_anger.append(sum(count_anger.values()))\n",
    "            count_fear = Counter(x[0] for x in sent if x[0] in fear)\n",
    "            tot_fear.append(sum(count_fear.values()))\n",
    "            count_trust = Counter(x[0] for x in sent if x[0] in trust)\n",
    "            tot_trust.append(sum(count_trust.values()))\n",
    "            count_surprise = Counter(x[0] for x in sent if x[0] in surprise)\n",
    "            tot_surprise.append(sum(count_surprise.values()))\n",
    "            count_sad = Counter(x[0] for x in sent if x[0] in sadness)\n",
    "            tot_sadness.append(sum(count_sad.values()))\n",
    "            count_joy = Counter(x[0] for x in sent if x[0] in joy)\n",
    "            tot_joy.append(sum(count_joy.values()))\n",
    "            count_disgust = Counter(x[0] for x in sent if x[0] in disgust)\n",
    "            tot_disgust.append(sum(count_disgust.values()))\n",
    "            count_neg = Counter(x[0] for x in sent if x[0] in neg_NRC)\n",
    "            tot_neg_NRC.append(sum(count_neg.values()))\n",
    "            count_pos = Counter(x[0] for x in sent if x[0] in pos_NRC)\n",
    "            tot_pos_NRC.append(sum(count_pos.values()))\n",
    "            \n",
    "            # Use TextBlob to sentence-level subjectivity and polarity scores\n",
    "            # Each word in the lexicon has scores for:\n",
    "            # 1) polarity: negative vs. positive    (-1.0 => +1.0)\n",
    "            # 2) subjectivity: objective vs. subjective (+0.0 => +1.0)\n",
    "            new_sent = \" \".join([a for a, b in sent])\n",
    "            text = TextBlob(new_sent)\n",
    "            untagged_sent.append(new_sent)\n",
    "            subjectivity.append(text.sentiment.subjectivity)\n",
    "            polarity2.append(text.sentiment.polarity)\n",
    "            \n",
    "            \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600668\n",
      "600668\n",
      "600667\n",
      "600667\n"
     ]
    }
   ],
   "source": [
    "print(len(reviews))\n",
    "print(len(sentences))\n",
    "print(len(negative_words))\n",
    "print(len(subjectivity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a dataframe of sentence-level records\n",
    "setup = {'Reviews':reviews, 'Sentence':sentences, 'Untagged': untagged_sent, \\\n",
    "         'Word_Count': word_count, 'Nouns': nouns, 'Adjectives':adj, \\\n",
    "         'Comparatives': comparatives, 'Superlatives':superlatives, 'Adverbs': adverbs,\\\n",
    "         'Subjectivity': subjectivity, 'Tense': tense, 'Digits': dt, \\\n",
    "         'Polarity': polarity, 'Polarity2': polarity2, 'First Person': first_person_plural,    \n",
    "         'Named Entities': ne, 'Third Person': third_person_prn, 'Past Tense': past_tense,\n",
    "         'Neg_Words': negative_words}\n",
    "opinions = pd.DataFrame(setup)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(opinions['Reviews'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opinions.to_csv('opinions_features_1_all', sep=',')\n",
    "#opinions_csv = pd.read_csv('opinions_features_1_updated')\n",
    "#opinions_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Adjectives</th>\n",
       "      <th>Adverbs</th>\n",
       "      <th>Comparatives</th>\n",
       "      <th>Digits</th>\n",
       "      <th>First Person</th>\n",
       "      <th>Named Entities</th>\n",
       "      <th>Neg_Words</th>\n",
       "      <th>Nouns</th>\n",
       "      <th>Past Tense</th>\n",
       "      <th>...</th>\n",
       "      <th>Polarity2</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Superlatives</th>\n",
       "      <th>Tense</th>\n",
       "      <th>Third Person</th>\n",
       "      <th>Untagged</th>\n",
       "      <th>Word_Count</th>\n",
       "      <th>actual_rev_no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>[('We', 'PRP'), ('are', 'VBP'), ('diamond', 'J...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>present</td>\n",
       "      <td>0</td>\n",
       "      <td>We are diamond players , this is Harrah 's fin...</td>\n",
       "      <td>14</td>\n",
       "      <td>87281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>[('The', 'DT'), ('rooms', 'NNS'), ('are', 'VBP...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>present</td>\n",
       "      <td>0</td>\n",
       "      <td>The rooms are always immaculate and the amenit...</td>\n",
       "      <td>10</td>\n",
       "      <td>87281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.537500</td>\n",
       "      <td>1</td>\n",
       "      <td>[('This', 'DT'), ('place', 'NN'), ('is', 'VBZ'...</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0</td>\n",
       "      <td>present</td>\n",
       "      <td>0</td>\n",
       "      <td>This place is gorgeous not feminine beautiful ...</td>\n",
       "      <td>9</td>\n",
       "      <td>87281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>1</td>\n",
       "      <td>[('I', 'PRP'), ('love', 'VBP'), ('staying', 'V...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>present</td>\n",
       "      <td>0</td>\n",
       "      <td>I love staying here the grounds are really som...</td>\n",
       "      <td>9</td>\n",
       "      <td>87281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>1</td>\n",
       "      <td>[('Treat', 'NN'), ('yourself', 'PRP'), ('to', ...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>future</td>\n",
       "      <td>1</td>\n",
       "      <td>Treat yourself to a fine room and meal here yo...</td>\n",
       "      <td>14</td>\n",
       "      <td>87281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>[('My', 'PRP$'), ('husband', 'NN'), ('and', 'C...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0</td>\n",
       "      <td>present</td>\n",
       "      <td>0</td>\n",
       "      <td>My husband and I love the Mermaid Bar</td>\n",
       "      <td>8</td>\n",
       "      <td>87281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1</td>\n",
       "      <td>[('We', 'PRP'), ('actually', 'RB'), ('have', '...</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0</td>\n",
       "      <td>present</td>\n",
       "      <td>0</td>\n",
       "      <td>We actually have won money here , playing vide...</td>\n",
       "      <td>26</td>\n",
       "      <td>87281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>[('A', 'DT'), ('lot', 'NN'), ('to', 'TO'), ('s...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>future</td>\n",
       "      <td>0</td>\n",
       "      <td>A lot to see and do here</td>\n",
       "      <td>7</td>\n",
       "      <td>87281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Adjectives  Adverbs  Comparatives  Digits  First Person  \\\n",
       "0           0           2        0             0       0             0   \n",
       "1           1           2        1             0       0             0   \n",
       "2           2           2        2             0       0             0   \n",
       "3           3           0        2             0       0             0   \n",
       "4           4           1        2             0       0             0   \n",
       "5           5           0        0             0       0             0   \n",
       "6           6           1        4             0       0             1   \n",
       "7           7           0        1             0       0             0   \n",
       "\n",
       "   Named Entities  Neg_Words  Nouns  Past Tense      ...        Polarity2  \\\n",
       "0               1          1      4           0      ...         0.000000   \n",
       "1               0          2      2           0      ...         1.000000   \n",
       "2               0          3      3           0      ...         0.537500   \n",
       "3               0          3      2           0      ...         0.350000   \n",
       "4               0          2      3           0      ...         0.416667   \n",
       "5               1          2      3           0      ...         0.500000   \n",
       "6               0          6      6           2      ...         0.166667   \n",
       "7               0          3      1           0      ...         0.000000   \n",
       "\n",
       "   Reviews                                           Sentence Subjectivity  \\\n",
       "0        1  [('We', 'PRP'), ('are', 'VBP'), ('diamond', 'J...     0.000000   \n",
       "1        1  [('The', 'DT'), ('rooms', 'NNS'), ('are', 'VBP...     1.000000   \n",
       "2        1  [('This', 'DT'), ('place', 'NN'), ('is', 'VBZ'...     0.675000   \n",
       "3        1  [('I', 'PRP'), ('love', 'VBP'), ('staying', 'V...     0.400000   \n",
       "4        1  [('Treat', 'NN'), ('yourself', 'PRP'), ('to', ...     0.500000   \n",
       "5        1  [('My', 'PRP$'), ('husband', 'NN'), ('and', 'C...     0.600000   \n",
       "6        1  [('We', 'PRP'), ('actually', 'RB'), ('have', '...     0.466667   \n",
       "7        1  [('A', 'DT'), ('lot', 'NN'), ('to', 'TO'), ('s...     0.000000   \n",
       "\n",
       "   Superlatives    Tense Third Person  \\\n",
       "0             1  present            0   \n",
       "1             0  present            0   \n",
       "2             0  present            0   \n",
       "3             0  present            0   \n",
       "4             0   future            1   \n",
       "5             0  present            0   \n",
       "6             0  present            0   \n",
       "7             0   future            0   \n",
       "\n",
       "                                            Untagged Word_Count  actual_rev_no  \n",
       "0  We are diamond players , this is Harrah 's fin...         14          87281  \n",
       "1  The rooms are always immaculate and the amenit...         10          87281  \n",
       "2  This place is gorgeous not feminine beautiful ...          9          87281  \n",
       "3  I love staying here the grounds are really som...          9          87281  \n",
       "4  Treat yourself to a fine room and meal here yo...         14          87281  \n",
       "5              My husband and I love the Mermaid Bar          8          87281  \n",
       "6  We actually have won money here , playing vide...         26          87281  \n",
       "7                           A lot to see and do here          7          87281  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_1 = pd.read_csv('opinions_features_1_87282')\n",
    "results_2 = pd.read_csv('opinions_features_1_remaining')\n",
    "results_1['actual_rev_no'] = results_1['Reviews']-1\n",
    "results_2['actual_rev_no'] = results_2['Reviews']+87280\n",
    "result = pd.concat([results_1, results_2])\n",
    "#remove overlap\n",
    "result[result['actual_rev_no']==87281].drop([600665, 600666])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Aggregate sentence-level dataframe back into review-level\n",
    "aggregation_functions = {'Adjectives': 'sum', 'Adverbs': 'sum', 'Comparatives': 'sum', 'Superlatives': 'sum',\n",
    "                        'Digits': 'sum', 'Nouns': 'sum', 'Polarity': 'sum', 'Polarity2': 'mean',\n",
    "                        'Subjectivity': 'mean', 'Tense': lambda col: ', '.join(col), 'Word_Count': 'sum',\n",
    "                        'First Person': 'sum', 'Named Entities': 'sum', 'Third Person': 'sum', 'Past Tense': 'sum',\n",
    "                        'Neg_Words': 'sum'}\n",
    "df1 = result.groupby(result['actual_rev_no']).agg(aggregation_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adjectives                                                       10\n",
       "Adverbs                                                           8\n",
       "Comparatives                                                      1\n",
       "Superlatives                                                      0\n",
       "Digits                                                            2\n",
       "Nouns                                                            38\n",
       "Polarity                                                         72\n",
       "Polarity2                                                  0.294643\n",
       "Subjectivity                                               0.503571\n",
       "Tense             past, present, present, present, present, pres...\n",
       "Word_Count                                                      156\n",
       "First Person                                                      1\n",
       "Named Entities                                                    6\n",
       "Third Person                                                      6\n",
       "Past Tense                                                        7\n",
       "Neg_Words                                                        28\n",
       "Name: 3, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['My ol lady got a trip off orbits for me and my brothers to get out of town for my 40th birthday just to Dick around',\n",
       " ' Anyway this is a trendy boutique hotel',\n",
       " ' The room art is way to hip for me but I loved the bathrooms',\n",
       " ' Service was ok everybody’s too cool for school is the vibe they give out which is what they are trying to push',\n",
       " ' The real reason I didn’t give it a higher rating is because all hotels are now trying these signature scents by pumping out these smells thru diffusers and while I love the Ritz and Four Seasons scents the one the Thompson uses is absolutely horrible and inundates every corner of the hotel',\n",
       " ' Maybe they have changed it since I have been there but it that’s why the 3 star rating',\n",
       " ' Also we saw Brian Glazer in the lobby which was cool',\n",
       " '']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[3]['review_body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0}\n"
     ]
    }
   ],
   "source": [
    "print(set(list(range(0,247637))) - set(list(df1.index.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make values percentages\n",
    "df2 = df1[['Adjectives','Adverbs', 'Comparatives', 'Superlatives', 'Digits', 'Nouns', 'Polarity',\n",
    "   'Named Entities']].div(df1.Word_Count, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adjectives</th>\n",
       "      <th>Adverbs</th>\n",
       "      <th>Comparatives</th>\n",
       "      <th>Superlatives</th>\n",
       "      <th>Digits</th>\n",
       "      <th>Nouns</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Named Entities</th>\n",
       "      <th>Tense</th>\n",
       "      <th>Polarity2</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Word_Count</th>\n",
       "      <th>First Person</th>\n",
       "      <th>Third Person</th>\n",
       "      <th>Past Tense</th>\n",
       "      <th>Neg_Words</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_rev_no</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.365079</td>\n",
       "      <td>0.063492</td>\n",
       "      <td>past, past, past</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.608333</td>\n",
       "      <td>63</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.453125</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>present, past, present, past</td>\n",
       "      <td>0.473750</td>\n",
       "      <td>0.936250</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.127273</td>\n",
       "      <td>0.054545</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.490909</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>past, present, past, future</td>\n",
       "      <td>0.432812</td>\n",
       "      <td>0.618750</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.064103</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.00641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.243590</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>past, present, present, present, present, pres...</td>\n",
       "      <td>0.294643</td>\n",
       "      <td>0.503571</td>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.053571</td>\n",
       "      <td>0.089286</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.258929</td>\n",
       "      <td>0.348214</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>past, present, present, present, past, past, f...</td>\n",
       "      <td>0.460159</td>\n",
       "      <td>0.604286</td>\n",
       "      <td>112</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Adjectives   Adverbs  Comparatives  Superlatives    Digits  \\\n",
       "actual_rev_no                                                               \n",
       "0                0.095238  0.000000       0.00000           0.0  0.000000   \n",
       "1                0.125000  0.031250       0.00000           0.0  0.031250   \n",
       "2                0.127273  0.054545       0.00000           0.0  0.018182   \n",
       "3                0.064103  0.051282       0.00641           0.0  0.012821   \n",
       "4                0.053571  0.089286       0.00000           0.0  0.017857   \n",
       "\n",
       "                  Nouns  Polarity  Named Entities  \\\n",
       "actual_rev_no                                       \n",
       "0              0.333333  0.365079        0.063492   \n",
       "1              0.250000  0.453125        0.031250   \n",
       "2              0.200000  0.490909        0.036364   \n",
       "3              0.243590  0.461538        0.038462   \n",
       "4              0.258929  0.348214        0.035714   \n",
       "\n",
       "                                                           Tense  Polarity2  \\\n",
       "actual_rev_no                                                                 \n",
       "0                                               past, past, past   0.475000   \n",
       "1                                   present, past, present, past   0.473750   \n",
       "2                                    past, present, past, future   0.432812   \n",
       "3              past, present, present, present, present, pres...   0.294643   \n",
       "4              past, present, present, present, past, past, f...   0.460159   \n",
       "\n",
       "               Subjectivity  Word_Count  First Person  Third Person  \\\n",
       "actual_rev_no                                                         \n",
       "0                  0.608333          63             2             0   \n",
       "1                  0.936250          64             1             0   \n",
       "2                  0.618750          55             0             0   \n",
       "3                  0.503571         156             1             6   \n",
       "4                  0.604286         112             3             2   \n",
       "\n",
       "               Past Tense  Neg_Words  \n",
       "actual_rev_no                         \n",
       "0                       6         12  \n",
       "1                       5         11  \n",
       "2                       5          7  \n",
       "3                       7         28  \n",
       "4                       7         16  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Tense'] = df1['Tense']\n",
    "df2['Polarity2'] = df1['Polarity2']\n",
    "df2['Subjectivity'] = df1['Subjectivity']\n",
    "df2['Word_Count'] = df1['Word_Count']\n",
    "df2['First Person'] = df1['First Person']\n",
    "df2['Third Person'] = df1['Third Person']\n",
    "df2['Past Tense'] = df1['Past Tense']\n",
    "df2['Neg_Words'] = df1['Neg_Words']\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "247637"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reindex consciousness and data df\n",
    "consciousness['Reviews'] = df2.index.values\n",
    "consciousness.set_index('Reviews', inplace=True)\n",
    "data['Reviews'] = df2.index.values\n",
    "data.set_index('Reviews', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create column for Narrative to denote presence of narrative (sum of \n",
    "# past tense, perfect, and third person pronoun variables)\n",
    "df2['Narrative'] = df2['Past Tense'] + df2['Third Person']\n",
    "df2['Tense'] = [Counter(i.split(', ')).most_common()[0][0] for i in df2['Tense']]\n",
    "df2['affect'] = consciousness['affect']*.01\n",
    "df2['posemo'] = consciousness['posemo']*.01\n",
    "df2['negemo'] = consciousness['negemo']*.01\n",
    "df2['Trauma'] = [1 if (df2.iloc[i]['Narrative']>0) and (df2.iloc[i]['Neg_Words']>0) \n",
    "                 and (df2.iloc[i]['First Person']>0) else 0 for i in range(len(df2))]\n",
    "df2['anx'] = consciousness['anx']*.01*.01\n",
    "df2['anger'] = consciousness['anger']*.01\n",
    "df2['sad'] = consciousness['sad']*.01 #[:8088]\n",
    "df2['cogproc'] = consciousness['cogproc']*.01 #[:8088]\n",
    "df2['insight'] = consciousness['insight']*.01 #[:8088]\n",
    "df2['cause'] = consciousness['cause']*.01 #[:8088]\n",
    "df2['discrep'] = consciousness['discrep']*.01 #[:8088]\n",
    "df2['tentat'] = consciousness['tentat']*.01 #[:8088]\n",
    "df2['certain'] = consciousness['certain']*.01 #[:8088]\n",
    "df2['differ'] = consciousness['differ']*.01 #[:8088]\n",
    "df2['Rating'] = data['rating'] #[:8088]\n",
    "df2['Helpful'] = data['helpful_vote'] #[:8088]\n",
    "df2['city'] = data['city']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    247637.000000\n",
       "mean          0.076171\n",
       "std           0.039912\n",
       "min           0.000000\n",
       "25%           0.048100\n",
       "50%           0.069400\n",
       "75%           0.097600\n",
       "max           0.472200\n",
       "Name: affect, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['affect'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(217206, 34)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove rows with rating of 3\n",
    "df2 = df2[df2.Rating != 30]\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2['Rating'] = df2['Rating'].map({50: 1, 40: 1, 20: 0, 10: 0})\n",
    "df2['Tense'] = df2['Tense'].map({'past': -1, 'present': 2, 'future': 3})\n",
    "df2['city'] = df2['city'].map({'Chicago_Illinois_1.csv': 1, 'New_York_City_New_York_1.csv': 2, \n",
    "                              'San_Francisco_California_1.csv': 3, 'Las_Vegas_Nevada_1.csv': 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(consciousness.columns)\n",
    "\n",
    "consciousness['spatial'] = [2 if (consciousness.iloc[s]['space'] > 0) & (consciousness.iloc[s]['percept'] > 0) \n",
    "                            else 1 if (consciousness.iloc[s]['space'] > 0) & (consciousness.iloc[s]['percept'] == 0) \n",
    "                            else 0 for s in range(len(consciousness))]\n",
    "consciousness['temporal'] = [2 if (consciousness.iloc[s]['time'] > 0) & (consciousness.iloc[s]['cause'] > 0) \n",
    "                            else 1 if (consciousness.iloc[s]['time'] > 0) | (consciousness.iloc[s]['cause'] > 0) \n",
    "                            else 0 for s in range(len(consciousness))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2['spatial'] = consciousness['spatial']\n",
    "df2['temporal'] = consciousness['temporal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('Chi_NYC_LV_SF_features_1', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive reviews: 191625\n",
      "Number of negative reviews: 25581\n",
      "% of positive: 88.22\n"
     ]
    }
   ],
   "source": [
    "print('Number of positive reviews: ' + str(len(df2[df2['Rating'] == 1])))\n",
    "print('Number of negative reviews: ' + str(len(df2[df2['Rating'] == 0])))\n",
    "print('% of positive: ' + str(round((len(df2[df2['Rating'] == 1])/(len(df2[df2['Rating'] == 1])+len(df2[df2['Rating'] == 0])))*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Features to Predict Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df1 = df1.drop(61464, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Adjectives', 'Adverbs', 'Comparatives', 'Superlatives', 'Digits',\n",
       "       'Nouns', 'Polarity', 'Named Entities', 'Tense', 'Polarity2',\n",
       "       'Subjectivity', 'Word_Count', 'First Person', 'Third Person',\n",
       "       'Past Tense', 'Neg_Words', 'Narrative', 'affect', 'posemo', 'negemo',\n",
       "       'Trauma', 'anx', 'anger', 'sad', 'cogproc', 'insight', 'cause',\n",
       "       'discrep', 'tentat', 'certain', 'differ', 'Rating', 'Helpful', 'city',\n",
       "       'spatial', 'temporal'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = df2['Rating']\n",
    "X = df2[['Polarity2','Subjectivity', 'Word_Count', 'Named Entities',\n",
    "       'affect', 'cogproc','Helpful', 'city', 'Trauma','spatial', 'temporal', 'Third Person', 'Past Tense']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.94\n",
      "[[ 4690  2984]\n",
      " [ 1223 56265]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.61      0.69      7674\n",
      "          1       0.95      0.98      0.96     57488\n",
      "\n",
      "avg / total       0.93      0.94      0.93     65162\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))\n",
    "confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)\n",
    "print(metrics.classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arthur/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/arthur/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "results_df = X_test\n",
    "results_df['y_test']= y_test\n",
    "results_df['y_pred']=y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "incorrects = results_df[results_df['y_test']!=results_df['y_pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "false_positives = incorrects[(incorrects['y_test']==0) & (incorrects['y_pred']==1)]\n",
    "false_negatives = incorrects[(incorrects['y_test']==1) & (incorrects['y_pred']==0)]\n",
    "true_positives = results_df[(results_df['y_test']==1) & (results_df['y_pred']==1)]\n",
    "true_negatives = results_df[(results_df['y_test']==0) & (results_df['y_pred']==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False+ | Polarity2: 0.1273470619787051 True- |-0.07703048821232189\n",
      "False+ | Subjectivity: 0.4150246935799466 True- |0.3835847759708672\n",
      "False+ | Word_Count: 142 True- |176\n",
      "False+ | Helpful: 19 True- |10\n",
      "False+ | affect: 0.05199510333863275 True- |0.04454327666151468\n",
      "False+ | cogproc: 0.10042445151033387 True- |0.10040991388827555\n",
      "False+ | Trauma: 0 True- |0\n",
      "False+ | spatial: 1 True- |1\n",
      "False+ | temporal: 1 True- |1\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean \n",
    "print('False+ | Polarity2: ' + str(mean(false_positives.Polarity2)) + ' True- |' +str(mean(true_negatives.Polarity2)))\n",
    "print('False+ | Subjectivity: ' + str(mean(false_positives.Subjectivity))+ ' True- |' +str(mean(true_negatives.Subjectivity)))\n",
    "print('False+ | Word_Count: ' + str(mean(false_positives.Word_Count))+ ' True- |' +str(mean(true_negatives.Word_Count)))\n",
    "print('False+ | Helpful: ' + str(mean(false_positives.Helpful))+ ' True- |' +str(mean(true_negatives.Helpful)))\n",
    "print('False+ | affect: ' + str(mean(false_positives.affect))+ ' True- |' +str(mean(true_negatives.affect)))\n",
    "print('False+ | cogproc: ' + str(mean(false_positives.cogproc))+ ' True- |' +str(mean(true_negatives.cogproc)))\n",
    "print('False+ | Trauma: ' + str(mean(false_positives.Trauma))+ ' True- |' +str(mean(true_negatives.Trauma)))\n",
    "print('False+ | spatial: ' + str(mean(false_positives.spatial))+ ' True- |' +str(mean(true_negatives.spatial)))\n",
    "print('False+ | temporal: ' + str(mean(false_positives.temporal))+ ' True- |' +str(mean(true_negatives.temporal)))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False- | Polarity2: -0.022712984152377387 True+ |0.3127465107601093\n",
      "False- | Subjectivity: 0.3794892041400024 True+ |0.5177233922593242\n",
      "False- | Word_Count: 165 True+ |100\n",
      "False- | Helpful: 13 True+ |18\n",
      "False- | affect: 0.04686406124093473 True+ |0.08354321652710367\n",
      "False- | cogproc: 0.10795028203062047 True+ |0.08189278361512614\n",
      "False- | Trauma: 0 True+ |0\n",
      "False- | spatial: 1 True+ |1\n",
      "False- | temporal: 1 True+ |1\n"
     ]
    }
   ],
   "source": [
    "print('False- | Polarity2: ' + str(mean(false_negatives.Polarity2))+ ' True+ |' +str(mean(true_positives.Polarity2)))\n",
    "print('False- | Subjectivity: ' + str(mean(false_negatives.Subjectivity))+ ' True+ |' +str(mean(true_positives.Subjectivity)))\n",
    "print('False- | Word_Count: ' + str(mean(false_negatives.Word_Count))+ ' True+ |' +str(mean(true_positives.Word_Count)))\n",
    "print('False- | Helpful: ' + str(mean(false_negatives.Helpful))+ ' True+ |' +str(mean(true_positives.Helpful)))\n",
    "print('False- | affect: ' + str(mean(false_negatives.affect))+ ' True+ |' +str(mean(true_positives.affect)))\n",
    "print('False- | cogproc: ' + str(mean(false_negatives.cogproc))+ ' True+ |' +str(mean(true_positives.cogproc)))\n",
    "print('False- | Trauma: ' + str(mean(false_negatives.Trauma))+ ' True+ |' +str(mean(true_positives.Trauma)))\n",
    "print('False- | spatial: ' + str(mean(false_negatives.spatial))+ ' True+ |' +str(mean(true_positives.spatial)))\n",
    "print('False- | temporal: ' + str(mean(false_negatives.temporal))+ ' True+ |' +str(mean(true_positives.temporal)))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arthur/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/arthur/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/arthur/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "incorrects['review_body']=np.nan\n",
    "incorrects['city']=np.nan\n",
    "incorrects['5_pt_rating']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 43473, 183868, 204516, ...,  17421, 231850, 175507])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrects.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arthur/anaconda/lib/python3.6/site-packages/pandas/core/indexing.py:179: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/Users/arthur/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/arthur/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/arthur/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "for i in incorrects.index.values:\n",
    "    #print(data.loc[[i],['review_body']])\n",
    "    incorrects['review_body'].loc[i] = data.loc[i]['review_body']\n",
    "    incorrects['city'].loc[i] = data.loc[i]['city']\n",
    "    incorrects['5_pt_rating'].loc[i] = data.loc[i]['rating']\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Adjectives', 'Adverbs', 'Comparatives', 'Superlatives', 'Digits',\n",
       "       'Nouns', 'Polarity', 'Named Entities', 'Tense', 'Polarity2',\n",
       "       'Subjectivity', 'Word_Count', 'First Person', 'Third Person',\n",
       "       'Past Tense', 'Neg_Words', 'Narrative', 'affect', 'posemo', 'negemo',\n",
       "       'Trauma', 'anx', 'anger', 'sad', 'cogproc', 'insight', 'cause',\n",
       "       'discrep', 'tentat', 'certain', 'differ', 'Rating', 'Helpful', 'city',\n",
       "       'spatial', 'temporal'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "incorrects.tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arthur/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/arthur/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/arthur/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/arthur/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/arthur/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/Users/arthur/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/arthur/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/Users/arthur/anaconda/lib/python3.6/site-packages/pandas/core/indexing.py:179: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/Users/arthur/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/Users/arthur/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Users/arthur/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/arthur/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/Users/arthur/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/Users/arthur/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/arthur/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "incorrects['adjectives']=np.nan\n",
    "incorrects['comparatives']=np.nan\n",
    "incorrects['superlatives']=np.nan\n",
    "incorrects['NE']=np.nan\n",
    "incorrects['digits']=np.nan\n",
    "incorrects['polarity2']=np.nan\n",
    "incorrects['affect']=np.nan\n",
    "for i in incorrects.index.values:\n",
    "    incorrects['affect'].loc[i] = df2.loc[i]['affect']\n",
    "    incorrects['adjectives'].loc[i] = df2.loc[i]['Adjectives']\n",
    "    incorrects['comparatives'].loc[i] = df2.loc[i]['Comparatives']\n",
    "    incorrects['superlatives'].loc[i] = df2.loc[i]['Superlatives']\n",
    "    incorrects['digits'].loc[i] = df2.loc[i]['Digits']\n",
    "    incorrects['NE'].loc[i] = df2.loc[i]['Named Entities']\n",
    "    incorrects['Polarity2'].loc[i] = df2.loc[i]['Polarity2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print('Actual: ' + str(incorrects.iloc[i]['y_test']))\n",
    "    print('Predicted: ' + str(incorrects.iloc[i]['y_pred']))\n",
    "    print('Review: ' + str(incorrects.iloc[i]['review_body']))\n",
    "    print('City: ' + str(incorrects.iloc[i]['city']))\n",
    "    print('Rating: ' + str(incorrects.iloc[i]['5_pt_rating']))\n",
    "    print('affect: ' + str(incorrects.iloc[i]['affect']))\n",
    "    print('adjectives: ' + str(incorrects.iloc[i]['Adjectives']))\n",
    "    print('comparatives: ' + str(incorrects.iloc[i]['Comparatives']))\n",
    "    print('superlatives: ' + str(incorrects.iloc[i]['Superlatives']))\n",
    "    print('digits: ' + str(incorrects.iloc[i]['Digits']))\n",
    "    print('NE: ' + str(incorrects.iloc[i]['Named Entities']))\n",
    "    print('Polarity2: ' + str(incorrects.iloc[i]['Polarity2']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "incorrects.to_csv('incorrects', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Up-sample Minority Class (Neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    191625\n",
       "0    191625\n",
       "Name: Rating, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "# Separate majority and minority classes\n",
    "df_majority = df2[df2.Rating==1]\n",
    "df_minority = df2[df2.Rating==0]\n",
    " \n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=len(df2[df2['Rating'] == 1]),    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    " \n",
    "# Display new class counts\n",
    "df_upsampled.Rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_upsampled.to_csv('Chi_NYC_LV_SF_features_1_upsampled', sep=',')\n",
    "df_upsampled = pd.read_csv('Chi_NYC_LV_SF_features_1_upsampled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.88\n",
      "Precision: 0.8899360543978015\n",
      "Recall: 0.8742126393022773\n",
      "[[50939  6248]\n",
      " [ 7269 50519]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.89      0.88     57187\n",
      "          1       0.89      0.87      0.88     57788\n",
      "\n",
      "avg / total       0.88      0.88      0.88    114975\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Scale data to determine feature importance\n",
    "y1 = df_upsampled.Rating\n",
    "X1 = df_upsampled[['Subjectivity', 'Word_Count', 'Named Entities', 'Polarity2',\n",
    "       'affect', 'cogproc','Helpful', 'city', 'Trauma','spatial', 'temporal', 'Third Person', 'Past Tense']]\n",
    "#scaler = RobustScaler()\n",
    "#scaler.fit(X1) \n",
    "#X_scaled1 = pd.DataFrame(scaler.transform(X1),columns = X1.columns)\n",
    "#X_scaled1.head()\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.3, random_state=0)\n",
    "logreg1 = LogisticRegression()\n",
    "logreg1.fit(X_train1, y_train1)\n",
    "y_pred1 = logreg1.predict(X_test1)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg1.score(X_test1, y_test1)))\n",
    "print(\"Precision:\",metrics.precision_score(y_test1, y_pred1))\n",
    "print(\"Recall:\",metrics.recall_score(y_test1, y_pred1))\n",
    "confusion_matrix1 = metrics.confusion_matrix(y_test1, y_pred1)\n",
    "print(confusion_matrix1)\n",
    "print(metrics.classification_report(y_test1, y_pred1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision: how accurate your model is. In other words, you can say, when a model makes a prediction, how often it is correct.\n",
    "\n",
    "Recall: if there are positive reviews in the test set, this Logistic Regression model can identify it 86% of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e42fe48>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_proba = logreg1.predict_proba(X_test1)[::,1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test1,  y_pred_proba)\n",
    "auc = metrics.roc_auc_score(y_test1, y_pred_proba)\n",
    "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUC score 1 represents perfect classifier, and 0.5 represents a worthless classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Down-sample Majority Class (Pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    25581\n",
       "0    25581\n",
       "Name: Rating, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_majority = df2[df2.Rating==1]\n",
    "df_minority = df2[df2.Rating==0]\n",
    " \n",
    "# Downsample majority class\n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                                 replace=False,    # sample without replacement\n",
    "                                 n_samples=len(df2[df2['Rating'] == 0]),     # to match minority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine minority class with downsampled majority class\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    " \n",
    "# Display new class counts\n",
    "df_downsampled.Rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_downsampled.to_csv('Chi_NYC_LV_SF_features_1_downsampled', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.87\n",
      "[[6764  897]\n",
      " [1041 6647]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.88      0.87      7661\n",
      "          1       0.88      0.86      0.87      7688\n",
      "\n",
      "avg / total       0.87      0.87      0.87     15349\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Scale data to determine feature importance\n",
    "y2 = df_downsampled.Rating\n",
    "X2 = df_downsampled[['Polarity2',\n",
    "       'Subjectivity', 'Word_Count',\n",
    "       'affect', 'cogproc','Helpful', 'city', 'Trauma','spatial', 'temporal']]\n",
    "#scaler = RobustScaler()\n",
    "#scaler.fit(X2) \n",
    "#X_scaled2 = pd.DataFrame(scaler.transform(X2),columns = X2.columns)\n",
    "#X_scaled2.head()\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.3, random_state=0)\n",
    "logreg2 = LogisticRegression()\n",
    "logreg2.fit(X_train2, y_train2)\n",
    "y_pred2 = logreg2.predict(X_test2)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg2.score(X_test2, y_test2)))\n",
    "confusion_matrix2 = metrics.confusion_matrix(y_test2, y_pred2)\n",
    "print(confusion_matrix2)\n",
    "print(metrics.classification_report(y_test2, y_pred2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>downsampled</th>\n",
       "      <th>feature</th>\n",
       "      <th>upsampled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.883631</td>\n",
       "      <td>13.886057</td>\n",
       "      <td>Polarity2</td>\n",
       "      <td>14.241190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.592882</td>\n",
       "      <td>7.658822</td>\n",
       "      <td>affect</td>\n",
       "      <td>10.908811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.909641</td>\n",
       "      <td>0.156299</td>\n",
       "      <td>Subjectivity</td>\n",
       "      <td>0.018235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.043231</td>\n",
       "      <td>0.144730</td>\n",
       "      <td>Trauma</td>\n",
       "      <td>0.163428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.004936</td>\n",
       "      <td>0.003402</td>\n",
       "      <td>Helpful</td>\n",
       "      <td>0.003504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.002226</td>\n",
       "      <td>-0.001712</td>\n",
       "      <td>Word_Count</td>\n",
       "      <td>-0.001490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.123513</td>\n",
       "      <td>-0.155762</td>\n",
       "      <td>spatial</td>\n",
       "      <td>-0.170837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.135268</td>\n",
       "      <td>-0.081760</td>\n",
       "      <td>temporal</td>\n",
       "      <td>-0.009513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.191004</td>\n",
       "      <td>-0.212751</td>\n",
       "      <td>city</td>\n",
       "      <td>-0.207429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.461960</td>\n",
       "      <td>-8.066941</td>\n",
       "      <td>cogproc</td>\n",
       "      <td>-10.250991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        coef  downsampled       feature  upsampled\n",
       "0  14.883631    13.886057     Polarity2  14.241190\n",
       "3   4.592882     7.658822        affect  10.908811\n",
       "1   0.909641     0.156299  Subjectivity   0.018235\n",
       "7   0.043231     0.144730        Trauma   0.163428\n",
       "5   0.004936     0.003402       Helpful   0.003504\n",
       "2  -0.002226    -0.001712    Word_Count  -0.001490\n",
       "8  -0.123513    -0.155762       spatial  -0.170837\n",
       "9  -0.135268    -0.081760      temporal  -0.009513\n",
       "6  -0.191004    -0.212751          city  -0.207429\n",
       "4  -5.461960    -8.066941       cogproc -10.250991"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs = logreg.coef_\n",
    "coefs1 = logreg1.coef_\n",
    "coefs2 = logreg2.coef_\n",
    "coef_df = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'coef': coefs[0],\n",
    "    'upsampled': coefs1[0],\n",
    "    'downsampled': coefs2[0]\n",
    "        \n",
    "    })\n",
    "coef_df.sort_values(by=['coef'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"Chi_NYC_LV_SF_features_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Adjectives</th>\n",
       "      <th>Adverbs</th>\n",
       "      <th>Comparatives</th>\n",
       "      <th>Superlatives</th>\n",
       "      <th>Digits</th>\n",
       "      <th>Nouns</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Polarity2</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>...</th>\n",
       "      <th>sad</th>\n",
       "      <th>cogproc</th>\n",
       "      <th>insight</th>\n",
       "      <th>cause</th>\n",
       "      <th>discrep</th>\n",
       "      <th>tentat</th>\n",
       "      <th>certain</th>\n",
       "      <th>differ</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Helpful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0.380651</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.608333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.450801</td>\n",
       "      <td>0.473750</td>\n",
       "      <td>0.936250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.43</td>\n",
       "      <td>1.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.497391</td>\n",
       "      <td>0.432812</td>\n",
       "      <td>0.618750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.67</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>0.429011</td>\n",
       "      <td>0.294643</td>\n",
       "      <td>0.503571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>0.343896</td>\n",
       "      <td>0.460159</td>\n",
       "      <td>0.604286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.22</td>\n",
       "      <td>2.22</td>\n",
       "      <td>2.22</td>\n",
       "      <td>2.22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Reviews  Adjectives  Adverbs  Comparatives  Superlatives  Digits  Nouns  \\\n",
       "0        1           6        0             0             0       0     21   \n",
       "1        2           8        2             0             0       2     16   \n",
       "2        3           7        3             0             0       1     11   \n",
       "3        4          10        8             1             0       2     38   \n",
       "4        5           6       10             0             0       2     29   \n",
       "\n",
       "   Polarity  Polarity2  Subjectivity   ...     sad  cogproc  insight  cause  \\\n",
       "0  0.380651   0.475000      0.608333   ...     0.0     3.39     0.00    0.0   \n",
       "1  0.450801   0.473750      0.936250   ...     0.0     9.43     1.89    0.0   \n",
       "2  0.497391   0.432812      0.618750   ...     0.0    10.67     0.67    4.0   \n",
       "3  0.429011   0.294643      0.503571   ...     0.0     8.00     0.00    0.0   \n",
       "4  0.343896   0.460159      0.604286   ...     0.0     6.67     0.00    0.0   \n",
       "\n",
       "   discrep  tentat  certain  differ  Rating  Helpful  \n",
       "0     0.00    0.00     1.69    1.69     1.0     20.0  \n",
       "1     0.00    1.89     0.00    7.55     1.0      8.0  \n",
       "2     0.00    2.00     2.67    2.00     0.0     20.0  \n",
       "3     3.00    1.00     2.00    2.00     1.0     15.0  \n",
       "4     2.22    2.22     2.22    2.22     1.0      0.0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "s = sns.barplot(x='feature', y='coef', data=coef_df)\n",
    "labels=['Adjectives', 'Adverbs', 'Comparatives', 'Superlatives', 'Digits',\n",
    "       'Nouns', 'Polarity', 'Polarity2', 'Subjectivity', 'Tense', 'Word Count',\n",
    "       'First Person', 'Named Entities', 'affect', 'posemo', 'negemo', 'anx',\n",
    "       'anger', 'sad', 'cogproc', 'insight', 'cause', 'discrep', 'tentat',\n",
    "       'certain', 'differ', 'Helpful']\n",
    "s.set_xticklabels(labels, rotation=15)\n",
    "s.set_title('Feature Importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Conditional Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cdf = pd.DataFrame()\n",
    "cdf['Adjectives'] = [1 if x >= 1 else 0 for x in df1['Adjectives']]\n",
    "cdf['Adverbs'] = [1 if x >= 1 else 0 for x in df1['Adverbs']]\n",
    "cdf['Comparatives'] = [1 if x >= 1 else 0 for x in df1['Comparatives']]\n",
    "cdf['Superlatives'] = [1 if x >= 1 else 0 for x in df1['Superlatives']]\n",
    "cdf['Digits'] = [1 if x >= 1 else 0 for x in df1['Digits']]\n",
    "cdf['Nouns'] = [1 if x >= 1 else 0 for x in df1['Nouns']]\n",
    "cdf['First Person'] = [1 if x >= 1 else 0 for x in df1['First Person']]\n",
    "cdf['Rating'] = df1['Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adjectives</th>\n",
       "      <th>Adverbs</th>\n",
       "      <th>Comparatives</th>\n",
       "      <th>Superlatives</th>\n",
       "      <th>Digits</th>\n",
       "      <th>Nouns</th>\n",
       "      <th>First Person</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Adjectives  Adverbs  Comparatives  Superlatives  Digits  Nouns  \\\n",
       "0           1        0             0             0       0      1   \n",
       "1           1        1             0             0       1      1   \n",
       "2           1        1             0             0       1      1   \n",
       "3           1        1             1             0       1      1   \n",
       "4           1        1             0             0       1      1   \n",
       "\n",
       "   First Person  Rating  \n",
       "0             0       1  \n",
       "1             0       1  \n",
       "2             0       1  \n",
       "3             0       0  \n",
       "4             0       1  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adv_count = len(cdf[(cdf['Adverbs']==1) & (cdf['Rating']==1)])\n",
    "adj_count = len(cdf[(cdf['Adjectives']==1) & (cdf['Rating']==1)])\n",
    "n_count = len(cdf[(cdf['Nouns']==1) & (cdf['Rating']==1)])\n",
    "fp_count = len(cdf[(cdf['First Person']==1) & (cdf['Rating']==1)])\n",
    "c_count = len(cdf[(cdf['Comparatives']==1) & (cdf['Rating']==1)])\n",
    "s_count = len(cdf[(cdf['Superlatives']==1) & (cdf['Rating']==1)])\n",
    "d_count = len(cdf[(cdf['Digits']==1) & (cdf['Rating']==1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ | Adverb: 0.9175\n",
      "+ | Adjective: 0.945\n",
      "+ | Nouns: 0.945\n",
      "+ | First Person Plural: 0.0\n",
      "+ | Comparatives: 0.15\n",
      "+ | Superlatives: 0.1525\n",
      "+ | Digits: 0.315\n"
     ]
    }
   ],
   "source": [
    "# Probability of Positive Given Presence of Type of wWrd\n",
    "print('+ | Adverb: ' + str(adv_count/len(cdf)))\n",
    "print('+ | Adjective: ' + str(adj_count/len(cdf)))\n",
    "print('+ | Nouns: ' + str(n_count/len(cdf)))\n",
    "print('+ | First Person Plural: ' + str(fp_count/len(cdf)))\n",
    "print('+ | Comparatives: ' + str(c_count/len(cdf)))\n",
    "print('+ | Superlatives: ' + str(s_count/len(cdf)))\n",
    "print('+ | Digits: ' + str(d_count/len(cdf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- | Adverb: 0.0825\n",
      "- | Adjective: 0.055\n",
      "- | Nouns: 0.055\n",
      "- | First Person Plural: 1.0\n",
      "- | Comparatives: 0.85\n",
      "- | Superlatives: 0.8475\n",
      "- | Digits: 0.685\n"
     ]
    }
   ],
   "source": [
    "# Probability of Neutral/Negative Given Presence of Type of wWrd\n",
    "print('- | Adverb: ' + str((len(cdf)-adv_count)/len(cdf)))\n",
    "print('- | Adjective: ' + str((len(cdf)-adj_count)/len(cdf)))\n",
    "print('- | Nouns: ' + str((len(cdf)-n_count)/len(cdf)))\n",
    "print('- | First Person Plural: ' + str((len(cdf)-fp_count)/len(cdf)))\n",
    "print('- | Comparatives: ' + str((len(cdf)-c_count)/len(cdf)))\n",
    "print('- | Superlatives: ' + str((len(cdf)-s_count)/len(cdf)))\n",
    "print('- | Digits: ' + str((len(cdf)-d_count)/len(cdf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in Subjectivity Lexicon - only strong subjectivity words\n",
    "#subjectivity_words = []\n",
    "#with open('strong_subjectivity.csv', 'r') as f:\n",
    "    #reader = csv.reader(f)\n",
    "    #for row in reader:\n",
    "        #subjectivity_words.append(row[0])\n",
    "\n",
    "# Read in dynamic adjectives\n",
    "#dynamic = []\n",
    "#with open('dynamic_adj.csv', 'r') as f:\n",
    "    #reader = csv.reader(f)\n",
    "    #for row in reader:\n",
    "        #dynamic.append(row[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
