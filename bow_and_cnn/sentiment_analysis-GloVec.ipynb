{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook implements the CNN-GloVec Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emmylau/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib as plt \n",
    "import glob\n",
    "from importlib import reload\n",
    "\n",
    "import os, sys, re, json, time, datetime, shutil\n",
    "from common import utils, constants, spell\n",
    "\n",
    "import tensorflow as tf\n",
    "import tripadvisor_ds\n",
    "import visualization\n",
    "\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except ModuleNotFoundError:\n",
    "    import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reload(tripadvisor_ds)\n",
    "\n",
    "input_length = 500\n",
    "max_bytes = 2**31 - 1\n",
    "\n",
    "data_file = 'data/tripadvisor_ds.pkl'\n",
    "\n",
    "if os.path.isfile(data_file):\n",
    "\n",
    "    bytes_in = bytearray(0)\n",
    "    input_size = os.path.getsize(data_file)\n",
    "    with open(data_file, 'rb') as f_in:\n",
    "        for _ in range(0, input_size, max_bytes):\n",
    "            bytes_in += f_in.read(max_bytes)\n",
    "    ds = pickle.loads(bytes_in)\n",
    "        \n",
    "else:\n",
    "    ds = tripadvisor_ds.TripAdvisor_DS().process(input_length=input_length)\n",
    "    ds.save(data_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    413463\n",
       "2    231827\n",
       "1    106079\n",
       "0     90053\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.DataFrame({'rating': ds.train_labels})\n",
    "labels.rating.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set up model Configuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_params = dict(V=ds.vocab.size, \n",
    "                    embed_dim=100, \n",
    "                    num_classes=len(ds.target_labels),\n",
    "                    encoder_type='cnn', \n",
    "                    filter_sizes = [2,3,4,5], \n",
    "                    num_filters=128, \n",
    "                    hidden_dims=[1024, 64], \n",
    "                    input_length=input_length,\n",
    "                    dropout_rate=0.5,\n",
    "                    lr=0.00001, \n",
    "                    optimizer='adam', \n",
    "                    beta=0.00001)\n",
    "                    \n",
    "train_params = dict(batch_size=64, \n",
    "                    total_epochs=20, \n",
    "                    eval_every=2)\n",
    "\n",
    "\n",
    "\n",
    "summary_params = dict(chkpt_dir=\"./tmp/266_cnn_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if os.path.isdir(summary_params['chkpt_dir']):\n",
    "    shutil.rmtree(summary_params['chkpt_dir'])\n",
    "\n",
    "def variable_summaries(var):\n",
    "    \"\"\"Attach a lot of summaries to a Tensor (for TensorBoard visualization).\"\"\"\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean', mean)\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "        tf.summary.scalar('stddev', stddev)\n",
    "        tf.summary.scalar('max', tf.reduce_max(var))\n",
    "        tf.summary.scalar('min', tf.reduce_min(var))\n",
    "        tf.summary.histogram('histogram', var)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Read GloVec Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marrtiott\n",
      "fantastis\n",
      "zenshin\n",
      "modeern\n",
      "rntal\n",
      "annbiversary\n",
      "ift18\n",
      "eugyl/nancy\n",
      "modern-check\n",
      "closet-like\n",
      "subway/l\n",
      "disapporinting\n",
      "mommy-daddy\n",
      "üöø\n",
      "schi\n",
      "best..\n",
      "deliveri\n",
      "pub/hotel\n",
      "uncomfor\n",
      "laser-focused\n",
      "circ-de-sol\n",
      "hasile\n",
      "mouses/rats\n",
      "33w\n",
      "options-\n",
      "location-easy\n",
      "engageme\n",
      "DG-DG.\n",
      "ok.we\n",
      "story.i\n",
      "amertania\n",
      "bellegio\n",
      ".slighty\n",
      "atmosphere.we\n",
      "perfextion\n",
      "joine\n",
      "◊ß◊©◊ï◊ë\n",
      "imponent\n",
      ".essence\n",
      "barmtzvah\n",
      "responsivenes\n",
      "seminarfest\n",
      "maintained.or\n",
      "timein\n",
      "'curio\n",
      "rooms.i\n",
      "ÌïòÍ≥†Ïã∂ÏäµÎãàÎã§.Ìï≠Í≥µÏÇ¨Ïùò\n",
      "unglaublich\n",
      "awesome..definitely\n",
      "gal-friend\n",
      "kimpton48\n",
      "heritag\n",
      "over-pr\n",
      "chargesd\n",
      "go-round\n",
      "\\nsave\n",
      "c-mas\n",
      "janowiak\n",
      "aaaahhhhhhh\n",
      "stylemore\n",
      "nickel-an\n",
      "2brs\n",
      "visit.i\n",
      "physion\n",
      "timesquare\n",
      "wonderdust\n",
      "bucchanal\n",
      "stre\n",
      "terrace-tastic\n",
      "distriikt\n",
      "price/nice\n",
      "recomment\n",
      "spaciosus\n",
      "5-ni\n",
      "ÿ±ÿßÿ¶ÿπ\n",
      "glitche\n",
      "place-sorta\n",
      "sensat\n",
      "propertygreat\n",
      "fitout\n",
      "plus.ac\n",
      "'funky\n",
      "bugs-\n",
      "farewel\n",
      "re~model\n",
      "staff.disa\n",
      "hipsteville\n",
      "vrooommm\n",
      "conveinant\n",
      "hotel.gr\n",
      "argonaunt\n",
      "kesly\n",
      "..big\n",
      ".fresh\n",
      "w/teens\n",
      "non-entertainment\n",
      "housekeeping/maintenance\n",
      ".adorable\n",
      "guarantiees\n",
      "11th-12\n",
      "staff/location/creature\n",
      "confortafle\n",
      "riving\n",
      "sahhh\n",
      "obnoxi\n",
      "169/nig\n",
      "johnson..\n",
      "player-friendly\n",
      "terribile\n",
      "4nigh\n",
      ".all\n",
      "accomondate\n",
      ".i\n",
      "travlers\n",
      "hotels.com/horr\n",
      "disappointed-\n",
      "aftersales\n",
      "oneclose\n",
      "woww\n",
      "restura\n",
      "reviews..but\n",
      "djalali\n",
      "suitca\n",
      "weekene\n",
      "compensat\n",
      "amaziiiiiiiiiinnnnnnngggggggg\n",
      "bad/\n",
      "this-\n",
      "bdrm\n",
      "requis\n",
      "gopez\n",
      "there-nothing\n",
      "undisc\n",
      "awesum\n",
      "hbcubizdean\n",
      "fiaher\n",
      "flawles\n",
      "perfectl\n",
      "pridessional\n",
      "gregreat\n",
      "great.service\n",
      "nighttim\n",
      "square..\n",
      "wld\n",
      "m.bello\n",
      "jennifer~\n",
      "eco-fri\n",
      "radisson-martinique\n",
      "tjiis\n",
      "long-tim\n",
      "conforence\n",
      "'everything\n",
      "relativly\n",
      "hotel/vibe\n",
      "wors\n",
      "selli\n",
      "28-may2\n",
      "conference-type\n",
      "Âì°Â∑•ÈùûÂ∏∏ÂèãÂñÑÔºåÂú∞ÈªûÈÇÑÁÆó‰∏çÈåØ\n",
      "dee-lightful\n",
      "unaccept\n",
      "event/business\n",
      "neg-\n",
      "sibelia\n",
      "plac3s\n",
      ".fir\n",
      "moovie\n",
      "square/shopping\n",
      "baxk\n",
      "small-space\n",
      "stay-fabulous\n",
      "wonferful\n",
      "meridi\n",
      "kcrowley\n",
      "hayalkƒ±rƒ±klƒ±ƒü\n",
      "‚Ä¢great\n",
      "fiezennia\n",
      "slow/bad\n",
      "location.customer\n",
      "find..\n",
      "again..good\n",
      "deal.great\n",
      "vertig\n",
      "people-need\n",
      "embarrasi\n",
      "sflocation\n",
      "cococure\n",
      "underluxed\n",
      "12-year-\n",
      "buleva\n",
      "service/great-sized\n",
      "totalrewards\n",
      "fetullah\n",
      "blackja\n",
      "optoon\n",
      "vegas.all\n",
      "flamingo-our\n",
      "cleaned.house\n",
      "perto\n",
      "overprized\n",
      "noisest\n",
      "defe\n",
      "üè©üè´üïå‚õ™Ô∏èüïçüì∏üì∑\n",
      "üí∞\n",
      "aom-2018\n",
      "poopie\n",
      "primari\n",
      "lies‚Ä¶.\n",
      "sicolo\n",
      "location.close\n",
      "spaciousw\n",
      "sqeaky\n",
      "room-upgrade-waste\n",
      "superl\n",
      "bedroom/on\n",
      "chicago~\n",
      "ago-sad\n",
      "hote.\n",
      "eve/day\n",
      "staff.big\n",
      "dad,18\n",
      "travelogue-san\n",
      "uncl\n",
      "radissonblu\n",
      "unpleased\n",
      "tuesday-friday\n",
      "suites-\n",
      "fantastic.the\n",
      "priced/noisy\n",
      "four-nig\n",
      "announc\n",
      "moonrunners\n",
      "excellent..just\n",
      ".convenient\n",
      "vegas.first\n",
      "dicoit\n",
      "hungrey\n",
      "satisfied.from\n",
      "couli\n",
      "rediculosly\n",
      "microliving\n",
      "piazz\n",
      "effort-\n",
      "hostil\n",
      "it.my\n",
      "terrece\n",
      "myfriends\n",
      "luxury/comfort/quality/service\n",
      "thisxhotel\n",
      "layove\n",
      "breakf\n",
      "blackstone-palooza\n",
      "off/strip\n",
      "'vacat\n",
      "service-minded\n",
      "screws/no\n",
      "-classy\n",
      "quinessential\n",
      "layou\n",
      "conclus\n",
      "excellet\n",
      "charming/retro\n",
      "terrible.so\n",
      "DGDGDG*\n",
      "granddaughter/family\n",
      "not-so-magnificent\n",
      "friends..\n",
      "nice.th\n",
      "Î∞îÎÄå\n",
      "valeting\n",
      "room-was\n",
      "clusterf*\n",
      "asthetics\n",
      "rasied\n",
      "rooms-wors\n",
      "usal\n",
      "sub-p\n",
      "enjoyes\n",
      "outdated-i\n",
      "-tourist\n",
      "manhatan\n",
      "caint\n",
      "injoye\n",
      "emipre\n",
      "non-exist\n",
      "gov't\n",
      "desireabl\n",
      "evelators\n",
      "business/pleasure\n",
      "fashionabl\n",
      "clean.no\n",
      "resort|\n",
      "excellenct\n",
      "serg\n",
      "chantay386\n",
      "-friendly\n",
      "guellin\n",
      "daddy-daughter\n",
      "1st-class\n",
      "websi\n",
      "budget-chic\n",
      "oozin\n",
      "-currently\n",
      "friends/family\n",
      "awefully\n",
      "caeasar\n",
      "affordableprice\n",
      "hgits\n",
      "zuribel\n",
      "DGDGDGDG/\n",
      "unsuspectin\n",
      "DGDG.DGDG.DGDGDGDG\n",
      "fantasticconfort\n",
      "openin\n",
      "assessa\n",
      "flemingo\n",
      "disappointed.i\n",
      "mmmh\n",
      "property..just\n",
      "one..the\n",
      "locationvery\n",
      "visib\n",
      "wolcot\n",
      "oct.2014\n",
      "markettin\n",
      "ccommodations\n",
      "my2cents\n",
      "ok-nothing\n",
      "awesome‚ù§Ô∏èlocation-perfect\n",
      "hinton/russel\n",
      "criteri\n",
      "gwen‚Ä¶\n",
      "worse..\n",
      "birthdaystay\n",
      "ny-business\n",
      "discrim\n",
      ".pass\n",
      "car-close\n",
      "hotelk\n",
      "backi\n",
      "inconve\n",
      "productivi\n",
      "alllowance\n",
      "percection\n",
      "peeceful\n",
      "rrhof\n",
      "found..ha\n",
      "doubl\n",
      "souvenier\n",
      "concier\n",
      "quality/\n",
      "lobby/lounge/bar\n",
      "rownyc\n",
      "Ï¢ãÏïÑÏöî~~\n",
      "unab\n",
      "oase\n",
      "prequalify\n",
      "overw\n",
      "2016..after\n",
      "fun/chic/modern\n",
      "ninete\n",
      "hurrica\n",
      "restaurants.sta\n",
      "awssome\n",
      "-extremely\n",
      "86'ed\n",
      "room.amazing\n",
      "detai\n",
      "*sigh*\n",
      "impers\n",
      "fransic\n",
      "vidit\n",
      "firestation\n",
      "panoram\n",
      ".phyllis\n",
      "cutes\n",
      "careful-\n",
      "regancy\n",
      ".such\n",
      "staffgre\n",
      "daytoneljo\n",
      "overdu\n",
      "casino..a\n",
      "smokiest\n",
      "ü§¢üò∑\n",
      "formulatic\n",
      "time‚Äîstill\n",
      "*reviewing\n",
      "..second\n",
      "winter/christmas\n",
      "rhym\n",
      "amazibg\n",
      "gagliot\n",
      "iawn/very\n",
      "the.best.ever\n",
      "favority\n",
      "*my*\n",
      "stay‚Ä¶for\n",
      "newly-refurb\n",
      "harrah's-center\n",
      "..long\n",
      "..splurge\n",
      "cramped-\n",
      "room/enjoyable\n",
      "amzzing\n",
      "wynn-ing\n",
      "room/tired\n",
      "wedding‚Äîclean\n",
      ".cost\n",
      "augost\n",
      "-of\n",
      "/liers\n",
      "works.a\n",
      "opte\n",
      "jits\n",
      "'to\n",
      "inatt\n",
      "pamp\n",
      "everythingnice\n",
      "day/3\n",
      "comftarble\n",
      ".tahiti\n",
      "class/school\n",
      "hrlv\n",
      "always..\n",
      "southstreet\n",
      "bavette\n",
      "midtownüòäüòäüòäüòäüòäüòäüòäüòä\n",
      "admiror\n",
      "quietud\n",
      "afrop\n",
      "dustrict\n",
      "epic-ness\n",
      "inexspensive\n",
      ".select\n",
      "beond\n",
      "üåã\n",
      "dontgo\n",
      "location..it\n",
      "eugy\n",
      "suite-resort\n",
      "nearnes\n",
      "wow.we\n",
      "bcz\n",
      "re-f\n",
      "ÔΩÖÔΩåÔΩâÔΩöÔΩÅÔΩÇÔΩÖÔΩîÔΩà\n",
      "roomexcellent\n",
      "omnish\n",
      "perfectits\n",
      "no-where\n",
      "expurience\n",
      "hotel/customer\n",
      "strip.c\n",
      "dreadfu\n",
      "anonym\n",
      "emonjel\n",
      "pizz\n",
      "semitranslu\n",
      "northamerica\n",
      "greatb\n",
      "york/manhattan-m\n",
      "product..\n",
      "high-rolling\n",
      "lightin\n",
      "locatopn\n",
      "accordingky\n",
      "poor..tim\n",
      "ogne\n",
      "overwhelmi\n",
      "hyatt48lex\n",
      "re-visiting\n",
      "sfmarquis\n",
      "clean/eco\n",
      "huuuuuuge\n",
      "◊û◊ï◊û◊ú◊•\n",
      "-ever\n",
      "apt.was\n",
      "'times\n",
      "definitio\n",
      "experience/sub-par\n",
      "m√©diocre\n",
      "pied-√†-terre\n",
      "unsatisfi\n",
      "okay..bu\n",
      "berksh\n",
      "best‚óædescribe\n",
      "boxin\n",
      "*do\n",
      "super-f\n",
      "price/quality/location\n",
      "all.g\n",
      "excelsi\n",
      "plumbi\n",
      "surfa\n",
      "satisfie\n",
      "hallways..but\n",
      "place.l\n",
      "wfficient\n",
      "qwerky\n",
      "excpected\n",
      "stay..centrally\n",
      "here***spoil\n",
      "thousa\n",
      "convienet\n",
      "8.30pm\n",
      "bussines\n",
      "surpisingly\n",
      "aug/\n",
      ".surprise\n",
      ".last\n",
      "jane/wacky\n",
      "location/perfect\n",
      "beautfu\n",
      "buzzling\n",
      "awesone\n",
      "wellwe\n",
      "fianc√©es\n",
      "january2016\n",
      "vegas/upgrades\n",
      "debit/cc\n",
      "getaway/friends\n",
      "stuffe\n",
      "stayh\n",
      "turism\n",
      "unacc\n",
      "sf-accessibel\n",
      "getaway/wedding\n",
      "unnotified\n",
      "witforaqueen\n",
      "infountain\n",
      "tricksy\n",
      "jeoff\n",
      "baymon\n",
      "here-\n",
      "..everyo\n",
      "rio-always\n",
      "delivere\n",
      "itwas\n",
      "expctations\n",
      "buzziest\n",
      "overbookings\n",
      "back..the\n",
      "attat\n",
      "formatio\n",
      "wifee\n",
      "workd\n",
      "acciden\n",
      "sleep-ever\n",
      "comfoetable\n",
      "yorkj\n",
      "ave/northwestern\n",
      "excaliber\n",
      "misconce\n",
      "torturous.\n",
      "home-feel\n",
      "projectil\n",
      "sadl\n",
      "warinng\n",
      "perfectlodging\n",
      "porximity\n",
      "avoide\n",
      "share/frac\n",
      "post-remodel\n",
      "granse\n",
      "jayms\n",
      "emai\n",
      "mid-stri\n",
      "soloyolo\n",
      "w/senior\n",
      "evwr\n",
      "runni\n",
      "spontaneou\n",
      "back-\n",
      "√ºbernachtungshotel\n",
      "disspointing\n",
      "attractivel\n",
      "satisfacto\n",
      "faciliites\n",
      "pgon\n",
      "luxor-the\n",
      "business/21st\n",
      "peoplewe\n",
      "accommodations-\n",
      "thabk\n",
      "experiencew\n",
      "pyramidizzed\n",
      "w/\n",
      "fitzpa\n",
      "verything\n",
      "roomwas\n",
      "conference.wow\n",
      "transa\n",
      "srayed\n",
      "downtown/financial\n",
      "awesomeee\n",
      "3-days\n",
      "sux\n",
      "cashe\n",
      "chicago/u\n",
      ".prime\n",
      "rinnovato\n",
      "DG-DGDGDGDG\n",
      "hotel-fun\n",
      "inroom\n",
      "peopleafter\n",
      "DG-DG.DG\n",
      "wifer\n",
      "caf√©/bar\n",
      "underdeliver\n",
      "DGDG-DGDGDG-DGDGDG-DGDGDGDG\n",
      "..a\n",
      ".choose\n",
      "asbolutely\n",
      "payout..overall\n",
      "-average\n",
      "calmi\n",
      "underimpressed\n",
      "luxu\n",
      "8:30am\n",
      "bachel\n",
      "'owners\n",
      "incomp\n",
      "hotelis\n",
      "stayf\n",
      "blvd-\n",
      "DG*****\n",
      "dingy.our\n",
      "hotel.what\n",
      "foosevelt\n",
      "ballys-there\n",
      "cortez-\n",
      "=musty\n",
      "non-r\n",
      "üóëdirty.we\n",
      "gem-tuscan\n",
      "check-in/checkout\n",
      "tucked-away\n",
      "bucket-\n",
      "peopl\n",
      "recommend.nice\n",
      "enjyed\n",
      "leag\n",
      "essenti\n",
      "avaerage\n",
      "fenomenal\n",
      "weekeend\n",
      "englishe\n",
      "cockt\n",
      "conventi\n",
      "edesign\n",
      "waitlines\n",
      "supeb\n",
      "vegassss\n",
      "niec\n",
      "stay/very\n",
      "vegas/birthday\n",
      "hiwe\n",
      "w26th\n",
      "breifly\n",
      "beautfiul\n",
      "hill-\n",
      "midni\n",
      "strip/check-in\n",
      "shld\n",
      "scombroid\n",
      "shabby..\n",
      "pre-vacay\n",
      "price..clean\n",
      "ÂâçÂè∞Êé•ÂæÖÂæàÁÉ≠ÊÉÖÔºåÊúçÂä°ÂæàÂ•ΩÔºåÊàøÈó¥Â∫äÈì∫ÊØèÂ§©ÈÉΩÊç¢ÔºåÊúçÂä°‰∫∫ÂëòÈÉΩÂæàÁÉ≠ÊÉÖ\n",
      "revisting\n",
      "impressionw\n",
      "selecte\n",
      "cubs-\n",
      "DGDG-DGDG-DGDG\n",
      "declans\n",
      "potenti\n",
      "-renovations\n",
      "suprer\n",
      "nclex\n",
      "perfectüòÑüëç\n",
      "infustion\n",
      "..really\n",
      "ball'y\n",
      "sfayted\n",
      "'staying\n",
      "backf\n",
      "hotel/casino\n",
      "straf\n",
      "yuge\n",
      "near-perf\n",
      "prosstayed\n",
      ".hmmmm\n",
      "may5-6/2018\n",
      "view..great\n",
      "midtown-t\n",
      "over-charging\n",
      "bdwy\n",
      "someon\n",
      "guess..\n",
      "h.s.reunion\n",
      "ceme\n",
      "business-pleasure\n",
      "location/dated\n",
      "location-friendly\n",
      "nocal\n",
      "moneyhe\n",
      "-stay\n",
      "rude/unhelpful\n",
      "fairfields\n",
      "timless\n",
      "insuite\n",
      "visit‚Äîsurpassed\n",
      "stay/hotel\n",
      "strip-suite\n",
      "foole\n",
      "w/coworkers\n",
      "re-do\n",
      "'rocking'at\n",
      "last-mi\n",
      "day+\n",
      "nonono\n",
      "stay..a\n",
      "internet/wifi\n",
      "choice.ac\n",
      "ttay\n",
      "managmen\n",
      "odd-\n",
      "perk-up\n",
      "get-a-\n",
      "horific\n",
      "DG/DG-\n",
      "dooper\n",
      "priceline/agoda\n",
      "brand.friendly\n",
      "great~~~~\n",
      "fambam\n",
      "enjoysble\n",
      "orgenized\n",
      "zipli\n",
      "pripert\n",
      "dissatisfied/disappointment\n",
      "junk/go\n",
      "s**t\n",
      "boooked\n",
      "iland/and\n",
      "st.francis\n",
      "stafc\n",
      "best..but\n",
      "excellentdow\n",
      "bluegree\n",
      "w/drawbacks\n",
      "touristland\n",
      "chirstmas\n",
      "-nice\n",
      "decipeve\n",
      "stay.great\n",
      "jav\n",
      "price/small\n",
      "calue\n",
      "prere\n",
      "rooms/great\n",
      "lannett\n",
      "toddlerville\n",
      "9/10room\n",
      "disabi\n",
      "jubile\n",
      "velet\n",
      "here-pick\n",
      "DG-DG/DG\n",
      "iocationeasy\n",
      "ever..\n",
      "stylereview\n",
      "intere\n",
      "oldloca\n",
      "sophtisicated\n",
      "inly\n",
      "lollapolooza\n",
      "location-wise\n",
      "finess\n",
      "/check\n",
      "shantelle\n",
      "mega-\n",
      "depressi\n",
      "so-hi\n",
      "alljust\n",
      "helpfuln\n",
      "DGDG/DGDGüòÑüòé\n",
      "stude\n",
      "estandby\n",
      "amoma.com\n",
      "'if\n",
      "cancelle\n",
      "beds/\n",
      "'ol\n",
      "updating.no\n",
      "'staycation\n",
      "brequ\n",
      "vizient\n",
      "teribble\n",
      "okay-elevators\n",
      "december/holiday\n",
      "weekend/\n",
      "compact..by\n",
      "roblem\n",
      "just-right\n",
      "crazin\n",
      "bobgeri\n",
      "perfer\n",
      "days.there\n",
      "propwrty\n",
      "primar\n",
      "outstanding.everyth\n",
      "blue/chicago\n",
      "poor..\n",
      "non-hotel\n",
      "subway-\n",
      "concer\n",
      "gansevoorthotel\n",
      "couldd\n",
      "rockefel\n",
      "zubietha\n",
      "handy.the\n",
      "***************************nicely\n",
      "food/beverage\n",
      "vegasstay\n",
      "familygood\n",
      "stqay\n",
      "pleasantlysurprised\n",
      "handerly\n",
      "service.as\n",
      "meanin\n",
      "myharrahs\n",
      "sigston\n",
      "non-tourist\n",
      "splender\n",
      "servivice\n",
      "eiffle\n",
      "/conferences\n",
      "fabulous.g\n",
      "employe\n",
      "sticke\n",
      "designe\n",
      "casono\n",
      "aweeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeeesome\n",
      "casers\n",
      "feather-free\n",
      "boarderline\n",
      "nights.boo\n",
      "propertie\n",
      "disapointm\n",
      "niceee\n",
      "stratosphe\n",
      "uniquie\n",
      "stylemax\n",
      "hackin\n",
      "airport/\n",
      "sumptious\n",
      "fwiw\n",
      "highest-end\n",
      "says..\n",
      "thisbhostel\n",
      "relevan\n",
      "-visit\n",
      "regeny\n",
      "slippe\n",
      "chicagos\n",
      "directi\n",
      "peoples-pugh\n",
      "icrs\n",
      "great.cl\n",
      "pleanty\n",
      "gratuation\n",
      "incor\n",
      "l-vegas\n",
      "..almost\n",
      "parents-\n",
      "presdidio\n",
      "sist\n",
      "work.showe\n",
      "smoking1\n",
      "landscapin\n",
      "unli\n",
      "nthe\n",
      "intersting\n",
      "montoto\n",
      "propertys\n",
      "unexceptible\n",
      "arrog\n",
      "toght\n",
      "glitte\n",
      "vegasstrip\n",
      "room/shower\n",
      "bizniss\n",
      "overall.got\n",
      "drun\n",
      "airpot\n",
      "sashika\n",
      "beefea\n",
      "'go-to\n",
      "contempor\n",
      "aaaahhh\n",
      "atrociooa\n",
      "üé∞\n",
      "days.convenient\n",
      "centrall\n",
      "jetto\n",
      "'superbowl\n",
      "lost/found\n",
      "-sat\n",
      ".mgm\n",
      "check-in..long\n",
      "srat\n",
      "Îòê\n",
      "perrrrrrfect\n",
      "anmeties\n",
      "perfefect\n",
      "exceptonal\n",
      "tiny/nonexistent\n",
      "ubica\n",
      "tabulous\n",
      "tourniment\n",
      "up-t\n",
      "comfortable.bed\n",
      "fabulo\n",
      "cozt\n",
      "inexp\n",
      "waitresse\n",
      "d-bay\n",
      "ronh\n",
      "fromtower\n",
      "wed.-sun\n",
      "boulvard\n",
      "thusrday\n",
      "rocha¬¥s\n",
      "mg1403\n",
      "terrac\n",
      "difficu\n",
      "non-drinker/g\n",
      "20-24th\n",
      "varioety\n",
      "stay..i\n",
      "cleanlin\n",
      "missing/stolen\n",
      "luxiousness\n",
      "—Å–µ–±–µ\n",
      "metopera\n",
      "cocktai\n",
      "rissec\n",
      "kawanna\n",
      "deliberat\n",
      "mmile\n",
      "signaturehad\n",
      "himy\n",
      "gallivant\n",
      "flamingo.noth\n",
      "misun\n",
      "radisso\n",
      "**room\n",
      "stayüòÄ\n",
      "terrbile\n",
      "pre-teens/teens\n",
      "non-care\n",
      "trainstation\n",
      "plasant\n",
      "solie-\n",
      ".up\n",
      "hotel/nyc\n",
      "excleent\n",
      "only-\n",
      "frequen\n",
      "friendly-even\n",
      "1ni\n",
      "heber-taylor\n",
      "rattlin\n",
      "trustable\n",
      "northalsted\n",
      "powerhoue\n",
      "hotel.classy\n",
      "nyc/nj\n",
      "oldf\n",
      "appoi\n",
      "trip-\n",
      "revita\n",
      "expwerience\n",
      "tried-out\n",
      "hadmy\n",
      "'off\n",
      "pre-check-in\n",
      "excedded\n",
      "personablely\n",
      "finsherman\n",
      "rest-rants\n",
      "expectatives\n",
      "üéäüéä\n",
      "ÿ¨ŸÖŸäŸÑ\n",
      "instructio\n",
      "peefect\n",
      "changedüò¢\n",
      "hiliday\n",
      "destinatio\n",
      "locaties\n",
      "pariee\n",
      "22n\n",
      "expactations\n",
      "followi\n",
      "hotel/ti\n",
      "chelan1969\n",
      "un-ritzy\n",
      "paris/ca\n",
      "mellennium\n",
      "check-in/c\n",
      "lakefron\n",
      "uprade\n",
      "restraunts\n",
      "wondurful\n",
      "senaka\n",
      "re-review\n",
      "onestream\n",
      "-f\n",
      "inconsis\n",
      "thanks..\n",
      "..too\n",
      "rollaway\n",
      "fimest\n",
      "location/decent\n",
      "delano.this\n",
      "needs-\n",
      "professionall\n",
      "guest_\n",
      "luxor..\n",
      "audr\n",
      "surprise+delight\n",
      "eventhoug\n",
      "experience.onl\n",
      "3time\n",
      "stratoshpere\n",
      "aaro\n",
      "cleaneless\n",
      "show..\n",
      "boulv\n",
      "locagtion\n",
      "splur\n",
      "wacations\n",
      "optim\n",
      "plen\n",
      "resory\n",
      "tebroglio\n",
      "everithing\n",
      "marakech\n",
      "priced-right\n",
      "hliton\n",
      "everroom\n",
      "york/tribeca\n",
      "maraige\n",
      "disappointed‚Ä¶\n",
      "september.room\n",
      "well-pric\n",
      "fianc√©s\n",
      "Ïû•Ï†êÏûÖÎãàÎã§\n",
      "dissapointimng\n",
      "lnto\n",
      "recimmended\n",
      "ÿ¨ŸäÿØ\n",
      "eddys\n",
      "'fremo\n",
      "hotel.that\n",
      "pros:2\n",
      "highw\n",
      "exlusive\n",
      "alysson\n",
      "friendcation\n",
      "thetop\n",
      "boutique-type\n",
      "well-appoi\n",
      "station/msg\n",
      "telephon\n",
      "-quick\n",
      "amaziing\n",
      "service.all\n",
      "upgrad\n",
      "value-excellent\n",
      "adreanne\n",
      "homelyexcelle\n",
      "acti\n",
      "price.th\n",
      ".interesting\n",
      "pool/outdoor\n",
      "enjy\n",
      "hotel‚Ä¶great\n",
      "e=be\n",
      "plantet\n",
      "orary\n",
      "sloooooooow\n",
      "10hr\n",
      "placet\n",
      "temperatur\n",
      "3rd-7th\n",
      "hotel/staff/location\n",
      "tumps\n",
      "park/bucktown\n",
      "gusmary\n",
      "room/apartment\n",
      "Í∞ùÏã§\n",
      "tonsilectomy\n",
      "throu\n",
      "controlle\n",
      "-left\n",
      "is/\n",
      "inprovements\n",
      "lonunge\n",
      "‚Äìlas\n",
      "vacatione\n",
      "rated-\n",
      "üóΩ*\n",
      "'upgraded\n",
      "bare-minimum\n",
      "unreliabl\n",
      "pergatory\n",
      "s.f.gaints\n",
      "st.paddys\n",
      "fridge/\n",
      "vacum\n",
      "actitude\n",
      "non-refu\n",
      "non-smoking/non-gambling\n",
      "kimberl\n",
      "center/hos\n",
      "location..average\n",
      "quic\n",
      "extrenely\n",
      "cowork\n",
      ",shopping\n",
      "litlle\n",
      "nights.loca\n",
      "desorganized\n",
      "fieris\n",
      "bbqin\n",
      "cupboar\n",
      "accep\n",
      "bathroom.outdated\n",
      "experience/good\n",
      "roach/bed\n",
      "unfo\n",
      "general.pros\n",
      "sanfra\n",
      "rock-n-royalty\n",
      "w/kids\n",
      "kickerbo\n",
      "cheerfull\n",
      "wowi\n",
      "cleanbut\n",
      "superb..\n",
      "uswt\n",
      "rentet\n",
      "locatioon\n",
      "buttross\n",
      "unconfortab\n",
      "g.m\n",
      "pleaze\n",
      "elyse√®\n",
      "feb.2018\n",
      "here..gorgeous\n",
      "shower-bunga\n",
      "good1\n",
      "ahea\n",
      "vicin\n",
      "locacation\n",
      "staff-clean\n",
      "landmar\n",
      "chaicago\n",
      "belongin\n",
      "rocketts\n",
      "company/team\n",
      "concierges/slowwwww\n",
      "sofa-bed\n",
      "bar/food\n",
      "cntr\n",
      "mwahhhh\n",
      "superbl\n",
      "choice-great\n",
      "weekens\n",
      "juob\n",
      "fly2907\n",
      "eeeeh\n",
      "espeically\n",
      "tradittional\n",
      "flati\n",
      "gracio\n",
      "clev\n",
      "updated/\n",
      "staryed\n",
      "leisurr\n",
      "conferences/business\n",
      "dodgers-mets\n",
      "pverall\n",
      "DG-DG/\n",
      "bufffet\n",
      "amazing.our\n",
      "staff/\n",
      "hotel..across\n",
      "time..prop\n",
      "locatoin1\n",
      "chicago\\nmia\n",
      "woundconvention\n",
      "expecte\n",
      "dis-gus-ting\n",
      "nine-y\n",
      "vibe-exciting\n",
      "underloved\n",
      "cute/girl\n",
      "moldly\n",
      "whils\n",
      "daugthe\n",
      "consservice\n",
      "freeeeeee\n",
      "ktichenette\n",
      "hilton-points\n",
      "old/historic\n",
      "midtown.while\n",
      "christkindlmarket\n",
      "hotelc\n",
      "ipanama\n",
      "flamingo-below\n",
      "350/nightly\n",
      ",the\n",
      "ohhhhhh\n",
      "stains.\n",
      "decent-harassment\n",
      "review-great\n",
      "recept\n",
      "9:30am\n",
      "exhibite\n",
      "farfield\n",
      "wyhdham\n",
      "belligo\n",
      "apprec\n",
      "disguis\n",
      "atmostphere\n",
      "off-off-off\n",
      "un-clean\n",
      "positives/\n",
      "-tom\n",
      "Í≥µÌï≠\n",
      "ups/some\n",
      "sooooo..much\n",
      "alternativ\n",
      "exciti\n",
      "direc\n",
      "pictur\n",
      "oxcarol\n",
      "sloooow\n",
      "preauthorizati\n",
      "2326.i\n",
      "auto-show\n",
      "rentals-wynn\n",
      "staff/personal\n",
      "walked.i\n",
      "desk=awesome\n",
      "qaulity\n",
      "arrival..\n",
      "nsiki\n",
      "husband/\n",
      "steinmiller\n",
      "womderful\n",
      "inn.it\n",
      "caisers\n",
      "birthday/american\n",
      "wro\n",
      "üòã\n",
      "non-thematic\n",
      "slowww/\n",
      "comfrotabl\n",
      "masqueradi\n",
      "-well\n",
      "conceirg\n",
      "attactions\n",
      "'ghastly\n",
      "lascvegas\n",
      "tsunezumi\n",
      "dissapoined\n",
      "pickwi\n",
      "tumbl\n",
      "4:00pm\n",
      "ultra-cool\n",
      "cleanliest\n",
      "unforgett\n",
      "hyatt-grand\n",
      "fun..\n",
      "employees..easy\n",
      "fhey\n",
      "nyc..\n",
      "enviroment/dining\n",
      "hayde\n",
      "lowsy\n",
      "4xs\n",
      "turistic\n",
      "suites.very\n",
      "reasonably-price\n",
      "double-charged\n",
      "demog\n",
      "pyriamid\n",
      "mis-selling\n",
      "out-of-sta\n",
      "fantatic\n",
      "amazzzinnnngggg\n",
      "inpu\n",
      "manhattan/united\n",
      "glamurous\n",
      "bassic\n",
      "bed/\n",
      "frus\n",
      "jendy\n",
      "day‚òòÔ∏è\n",
      "nyc‚ù§Ô∏è\n",
      "w46th\n",
      "business/l\n",
      "locationto\n",
      "balleys\n",
      "poor.i\n",
      "carlz\n",
      "out-of-t\n",
      "room/stay\n",
      "54sweetcookie\n",
      "stay..absolutely\n",
      "w=a\n",
      "vibe..no\n",
      "horriblely\n",
      "waterctower\n",
      "tobacc\n",
      "enviromentally\n",
      "warningdo\n",
      "and\\ncasino\n",
      "underwh\n",
      "qualiti\n",
      "newyorquais\n",
      "tempte\n",
      "sf.th\n",
      "cohen67\n",
      "27get\n",
      "clean-friendly-\n",
      "4-n\n",
      "prefere\n",
      "knotch\n",
      "douetree\n",
      "vouchers/\n",
      ".trip\n",
      "139/night\n",
      "coutney\n",
      "olny\n",
      "wynn/enc\n",
      "intimat\n",
      "hesitat\n",
      "property‚Ä¶‚Ä¶.seriously\n",
      "larg\n",
      "roomwe\n",
      "feautures\n",
      ".starting\n",
      "huntingto\n",
      "manhattan/financial\n",
      "commen\n",
      "self-consciousl\n",
      "price-gouging\n",
      "warwic\n",
      "flowe\n",
      "michugan\n",
      "inventively/originally\n",
      "twoadult\n",
      "open/op\n",
      "deforment\n",
      "bugdeted\n",
      "very.stylish\n",
      "macrery\n",
      "bachlerotte\n",
      "line.s\n",
      "orleans..it\n",
      "localizat\n",
      "hype..\n",
      "wellas\n",
      "property-\n",
      ".only\n",
      "flott\n",
      "entere\n",
      "yaaaaawn\n",
      "28-30sep17\n",
      "gradu\n",
      "awsesome\n",
      "sexxy\n",
      "used-up\n",
      "4.15pm\n",
      "eleg\n",
      "stayted\n",
      "honeymoon-\n",
      "mid-mar\n",
      "fabuolus\n",
      "-awesome\n",
      "hotel/apartment\n",
      "so-s\n",
      "deterior\n",
      "9/10beds\n",
      "terraces/balcony\n",
      "chriskindlemart\n",
      "amezing\n",
      "outrageuos\n",
      "hhotel\n",
      "semi-off\n",
      "balconie\n",
      "lodgment\n",
      "holiday-inn\n",
      "i_was\n",
      "ah-pillow\n",
      "concirege\n",
      "amazing.not\n",
      "locariam\n",
      "objec\n",
      "mattresd\n",
      "south/midtown\n",
      "expencive\n",
      "nostaglia\n",
      "invoives\n",
      "propwety\n",
      "business-\n",
      "paridice\n",
      "disappointing-\n",
      "'destinat\n",
      "ticke\n",
      "tmobile\n",
      "but..smaller\n",
      "may15-19\n",
      "unlim\n",
      "high-l\n",
      "aaaaamazing\n",
      "rfeview\n",
      "disapp\n",
      "sister-9n-law\n",
      "unbeliev\n",
      "w/a\n",
      "room+\n",
      "locaion\n",
      "pleasen\n",
      "cotemporary\n",
      "scamm\n",
      "feces-water\n",
      "pryamid\n",
      "service-value-location\n",
      "upgrade..\n",
      "off-the-charts\n",
      "flamazingo\n",
      "neat.\n",
      "bookedthis\n",
      "..o\n",
      "terriffically\n",
      "grsndchildren\n",
      "maywea\n",
      "spectacu\n",
      "i.s.c\n",
      "city.a\n",
      "ediso\n",
      "location/stay\n",
      "stay-again\n",
      "andulsian\n",
      "4th-8th\n",
      "hallwa\n",
      "sanfransico\n",
      "spoile\n",
      "dcat\n",
      "cener\n",
      "moiz\n",
      "30t\n",
      "goooooood\n",
      "throughou\n",
      "tropi\n",
      "oveanmom\n",
      "families/tou\n",
      "rooms-\n",
      "neces\n",
      "execellent\n",
      "beacon‚Äîbest\n",
      "boyfri\n",
      "year+\n",
      "good+\n",
      "topsheets\n",
      "anniversary.what\n",
      "stunnin\n",
      "super-scented\n",
      "properte\n",
      "friendlygreat\n",
      "hstory\n",
      "utili\n",
      "meh-er\n",
      "desoite\n",
      "bitnrday\n",
      "garantichef\n",
      "midtow\n",
      "scva\n",
      "descripti\n",
      "occasi\n",
      "night/4th\n",
      "anythi\n",
      "cicrus\n",
      "rooms:5/5\n",
      "aggrava\n",
      "estive\n",
      "exces\n",
      "primehouse\n",
      "re-tread\n",
      "23h55\n",
      "opps\n",
      "impressed..\n",
      "hold'em\n",
      "priceline*\n",
      "spendy‚Äî‚Äîbut\n",
      "pmafter\n",
      "diffe\n",
      "water..\n",
      "1.30pm\n",
      "beaken\n",
      "re-modeling\n",
      "extraordinary.it\n",
      "'convenience\n",
      "run-dow\n",
      "accidentall\n",
      "mortoranos\n",
      "decade..\n",
      "water/pool\n",
      "anssuming\n",
      "square/\n",
      "+the\n",
      "frst\n",
      "'middle\n",
      "2015.can\n",
      "groun\n",
      "goodv\n",
      "mr.mohammed\n",
      "oshay\n",
      "aftter\n",
      "cous\n",
      "always.could\n",
      "36-ho\n",
      "..pleasant\n",
      "diring\n",
      "grrrrreat\n",
      "'different\n",
      "deari\n",
      "locationat\n",
      "centeral\n",
      "friendless.no\n",
      "7/2-7/7.not\n",
      "superbo\n",
      "locationconvenie\n",
      "july2015\n",
      "distrac\n",
      "3nights\n",
      "undoubt\n",
      "surroundin\n",
      "surprise..\n",
      "üá¨üáß‚úàÔ∏è\n",
      "heyon\n",
      "bad.not\n",
      "magnificenc\n",
      "bookingenquiry\n",
      "strip/close\n",
      "underserving\n",
      "positivescircus\n",
      "disgrac\n",
      "rooseveldt\n",
      "offensivley\n",
      "giraf\n",
      "fairmont-nob\n",
      "honeymoon/new\n",
      "fantastuc\n",
      "absolutl\n",
      "hongthere\n",
      "terrible/\n",
      "nice/cool\n",
      "overalll\n",
      "floors/gaps\n",
      "downhil\n",
      "afterpark\n",
      "room/terrible\n",
      "aervice\n",
      "up-to-d\n",
      "yess\n",
      "professi\n",
      "stay/basic\n",
      "review-new\n",
      "incredily\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stay..can\n",
      "canadianguy\n",
      "side-\n",
      "half-t\n",
      "hgi/midtown\n",
      "beaonca\n",
      "to.a\n",
      "timesqure\n",
      "soacious\n",
      "stayuing\n",
      "5*perfe\n",
      "waldor\n",
      "hny\n",
      "wynn-best\n",
      "staff.the\n",
      "-made\n",
      "pre-remodel\n",
      "honeymoon..\n",
      "staff..spac\n",
      "convenience/large\n",
      "luxurious-\n",
      "eally\n",
      "ordere\n",
      "immaculate-practical-brand\n",
      "stay.and\n",
      "coldes\n",
      "deco-inspired\n",
      "friendly*\n",
      "2015th\n",
      "all.service\n",
      "inters\n",
      "express-wall\n",
      "wonderfulw\n",
      "'reas\n",
      "muchlocation\n",
      "hotel-6\n",
      "28-may1\n",
      "somewha\n",
      "venetian/las\n",
      "disappointing-too\n",
      "experia\n",
      "unmat\n",
      "eveywhere\n",
      "accommadatio\n",
      "iÃán\n",
      "average..and\n",
      "strip.lo\n",
      "stay.very\n",
      "sohor\n",
      "niced\n",
      "startosphere\n",
      "heater+hidden\n",
      "bellme\n",
      "vication\n",
      "-n\n",
      "◊í◊ì◊ï◊ú\n",
      "loccation\n",
      "experience..nicest\n",
      "onewtc\n",
      "charm..\n",
      "wynham\n",
      "vibram\\nrelaxing\n",
      "DGDGDG-DGDGDG\n",
      "conceirge\n",
      "s.e.c\n",
      "chioce\n",
      "heig\n",
      "nearstrip\n",
      "hotelthis\n",
      "vacations-\n",
      "masqueradin\n",
      "üíìüíì\n",
      "t-m\n",
      "retreat-great\n",
      "tournements\n",
      "hotel.g\n",
      "miife\n",
      "renovated-\n",
      "hipsterish\n",
      "4thumbs\n",
      "rennaissance\n",
      "overi\n",
      "up/dropp\n",
      "wrost\n",
      "'lack\n",
      "updated-nee\n",
      "efficiency/business\n",
      "expereince\n",
      "wear-\n",
      "complety\n",
      "***just\n",
      "expected/\n",
      "reasonabley\n",
      "'dumped\n",
      "fitzparick\n",
      "comendable\n",
      "comrback\n",
      "property..huge\n",
      "harrahs/\n",
      "in-dining\n",
      "300/nig\n",
      "3ni\n",
      "okay~\n",
      "florr\n",
      "nosty\n",
      "fistherma\n",
      "newspap\n",
      "'suite\n",
      "agowonderful\n",
      "entertainiing\n",
      "enironmen\n",
      "„Å®„Å¶„ÇÇ‰∏çÊ∫Ä\n",
      "oferece\n",
      "location+free\n",
      "tosee\n",
      "neverthles\n",
      ".kept\n",
      "locaci√≥n\n",
      "holliwood\n",
      "illnes\n",
      "rooms.little\n",
      "northe\n",
      "facade-\n",
      "..wow\n",
      "things.1\n",
      "embasy\n",
      "trunp\n",
      "clud\n",
      "b-fast\n",
      "locations-good\n",
      "york1710better\n",
      "positivesgreat\n",
      "cigarets\n",
      "surprise..booked\n",
      "erverthing\n",
      "springsteenonbroadway\n",
      "smallwith\n",
      "notworthy/exce\n",
      "mid-s\n",
      "comfortanle\n",
      "pricilla\n",
      "dumbfounde\n",
      "aprehensive\n",
      "rcoks\n",
      "idear\n",
      "priced/bad\n",
      "pr√©venir\n",
      "is-without\n",
      "caesaers\n",
      "stella-great\n",
      "considerintg\n",
      "desk..\n",
      "wtc/downtown\n",
      "imprivement\n",
      "rayj\n",
      "grand/avoid\n",
      "legitimat\n",
      "few-year\n",
      "cultu\n",
      "roosevel\n",
      "seagals\n",
      "stay/value\n",
      "seatin\n",
      "honymoon\n",
      "chelsea/midtown\n",
      "g.n\n",
      "wonderfull\n",
      "down/mid/\n",
      "200/night\n",
      "play/do\n",
      "midd\n",
      "visit\\\n",
      "standars\n",
      "forgetable\n",
      "tocome\n",
      "halfwa\n",
      "awesoe\n",
      "additio\n",
      "undercharged\n",
      "gotower\n",
      "timne\n",
      "hotelm\n",
      "loistava\n",
      "helpfulro\n",
      "frauded\n",
      "terurn\n",
      "septembe\n",
      "bouti\n",
      "ayee\n",
      "arizo\n",
      "treausre\n",
      "josh-ooh-aah\n",
      "kayak/getaroom\n",
      "nieghborhood\n",
      "‚ò∫Ô∏è\n",
      "‚òπÔ∏è\n",
      "expansi\n",
      "dishone\n",
      "at/near\n",
      "perfct\n",
      "nnot\n",
      "marriott.c\n",
      "through12\n",
      "directin\n",
      "contrar\n",
      "buuuut\n",
      "muffi\n",
      "-consistently\n",
      "musicman\n",
      "hamtpton\n",
      "clean/quiet\n",
      "th0l‚Ç¨\n",
      "spaciousmy\n",
      "***be\n",
      "hotel.central\n",
      "crew/hotel\n",
      "chitown\n",
      "hosti\n",
      "fran/first\n",
      "'liam\n",
      "stay.what\n",
      "fiants\n",
      "housseke\n",
      "25min-walk\n",
      "recceptionist\n",
      "checkb\n",
      "surpirsingly\n",
      "..never\n",
      "amenities/\n",
      "famlity\n",
      "bargednin\n",
      "enjoyedmy\n",
      "defenitevley\n",
      "roosev\n",
      "bar-none\n",
      "birthdays/trip\n",
      "excele\n",
      "square-the\n",
      "spaciously\n",
      "valez\n",
      "le-\n",
      "385the\n",
      "exceptional..\n",
      "staff/team\n",
      "andjacob\n",
      "ÁöÑdouble\n",
      "'last\n",
      "well-priced\n",
      "tonyb\n",
      "compli\n",
      "stay/perfect\n",
      "roomfacilities\n",
      "anniversary/thanksgiving\n",
      "highish\n",
      "locati0n\n",
      "gjd\n",
      "opin\n",
      "1616-strong\n",
      "eylse\n",
      "mean..it\n",
      "unloadi\n",
      "masat\n",
      ".ro\n",
      "tasefull\n",
      "rididulous\n",
      ".staying\n",
      "hho\n",
      "sports-bar\n",
      "chanc\n",
      "7.30pm\n",
      "noisy..\n",
      "tiems\n",
      "memeb\n",
      "wow.omg\n",
      "nost\n",
      "cleanstaff\n",
      "wynning\n",
      "6mths\n",
      "avertised\n",
      "derailmen\n",
      "vegas-airport\n",
      "nyc-siz\n",
      "'dated\n",
      "station/herald\n",
      "roomstay\n",
      "job-\n",
      "easy-to-navigate\n",
      "experiense\n",
      "me.the\n",
      "excalbur\n",
      "indivi\n",
      "hotmail.co.uk\n",
      "fun/business\n",
      "property1\n",
      "yhe\n",
      "location-close\n",
      "repai\n",
      "fruendly\n",
      "towneplace\n",
      "zoerecently\n",
      "location-conveniently\n",
      "parisia\n",
      "cross-\n",
      "cassad\n",
      "stayb\n",
      ",up\n",
      "tower..\n",
      "fantabulous\n",
      "12-4pm\n",
      "work/play\n",
      "cheapish\n",
      "tungvo\n",
      "paris..do\n",
      "dreame\n",
      "establishmentnot\n",
      "rptkid\n",
      "accomadating\n",
      "travller\n",
      "citizenmmmmmm\n",
      "hotel..breakfast\n",
      "vegasthe\n",
      "jerse\n",
      "pre-paying\n",
      "particu\n",
      "-bathroom\n",
      "h/c\n",
      "griifin\n",
      "xfirst\n",
      "smoky.the\n",
      "ligh\n",
      "neigbourhood\n",
      "woooow\n",
      "tmeshare\n",
      "cleveland-chicago\n",
      "beds-large\n",
      "clost\n",
      "rons\n",
      "valetine\n",
      "supersmall\n",
      "beautifullest\n",
      "dirty-\n",
      "refridgerater\n",
      "DGDG.DGDGDG\n",
      "friedns\n",
      "hotel-still\n",
      "famalies\n",
      "service/stay\n",
      "britany\n",
      "business.place\n",
      "disappoints..\n",
      "iperfect\n",
      "accerss\n",
      "he**\n",
      "brijak\n",
      "fee-per-service\n",
      "uninterr\n",
      "hotel.spacio\n",
      "tfmes\n",
      "threfore\n",
      "top3\n",
      "locationgoo\n",
      "residenti\n",
      "service~\n",
      "innsider\n",
      "quintaesential\n",
      "tentati\n",
      "small/boutique\n",
      "qualit6\n",
      "play-\n",
      "happin\n",
      "enthusi\n",
      "knowhere\n",
      ".luxurious\n",
      "mcdonnels\n",
      "confin\n",
      "non-intercontinental\n",
      "indifferent/lousy\n",
      "in/on\n",
      "carlso\n",
      "-pretty\n",
      "iowa-first\n",
      "ottimo\n",
      "hi-international\n",
      "consgliatissimo\n",
      "tahmina\n",
      "babie\n",
      "douz\n",
      "surpized\n",
      "securitythe\n",
      "bridge-to-bridge\n",
      "seven-star\n",
      "disple\n",
      "bavettes\n",
      "nobh\n",
      "uncomforta\n",
      "surr\n",
      "favourity\n",
      "maintenace\n",
      "rooms/dirty\n",
      "location-missed\n",
      "‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è\n",
      "uncer\n",
      "momm\n",
      "definitel\n",
      "central/boutiquish\n",
      "park/world\n",
      "blehhhh\n",
      "weekend-dinner\n",
      ".everything\n",
      "stars//recieved\n",
      "tea/coffe\n",
      "usuals\n",
      "hotel-nothing\n",
      "djumin\n",
      "instan\n",
      "custommer\n",
      "-d\n",
      "breafast\n",
      "tradesh\n",
      "unifieds\n",
      "ok..we\n",
      "erage\n",
      "pilot-friendly\n",
      "knicekerbocker\n",
      "shoptacular\n",
      "exxperience\n",
      "'find\n",
      "DGDG/\n",
      "‚Ä¶and\n",
      "ago-\n",
      "effici\n",
      "bath/\n",
      "adequite\n",
      "referb\n",
      "queit\n",
      "wonderi\n",
      "ameninties\n",
      "servece\n",
      "windam\n",
      "briliant\n",
      "perfec\n",
      "un-sanitized\n",
      "matth\n",
      "propertry\n",
      "must-d\n",
      "shepreview\n",
      "hotel-parking\n",
      "super-well\n",
      "nyÂàùÂøÉËÄÖ„ÅØÊòØÈùû„Åì„Åì„Å∏ÔºÅ\n",
      "3-stars\n",
      "spouce\n",
      "accessibl\n",
      "ahhhmazing\n",
      "nubies\n",
      "ÎßêÎ∂ÄÌÑ∞\n",
      "spatiousplenty\n",
      "üòäüòä\n",
      "schlacky\n",
      "a-w-s-o-m-e\n",
      "safeg\n",
      "sucks.gr\n",
      "craphole\n",
      "suite.nice\n",
      "staff.grea\n",
      "degr\n",
      "immediatel\n",
      "japan-town\n",
      "business-class\n",
      "conventioning\n",
      "hollywoord\n",
      "tripto\n",
      "atteactions\n",
      "bestüëåüíú\n",
      "nights/\n",
      "sanfo\n",
      "expectations‚Ä¶\n",
      "definitetly\n",
      "nighth\n",
      ".poo\n",
      "„Åì„ÅÆ‰æ°Ê†º„Åß„ÄÅsf„Å´Ê≥ä„Åæ„Çå„Çã„ÅÆ„ÅØ„ÅäÂÄ§Êâì„Å°„Å†„Å®ÊÄù„ÅÑ„Åæ„Åô„ÄÇÊúùÈ£ü„ÅØÊ¥ªÊ∞ó„Åå\n",
      "service-elevator\n",
      "price/great\n",
      "hypoal\n",
      "chicago-one\n",
      "wedding/relaxation\n",
      "excelletn\n",
      "justifyng\n",
      "-run\n",
      "haevn\n",
      "cansell\n",
      "remotel\n",
      "arguab\n",
      "*because\n",
      "arrived..\n",
      "nursing/working\n",
      "heatd\n",
      "=fantastic\n",
      "üîÜ\n",
      "costdelano\n",
      "rellax\n",
      "cegas\n",
      "locationcons-we\n",
      "thje\n",
      "bentley-ny\n",
      "crasy\n",
      "clelan\n",
      "loud/o\n",
      "perfecly\n",
      "chundhury\n",
      "stay.in\n",
      "finishe\n",
      "outlookpoor\n",
      "location..literally\n",
      "ehich\n",
      "respectf\n",
      "hot/not\n",
      "mypartner\n",
      "faciltiy\n",
      "explor\n",
      "chicogo-priced\n",
      "river-walk\n",
      "friendsgiving\n",
      "again-a+\n",
      "10yr\n",
      "rvsites\n",
      "staffloved\n",
      "oerfect\n",
      "good-\n",
      "wowzers\n",
      "miney\n",
      "6d/5n\n",
      "thankf\n",
      "f-\n",
      "cllub\n",
      "enviting\n",
      "premiew\n",
      "value‚Ä¶\n",
      "lot-\n",
      "nice-siz\n",
      "unplesent\n",
      "staqy\n",
      "stratospere\n",
      "citiz\n",
      "quitewhat\n",
      "action-\n",
      "downtown/financi\n",
      "grumblesclean\n",
      "believ\n",
      "convenieces\n",
      "comprarable\n",
      "magnificen\n",
      "eclect\n",
      "hotel..clean\n",
      "glamo\n",
      "hotel..but\n",
      "allvery\n",
      "accousted\n",
      "jfkÁ©∫Ê∏Ø„Åã„Çâ„Éõ„ÉÜ„É´„Åæ„Åß„Çø„ÇØ„Ç∑„Éº„Å†„Å®Ê∏ãÊªû„Åß1-2ÊôÇÈñì\n",
      "contemplat\n",
      "staycationüëçüèº\n",
      "‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏£‡∏Å‡∏ó‡∏µ‡πà‡∏û‡∏≤‡∏ï‡∏±‡∏ß‡πÅ‡∏ó‡∏ô‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡∏°‡∏≤\n",
      "helpfll\n",
      "anticipat\n",
      "hotel-wo\n",
      "nyc-nyc\n",
      "escorte\n",
      "nwm\n",
      "location/tremendous\n",
      "wen5t\n",
      "depres\n",
      "przybysz\n",
      "exemp\n",
      "tooooooo\n",
      "grandmother-granddaughter\n",
      "referenc\n",
      "kochoski\n",
      "aferre\n",
      "grandeand\n",
      "experience.our\n",
      "brake.sorry\n",
      "mandalay/mirage\n",
      "coutyard\n",
      "üò±üòµ\n",
      "contempory\n",
      "grillhad\n",
      "it.room\n",
      "consistenly\n",
      "friendly..what\n",
      "excalibe\n",
      "good*\n",
      "vieuw\n",
      "bj.s\n",
      "expensive.rating\n",
      "20hr\n",
      "themiddl\n",
      "ultra-slow\n",
      "bucklist\n",
      "roomsfr\n",
      "assistance.beatiful\n",
      "expectaion\n",
      "nethe\n",
      "cosmopolita\n",
      "chuwdhuny\n",
      "prefectly\n",
      "masquera\n",
      "diff√©ren\n",
      "blowoff\n",
      "newyorkese\n",
      "deterioriate\n",
      "*very*\n",
      "freemo\n",
      "rundown/unfriendly\n",
      "restoc\n",
      "ahyatt\n",
      "arbonne\n",
      "disappoinred\n",
      "hotel-shame\n",
      "elys\n",
      "mocated\n",
      "eigh\n",
      "impression..\n",
      "aug.26-\n",
      "chigago\n",
      "virtuos\n",
      "four-y\n",
      "free/game\n",
      "non-casino-type\n",
      "*filt\n",
      "somet\n",
      "alalshaikh\n",
      "fantist\n",
      "location/experiance\n",
      "location_dvb\n",
      "awesom\n",
      "u'r\n",
      "location/friendliest\n",
      "wowwwwwww\n",
      "hottel\n",
      "kodi/str\n",
      "khotel\n",
      "extravagent\n",
      "fitne\n",
      "8/21/2016from\n",
      "location.loved\n",
      "accommodationthe\n",
      "surving\n",
      "surfac\n",
      "freement\n",
      "location-great\n",
      "DG/DGDG/DGDGDGDG\n",
      "havi\n",
      "grerat\n",
      "strip.great\n",
      "beeare\n",
      "easy-to-access\n",
      "photoshopping\n",
      "pig-sty\n",
      "whittakers\n",
      "knickerbobockers\n",
      "ave..\n",
      "w.thomas\n",
      "fially\n",
      "envirement\n",
      "supprise\n",
      "buffe\n",
      "registeri\n",
      "forwarned-\n",
      "verygood\n",
      "jkf\n",
      "surprised..in\n",
      "cleanfood\n",
      "housi\n",
      "w/c\n",
      "Í∞ÄÏû•\n",
      "p√©ssimo\n",
      "medicore\n",
      "rooms/ammenities\n",
      "high-life\n",
      "batthrooms\n",
      "overpricec\n",
      "tomorr\n",
      "stafy\n",
      "check-in/check-o\n",
      "v.enjoyable\n",
      "amaris\n",
      ".gre\n",
      "percfect\n",
      "pod-tastic\n",
      "ocurra\n",
      "sheets/to\n",
      "hefre\n",
      "epit\n",
      "shop-\n",
      "cockroa\n",
      "effiient\n",
      "asiate\n",
      "unbelivable\n",
      "bar/lounge\n",
      "rioms\n",
      "windycity\n",
      "..hip\n",
      "twce\n",
      "frsncisco\n",
      "ball's-las\n",
      "chelsea/herald\n",
      "exclibur\n",
      "sharehol\n",
      "geteaway\n",
      "room-comfortable\n",
      "birhtday\n",
      "nniversary\n",
      "renovated.\n",
      "despera\n",
      "cunni\n",
      "DGDG.DG.-DGDG.DG.DGDG\n",
      "dated.breakfast\n",
      "march'2018\n",
      "instalations\n",
      "hoteleasy\n",
      "day-in\n",
      "beiber-rific\n",
      "stafg\n",
      "surtout\n",
      "christmas/ne\n",
      "noxy\n",
      "review*\n",
      "classey\n",
      "carshow\n",
      ".elevators\n",
      "nightsg\n",
      "enormou\n",
      "thsi\n",
      "tasy\n",
      "accessibili\n",
      "sportsbookx\n",
      "sofite\n",
      "palacial\n",
      "üëçüëçüëçüëçüëç\n",
      "thewifi\n",
      "hotel-grand\n",
      "rellaxing\n",
      "Í∞ÄÍπåÏö∞Î©¥ÏÑú\n",
      "hitlon\n",
      "thegiraffe\n",
      "-fi\n",
      "impressive.che\n",
      "disrespecful\n",
      "stay.s\n",
      "sweetotel\n",
      "experience~\n",
      "wkn\n",
      "vacation‚Äîeverythi\n",
      "inn/downto\n",
      "sponsore\n",
      "north/mag\n",
      "pros-\n",
      ".expensive\n",
      "‚ù§Ô∏ètrave\n",
      "areally\n",
      "staff/noisy\n",
      "downtown/\n",
      "eccellent\n",
      "obtaine\n",
      "'round\n",
      "affinina\n",
      "peaseful\n",
      "septmebe\n",
      "kelliani\n",
      "restaurant/pub\n",
      "kailihiwa\n",
      "üòâ\n",
      "colleg\n",
      "nickh\n",
      "ddd-\n",
      "impeccible\n",
      "expectionally\n",
      "fashiononable\n",
      "philad\n",
      "accura\n",
      "susbstance\n",
      "previ\n",
      "vacation/sight\n",
      "locstuon\n",
      "remod\n",
      "mgm-get\n",
      "pefect\n",
      "old-ish\n",
      "leanin\n",
      "addage\n",
      "park-\n",
      "fischermans\n",
      "bad:1\n",
      "seevive\n",
      "magini\n",
      "semi-convenient\n",
      "primptness\n",
      "relaxig\n",
      "hotel-sorry\n",
      "flatir\n",
      "zwolinski\n",
      "exporers\n",
      "chicago-south\n",
      "plece\n",
      "view/perfect\n",
      "cheaper/immature\n",
      "location..small\n",
      "bellagio..the\n",
      "likedo\n",
      "pitbull-\n",
      "perfecr\n",
      "in/near\n",
      "'motor\n",
      "average..\n",
      "chouce\n",
      "üçç\n",
      "extreml\n",
      "greatcation\n",
      "manhatteb\n",
      "personalble\n",
      "sugges\n",
      "pitch-not\n",
      "unpretensious\n",
      "onerall\n",
      "coupons.no\n",
      "heart-related\n",
      "ceasors\n",
      "stay.i\n",
      "wjhotel\n",
      "unncomfortable\n",
      "casino-old\n",
      "bookin\n",
      "restez\n",
      "therethe\n",
      "choices..\n",
      "plani\n",
      "new/recently\n",
      "book'em\n",
      "mgms\n",
      "ammenties\n",
      "espessialy\n",
      "construciton\n",
      "liabl\n",
      "flamingo-handled\n",
      "village-ended\n",
      "lane-new\n",
      "non-g\n",
      "conveniennt\n",
      "wasy\n",
      "wonderful‚Äîbest\n",
      "befs\n",
      "DG.DGDG\n",
      "breathtak\n",
      "craz\n",
      "absollutely\n",
      "staff+excellent\n",
      "mandalalay\n",
      "cusotmer\n",
      "'idiosyncratic\n",
      "clean.the\n",
      "disturbanc\n",
      "hotel.off\n",
      "cigarttes\n",
      "-cleancons\n",
      "jun18\n",
      "day-out\n",
      "pattys/marchmadness\n",
      "springbreak\n",
      "wednesd\n",
      "minuteaccomodation\n",
      ".grand\n",
      "Õ°¬∞\n",
      "non-alley\n",
      "ripped-off\n",
      "-everyt\n",
      "bevrage\n",
      "bacarrat\n",
      "probs\n",
      "center-of-strip\n",
      "3ti\n",
      ".times\n",
      "vacaion\n",
      "righteo\n",
      "bettter\n",
      "limittaions\n",
      "-DG.\n",
      "üòñ\n",
      "fine.zero\n",
      "thevery\n",
      "yes-we\n",
      "amayzing\n",
      "qualilty\n",
      "nights..f\n",
      "pros:1\n",
      "brilluant\n",
      "18th-21st\n",
      "adrrrrriiiaaaaannnn\n",
      "Õú ñ\n",
      "smack-dab\n",
      "ecletic\n",
      "guyshad\n",
      "comfortable/convenient\n",
      "wall.shower\n",
      "aaoms\n",
      "spa-ish\n",
      "imperfectio\n",
      "mmmmmm\n",
      "grisse\n",
      "disti\n",
      "but‚Ä¶\n",
      "greatful\n",
      "edgie\n",
      "nra17\n",
      "do‚Ä¢the\n",
      "milleium\n",
      "suite-esque\n",
      "degradeted\n",
      "undergro\n",
      "motherf'ker\n",
      ".stayed\n",
      "not-so-grand\n",
      "referen\n",
      "show/meals/train\n",
      "distgusting\n",
      "enyoed\n",
      "definitiv\n",
      "rooms/price\n",
      "nighr\n",
      "explanato\n",
      "cozy/\n",
      "disappointe\n",
      "hotl\n",
      "..cent\n",
      "updatd\n",
      "gvmp\n",
      "distrcit\n",
      "quickly-\n",
      "grew-up\n",
      "prejud\n",
      "forgi\n",
      "ÏúÑÏπòÎèÑ\n",
      "trip/visit\n",
      "supurb\n",
      "hard-lived\n",
      "casino/sports\n",
      "üëçüíØüîù‚ù§Ô∏è\n",
      "satff\n",
      "o/night\n",
      "fantast\n",
      "unreaso\n",
      "wedfing\n",
      ".twice\n",
      "5-diamond\n",
      "kitchen/\n",
      "effcient\n",
      "grd9141\n",
      "wedding-caesars\n",
      "price/product\n",
      "hotels.thi\n",
      "convinent\n",
      "room/amenities\n",
      "legenday\n",
      "easy..\n",
      "remebered\n",
      "hotel-dual\n",
      "ohhotdamn\n",
      "establishents\n",
      "hopes-\n",
      "convinience\n",
      "7:30am\n",
      "crew-\n",
      "smellt\n",
      "natsa\n",
      "midtown/times\n",
      "place.we\n",
      "hotelw\n",
      "espensive\n",
      "ny-\n",
      "life-lon\n",
      "interc\n",
      "bacholer\n",
      "echeck\n",
      "crawlin\n",
      "gem-loved\n",
      "11ni\n",
      "eccu2014\n",
      "great/comfortable\n",
      "modelle\n",
      "elsewhere-\n",
      "weekend-the\n",
      "entermaimnet\n",
      "del-ightful\n",
      "nice.pros\n",
      "timeshare/hotel/location\n",
      "patien\n",
      "crazines\n",
      "◊û◊ï◊ß◊§◊ì\n",
      "venez\n",
      "inconvinience\n",
      "tower/good\n",
      "straroaphere\n",
      "exerpience\n",
      ".hands\n",
      "glamourised\n",
      "ambival\n",
      "yipee\n",
      "check-point\n",
      "casino/h\n",
      "here-go\n",
      "arlingt\n",
      "rente\n",
      "barte\n",
      "brief:1.\n",
      "chicage\n",
      "service-service-service\n",
      "emcworld\n",
      "beautiful..mod\n",
      "üíÉüèæ\n",
      "fril\n",
      "sanf\n",
      "htotel\n",
      "qiet\n",
      "stay+restaurant\n",
      "jewel-box\n",
      "exnteded\n",
      "goodroom\n",
      "15yr\n",
      "chicago-\n",
      "coast/excellent\n",
      "hotelli/awesome\n",
      "day-after-wedding\n",
      "daddy-\n",
      "foverer\n",
      "worst-\n",
      "cool-\n",
      "hotel..yes\n",
      "epensive\n",
      "check-inwe\n",
      "overated\n",
      "sijainti\n",
      "nice.r\n",
      "carvi\n",
      "incompe\n",
      "Ïã∂ÏùÄ\n",
      "mahammed\n",
      "convienient\n",
      "reveiws\n",
      "vegaaaaas\n",
      "mither-daughter\n",
      "roooms\n",
      "manged\n",
      "exper\n",
      "peopel\n",
      "oriented/not\n",
      "monume\n",
      "amazeballs\n",
      "cheking\n",
      "mid-nov\n",
      "includin\n",
      "mrs.bae\n",
      "moon.out\n",
      "emacu\n",
      "cetral\n",
      "ddw\n",
      "location-w\n",
      "appartments\n",
      ".perf\n",
      "room-12th\n",
      "often-\n",
      "stageing\n",
      "turtle¬¥s\n",
      "expectdd\n",
      "suitefloor\n",
      "preciding\n",
      "hotel..we\n",
      "stay-perfect\n",
      "survery\n",
      "celecration\n",
      "whateve\n",
      "great/safe\n",
      "disrespectf\n",
      "winn/encore\n",
      "ave/nylo\n",
      "DGDG/DGDG/DGDGDGDG\n",
      "srevive\n",
      "namb\n",
      "nonreservation\n",
      "attuidue\n",
      "location/large\n",
      "updates/\n",
      "sheas\n",
      "DGDGDGDGDGDGDGDG\n",
      "fourqueens\n",
      "well-c\n",
      "growt\n",
      "exoerience\n",
      "awesomw\n",
      "luvegas\n",
      "odintsova\n",
      "*please\n",
      "aour\n",
      "mostin\n",
      "checkou\n",
      "30yo\n",
      "jan-feb\n",
      "firsttimer\n",
      "adjustin\n",
      "fdr/public\n",
      "conveience\n",
      "staff..concierge\n",
      "parkinf\n",
      "kept..\n",
      "inadeq\n",
      "flasjy\n",
      "housekeep\n",
      "old-styled\n",
      "complem\n",
      "suites-times\n",
      "DG/DGDG-DG/DGDG/DGDGDGDG\n",
      "27-29th\n",
      "prosroom\n",
      "toyfair\n",
      "relaxation/luxury\n",
      "lassis\n",
      "relations/experience\n",
      "brollies\n",
      "sunshi\n",
      "hotel..new\n",
      "night/\n",
      "one.\n",
      "headcoak\n",
      "you¬¥re\n",
      "mr.fu\n",
      "increidbl\n",
      "niiice\n",
      "nyc/eventi\n",
      "internat\n",
      "supervis\n",
      "pros-perfectly\n",
      "weath\n",
      "amazing..the\n",
      "everwhere\n",
      "bedroom:22nd\n",
      "hotel8\n",
      "cosmeti\n",
      "not-great\n",
      "belago\n",
      "crazy-\n",
      "renassiance\n",
      "good-great\n",
      "hoggi\n",
      "day/4night\n",
      "recommendatio\n",
      "hotel.k\n",
      "nicelate\n",
      "re-train\n",
      "wynn..\n",
      "bellegios\n",
      "abbys\n",
      "outstandiing\n",
      "flithy\n",
      "incre√≠ble\n",
      "unhelpfull\n",
      ".is\n",
      "tolas\n",
      "4-th\n",
      "sizebeds\n",
      "located/clean/good\n",
      "skyrise\n",
      "renovated-great\n",
      "craftsma\n",
      "4nights\n",
      "clean.had\n",
      "underdeliv\n",
      "mis-sold\n",
      "tret\n",
      "inaccurate/\n",
      "daugters\n",
      "hww\n",
      "seevice\n",
      "amtb\n",
      "fixt\n",
      "price-free\n",
      "on-site..\n",
      "smaller/bo\n",
      "5-night\n",
      "exceelnt\n",
      "kamping\n",
      "locafion\n",
      ".firs\n",
      "'streets\n",
      "goes-\n",
      "vernac\n",
      "eloq\n",
      "hookers/es\n",
      "fanstatic\n",
      "ztower\n",
      "monotrails\n",
      "mcormick\n",
      "2014lov\n",
      "owner/management\n",
      "excent\n",
      "deysi\n",
      "extraordin\n",
      "wayting\n",
      "mother-\n",
      "DGDG-DGDGDG\n",
      "citizenm-agnificent\n",
      "loacaton\n",
      "la-styled\n",
      "socce\n",
      "strp\n",
      "hospitallity\n",
      "around..\n",
      "showerdirty\n",
      "visislting\n",
      "voer\n",
      "daphnee\n",
      "devon..\n",
      "magnif\n",
      "resturatns\n",
      "absoloutly\n",
      "'DG\n",
      "city/river\n",
      "vultur\n",
      "midto\n",
      "feb21-feb\n",
      "heati\n",
      "room/beds\n",
      "compd\n",
      "botic\n",
      "wondnerful\n",
      "uber-cool\n",
      "austoria\n",
      "spuare\n",
      "canyon/hoover\n",
      "..fab\n",
      "establishme\n",
      "service/friendliest\n",
      "only.the\n",
      "casino-less\n",
      "up-sell\n",
      "megafam\n",
      "courtyard+\n",
      "-double\n",
      "servicevery\n",
      "nicer-than-usual\n",
      ".rooms\n",
      "approac\n",
      "help/training\n",
      "cloud-roof\n",
      "notel\n",
      "raddison\n",
      "rudechristina\n",
      ".safe\n",
      "fan-\n",
      "experience-with\n",
      "relex\n",
      "fwny\n",
      "DG*\n",
      "collectgi\n",
      "beginn\n",
      "staywell\n",
      "weakne\n",
      "novemer\n",
      "majestics\n",
      "nycs\n",
      "resortism\n",
      "rooms/suites\n",
      "mold.room\n",
      "barista/b\n",
      "toleit\n",
      "views.bee\n",
      "room/suite\n",
      "purpusefully\n",
      "aahhhh\n",
      "zingapan\n",
      "dream‚Ä¶\n",
      "..incredi\n",
      "out-\n",
      "name-your\n",
      "downsides-\n",
      "public/common\n",
      "mid-eveni\n",
      "doho\n",
      "clean/comfortable/friendly\n",
      "smarthotel\n",
      "mistage\n",
      "proscheck-in\n",
      "stay-excellent\n",
      "sun-frid.booked\n",
      "awesomr\n",
      "exlent\n",
      "underwelming\n",
      "impanema\n",
      "wolc\n",
      "farrrrrr\n",
      "trendy/modern\n",
      "staff.was\n",
      "midtiwn\n",
      "nightrep\n",
      "acess.the\n",
      "upsale\n",
      "-bad\n",
      "takeaw\n",
      "6-nig\n",
      "mis-leading\n",
      "welli\n",
      "adverti\n",
      "neasy\n",
      "hosptality\n",
      "warni\n",
      "1980'ies\n",
      "orientati\n",
      "venue-\n",
      "nortw\n",
      "s.n\n",
      "√©xcellent\n",
      "tahit\n",
      "casino/res\n",
      "wheth\n",
      "average.r\n",
      "nnyc\n",
      "nights.thi\n",
      "semi-scary\n",
      "hotelhe\n",
      "excelltant\n",
      "seaso\n",
      "traveloci\n",
      "ganb\n",
      "location/superior\n",
      "couples..we\n",
      "hotel/re\n",
      "august17vegas\n",
      "correctio\n",
      "broadway-ja\n",
      "strip.nd\n",
      "radtastic\n",
      "locationgo\n",
      "magnificant\n",
      "sir/\n",
      "infla\n",
      "get-a-wa\n",
      "..wo\n",
      "fitn\n",
      "/resorts\n",
      "n-y-c\n",
      "10:15pm\n",
      "*we\n",
      "DGDG:DGDG.-\n",
      "2017great\n",
      "**maddy\n",
      "kindly.nice\n",
      "placesuper\n",
      "toas\n",
      "intendin\n",
      "burkeshire\n",
      "dimey\n",
      "styed\n",
      "staffs.i\n",
      "splurg\n",
      "bachelour\n",
      "‚Ä¢center\n",
      "conforto\n",
      "middle-of-the-\n",
      "hotel/motel\n",
      "memor\n",
      "betterable\n",
      "astot\n",
      "two-bedr\n",
      "ttwo\n",
      "worldclass\n",
      "again.roo\n",
      "propertyand\n",
      "ginas\n",
      "unintereste\n",
      "feb-2015\n",
      "amazig\n",
      "graduall\n",
      "missold\n",
      "ÊàëÂú®ÈÇ£Ë£°‰Ωè‰∫Ü3ÊôöÔºåÊòØ‰∏ÄÈñìÂæàÊ∫´È¶®ÁöÑÊóÖÈ§®\n",
      "overp\n",
      "likes.\n",
      "accomidating\n",
      "wehad\n",
      "apointed\n",
      "vetry\n",
      "elegent\n",
      "magnificien\n",
      "-upd\n",
      "atenciosidade\n",
      "‚òÜ‚òÜ‚òÜ\n",
      "√≥timo\n",
      "staff-\n",
      "slowwwww\n",
      "vegas-visits\n",
      "dynatrace\n",
      "micro-br\n",
      "chicaago\n",
      "luurious\n",
      "'few\n",
      "demographi\n",
      "user-fr\n",
      "shortl\n",
      "cenral\n",
      "fortu\n",
      "'friendly\n",
      "central/pauls\n",
      "********\n",
      "guest-focused\n",
      "2-bedro\n",
      "visit-will\n",
      "2br\n",
      "p-\n",
      "timertime\n",
      "happnstans\n",
      "nov/21st\n",
      "auditioni\n",
      "gofest\n",
      "usual..\n",
      "w/legendary\n",
      "amacing\n",
      "betting/sports\n",
      "pricepoint\n",
      "resevered\n",
      "misteps\n",
      "newl\n",
      "celebretion\n",
      "run-d\n",
      "hotels..\n",
      "frig\n",
      "—Å–æ–≤—Ä\n",
      "◊©◊ô◊®◊ï◊™\n",
      "bar‚Ä¶\n",
      "basical\n",
      "c848\n",
      "dining.food\n",
      "car/shuttle\n",
      "marriots\n",
      "retreat~\n",
      "sleeze\n",
      "elavators\n",
      "emplyees\n",
      "pleadure\n",
      "ti.we\n",
      "incredi\n",
      "sparkli\n",
      "decieved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comforable\n",
      "circum\n",
      "un-beatable\n",
      "attitude~~~\n",
      "bathroo\n",
      "amenitites\n",
      "platinums\n",
      "staff‚Äîwillie\n",
      "üëçüèæüëçüèæüëçüèæ\n",
      "ny.ideally\n",
      "reasonble\n",
      "our2\n",
      "'cancelon\n",
      "food..and\n",
      "15years\n",
      "yeaa\n",
      "hotel/condo\n",
      "üíô\n",
      "bogglin\n",
      "expirance\n",
      "wi5\n",
      "york/midtown-south\n",
      "..will\n",
      "old-fas\n",
      "omni-berkshire\n",
      "service/hidden\n",
      "business.fantastic\n",
      "wowsa\n",
      "birthday-\n",
      "defent\n",
      "moneyno\n",
      "location.hotel\n",
      "fran-westin\n",
      "okay-larg\n",
      "syaed\n",
      "fisrt\n",
      "proclaimer\n",
      "desaster\n",
      "city-sized\n",
      "remodeling-\n",
      "side-stay\n",
      "hotel.is\n",
      "hakone/s\n",
      "cosino\n",
      "anyw\n",
      "dciny\n",
      "accoun\n",
      "location/facility\n",
      "revam\n",
      "+++++\n",
      "stayed.u\n",
      "working/nursing\n",
      "disregar\n",
      "cruiseripl\n",
      "6:30pm\n",
      "hotsl\n",
      "soooo-o-o\n",
      "azzie\n",
      "buuuuuut\n",
      "improm\n",
      "specialy\n",
      "d√©cent\n",
      "dec√≥r\n",
      "üòçüòç\n",
      "brilliant‚Ä¶apart\n",
      "beautiful/trendy\n",
      "tropical-feel\n",
      "underne\n",
      "forewa\n",
      "yeeeessssss\n",
      "requir\n",
      "reviews‚Ä¶b\n",
      "hotel-best\n",
      "beat-lot\n",
      "..convenient\n",
      "trye\n",
      "misle\n",
      "fly-drive\n",
      "envir\n",
      "hoitel\n",
      "crocodi\n",
      "breakfad\n",
      "crroks\n",
      "view/average\n",
      "grandparen\n",
      "unfrienly\n",
      "mediocore\n",
      "attendent\n",
      "surpising\n",
      "understaff\n",
      "‚úîÔ∏èDG\n",
      "nbbi\n",
      "one-ha\n",
      "maintainedfro\n",
      "accrosso\n",
      "back-packer\n",
      "beds-great\n",
      "location+excellent\n",
      "trip/\n",
      "klakouski\n",
      "francisto\n",
      "ahead**\n",
      "night/5\n",
      "entertainmenti\n",
      "t.i.riffic\n",
      "positivesthan\n",
      "elto\n",
      "classiness\n",
      "unamazing\n",
      "tremendo\n",
      "kurty\n",
      "auberge.from\n",
      "small-boutique\n",
      "casino-phenomenal\n",
      "train..\n",
      "nadoa\n",
      "youpay\n",
      "lovery\n",
      "york..\n",
      "impressive..\n",
      "comfi\n",
      "aium\n",
      "complaine\n",
      "s..\n",
      "379/night-before\n",
      "forfamily\n",
      "bellisimma\n",
      "a+++++\n",
      "popu\n",
      "absaloute\n",
      "cornerview\n",
      "costum\n",
      "restora\n",
      "valuewe\n",
      "privelage\n",
      "location-clean\n",
      "broadwa\n",
      "bookeeping\n",
      "********************christmas\n",
      "profe\n",
      "villag\n",
      "elevators.ery\n",
      "imitatly\n",
      "old-f\n",
      "buty\n",
      "surpr\n",
      "handwasher\n",
      "divaliciois\n",
      "18rh\n",
      "lasvegas\n",
      "locationüëçüèª\n",
      "medium-notch\n",
      "lex48\n",
      "meeting..\n",
      "gal-pals\n",
      "ebrithyng\n",
      "impossibile\n",
      "welcomingl\n",
      "goodi\n",
      "festivi\n",
      "confusin\n",
      "lakeview/lincoln\n",
      "comfable\n",
      "clean.food\n",
      "happiness/sadness\n",
      "struc\n",
      "horrendousl\n",
      "locationcleanfri\n",
      "lesiure\n",
      "family/wedding\n",
      "else.a\n",
      "x-small\n",
      "semi-\n",
      "refurbishm\n",
      "neat-if\n",
      "very.nice\n",
      "experience..would\n",
      "inpressed\n",
      "ghiradell\n",
      "lucern\n",
      "memorisl\n",
      "compari\n",
      "ttoooo\n",
      "robbied\n",
      "sensitiv\n",
      "offerable\n",
      "mcelvy\n",
      "prosclean\n",
      "good.also\n",
      "..spend\n",
      "fun/funky\n",
      "great-location\n",
      "DGDG/DGDG-DGDG/\n",
      "high-stress\n",
      "convently\n",
      "1:58am\n",
      "luxerious\n",
      "disappon\n",
      "snazz\n",
      "-w\n",
      "extravaganz\n",
      "standard-what\n",
      "beleave\n",
      "ballegio\n",
      "„Ç´„Ç∏„Éé„Å®„Ç∑„Éß„Ç¶Ë°ó\n",
      "price/value/location\n",
      "balldrop\n",
      "lanch\n",
      "besttop\n",
      "promp\n",
      "gwinns\n",
      "enorm\n",
      "vacation/anniversary\n",
      "nonprof\n",
      "unprofessio\n",
      "location.find\n",
      "declin\n",
      "strpi\n",
      "comfotable\n",
      "new/old\n",
      "hotelcasino\n",
      "seeing/family\n",
      "un-grand\n",
      "accountin\n",
      "location/they\n",
      "keysdid\n",
      "price+friendly\n",
      "home..while\n",
      "granddau\n",
      "servicecleanest\n",
      "money+\n",
      "st./so\n",
      "boug\n",
      "good.onl\n",
      "stancato\n",
      "kcampo\n",
      "stayca\n",
      "paris.it\n",
      "clean.a\n",
      "attende\n",
      "1-8th\n",
      "hostest\n",
      "fransisco-\n",
      "rip-offfor\n",
      "others..it\n",
      "horendous\n",
      "week.allow\n",
      "multit\n",
      "nycharm\n",
      "decemb\n",
      "go-tos\n",
      "ago.to\n",
      "nickel-a\n",
      "sareli\n",
      "dislik\n",
      "-staye\n",
      "basicall\n",
      "teenage/colleg\n",
      "priced/small\n",
      "twiins\n",
      "bobbyg1960\n",
      "convention/trade\n",
      "metro-\n",
      "labyrin\n",
      "maintenanc\n",
      "reze\n",
      "66t\n",
      "razzle-dazzle\n",
      "everywa\n",
      "queing\n",
      "10/10fre\n",
      "casablan\n",
      "flamingooo\n",
      "riverfront/loop\n",
      "flatiron.you\n",
      "bar..not\n",
      "servicerooms\n",
      "toc√≥\n",
      "excellent..my\n",
      "plus-hot\n",
      "amazingggg\n",
      "satifactory\n",
      "consitent\n",
      "independe\n",
      "bcollege\n",
      "nastalgia\n",
      "confeence\n",
      "mutli-cultural\n",
      "stlv\n",
      "oddit\n",
      "cortaditos\n",
      "Ÿàÿßÿ≥ÿπ\n",
      "tower=\n",
      "bresk\n",
      "employees/tight\n",
      "-nothing\n",
      "shenaniga\n",
      "-impression\n",
      "experienceeveryon\n",
      "rsna\n",
      "quilkie\n",
      "ogh\n",
      "-center\n",
      "alvir\n",
      "'yes\n",
      "*my\n",
      "vegad\n",
      "convenent\n",
      "pickw\n",
      "pleasi\n",
      "hotel..in\n",
      "entertaiment\n",
      ".warm\n",
      "conventon/sporting\n",
      "hemingwa\n",
      "vafam\n",
      "desiever\n",
      "sweeeeeeeet\n",
      "here.this\n",
      "annniversary\n",
      "upco\n",
      "awful/terrible\n",
      "busienss\n",
      "transitiona\n",
      "well-appoint\n",
      "location-elegant\n",
      "unavailabl\n",
      "-unkept\n",
      "price/classic\n",
      "helpful.debra\n",
      "new..\n",
      "mezmorizing\n",
      "iome\n",
      "dealas\n",
      "amaziiiiiing\n",
      "hyatt48\n",
      "stll\n",
      "ridicul\n",
      "niceeee\n",
      "night.roo\n",
      "in-large\n",
      "estaff\n",
      "regencey\n",
      "sunc\n",
      "potpourr\n",
      "quakity\n",
      "vegaws\n",
      ".room\n",
      "usope\n",
      "availabilit\n",
      "old..the\n",
      "diningroom\n",
      "perfetc\n",
      "oz*some\n",
      "camptongreat\n",
      "locationlot\n",
      "reproa\n",
      "on‚Ä¶\n",
      "-DGDGDGDG\n",
      "wonderfulhotel\n",
      "cartwrig\n",
      "jaw-drop\n",
      "letoh\n",
      "mutlitple\n",
      "staybri\n",
      "accommodatoins\n",
      "/shopping\n",
      "troplv\n",
      "DGDGDGDGDG.DG\n",
      "enojable\n",
      "lobby.smoke\n",
      "availabil\n",
      "trip2018\n",
      "w/nick\n",
      "theatreland\n",
      "grandchildre\n",
      "babymoon/\n",
      "work/architecture\n",
      "paris-our\n",
      "amhazing\n",
      "imcredible\n",
      "nicep\n",
      "loud/busy\n",
      "verrry\n",
      "hgvg\n",
      "feeezing\n",
      "jaavits\n",
      "nyc-terrific\n",
      "desappointed\n",
      "lucer\n",
      "airshaft\n",
      "wynn-\n",
      "tleaf\n",
      "were:1.\n",
      "wvc\n",
      "shower-\n",
      "roomskiosk\n",
      "resort..this\n",
      "mid-manhat\n",
      "subline\n",
      "unexperie\n",
      "2.30pm\n",
      "firendly\n",
      "uxu\n",
      "summer16\n",
      "worsed\n",
      "v√¨p\n",
      "swisso\n",
      "wonder-\n",
      "complaint.this\n",
      "restaurants~\n",
      "comphy\n",
      "placefor\n",
      "revie4w\n",
      "trip0\n",
      "pleasur\n",
      "wonde\n",
      "gelatto\n",
      "800-900/night\n",
      "stephensign\n",
      "view..but\n",
      "woohoooo\n",
      "quickl\n",
      "pet-fri\n",
      "nickel-and-dime\n",
      "prebook\n",
      "luxor.good\n",
      "service.spectacular\n",
      "tstaying\n",
      "umm..\n",
      "connec\n",
      "will.-\n",
      "checked-in\n",
      "decorto\n",
      "propertyt\n",
      "street..\n",
      "xcellent\n",
      "arriver\n",
      "hm..\n",
      "rooms.bu\n",
      "cool~\n",
      "'poor\n",
      "fixtur\n",
      "breathtakin\n",
      "great/extraordinary\n",
      "buotique\n",
      "perio\n",
      "warml\n",
      "day‚ù£‚ù£‚ù£\n",
      "flamingohotel\n",
      "availale\n",
      "painles\n",
      "families.nothing\n",
      "breakstayed\n",
      "getawta\n",
      "granddaughte\n",
      "wonderous\n",
      "service/ok\n",
      "experience-the\n",
      "pezey\n",
      "üçéüòò\n",
      ".canceled\n",
      "expection\n",
      "fairmonterrific\n",
      "cathedral-view\n",
      "ÔΩéÔΩô\n",
      "begoo\n",
      "impresssed\n",
      "accesse\n",
      "/DG\n",
      "service:1\n",
      "andersonvil\n",
      "methe\n",
      "luxureous\n",
      "valete\n",
      "enthusiastical\n",
      "..where\n",
      "medival\n",
      "locaaaatioooon\n",
      "danger-the\n",
      "forc\n",
      "summar\n",
      "grandvie\n",
      "tropicana-las\n",
      "budget‚Ä¶\n",
      "workation\n",
      "extre\n",
      "evet\n",
      "warnin\n",
      "mentioni\n",
      "hotelh\n",
      "ancili\n",
      "hotelüëç\n",
      "wayfi\n",
      "-20degr\n",
      "whithin\n",
      "fornitures\n",
      "everyda\n",
      "experience..good\n",
      "üëû\n",
      "grimey\n",
      "disctr\n",
      "suite.k\n",
      "proximi\n",
      "dilapid\n",
      "won¬¥t\n",
      "/mothers\n",
      "exeriences\n",
      "wonderful..\n",
      "locropn\n",
      "2/3rds\n",
      ".first\n",
      "exaptation\n",
      ",in\n",
      "shooti\n",
      "mid-n\n",
      "lifesytle\n",
      "stayedat\n",
      "expectations.all\n",
      "..comfy\n",
      "chicagochicagoi\n",
      "mccarr\n",
      "◊û◊î◊õ◊†◊ô◊°◊î\n",
      "hisband\n",
      "condidhim\n",
      "simil\n",
      "room/food\n",
      "hotel..yikes\n",
      "rigmarol\n",
      "mediocre.had\n",
      "outsi\n",
      "cosmopolitian\n",
      "heartbea\n",
      "expericne\n",
      "staued\n",
      "rock'n'r\n",
      "pots..\n",
      "hubting\n",
      "motel-type\n",
      "roommy\n",
      "ncy\n",
      "weekend/weekday\n",
      "gnlv\n",
      "picssso\n",
      "becouse\n",
      "outstan\n",
      "witin\n",
      "respit\n",
      "recommandatiom\n",
      "updatin\n",
      "campu\n",
      "superbook\n",
      "atmosphere/\n",
      "cheaper-side\n",
      "mother/dau\n",
      "cjoice\n",
      "surprisngly\n",
      "wiill\n",
      "excelellent\n",
      "mom-\n",
      "hash-tag\n",
      "insenstive\n",
      "less-is-m\n",
      "impre\n",
      "designtex\n",
      "flaw-noise\n",
      "upda\n",
      "gogeous\n",
      "*minimal*\n",
      "stay-highly\n",
      "decwnt\n",
      "year-\n",
      "nlv\n",
      "christmas/birthday\n",
      "right-sized\n",
      "shyt\n",
      "chowmazing\n",
      "vegsd\n",
      "downtow\n",
      "granddaught\n",
      "definiitely\n",
      "kuds\n",
      "non-gambling\n",
      "neopalitan\n",
      "archtecurally\n",
      "stay..never\n",
      "welcomi\n",
      "'swipe\n",
      "tripadvised\n",
      "everyhting\n",
      "vegas-far\n",
      "experienceplace\n",
      "20-23rd\n",
      "winjum\n",
      "5-min\n",
      "sound-\n",
      "restro\n",
      "must-visit\n",
      "l9vely\n",
      "homeüéàüéÇüéâüéä\n",
      "stayvaction\n",
      "smoothl\n",
      "üò°üò°üò°üò°\n",
      "charmimg\n",
      "valuably\n",
      "'designerly\n",
      "nebst\n",
      "*DGDG/DGDG/DGDG-DGDG/DGDG/DGDG\n",
      "planner/designer\n",
      "meshan\n",
      "..excellent\n",
      "location-fair\n",
      "srevice\n",
      "associatio\n",
      "sovi\n",
      ".fine\n",
      "mclintons\n",
      "lady-\n",
      "one-and-only\n",
      "sufisticated\n",
      "pleasant/helpful\n",
      "dfntly\n",
      "alcratraz\n",
      "comfortble\n",
      "staff/sleep/location\n",
      "constrion\n",
      "york¬¥s\n",
      "free/no\n",
      "of.sm\n",
      "etreme\n",
      "melho\n",
      "deciving\n",
      "prosparking-\n",
      "'just\n",
      "üé∂\n",
      "vegas-red\n",
      "strickly\n",
      "designed.third\n",
      "sig-mgm\n",
      "performan\n",
      "inercontinental\n",
      "recognitio\n",
      "customern\n",
      "tropican\n",
      "nighclub\n",
      "cfo/coo\n",
      "same.\n",
      "58custom\n",
      "marquie\n",
      "laquin\n",
      "location/staff\n",
      "babyüá∫üá∏\n",
      "coomunications\n",
      "excepyional\n",
      "mmmmhhhh\n",
      "h‚ù§rts\n",
      "-amazing\n",
      "midsets\n",
      "excellent.however\n",
      "yoli\n",
      "delcy\n",
      "americean\n",
      "trip.to\n",
      "stay-vacation\n",
      "client-oriented\n",
      "rude/\n",
      "~DGDG\n",
      "meraviglia\n",
      "nicholoson\n",
      "drinkwell\n",
      "small-\n",
      "nervou\n",
      "DG-DGDG\n",
      "e.ma\n",
      "espes\n",
      "away-card\n",
      "/day\n",
      "gresat\n",
      "plesently\n",
      "unexpla\n",
      "stunningwed\n",
      "w-hotel\n",
      "i0n\n",
      "soho/tribe\n",
      "exceptio\n",
      "awesomecasino\n",
      "chake\n",
      "DGDGDGDGDGDG\n",
      "so-\n",
      "kids.fac\n",
      "4th/birthday\n",
      "cravet\n",
      "value/service-highly\n",
      "12:30am\n",
      "was.in\n",
      "topn\n",
      "rcvd\n",
      "venue.t\n",
      "m.g\n",
      "stowfo\n",
      "room.badly\n",
      "largeish\n",
      "normal.-\n",
      "reop\n",
      "diffiult\n",
      "nickel/dime\n",
      "induldge\n",
      "locationgood\n",
      "pool.nice\n",
      "experiencw\n",
      "skylawn\n",
      "25tg\n",
      "useles\n",
      "roomsf\n",
      "ambie\n",
      "elevaor\n",
      "facili\n",
      "location-walking\n",
      "experience/upscale\n",
      "2bed\n",
      "expercience\n",
      "trasport\n",
      "comopolitan\n",
      "freiendlines\n",
      "gggggggggggggre\n",
      "javitt\n",
      "aweosme\n",
      "..way\n",
      "hotel.everyone\n",
      "disappooints\n",
      "would'nt\n",
      "vdery\n",
      "carnegei\n",
      "fleetweek\n",
      "serivice\n",
      "üò¢\n",
      "reflec\n",
      "hub-bub\n",
      "gross-apex\n",
      "millenial\n",
      "gameq\n",
      "property-worthy\n",
      "andf\n",
      "ludlo\n",
      "febreeze\n",
      "remodel/update\n",
      "sqaure\n",
      "annaversery\n",
      "elegant-exclusive-relaxed\n",
      "districk\n",
      "un-informed\n",
      "all-in-suite\n",
      "comfortbale\n",
      "imperso\n",
      "casino.best\n",
      "worlde\n",
      "hudso\n",
      "9-days\n",
      "view-holds\n",
      "palazzo/veneti\n",
      "comfy*resta\n",
      "lurvvvvvvvvvvvvvvvvvvvvvvvve\n",
      "siutated\n",
      "squar\n",
      "'gentlemans\n",
      "bachorelette\n",
      "valet/door\n",
      "bullicio\n",
      "kandha\n",
      "travel/lifestyle\n",
      "amoma\n",
      "hechanova\n",
      "resear\n",
      "charac\n",
      "wanderful\n",
      "biohaza\n",
      "rcoe63\n",
      "marguis\n",
      "nyc-affinia\n",
      "accommoda\n",
      "5*****star\n",
      "it‚Ä¶‚Ä¶\n",
      "27-28-29th\n",
      "samoea\n",
      "manahatten\n",
      "rivingto\n",
      "inn/time\n",
      "tub/sauna\n",
      "rooms-amazing\n",
      "bae-cation\n",
      "night.c\n",
      "theknickoftime\n",
      "stay-near\n",
      "vacation-never\n",
      "'afternoon\n",
      "sta-cat\n",
      "indulgen\n",
      "chance-llor\n",
      "beeing\n",
      "manageabl\n",
      "worn/rundown\n",
      "doubled-down\n",
      "room-strip\n",
      "againh\n",
      "well-maintain\n",
      "points/cash\n",
      "show/business\n",
      "brekfas\n",
      "hotel-situated\n",
      "confere\n",
      "morenythanny\n",
      "nivht\n",
      "strange..\n",
      "boutique/\n",
      "rudyvi\n",
      "conveinet\n",
      "location.could\n",
      "DG/DGDG-DG/DG\n",
      "well-neat\n",
      "aaarrghhh\n",
      "kiasocks\n",
      "hotel.clean\n",
      "entusiast\n",
      "construction/remodeli\n",
      "this-avoid\n",
      "large-\n",
      "2-unit\n",
      "elevat\n",
      "honeympon\n",
      "shearaton\n",
      "2:30am\n",
      "introduct\n",
      "zcentral\n",
      "francisco/near\n",
      "tree-chelsea-newyork\n",
      "benjamin-\n",
      "miile\n",
      "housek\n",
      "suggesti\n",
      "channges\n",
      "javit\n",
      "milennium\n",
      "definitly\n",
      "Á∂ìÈ©óÂæàÊ£í„ÄÇÊàøÈñìÈùûÂ∏∏‰πæÊ∑®ÔºåÊôØ\n",
      "improvement.also\n",
      "location..good\n",
      "beeautiful\n",
      "review..\n",
      "dramaticly\n",
      "fee-asco\n",
      ".love\n",
      "fla-stink-o\n",
      "clientele..\n",
      "weddkng\n",
      "sanfr\n",
      "trip..amazing\n",
      "atms„ÄÇto\n",
      "convientent\n",
      "affectionado\n",
      "eugena\n",
      "octaviu\n",
      "..mlife\n",
      "mid-2019\n",
      "rivi\n",
      "postione\n",
      "cleanli\n",
      "gazillionth\n",
      "jordymiester\n",
      "servicegre\n",
      "knickerbock\n",
      "room..great\n",
      "avoi\n",
      "comprom\n",
      "do0r\n",
      "basic-\n",
      ",bad\n",
      "DGDG/DGDG*****\n",
      "upsold\n",
      "do-not-disturb\n",
      "2-march\n",
      "staff+incredible\n",
      "terrible.li\n",
      "assistan\n",
      "manhata\n",
      "requi\n",
      "less-than-impressive\n",
      "on-\n",
      "iece\n",
      "7nights\n",
      "erickson-hoffman\n",
      "poorly-trained\n",
      "sorprise\n",
      "w36th\n",
      "maceys\n",
      "‚úàÔ∏èüá∫üá∏‚úàÔ∏è\n",
      "mxon\n",
      "aaa+++\n",
      "hotzone\n",
      "bustli\n",
      "work.sh\n",
      "we'very\n",
      "'non\n",
      "locatio0n\n",
      "minicaton\n",
      "gratef\n",
      "comp'ed\n",
      "select-service\n",
      "flirst\n",
      "focuse\n",
      "everüëçüèªüëçüèª\n",
      "yhing\n",
      "ugh..do\n",
      "singl\n",
      "especia\n",
      "nyc-living\n",
      "aweseom\n",
      "viand\n",
      "exhorbidant\n",
      "etiquet\n",
      "'buzz\n",
      ".smell\n",
      "stay-exceptional\n",
      "bally's/gold\n",
      "out-of-sight\n",
      "withiin\n",
      "roomc\n",
      "considered-\n",
      "joyed\n",
      "not-\n",
      "direcyor\n",
      "conciergew\n",
      "localizado\n",
      "recommended..\n",
      "resort-\n",
      "hotel/elevators\n",
      "DGDG/DG/DGDG\n",
      "stars-housekeeping\n",
      "monoco\n",
      "giovann\n",
      "drake/\n",
      "nqr\n",
      "hotel48\n",
      "celebr\n",
      "t.p\n",
      "zacha\n",
      "dissappointing\n",
      "strip..\n",
      "a+for\n",
      "class-act\n",
      "fabulous-\n",
      "liberry\n",
      "uncomfortab\n",
      "fountain/beautiful\n",
      "wasnot\n",
      "night/3\n",
      "change-\n",
      ".thr\n",
      "favo\n",
      "summer2018\n",
      "brand-where\n",
      "extreemly\n",
      "condotel\n",
      "hustl\n",
      "-claustrophobic\n",
      "youuuu\n",
      "advan\n",
      "recue\n",
      "prepla\n",
      ".soho\n",
      "dispointed\n",
      "archit\n",
      "hotelwat\n",
      "advertising_poor\n",
      "oassiz\n",
      "javitts\n",
      "pre-xmas\n",
      "price/quality-ratio\n",
      ".aft\n",
      "business/getaway\n",
      "great.went\n",
      "caesari\n",
      "omin\n",
      "smoker-friendly\n",
      "wubs-stay\n",
      "attitude/service\n",
      "settl\n",
      "trepidat\n",
      "downfal\n",
      "matresss\n",
      "endulge\n",
      "kual\n",
      "nights.lu\n",
      "utiliza\n",
      "excellinent\n",
      "bedfor\n",
      "before..\n",
      "-this\n",
      "exceeded..\n",
      "argonautwe\n",
      "york/manhat\n",
      "bellagio-still\n",
      "serivces\n",
      "senb\n",
      "hbothe\n",
      "reuinion\n",
      "ok.\n",
      "pfizenmayer\n",
      "spot-great\n",
      "romant\n",
      "celion\n",
      "everyboby\n",
      "premiun\n",
      "eehh\n",
      "michaleangelo\n",
      "wrekrnd\n",
      "locationcons\n",
      "phenemonal\n",
      "averadge\n",
      "year..\n",
      "perk/\n",
      "again-love\n",
      "fast..unfortunate\n",
      "nekola\n",
      "budgetplaces\n",
      "jastania\n",
      "convenietnly\n",
      "glamerous\n",
      "consistance\n",
      "outstsnding\n",
      "ganservoort\n",
      "hotel48lex\n",
      "days.the\n",
      "showers/toilets\n",
      "poshmark\n",
      "all-su\n",
      "eve/\n",
      "spaciousc\n",
      "breathi\n",
      "conveniance\n",
      "peerfect\n",
      "location/roomy\n",
      "headboa\n",
      "hip-looking\n",
      "*good\n",
      "especifi\n",
      "check‚Äëin/\n",
      "interacti\n",
      "staffrooms\n",
      "dear..\n",
      "location.cell\n",
      "pre-vi\n",
      "elsewher\n",
      "amaizng\n",
      "manhatte\n",
      "uncr\n",
      "week.easy\n",
      "maykiel\n",
      "'unreal\n",
      "cons1\n",
      "prosexcellent\n",
      "honeymoon-ing\n",
      "question09/09/2017\n",
      "lqs\n",
      "addressin\n",
      "bitt\n",
      "restaura\n",
      "kne\n",
      "closedplace\n",
      "mo_nyc\n",
      "geraldini\n",
      "Á≥üÈÄè‰∫Ü\n",
      "4th-\n",
      "relaxatio\n",
      "jubalee\n",
      "feedbackour\n",
      "adequat\n",
      "implacabl\n",
      "‚ù§\n",
      "stayed.enjoyed\n",
      "unsatsified\n",
      "¬£DG\n",
      "rafaell\n",
      "aqu\n",
      "nikk\n",
      "daunus\n",
      "1.30am\n",
      "tower-\n",
      "brillaint\n",
      "newy\n",
      "families..\n",
      "stop..nyc\n",
      "isses\n",
      "guestro\n",
      "masterpi\n",
      "hhelp\n",
      "flahmingo\n",
      "resturan\n",
      "cormwell\n",
      "aquare\n",
      "lobby/tired\n",
      "race/spor\n",
      "thouroughly\n",
      "club-amazing\n",
      "excessi\n",
      "pressure‚Ä¶\n",
      "carolcanada15\n",
      "jessiana\n",
      "tops-\n",
      "freom\n",
      "adjustmen\n",
      "andersonville-wrigley\n",
      "wesrgat\n",
      "aweome\n",
      "prefrabl\n",
      "soho/tribeca-a\n",
      "hotel.exelle\n",
      "daysbeautiful\n",
      "hi..\n",
      "price-just\n",
      "kayra\n",
      "in/general\n",
      "fustrated\n",
      "frantastic\n",
      "pourly\n",
      "hestitancy\n",
      "hotel-memorable\n",
      "fine..\n",
      "meradith\n",
      "refu\n",
      "hassels\n",
      "mile-chicago-i\n",
      "+chara\n",
      "dpot\n",
      "exc-ellent\n",
      "..plus\n",
      "transportati\n",
      "above-\n",
      "mintenance\n",
      "2015it\n",
      "westsider\n",
      "discoverin\n",
      "i80\n",
      "expectations.w\n",
      "impr\n",
      "venition\n",
      "intercontential\n",
      "delicious.my\n",
      "loveeeee\n",
      "gifte\n",
      "ÔºòÊúàÔºíÔºì„ÄúÔºíÔºñÊó•„ÄÅÂ¶π„Å®ÔºíÔºê‰ª£„ÅÆÁî•„ÄÅÁßÅ„Å®ÔºëÔºê‰ª£„ÅÆÊÅØ\n",
      "fan-dabby-dozzy\n",
      "allnot\n",
      "orginized\n",
      "sept30-oct\n",
      "clean.t\n",
      "choosen\n",
      "üé≠\n",
      "listüòç\n",
      "inconvenie\n",
      "kimpton-buchanan\n",
      "tenderloi\n",
      "city-break\n",
      "square-stay\n",
      "gage/petrouski\n",
      "citycent\n",
      "goodstay\n",
      "ughh\n",
      "small.ver\n",
      "unsavor\n",
      "lobby/econo\n",
      "benjami\n",
      "affordable/clean/large\n",
      "dating..\n",
      "lasvegs\n",
      "bathrooma\n",
      "over-price\n",
      "DG.DGDGDGDG\n",
      "visitori\n",
      ".small\n",
      "gallarbo\n",
      "thur-mon\n",
      "countp\n",
      "conventions..\n",
      "doweger\n",
      "..all\n",
      "suites-failure\n",
      "reviews..and\n",
      "diapointing\n",
      "city-trip\n",
      "locatcated\n",
      "argua\n",
      "design/concept\n",
      "thouroghly\n",
      "*ho\n",
      "timenin\n",
      "over-busy\n",
      "magcard\n",
      "anymore.\n",
      "thewow\n",
      "perfect/servi\n",
      "room.we\n",
      "guarant\n",
      "resort.small\n",
      "froliicing\n",
      "tranqui\n",
      "stirp\n",
      "no-gaming\n",
      "√ßok\n",
      "ÏùºÎã®\n",
      "w/fantastic\n",
      "improvement..\n",
      "„ÇÇ„ÅÜ‰∏ÄÂ∫¶Ê≥ä„Åæ„Çä„Åü„ÅÑ\n",
      "tower-it\n",
      "rgret\n",
      "location/poor\n",
      "130/night\n",
      "a'changing\n",
      "d443\n",
      "exacltly\n",
      "comvenient\n",
      "statio\n",
      "location..get\n",
      "earth..\n",
      "finantial\n",
      "beds.gre\n",
      "celebration/cancer\n",
      "it.had\n",
      "european-focused\n",
      "yorky\n",
      "uncomplicated-\n",
      "trendi\n",
      "mid/low\n",
      "sightseeng\n",
      "defently\n",
      "service.the\n",
      "city-location\n",
      "a/2\n",
      "smokinng\n",
      "condidtion\n",
      "lvegas\n",
      "construction=renovation\n",
      "caval\n",
      "tribute‚Äîpurple\n",
      "hotel.there\n",
      "itsby\n",
      "extensiv\n",
      "yest\n",
      "lex-marriott\n",
      "groupo\n",
      "lobelo\n",
      "3-n\n",
      "-c\n",
      "radiato\n",
      "'classic\n",
      "langha\n",
      "ces2015\n",
      "cost/benefit\n",
      "opci√≥n\n",
      "ardyss\n",
      "üé≤üé≤\n",
      "◊ó◊ï◊§◊©◊™\n",
      "Èõ£ÂæóÂÆ∂Â∫≠ÊóÖÈÅäÔºåÂπ∏ÈÅãÁöÑËÉΩÊèêÊó©ÂÖ•Êàø\n",
      "amazingl\n",
      "centerally\n",
      "championshipfs\n",
      "freinds\n",
      "malfu\n",
      "elton/reba\n",
      "toir\n",
      "2-weeks\n",
      "everrrrrr\n",
      "recei\n",
      "refurbishe\n",
      "nightlif\n",
      "awesome-rooms\n",
      "attracte\n",
      "stayeda\n",
      "b+b\n",
      "doorme\n",
      "annive\n",
      "panaramoic\n",
      "room-type\n",
      "***location\n",
      "üò¨\n",
      "indee\n",
      "acsses\n",
      "sleaz\n",
      "herrrrow\n",
      "‚Äãloved\n",
      "draperunne\n",
      "fountains..\n",
      "harrash\n",
      "inwe\n",
      "fantastic..\n",
      "friiendly\n",
      "..caesars\n",
      "DGDG..\n",
      "thetimes\n",
      "dispen\n",
      "celibration\n",
      "unattentive\n",
      "ever..the\n",
      "3-sta\n",
      "everrrrr\n",
      "accesible\n",
      "pre-the\n",
      "penins\n",
      "famiy\n",
      "afforability\n",
      "valintine\n",
      "wellendorff\n",
      "22-26th\n",
      "sporadicall\n",
      "eelegant\n",
      "slywia\n",
      "reasonablely\n",
      "gluten-friendly\n",
      "slssss\n",
      "attendan\n",
      "locationharrah\n",
      "soho+\n",
      "****\n",
      "freshes\n",
      "fab5\n",
      "boutique=smallon\n",
      "ocated\n",
      "vacationüå≤üå≤üå≤\n",
      "perfect.the\n",
      "attendents\n",
      "extremley\n",
      "phenomonal\n",
      "surprinsingly\n",
      "qfr\n",
      "k.sh\n",
      "dana-tastic\n",
      "customer-un\n",
      "hwent\n",
      "thomps\n",
      "three-\n",
      "staffni\n",
      "novody\n",
      "nicestaff\n",
      "all-s\n",
      "reccomend-clean\n",
      "margaritavile\n",
      "loveeee\n",
      "walkw\n",
      "averag\n",
      "geeat\n",
      "othereise\n",
      "service..chilly\n",
      "chiraq\n",
      "long-te\n",
      "vicero\n",
      "grand-suite\n",
      "services/care\n",
      "operatio\n",
      "histor\n",
      "mother-daug\n",
      "complaint-\n",
      "place-mike\n",
      "rooms-grumpy\n",
      "forwar\n",
      "coffemak\n",
      "cleap\n",
      "beekmans\n",
      "cosmotastic\n",
      "smoking-casino\n",
      "10/16/thru\n",
      "loveeeedddd\n",
      "w/outstanding\n",
      "mehh\n",
      "implimented\n",
      "venue.had\n",
      "back..\n",
      "manhattab\n",
      "unbel\n",
      "travelforreal\n",
      "location/mediocre\n",
      "worest\n",
      "old-fashione\n",
      "oooold\n",
      "tour-\n",
      "butihi\n",
      "aspcts\n",
      "crapless\n",
      "experirnce\n",
      "needs/wants\n",
      "weekand\n",
      "evlyn\n",
      "suppor\n",
      "irresponsive\n",
      "service/facilities\n",
      "valeted\n",
      "bennounas\n",
      "baystaye\n",
      "'semi\n",
      "dtown\n",
      "-celebration\n",
      "hanbed\n",
      "meluisa\n",
      "recommemded\n",
      "granddaghters\n",
      "sustai\n",
      "ofth\n",
      "sized-room\n",
      "coice\n",
      "raffaell\n",
      "complimentar\n",
      "mani/pedi\n",
      "inef\n",
      "hampton-las\n",
      "mini-apartment\n",
      "accomodations/best\n",
      "waow\n",
      "igno\n",
      "rooms/no\n",
      "side.par\n",
      "vidara\n",
      "august2017\n",
      "butique\n",
      "staygreat\n",
      "97kathm\n",
      "timealways\n",
      "ms.minh\n",
      "vegas-amazing\n",
      "location/expensive/needs\n",
      "level..a\n",
      "people-\n",
      "else..\n",
      "price-benefit\n",
      "..sa\n",
      "tuesday-s\n",
      "experiencenice\n",
      "'good\n",
      "plalazzo\n",
      "supprised\n",
      "outsta\n",
      "dcarpe\n",
      "dissapopintment\n",
      "cmcd\n",
      "electirc\n",
      "spous\n",
      "room-no\n",
      "superior.a\n",
      "love/not\n",
      "..did\n",
      "awsomee\n",
      "ontari\n",
      "stayfun\n",
      "inaccu\n",
      "a.‚Ä¢\n",
      "feelings-check\n",
      "acros\n",
      "encount\n",
      "resonabl\n",
      "airline-style\n",
      "sfctid\n",
      "1000/nigh\n",
      "vegas..seren\n",
      "..sup\n",
      "experjence\n",
      "nearb\n",
      "trhee\n",
      "from6/5\n",
      "..joining\n",
      "home-away-\n",
      "sincity\n",
      "hsve\n",
      "diffucult\n",
      "average-\n",
      "oasis/perfect\n",
      "booring\n",
      "fluffiest\n",
      "dpwntown\n",
      "3nites.my\n",
      "+location\n",
      "25h\n",
      "girl-cation\n",
      "receip\n",
      "first-r\n",
      "funcoast\n",
      "particula\n",
      "coworke\n",
      "awesonme\n",
      "spreak\n",
      "w/modern\n",
      "rebiew\n",
      "pre-booking/\n",
      "atend\n",
      "amazinh\n",
      "scorin\n",
      "iwe\n",
      "loungin\n",
      "airli\n",
      "riverf\n",
      "vdara-great\n",
      "‚Ä¶not\n",
      "design.lo\n",
      "mini-stay\n",
      "alise-chicago\n",
      "28-sept1\n",
      "summer2014\n",
      "upmarke\n",
      "hskp\n",
      "unplan\n",
      "yoir\n",
      "home.lo\n",
      "oui-oui\n",
      "remem\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eventi\n",
      "metr\n",
      "'treat\n",
      "4-seasons/ritz\n",
      "knuck\n",
      "chrismas\n",
      "diff.\n",
      "wifiwasher\n",
      "dispi\n",
      "delight..great\n",
      "incaesars\n",
      "inlove\n",
      "üèÜ\n",
      "unserviced\n",
      "casino/lame\n",
      "bi-annua\n",
      "semi-double\n",
      "30-may-5\n",
      "rockn\n",
      "location/quality\n",
      "deversity\n",
      "clean.s\n",
      "non-smoked\n",
      "ofdownto\n",
      "non-tacky\n",
      "üëå\n",
      "‚úå\n",
      "tastef\n",
      "exceede\n",
      "mediocracy\n",
      "billling\n",
      "uplifitin\n",
      "elegante/di\n",
      "room‚Äîfour\n",
      "updating/cleaning\n",
      "suite/sweet\n",
      "3days\n",
      "crazi\n",
      "intercontinenal\n",
      "tdunbar117\n",
      "sewards\n",
      "afgain\n",
      "hotelall\n",
      "convienieny\n",
      "generati\n",
      "weekendvtrip\n",
      "/n\n",
      "accurat\n",
      "siml\n",
      "arghhhhhhhh\n",
      "recoomandable\n",
      "choise\n",
      "there-we\n",
      "twent\n",
      "famly\n",
      "..the\n",
      "beatl\n",
      "francsc\n",
      "ameritan\n",
      "off-s\n",
      "adequatel\n",
      "spiri\n",
      "quieter..\n",
      "re-anniversary\n",
      "gorgeou\n",
      "perfect.you\n",
      "sejpal\n",
      "elara-\n",
      "opulent..massive..fun\n",
      "doubletre\n",
      "hotel-adequate\n",
      "lounge=sham\n",
      "*everyth\n",
      "value-fun\n",
      "side/midtown\n",
      "espetacul\n",
      "somegood\n",
      "disabled/handicap\n",
      "refrigerat\n",
      "midtown/hk\n",
      "staybrid\n",
      "beresfo\n",
      "pierr\n",
      "morni\n",
      "son-i\n",
      "floor-vie\n",
      "hotel-beware\n",
      "fairmontable\n",
      "starbu\n",
      "nocks\n",
      "extraordina\n",
      "differnce\n",
      "unrespectful\n",
      "auful\n",
      "heada\n",
      "snowzilla\n",
      "surte\n",
      "aug/sep\n",
      "inmidst\n",
      "yrip\n",
      "colorf\n",
      "terribe\n",
      "customer-oriented\n",
      "chels\n",
      "10th-\n",
      "..no\n",
      "hiddengem\n",
      "homophobics\n",
      "roomscasinosmall\n",
      "roomselevator\n",
      "DG‚≠êÔ∏è\n",
      "sizeany\n",
      "o'har\n",
      "sohooo\n",
      "weekda\n",
      ".outrageous\n",
      "bugsin\n",
      "eccellente\n",
      "covernience\n",
      "manhattan-just\n",
      "belv\n",
      "exeri\n",
      "'four\n",
      "krystin\n",
      "desk-very\n",
      "adults+2\n",
      "july-4aug\n",
      "money-stay\n",
      "..tiny\n",
      "to.address\n",
      "beginnin\n",
      "wuuao\n",
      "great..somewhat\n",
      "pros=\n",
      "hubub\n",
      "food/be\n",
      "hotel..op\n",
      "67/day\n",
      "customer-friendly\n",
      "wabi-sabi\n",
      "expectation..\n",
      "luxiourious\n",
      ".we\n",
      "automati\n",
      "twould\n",
      "..back\n",
      "fab-2nd\n",
      "fridg\n",
      "nassua\n",
      "hotelcarnevino\n",
      "balcomy\n",
      "chicagoi\n",
      "stay-space\n",
      "linq..t.he\n",
      "nice-midtown\n",
      "wyndh\n",
      "tecia\n",
      "..some\n",
      "glory..with\n",
      "allysa\n",
      ".amenaties\n",
      "days/two\n",
      "grandaughters\n",
      "weekemd\n",
      "lombardtastic\n",
      "suberb\n",
      "answe\n",
      "'cheap\n",
      "brya\n",
      "great.te\n",
      "intrrac\n",
      "over-ni\n",
      "everything~\n",
      "square/broadway\n",
      "godf\n",
      "vdara/vegas\n",
      "DGDGDG-\n",
      "accomondations\n",
      "nastelgic\n",
      "bathrooms‚Ä¶\n",
      "disappointing-shabby\n",
      "hottub\n",
      "hiran-best\n",
      "stay..and\n",
      "establi\n",
      "husband-good\n",
      "tekita\n",
      "finaliz\n",
      "atten\n",
      "mattr\n",
      "mattres\n",
      "terrible/never\n",
      "msdolly\n",
      "location.p\n",
      "night/birthday\n",
      "best/not\n",
      "shihayda\n",
      "recommend..\n",
      "break/bday\n",
      "brunchwe\n",
      "isperfect\n",
      "8-night\n",
      "ck-in\n",
      "DG/DGDG-DG/DG/DGDG\n",
      "spectacularness\n",
      "ceasa'rs\n",
      "fantastc\n",
      "nomosoho\n",
      "center-great\n",
      "eekend\n",
      "dining/entertainment\n",
      "saisfied\n",
      "closeby\n",
      "location/value/service\n",
      "location/moderate\n",
      "hotel.i\n",
      "werc\n",
      "/holiday\n",
      "cooli\n",
      "w/queen\n",
      "luxor-read\n",
      "unbea\n",
      "inatte\n",
      "disappointed-will\n",
      "DG/DGDG/DGDGDGDG-DG/DGDG/DGDGDGDG\n",
      "mirr\n",
      "venice..singing\n",
      "gizelle\n",
      "stabil\n",
      "location..rooms\n",
      "fussiest\n",
      "congen\n",
      "prehistor\n",
      "start-\n",
      "i/we\n",
      "for/\n",
      "experiences.seems\n",
      "innovation-style-hospitality\n",
      "nice-ish\n",
      "stayvaccomidati\n",
      "2016-aria\n",
      "nautically\n",
      ".style\n",
      "per-diem\n",
      "germaphobes\n",
      "workthe\n",
      "well-sit\n",
      "disappointmet\n",
      "reasonable..\n",
      "marrie\n",
      "french-themed\n",
      "evelytn\n",
      "ceter\n",
      "exellence\n",
      "vacation/celebration\n",
      "countr\n",
      "days.buffet\n",
      "ph35\n",
      "vegasgreat\n",
      "//\n",
      "anyday\n",
      "understatem\n",
      "wildl\n",
      "samstown\n",
      "comfor\n",
      "day-stay\n",
      ".basic\n",
      "lifestyl\n",
      "nejron\n",
      "mahatten\n",
      "peacefu\n",
      "unprofession\n",
      "veryyyyy\n",
      "hy-buddy\n",
      "sisters/cousin\n",
      "property/\n",
      "compara\n",
      "2:40am\n",
      "nothign\n",
      "normall\n",
      "gettting\n",
      "pirrow\n",
      "nondesc\n",
      "exensive\n",
      "ok'ish\n",
      "stewart=perfect\n",
      "valet/\n",
      "locationreason\n",
      "thankfull\n",
      "wonderstul\n",
      "tropicna\n",
      "happy/no\n",
      "desk/check-in\n",
      "proprrty\n",
      "/assistance\n",
      "llegamos\n",
      "staff/no\n",
      "ear-splitting\n",
      "york-missed\n",
      "-try\n",
      "6:40p\n",
      ",shame\n",
      "ooooooh\n",
      "byowater\n",
      "poaition\n",
      "deploym\n",
      "disapointeed\n",
      "nicewished\n",
      "man/woman\n",
      "pro-great\n",
      "noisy-busy-hectic-ordinary\n",
      "thatlobby\n",
      "airport/car\n",
      "lobby-\n",
      "lviin\n",
      "√±o\n",
      "reviewin\n",
      "hotel/casinoi\n",
      "undersrviced\n",
      "pyrimad\n",
      "ucdavis.edu\n",
      "margina\n",
      "srue\n",
      "üíÉ\n",
      "soebox\n",
      "frienday\n",
      "security/keys\n",
      "freidnly\n",
      "pre-trip\n",
      "strip.easy\n",
      "shoestrin\n",
      "marker~san\n",
      "devona\n",
      "‚Äãi\n",
      "ltttle\n",
      "decor..\n",
      "impro\n",
      "shocard\n",
      "exageratin\n",
      "satisfa\n",
      "nights.reco\n",
      "casinolas\n",
      "üëä\n",
      "hyper-trendy\n",
      "location-avoid\n",
      "hotein\n",
      "rooms..this\n",
      "6-star\n",
      "this‚Ä¶.luxurious\n",
      "york/central\n",
      "property-december\n",
      "hotel/quaint\n",
      "excellenthallways\n",
      "fisherma\n",
      "sanfransisco\n",
      "near-times\n",
      "cris-ann\n",
      "centralposition\n",
      "service.gre\n",
      "nachvollziehen\n",
      "everywh\n",
      "ocer\n",
      "knowledgea\n",
      "anticipati\n",
      "ever-never\n",
      "phenomenonal\n",
      "minute.com\n",
      "great‚Ä¶\n",
      "locationhousekeepi\n",
      "chic1\n",
      "pricedo\n",
      "courteo\n",
      "shufflemaster\n",
      "hotel/resort/ca\n",
      "summer-absolutely\n",
      "business/pleasue\n",
      "experience/golden\n",
      "thime\n",
      "loud-there\n",
      "aestheti\n",
      "room..they\n",
      "vegas.this\n",
      "turnt\n",
      "ÏßÅÏõêÎì§\n",
      "non-street\n",
      "stunded\n",
      "d√©co\n",
      "ladiestrip\n",
      "location.insu\n",
      "vegastrip2k16\n",
      "oppurtunity\n",
      "busness\n",
      "n.i.c.e\n",
      "deteriora\n",
      "double-queen\n",
      "locatedfive\n",
      "frisco-riffic\n",
      "floor.i\n",
      "√©l√©gant\n",
      "heart‚ù§Ô∏è\n",
      "~DGDGDG\n",
      "creapy\n",
      "wifi.2\n",
      "incroyable\n",
      "swagger/charm\n",
      "technology-forwar\n",
      "blizzar\n",
      "business.pleasure\n",
      "midtown.ro\n",
      "okay.if\n",
      "*amazing*\n",
      "value/brilliant\n",
      "primium\n",
      "entretainment\n",
      "linoln\n",
      "esport\n",
      "locet\n",
      "amaaaaazing\n",
      "tweens-stayed\n",
      "gambing\n",
      "updat\n",
      "downst\n",
      "DG.DG.\n",
      "relazed\n",
      "3da\n",
      "francico\n",
      "shodd\n",
      "renovation-a\n",
      "excelleent\n",
      "outch\n",
      ".g\n",
      "amaznig\n",
      "financia\n",
      "thoughtspot\n",
      "inexpens\n",
      "üëçüèΩ\n",
      "suprisingley\n",
      "friendly/helpfu\n",
      "iews\n",
      "osenrg\n",
      "staf5\n",
      "nostagic\n",
      "laset\n",
      "'bouti\n",
      "4nights.we\n",
      "workers.forst\n",
      "amenitus\n",
      "ex-hotel\n",
      "criticis\n",
      "parksleepfly\n",
      "ratng\n",
      "beekm\n",
      "üéÑ\n",
      "hollow/m\n",
      "hospitality..\n",
      "boigie\n",
      "mr.and\n",
      "coneniently\n",
      "margarittaville\n",
      "holiday/wedding\n",
      "queenbee\n",
      "house..\n",
      "envoyed\n",
      "***warn\n",
      "noises-\n",
      "spg5\n",
      "DGDG.DG.DGDGDGDG\n",
      "late..\n",
      "bulldo\n",
      "summer2017\n",
      "beatif\n",
      "pleasnt\n",
      "wynntrip\n",
      "630a\n",
      "crombez\n",
      "28/day\n",
      "penisula\n",
      "admitt\n",
      "girls-\n",
      "'time\n",
      "yolos\n",
      "squatr\n",
      "north-loyola\n",
      "unavailab\n",
      "'filmed\n",
      "hospitalil\n",
      "fashion..\n",
      "recenting\n",
      "surgica\n",
      "-grateful\n",
      "closet-size\n",
      "location/price\n",
      "mother/daughter\n",
      "rooms-j\n",
      ".helpful\n",
      "tank-sl\n",
      "exten\n",
      "w/river\n",
      "expensivr\n",
      "hastu\n",
      "linda..\n",
      "solo/business\n",
      "divey\n",
      "auricchio\n",
      "location:4/5bathroom:3/3lo\n",
      "specialt\n",
      "hh/hgv\n",
      "revviews\n",
      "servicies\n",
      "explorist\n",
      "hotel.roo\n",
      "clen\n",
      "expo/\n",
      "vaca/\n",
      "disappoointment\n",
      "stlv50\n",
      "200/nt\n",
      "buffet..\n",
      "3ed\n",
      "be..to\n",
      "justed\n",
      "Áâπ„Å´‰æ°Ê†º„ÅåÈ´ò„ÅÑÈÉΩÂ∏ÇÔºà„É≠„É≥„Éâ„É≥„ÄÅ„Çµ„É≥„Éï„É©„É≥„Ç∑„Çπ„Ç≥Á≠âÔºâ\n",
      "last-minu\n",
      "drinks/lite\n",
      "locationcleaning\n",
      "hotel-fabulous\n",
      "shiemk\n",
      "non-hilton\n",
      "mid-we\n",
      "execeptional\n",
      "immacculate\n",
      "well-locate\n",
      "ok-not\n",
      "connectivit\n",
      "hotel/extended\n",
      "wowdab\n",
      "impression-\n",
      "errr\n",
      "myopi\n",
      "recogniti\n",
      "simpel\n",
      "whard\n",
      "motel-style\n",
      "sunri\n",
      "welcomenice\n",
      "vunue\n",
      "rulez\n",
      "rown\n",
      "reaonable\n",
      "ececllent\n",
      "well-lighted\n",
      "v'dara\n",
      "visit..will\n",
      "üëçüèæ\n",
      "fair-at-best\n",
      "probkem\n",
      "hiltonhonor\n",
      "lavation\n",
      "acomodations\n",
      "hotel.trendy\n",
      "unexpected/not\n",
      "absouletly\n",
      "entertainment/a\n",
      "square/the\n",
      "‚ù§Ô∏èchicago‚ù§Ô∏è\n",
      "hotel/good\n",
      "trul\n",
      "alvsi\n",
      "reviewfirstly\n",
      "airpla\n",
      "-carpet\n",
      "chinat\n",
      "beat-ready\n",
      "togeth\n",
      "weeeknd\n",
      "fee-\n",
      "misleadimg\n",
      "5nights\n",
      "birthday/memorial\n",
      "plung\n",
      "time-\n",
      "desk/le\n",
      "value-clean\n",
      "parislv\n",
      "badthis\n",
      "amist\n",
      "elemen\n",
      "service-0\n",
      ".h\n",
      "boutique-li\n",
      "arrietta\n",
      "all-ar\n",
      "checkin/che\n",
      "atmosphere/the\n",
      "location-service-food\n",
      "crazy..\n",
      "friendlynice\n",
      "location/noisy\n",
      "lania\n",
      "ph2016\n",
      "exhibi\n",
      "extrodinaire\n",
      "efectiviness\n",
      "stay/excellent\n",
      "hotel-avoid\n",
      "smalll\n",
      "says-\n",
      "3:15am\n",
      "dhotel\n",
      "floor-still\n",
      "dfy\n",
      "getawe\n",
      "farmaid\n",
      "mislead/elevators\n",
      "-immaculate\n",
      "michelan\n",
      "aroune\n",
      "room-stylish\n",
      "experience***\n",
      "squarenear\n",
      "timatha\n",
      "positiv\n",
      "spected\n",
      "bscai\n",
      "servc\n",
      "arrivalupon\n",
      "good-s\n",
      "redemm\n",
      "noticea\n",
      "10.00pm\n",
      "Ôøºworst\n",
      "5.59/night\n",
      "newyorktastic\n",
      "-ok\n",
      "..location\n",
      "lookking\n",
      "seeetd\n",
      "uncoperative\n",
      "location/awesome\n",
      "even-\n",
      "avalo\n",
      "tired..\n",
      "best-located\n",
      "5-day-\n",
      "convience\n",
      "paperthin\n",
      "mirag\n",
      "rooms/family\n",
      "squeeeeeeeze\n",
      "dodgey\n",
      "comecome\n",
      "mis-represent\n",
      "fair..im\n",
      "hotel.fantastic\n",
      "special..\n",
      "horr√≠ble\n",
      "downsi\n",
      "hostel-esc\n",
      "renaissa\n",
      "sensetive\n",
      "cad/\n",
      "midtownish\n",
      "incomptent\n",
      "fastastico\n",
      "minimalist/ind\n",
      "tired-run\n",
      "balancin\n",
      "signatre\n",
      "venetianm\n",
      "experience-perfect\n",
      "maintena\n",
      "stratoshere\n",
      "low-frills\n",
      "everyone..\n",
      "peoplegood\n",
      "postage-s\n",
      "tomlinsons\n",
      "okbut\n",
      "ÊîæË°åÊùé‰ºëÊÅØÂæàÂèãÂñÑÁöÑ\n",
      "acceptab\n",
      "saturd\n",
      "rockfelle\n",
      "visitve\n",
      "mr.delano\n",
      "r-c\n",
      "service-bad\n",
      "insti\n",
      "tendin\n",
      "renaissan\n",
      "‰ªäÂõû„ÅØ„Åô„Åê„Åù„Å∞„Å´Ë¶≥Ë¶ßËªä„Åå„Åß„Åç„Å¶Áâπ„Å´Ê•Ω„Åó„ÇÅ„Åæ„Åó„Åü„ÄÇÂà©Áî®\n",
      "'better\n",
      "agiain\n",
      "staycati\n",
      "short-\n",
      ".comfort\n",
      "letti\n",
      "ridiculo\n",
      "matresses\n",
      "newyearstrip\n",
      "roosevelt-new\n",
      "renovted\n",
      "euro-chic\n",
      "meticul\n",
      "wow-here\n",
      "boutiquehotell\n",
      "treatmen\n",
      "uninspiri\n",
      "recive\n",
      "recomendation\n",
      "mashines\n",
      "we¬¥ve\n",
      "motiff\n",
      "not.in\n",
      "august-w\n",
      "rooms/best\n",
      "helfull\n",
      "presid\n",
      "elevatoring\n",
      "professio\n",
      "modern/industrial\n",
      "business/pleasure-50th\n",
      "neighborhoo\n",
      "platinium\n",
      "lot..\n",
      "deffinately\n",
      "designer-types\n",
      "-ideal\n",
      "virws\n",
      "high-enjd\n",
      "wonderdul\n",
      "agaian\n",
      "w/awesome\n",
      "nmun-ny\n",
      "sensatio\n",
      "well-maint\n",
      "anenties\n",
      "service.had\n",
      "fresheni\n",
      "privare\n",
      "◊û◊°◊ô◊ô◊¢\n",
      "trip=great\n",
      "restraunt\n",
      "-huge\n",
      "inbecause\n",
      "knowledg\n",
      "non-contactable\n",
      "suites-great\n",
      "underst\n",
      "othing\n",
      "sofistication\n",
      "harahs/ceasers\n",
      "w/reasonable\n",
      "adilla\n",
      "sercices\n",
      "5-s\n",
      "thursd\n",
      "dis-organized\n",
      "1-bedroom\n",
      "day/by\n",
      "locsion\n",
      "cirq\n",
      "hedious\n",
      "hoteldouble\n",
      "taberez\n",
      "semi-luxury\n",
      "obse\n",
      "cromwell101\n",
      "yorkbreak\n",
      "carefre\n",
      "gust√≥\n",
      "terriblecorrido\n",
      "nylony\n",
      "..attention\n",
      "stay-and\n",
      "family.as\n",
      "royalty-wise\n",
      "wayyyyy\n",
      "us.th\n",
      "coeliacs\n",
      "4th-may\n",
      "up-fro\n",
      "anoter\n",
      "chcked\n",
      "price/stay\n",
      "vegas..nonstop\n",
      "wacke\n",
      "ti‚Ä¶again\n",
      "ignor\n",
      "paris2018\n",
      "spacious+\n",
      "district-\n",
      "impressi\n",
      "ubtech\n",
      "1990s-style\n",
      "eventi-\n",
      "managemen\n",
      "room-long\n",
      "chgs\n",
      "excalibur..\n",
      "rate..th\n",
      "too.\n",
      "patr\n",
      "anniver\n",
      "treatament\n",
      "weathe\n",
      "opulenc\n",
      ".rare\n",
      "city/manhattan/times\n",
      "champs-√®lys√®e\n",
      "serenit\n",
      "..\n",
      "..r\n",
      "us..\n",
      "conge\n",
      "..check\n",
      "average-average-average\n",
      "mantained\n",
      "jet-lagged\n",
      "feelngs\n",
      "nostalgi\n",
      "apackage\n",
      "bited\n",
      "awesome..the\n",
      "night-great\n",
      "anothr\n",
      "finish.t\n",
      "perfeclynice\n",
      "location.fri\n",
      "hotel/res\n",
      "budg\n",
      "marcel-\n",
      "fab-\n",
      "upcyc\n",
      "hvae\n",
      "elseware\n",
      "3gg\n",
      "differenti\n",
      "expeadia\n",
      "mediocrit\n",
      "spacious-average\n",
      "phoneix\n",
      "paris.\n",
      "cadino\n",
      "over-pricin\n",
      "mvg\n",
      "hype-\n",
      "t.vsa\n",
      "horrrible\n",
      "zestiest\n",
      "kurzurlaub\n",
      "conference-\n",
      "flaminog\n",
      ",.we\n",
      "air/hotel\n",
      "crossi\n",
      ".f\n",
      "sparce\n",
      "aftercheck\n",
      "martinƒ±\n",
      "just-off-strip\n",
      "ikeisha\n",
      "DG/DGDG_DG\n",
      "–æ—á–µ–Ω—å\n",
      "long-es\n",
      "fant√°stica\n",
      "terrificall\n",
      ".amazing\n",
      "*note\n",
      "plave\n",
      "citybrea\n",
      "2short/great\n",
      "otel.com\n",
      "locatiob\n",
      "clib\n",
      "chippend\n",
      "book/stay\n",
      "adventual\n",
      "bear-y\n",
      "hyattplace\n",
      "realx\n",
      "superieor\n",
      "budnino87\n",
      "service**\n",
      "boutiquey/stylish\n",
      "floor.wonderf\n",
      "iÃát\n",
      "enormous-\n",
      "trailfinders\n",
      "swissotel/chicago\n",
      "news-ny\n",
      "familyvisit\n",
      "money-grubbing\n",
      "avergae\n",
      "ritz-car\n",
      "awesomerooms\n",
      "memories/\n",
      "gramer\n",
      "convenenient\n",
      "prosemployees\n",
      "stay/service\n",
      "friends/2\n",
      "greatvstay\n",
      "pros:1.beautiful\n",
      "location-that\n",
      "conservati\n",
      "diiscovery\n",
      "expwcting\n",
      "6-months\n",
      ".staff\n",
      "walk-able\n",
      "r√©ception\n",
      "forsuch\n",
      "paper-intensive\n",
      "year.nice\n",
      ".spend\n",
      "perfecti\n",
      "ejoy\n",
      "permanen\n",
      "insul\n",
      "'week\n",
      "miscieving\n",
      "vacation≈Ç\n",
      "anticpated\n",
      "scal\n",
      "phabulous\n",
      "csino\n",
      "had.gaming\n",
      "overbay6231\n",
      "great.check\n",
      "atmosphere..\n",
      "grand-casino\n",
      "great.weekend\n",
      "never..ever..again\n",
      "famillies\n",
      "birthday/anniversary\n",
      "cronwell\n",
      "gamit\n",
      "southstrip\n",
      "2017-10oct-16\n",
      ".awesome\n",
      "+great\n",
      "with‚Ä¶..\n",
      "copy-cat\n",
      "non-exi\n",
      "maise\n",
      "10trs\n",
      "bar/\n",
      "suspose\n",
      "alternat\n",
      "matazz\n",
      "siute\n",
      "camere\n",
      "location-for\n",
      "realisticall\n",
      "-to\n",
      "rio¬¥s\n",
      "discl\n",
      "safe-staff\n",
      "re-doing\n",
      "alam-engineer\n",
      "idealy\n",
      "critised\n",
      "surpas\n",
      "concierge/bell\n",
      "room.it\n",
      "middlew\n",
      "49era\n",
      ".be\n",
      "service-starema\n",
      "'home\n",
      "functioni\n",
      "xheck\n",
      "7nigh\n",
      "afterwar\n",
      "acutally\n",
      "reception/bar\n",
      "ginardi\n",
      "boulev\n",
      "/jacob\n",
      "5-9th\n",
      "artdeco\n",
      "de-nile\n",
      "modernl\n",
      "location.amazing\n",
      "facilities/need\n",
      "staying/playing\n",
      "location-hate\n",
      "club..well\n",
      "business/interview\n",
      "DG-DGDG.\n",
      "hotel-4.5\n",
      "refinery-\n",
      "room/out\n",
      "harrah's/mardi\n",
      "away/birthday\n",
      "s√®\n",
      "multic\n",
      "dissappointment\n",
      "üèô\n",
      "experience.tv\n",
      "redolence\n",
      "burr/\n",
      "stayded\n",
      "1721four\n",
      "rsvn\n",
      "wonderfuk\n",
      "hvg\n",
      "hotel/r\n",
      "/great\n",
      "locted\n",
      "cambr\n",
      "nyc-an\n",
      "reservatiuons\n",
      "-16s01g849193\n",
      "p-t\n",
      "bar-\n",
      "priceline..st\n",
      "Îì±Î°ùÌïòÍ≥†\n",
      ".glad\n",
      "hgu\n",
      "ihare\n",
      "regurarly\n",
      "'side\n",
      "reimbu\n",
      "environmentally-conscious\n",
      "disneylandish\n",
      "1-cut\n",
      "kimptom\n",
      "yote\n",
      "37/2018-3/12/2018..get\n",
      "bokyung\n",
      "meet-up\n",
      "location2\n",
      "11th-14th\n",
      "royalt\n",
      "2karat\n",
      "attracti\n",
      "‚Ä¶is\n",
      ".yay\n",
      ".location///location\n",
      "quiky\n",
      "appritiate\n",
      "assista\n",
      "playi\n",
      ".mu\n",
      "accoman\n",
      "DG/DGDG-DG\n",
      "croa\n",
      "ceck\n",
      "waaaaa\n",
      "sg2\n",
      "wonderful..will\n",
      "photosshopped\n",
      "pitchin\n",
      "stupidl\n",
      "show/valentine\n",
      "claime\n",
      "refurbsih\n",
      "hellopl\n",
      "check-inif\n",
      "hotel-excellent\n",
      "olace\n",
      "divalici\n",
      "ambula\n",
      "square/nyc\n",
      "post-wedding\n",
      "points-very\n",
      "jerr\n",
      "fun/different\n",
      "treatm\n",
      "bar‚ù§Ô∏è\n",
      "e-standby\n",
      "..customer\n",
      "-sta\n",
      "palces\n",
      "hotelcou\n",
      "talk/tre\n",
      "guilded\n",
      "/times\n",
      "t.i.s.e\n",
      "mile.an\n",
      "hipsville\n",
      "..past\n",
      "system/skeletal\n",
      "loveeeeee\n",
      "stay/room\n",
      "ehhhh\n",
      "millinum\n",
      "goobut\n",
      "opportunit\n",
      "pennyslyvania\n",
      "‚Ä¶‚Ä¶..\n",
      "stay..rooms\n",
      "onced\n",
      "forg\n",
      "spotle\n",
      "nychill2016\n",
      "switched/\n",
      "forem\n",
      "reasonalbe\n",
      "family/solo\n",
      "resonablity\n",
      "extrely\n",
      "pricw\n",
      "expereance\n",
      "reciepts\n",
      "carival\n",
      "anybod\n",
      "facility-\n",
      "entile\n",
      "biote\n",
      "zzzzzzz\n",
      "receivin\n",
      "mini-cay\n",
      "thankhiving\n",
      "allergie\n",
      "kitchene\n",
      "furthermo\n",
      "strip..con\n",
      "oppulance\n",
      "despi\n",
      "kitchen/t\n",
      "disas\n",
      "DGDG-DG-DG\n",
      "eve-chi-town\n",
      "strengthsdesign\n",
      "owkay\n",
      "mgmnt\n",
      "servicegrea\n",
      "comofrtable\n",
      "expecti\n",
      "s.c.except\n",
      "glammer\n",
      "tower/excellent\n",
      "nightsroomwas\n",
      "manhattan-seaport-fi\n",
      "impressiv\n",
      "boutiquiest\n",
      "location-good\n",
      "breake\n",
      "accomodatibg\n",
      "hollwoood\n",
      "thermosta\n",
      ".has\n",
      "fda007\n",
      "chicago-wonderful\n",
      "individ\n",
      "casesar\n",
      "supermodern\n",
      "greewich\n",
      "manija\n",
      "winup\n",
      "something..\n",
      "average+\n",
      "linni\n",
      "blackhat/defcon\n",
      "chicago-w-hotel\n",
      "honeymoon/last\n",
      "cheap‚Äîdon\n",
      "catrastrophe\n",
      "spg/marriott\n",
      "arvl\n",
      "underdelivery\n",
      "hotel/spa\n",
      "strip/mid\n",
      "c/\n",
      "bpwery\n",
      "may2017\n",
      "energe\n",
      "bedsvery\n",
      "conceirges\n",
      "paid..\n",
      "mcdonad\n",
      "refurbis\n",
      "injapanese\n",
      "fee/stay\n",
      "ronisha\n",
      "roim\n",
      "nights~everything\n",
      "diversy\n",
      "start..f\n",
      "2catch\n",
      "service/amenity\n",
      "locatikn\n",
      "subtl\n",
      "pleantly\n",
      "friendly/effici\n",
      "minimoon\n",
      "lli\n",
      "caea\n",
      "midr\n",
      "marqu\n",
      "inconsistant\n",
      "great-sized\n",
      "mastrocola\n",
      ".loved\n",
      "smoking-housekee\n",
      "ourtrip\n",
      "scr**\n",
      "8day\n",
      "bar/lounge/restaurant\n",
      "recognizabl\n",
      "friendlie\n",
      "3-minut\n",
      "nice-great\n",
      "well-a\n",
      "m939\n",
      "sportbook\n",
      "greatt\n",
      "propertyy\n",
      "accessible-for\n",
      "visit-what\n",
      "overpoweri\n",
      "upen\n",
      "toug\n",
      "springhi\n",
      "loop-ish\n",
      "onky\n",
      "chicago/river\n",
      "apperently\n",
      "ÈùûÂ∏∏Â∑ÆÁöÑÊúçÂãôÊÖãÂ∫¶Ôºâ\n",
      "batsymbol\n",
      "refurbisment\n",
      "sunset..\n",
      "disgusting/rude\n",
      "üòª\n",
      "sepul\n",
      "faboulos\n",
      "price/q\n",
      "stay/great\n",
      ".ate\n",
      "'over\n",
      "sohowithout\n",
      "weekwnd\n",
      "misfo\n",
      "knickbocker\n",
      "canyo\n",
      "staywa\n",
      "loctation\n",
      "-march\n",
      "dalusong\n",
      "california/nevada\n",
      "hotel/spa/fo\n",
      "spectacuar\n",
      "tumpshoho\n",
      "'no\n",
      "dinnin\n",
      "reactively\n",
      "good-value\n",
      "nabong\n",
      "hotel.asked\n",
      "bed.p\n",
      "kaera\n",
      "upgradescasino\n",
      "westin-\n",
      "perrrrrrrefect\n",
      "l.e.s\n",
      "recomandable\n",
      "birtyday\n",
      "DGDG.DGDGDGDG\n",
      "yesterda\n",
      "va/ca\n",
      "sprea\n",
      "helpfulÔºåb\n",
      "pre-valentine\n",
      "questionab\n",
      "üò§üò§\n",
      "annivera\n",
      "girl-6th\n",
      "hofel\n",
      "abigaillast\n",
      "sites/\n",
      "pretige\n",
      "Í∑∏Îü∞ÏßÄ\n",
      "oldsales\n",
      "servicespacious\n",
      "lizb\n",
      "parh\n",
      "nosyattitude\n",
      "terrif\n",
      "self-parking\n",
      "definely\n",
      "home.we\n",
      "rio.\n",
      "downsid\n",
      "sarvic\n",
      "week.on\n",
      "ladies-only\n",
      "impul\n",
      "royalson\n",
      "dissapointi\n",
      "elegant-beautiful-and\n",
      "mukava\n",
      "lovly\n",
      "chargeab\n",
      "location.b\n",
      "history-\n",
      "doubletr\n",
      "door=\n",
      "chnnge\n",
      "'edge\n",
      "angry-writing\n",
      "mentione\n",
      "one-time‚Äã\n",
      "excellentlong\n",
      "shenan\n",
      "mohammedw\n",
      "casino..reccommend\n",
      "attaract\n",
      "palor\n",
      "sogood\n",
      "southpoint\n",
      "cosiness\n",
      "wehadagreattime\n",
      "around/modern\n",
      "canilao\n",
      "primaril\n",
      "hotel..very\n",
      "locationroomcrowdfoodservicepricetripl\n",
      "hotel/small\n",
      "inpati\n",
      "parkingice\n",
      "chied\n",
      "represe\n",
      "swissotel-\n",
      "allena\n",
      "towels.-\n",
      "lo-ca-tion\n",
      "fine-\n",
      "intransparent\n",
      "emc2=\n",
      "staft\n",
      "DGDG.DG.DGDG\n",
      "◊í◊ì\n",
      "non-gamblers\n",
      "non-flashy\n",
      "reavh\n",
      "sacki\n",
      "'cozy\n",
      "nice-excellent\n",
      "smoking-garbage\n",
      "rental-a\n",
      "bestüëåüèª\n",
      "b.b\n",
      "recommende\n",
      "4.30pm\n",
      "rechar\n",
      ",DGDG\n",
      "overpriced..\n",
      "830pm\n",
      "hotel.mu\n",
      "fresh-looking\n",
      "in-stat\n",
      "washe\n",
      "renovaged\n",
      "restort\n",
      "was.there\n",
      "nln\n",
      "oadis\n",
      "cervise\n",
      "incon\n",
      "it‚Ä¶\n",
      "ayce\n",
      "vegas-nice\n",
      ".it\n",
      "requests-the\n",
      "hashbrowns\n",
      "choice.disappointed\n",
      "fult\n",
      "groomy\n",
      "wernt\n",
      "excilent\n",
      "c+\n",
      "dodwntown\n",
      "nugget-\n",
      "better/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "organisati\n",
      "DG/DG-DGDGDG\n",
      "town..\n",
      "it-want\n",
      "holet\n",
      "hotel.not\n",
      "manda-everything\n",
      "perfect.i\n",
      "square/chinat\n",
      "titani\n",
      "unhappy/disappointed\n",
      "servoce\n",
      "boutque\n",
      "visit/vacation\n",
      "bellperson\n",
      "ÏπúÏ†à\n",
      "ny'ers\n",
      "staff/stay\n",
      "*ugh*\n",
      "staffben\n",
      "sheratom\n",
      "roofrop\n",
      "suks\n",
      "ÊåëÈÅ∏Ê≠§ÈÖíÂ∫óÊòØÂõ†ÂÖ∂ÊàøË≤ªËºÉÂ§ßË°ó‰∏äÁöÑÈÖíÂ∫ó\n",
      "comfie\n",
      "in-important\n",
      "button/lig\n",
      "dirty..carpet\n",
      "-wacker\n",
      "'party\n",
      "penthoue\n",
      "receptionist/customer\n",
      "staff-ever\n",
      "thursdaycheck\n",
      "after-visit\n",
      "experiances\n",
      "**this\n",
      "hollywwod\n",
      "dive..reviews\n",
      "okay-ish\n",
      "counld'nt\n",
      "mostl\n",
      "employee-\n",
      "frendliest\n",
      "1130p\n",
      "no-chip\n",
      "housekeeping/\n",
      "old-scho\n",
      "experiencd\n",
      "downtown/strip\n",
      "newyears\n",
      "inclu\n",
      "3*\\nhotels\n",
      "check-ou\n",
      "immed\n",
      "swellington\n",
      "rooms/event\n",
      "stress-reducer\n",
      "**appauling\n",
      "non-smoky\n",
      "captai\n",
      "specifi\n",
      ".right\n",
      "vegas-go\n",
      "un-be-li-e-va-ble\n",
      "aeging\n",
      "unwilli\n",
      "absolutey\n",
      "a-location\n",
      "-look\n",
      "pre-9/11.t\n",
      "rundow\n",
      "hotel-but\n",
      "uk.it\n",
      "edisontimes\n",
      "non-vegas\n",
      "-prix\n",
      "ÿ™ÿ¨ÿ±ÿ®ÿ©\n",
      "nigts\n",
      "vegaas\n",
      "signat\n",
      "cristerna\n",
      "3-nites\n",
      "ameaising\n",
      "DGDGDG-DGDGDG.\n",
      "elsewhere.if\n",
      "double-billed\n",
      "access.the\n",
      "weekyou\n",
      "hill..still\n",
      "awesomenes\n",
      "average/\n",
      "navig\n",
      "hotel/best\n",
      "mariguana\n",
      "perfecct\n",
      "opulen\n",
      "crashpad\n",
      "microwavea\n",
      "staftt\n",
      "medicore..\n",
      "foood\n",
      "undecent\n",
      "üòÄüòÄüç∏üç∏\n",
      "e57th\n",
      "navigat\n",
      "rocksüòÄ\n",
      "they'r\n",
      "expected..\n",
      "oküòê\n",
      "arleenfromcovington\n",
      "choudhuny\n",
      "to.airport\n",
      "for-cheap\n",
      "hotel.indif\n",
      "centralisedvery\n",
      "ÏûòÎêòÍ≥†\n",
      "bucki\n",
      "week-day\n",
      "ac/heater\n",
      "affina\n",
      "okayy\n",
      ".have\n",
      "gamblingshop\n",
      "trafik\n",
      "working/running\n",
      "1/3/2018.cassa\n",
      "well-renovated\n",
      "condos/timeshare\n",
      "snggstl\n",
      "worn-o\n",
      "service/room\n",
      "location,1\n",
      "fuhgettaboudit\n",
      "-concierge\n",
      "location~\n",
      "three-n\n",
      "surprisingl\n",
      "staff/terrible\n",
      "q-tips\n",
      "again‚Ä¶.fantastic\n",
      "vegas/nascar\n",
      "hotel.a\n",
      "getawayüíó\n",
      "super-duper\n",
      "historicaly\n",
      "personable/personalized\n",
      "location/price/staff\n",
      "unexpexted\n",
      "bunkee\n",
      ",our\n",
      "experience.it\n",
      "heyyyyyyy\n",
      "plesure\n",
      "levadi\n",
      "localüòç\n",
      "egyptian-th\n",
      "sub-budge\n",
      "equipped.de\n",
      "42st\n",
      "orderl\n",
      "teleph\n",
      "super-chic\n",
      "'handicapped\n",
      "heavan\n",
      ".comedy\n",
      ".fifteen\n",
      "avaitors\n",
      "'other\n",
      "muckzor\n",
      "underg\n",
      "checkins\n",
      "vegas-er\n",
      ".frie\n",
      "more.the\n",
      "ressort\n",
      "couc\n",
      "cloc\n",
      "hamptonality\n",
      "cornerroom\n",
      "downtown/freemont\n",
      "personell\n",
      "excellent/\n",
      "price/clean/great\n",
      "meh-\n",
      "took/\n",
      "envirnoment\n",
      "hotel/rooms\n",
      "anniversary/birthday\n",
      "may5th-may8th\n",
      "quolity\n",
      "pages.carpet\n",
      "adje\n",
      "starionand\n",
      "empressed\n",
      "about-\n",
      "fantat\n",
      "expancive\n",
      "***warning***\n",
      "great/impeccable\n",
      "hellington\n",
      "biger\n",
      "üëåüèª\n",
      "biffville\n",
      "well-equi\n",
      "thaere\n",
      "timel\n",
      "cleand\n",
      "take..\n",
      "xeat\n",
      "nice/modern\n",
      "tremo\n",
      "all-da\n",
      "wowze\n",
      "cocnferen\n",
      "/nice\n",
      "-rules\n",
      "frantical\n",
      "ventalation\n",
      "sueta\n",
      "harrahd\n",
      "traf\n",
      "unfortunatel\n",
      "trumpowski\n",
      "wayyyy\n",
      "hompton\n",
      "at/un\n",
      "highroller\n",
      "closed-awesome\n",
      "upgraided\n",
      "in‚Äîbride\n",
      "Âø´ÈÅ©„Å™„Éõ„ÉÜ„É´„Åß„Åô\n",
      "desperat\n",
      "hotel.definite\n",
      "modern-contemporary\n",
      "anymo\n",
      "neeeeeeed\n",
      "hotehad\n",
      "service..be\n",
      "depictin\n",
      "dissatisfied-\n",
      "tufayel\n",
      "hollyday\n",
      "now**\n",
      "timer-\n",
      "lationo\n",
      "3-17th\n",
      "location-thin\n",
      "12-16th\n",
      "staff/clean\n",
      "desent\n",
      "checko\n",
      "wondferful\n",
      "taxis/\n",
      "ammenites\n",
      "that..\n",
      "perfectly-\n",
      "mmmeh\n",
      "co-workers/\n",
      "location-next\n",
      "refreshin\n",
      "intrguing\n",
      "hotel/interesting\n",
      "whatbyunwould\n",
      "confola\n",
      "loging\n",
      "tonw\n",
      "district/\n",
      "10.30am\n",
      "7:30pm\n",
      "luxury/beauty\n",
      "fantasic\n",
      "luxor-luxurious\n",
      "bum-town\n",
      "ventillation\n",
      "pros‚Ä¢great\n",
      "currentl\n",
      "slig\n",
      "vdara-\n",
      "returned-\n",
      "tnvisitor\n",
      "worthed\n",
      "stadd\n",
      "regille\n",
      "furn\n",
      "celabrate\n",
      "pleasure/vacation\n",
      "DG/DG/DGDG-DGDG/\n",
      "top-knotch\n",
      "üòä\n",
      "amenitiea\n",
      "fun.theres\n",
      "looooooooooooved\n",
      "blackst\n",
      "starwe\n",
      "yoooootel\n",
      "location-do\n",
      "susanadana\n",
      "DG.DG\n",
      "feli\n",
      "5****luxury\n",
      "sooooooooo\n",
      "aesth\n",
      "nice‚Ä¶.but\n",
      "pre-new\n",
      "streetervill\n",
      "location-small\n",
      "2queen\n",
      "roomnice\n",
      "interi\n",
      "soild\n",
      "dissaponted\n",
      "conected\n",
      "hideaw\n",
      "examp\n",
      "dident\n",
      "room-dark\n",
      "staff/guest\n",
      "dinner/show/overnight\n",
      "efficienc\n",
      "pop-opera\n",
      "swissh√¥tel\n",
      "touchpoi\n",
      "design/architecture\n",
      "floor.house\n",
      "selecti\n",
      "intersted\n",
      "distan\n",
      "unmaint\n",
      "shelome\n",
      "rockefe\n",
      "elevator/smoky\n",
      "*rooms\n",
      "wjhat\n",
      "buckinh\n",
      "fetaway\n",
      "horribalt\n",
      "pre-cru\n",
      "fgound\n",
      "ultra-comfortable\n",
      "lowcost\n",
      "old-designed\n",
      "continen\n",
      "everyhing\n",
      "timers-loved\n",
      "ckean\n",
      "fees‚Äîunprofessional\n",
      "DGDG/DGDG/DGDGDGDG-DGDG/DGDG/DGDGDGDG\n",
      "nyc-scbwi\n",
      "old/good\n",
      "positivesver\n",
      "attendeded\n",
      "10/10mana\n",
      ".location\n",
      "uptown/downtown\n",
      "stay..location\n",
      "priceÔºÅ\n",
      "gbusiness\n",
      "DG-DG/DGDG/DGDG\n",
      "chromecast\n",
      "refinment\n",
      "silven\n",
      "spaciousno\n",
      "psu/michigan\n",
      "reliable-\n",
      "wost\n",
      "treatüëçüèª\n",
      "double-bed\n",
      "flamingo=awesome\n",
      "üíç\n",
      "september15-16\n",
      "paris-oct\n",
      "..until\n",
      "chestman\n",
      "ameriania\n",
      "everying\n",
      "wanst\n",
      "conference/vacation\n",
      "htoel\n",
      "outle\n",
      "hundre\n",
      "disr\n",
      "welllington\n",
      "screec\n",
      "advic\n",
      "reonovated\n",
      "room-great\n",
      "DG.DG-DG\n",
      "ammentiies\n",
      "switc\n",
      "heyd\n",
      "ambassad\n",
      "excalibur-craps\n",
      "motel-\n",
      "mjl\n",
      "2017.w\n",
      "co-ope\n",
      "pharoah/queen\n",
      "preve\n",
      "dreadfull\n",
      "jermirth\n",
      "shows/great\n",
      "way.large\n",
      "arrianne\n",
      "night.that\n",
      "what.a.dump\n",
      "speaki\n",
      "fulf\n",
      "exorbita\n",
      "may-recommended\n",
      "gemmas\n",
      "downsides..\n",
      "coaste\n",
      "in-frickin-credible\n",
      "nevervagain\n",
      "location/pity\n",
      "kimberely\n",
      "courtco\n",
      "disgu\n",
      "subjec\n",
      "atthehotel\n",
      "equipp\n",
      "automat√≥w\n",
      "educa\n",
      "campgroun\n",
      "queu\n",
      "jennif\n",
      "thehard\n",
      "-fro\n",
      "magifican\n",
      "rtb_ri\n",
      "neatstaff\n",
      "get-a\n",
      "room.i\n",
      "jocke\n",
      "wedding/30th\n",
      "bedshee\n",
      "buitful\n",
      "roaim\n",
      "adream\n",
      "aircondition\n",
      "securit\n",
      "staff/hotel/casino\n",
      "by-\n",
      "bachlor\n",
      "no-n\n",
      "pleasuredome\n",
      "iroq\n",
      "fancie\n",
      "beaitful\n",
      "*1st\n",
      "buffasino.com\n",
      "üòò\n",
      "150/night\n",
      "location..immaculate\n",
      "great..excellent\n",
      "strategi\n",
      ".buenaaaaaa√°s\n",
      "manyquality\n",
      "beds/good\n",
      "belleclai\n",
      "disappointting\n",
      "place-long\n",
      "worta\n",
      "fece\n",
      "gteat\n",
      "unfrie\n",
      "play.the\n",
      "vacation.if\n",
      "wrigleyt\n",
      "apr15\n",
      "luvn\n",
      "special-\n",
      "panhandl\n",
      "-modern\n",
      "a'ight\n",
      "custkmer\n",
      "park/tribec\n",
      "roomsnice\n",
      "-mandalay\n",
      "out.no\n",
      "revist\n",
      "25th-2\n",
      "Ìé∏Ïù¥ÏßÄÎßå\n",
      "striip\n",
      "improvement/\n",
      "acceptional\n",
      "swissotels\n",
      "glisters\n",
      "lounge/lobby\n",
      "curretly\n",
      "sportsbo\n",
      "sept15/22\n",
      "overall..\n",
      "finetun\n",
      "switche\n",
      "paastrip\n",
      "pesent\n",
      "teenagers-\n",
      "nearevery\n",
      "garden/herald\n",
      "alinia\n",
      "/near\n",
      "luxor2015\n",
      "basketballl\n",
      "benidorn\n",
      "..bewa\n",
      "up-grade\n",
      "'central\n",
      "inlower\n",
      "shabbiest\n",
      "jimsandkittys\n",
      "baby-free\n",
      "üíπüëë\n",
      "treasurre\n",
      "-bell\n",
      "advi\n",
      "expectional\n",
      "runn\n",
      "hi-tec\n",
      "cabina\n",
      "bpaa\n",
      "carefr\n",
      "nope-not\n",
      "customer/guest\n",
      "again..best\n",
      "stay‚Ä¶\n",
      "treasu\n",
      "unprofessi\n",
      "slidi\n",
      "overprized-poor-quali\n",
      "valuein\n",
      "u.west\n",
      "7410.reat\n",
      "hotel/time\n",
      "mismarketed\n",
      "confirmati\n",
      "philadelp\n",
      "attentionate\n",
      "teeeeeeeny\n",
      "slots/selection\n",
      "bellcecl\n",
      "10days\n",
      "7:00a\n",
      "faceslots\n",
      "togethet\n",
      "emperor..\n",
      "hopping.it\n",
      "16-year-ol\n",
      "services-\n",
      "promot\n",
      "fashionis\n",
      "ouch..get\n",
      "stayaction\n",
      "desk/checkout\n",
      "DGDG.DG.DG\n",
      "purchasin\n",
      "semi-nice\n",
      "idiosyn\n",
      "re-fresh\n",
      "westhouse-best\n",
      "ny/ny\n",
      "tripgreat\n",
      "staffvery\n",
      "place.clean.good\n",
      "non-suite\n",
      "mantainance\n",
      "unaccomdating\n",
      "appretiat\n",
      "belaggio\n",
      "building.very\n",
      "sweatershirt\n",
      "plasure\n",
      "unknowledgeable\n",
      "non-ca\n",
      "location/extraordinary\n",
      "unbelieveably\n",
      "forla\n",
      "visit,7the\n",
      "cheapest/good\n",
      "keit\n",
      "city.great\n",
      "completel\n",
      "empana\n",
      "friedliest\n",
      "chciago\n",
      "exellen\n",
      "hipsteriest\n",
      "room/bar\n",
      "room.ex\n",
      "upgrade/update\n",
      "pros-inexpensive\n",
      "handle..\n",
      "non-s\n",
      "birthday/christmas\n",
      "priorit\n",
      "courner\n",
      "extrememly\n",
      "panarama\n",
      "hospita\n",
      "opportuniy\n",
      "excellentl\n",
      "room..good\n",
      "eexperience\n",
      "buut\n",
      "amazingfood\n",
      "location-it\n",
      "reviewstaying\n",
      "lastminute.c\n",
      "smellin\n",
      "only‚Ä¶\n",
      "great/hotel\n",
      "benehani\n",
      "stripf\n",
      "monkey-business\n",
      "get-a-way\n",
      "serives\n",
      "substandar\n",
      "centre..\n",
      "grandso\n",
      "abdominales\n",
      "bargaine\n",
      "oldfashioned\n",
      "minuters\n",
      "time..awesome\n",
      "catch-\n",
      "bucem\n",
      "palace/the\n",
      "weding\n",
      "bellclaire\n",
      "f'kin\n",
      "friggen\n",
      "*location*\n",
      ".kitchen\n",
      "unpersonal\n",
      "5*senka\n",
      "gasly\n",
      "suiite\n",
      "pros-beds\n",
      "dreamdowntown\n",
      "remoldeled\n",
      "5-hours\n",
      "elcellent\n",
      "itbes\n",
      "‚ò∫\n",
      "fun..my\n",
      "room/fro\n",
      ".howe\n",
      "prolocation\n",
      "vanilla-cinnamon\n",
      "nyÔºÅ\n",
      "ridiculousl\n",
      "cahrges\n",
      "attentiv\n",
      "fun-tivities\n",
      "beautiful-\n",
      "designi\n",
      "1night\n",
      "location/nice\n",
      "conslocation\n",
      "bowli\n",
      "wow..the\n",
      "antiquted\n",
      "room.pros\n",
      "enlivant\n",
      "time..all\n",
      "naviga\n",
      "mary-\n",
      "highsquick\n",
      "ventra\n",
      "units-\n",
      "unforgattable\n",
      "cleanlinesswell\n",
      "personali\n",
      "tripover\n",
      "inconvenienc\n",
      "hotel-perfectly\n",
      "5805easy\n",
      "upsell-heavy\n",
      "early-went\n",
      "ÏûàÏúºÎ©¥ÏÑú\n",
      "Âú∞ÁêÜ‰ΩçÁΩÆÈùûÂ∏∏‰ºòË∂ä„ÄÇÁ¶ªÊôØ\n",
      "tidy..\n",
      "price/decent\n",
      "eattention\n",
      "eckho\n",
      "competend\n",
      "nylo-best\n",
      "pros-spacious\n",
      "excelolent\n",
      "16-18th.wa\n",
      "chritmas\n",
      "pummy\n",
      "vineyarders\n",
      "18th-\n",
      "it.ill\n",
      "paris/ballys\n",
      "flmingo\n",
      "instaltio\n",
      "injur\n",
      "neighborsbath\n",
      "thanksgivi\n",
      "finace\n",
      "respon\n",
      "vegasv\n",
      "millenni\n",
      "enti\n",
      "lccation\n",
      "hotel.please\n",
      "escsoe\n",
      "thetheater\n",
      "swapp\n",
      "sguare\n",
      "back.great\n",
      "nobo\n",
      "tipical\n",
      "shi**r\n",
      "star.we\n",
      "balagio\n",
      "ravee\n",
      "iÃáf\n",
      "fee-crazy\n",
      "hotel/room\n",
      "thsnk\n",
      "DG.-\n",
      "nyc¬¥s\n",
      "webside\n",
      "6.15pm\n",
      "overchar\n",
      "vegas.al\n",
      "busy/sl\n",
      "amlost\n",
      "ÿßŸáŸÖ\n",
      "2-full\n",
      "-tired\n",
      "unexp\n",
      "platimum\n",
      "-gre\n",
      ".ver\n",
      "itÔºÅ\n",
      "nuget\n",
      "york/chelsea\n",
      "in-hotel\n",
      "focu\n",
      "rooma\n",
      "resoet\n",
      "exterio\n",
      "avarge\n",
      "misses..\n",
      "staff‚Ä¢\n",
      "supiste\n",
      "tub/shower\n",
      "managi\n",
      "poolsi\n",
      "picsand\n",
      "sewknitquilt\n",
      "upardot\n",
      "staycation/slot\n",
      "..b\n",
      "here.room\n",
      "love-love-love\n",
      "pool./hot\n",
      "chicago/ma\n",
      "√ºzerinde.od\n",
      "dream~\n",
      "stylis\n",
      "alloc\n",
      "in-out\n",
      "upgrde\n",
      "you.cant\n",
      "langham..\n",
      "lollapal\n",
      "mysterous\n",
      "horre\n",
      "5nigh\n",
      "skytower\n",
      "noralyn\n",
      "rogernice\n",
      "surprisin\n",
      "caesaars\n",
      "wirth125\n",
      "weekendr\n",
      "rio-2015-04\n",
      "1-bdr\n",
      "oct'17\n",
      "incidential\n",
      "'treated\n",
      "nyc.if\n",
      "emph\n",
      "-casino\n",
      "'fr\n",
      "4rth\n",
      "locationwith\n",
      "statyed\n",
      "issues_\n",
      "ubelievable\n",
      "needl\n",
      "staycation-\n",
      "aggrevation\n",
      "copor\n",
      "hrlpfu\n",
      "2018really\n",
      "clapto\n",
      "avealrage\n",
      "steakbouch\n",
      "lobby/severa\n",
      "clean/\n",
      "vvery\n",
      "english-inspired\n",
      "room/horrible\n",
      "730pm\n",
      "-close\n",
      "touc\n",
      "hersld\n",
      "hjotel\n",
      "price-even\n",
      "budgetmotel\n",
      "taxes/valet/fees\n",
      "üëåüëåüëåüëå\n",
      "mmm..\n",
      "intercontinenta\n",
      "dispointing\n",
      "hotel..about\n",
      "overwhe\n",
      "roomservice\n",
      "w/highs\n",
      "blizz\n",
      "great..room\n",
      "ü§™ü§™\n",
      "underwhelmingly\n",
      "hotel.room\n",
      "berks.uk\n",
      "congratulatiuons\n",
      "nights.ve\n",
      "upmos\n",
      "tourico\n",
      "memorial-sloan\n",
      "great..the\n",
      "vegas.fast\n",
      "hiif\n",
      "-pleasing\n",
      "squrare\n",
      "shapna\n",
      "bubthe\n",
      "experience‚Äîthanks\n",
      "renwi\n",
      "mudt\n",
      "carran\n",
      "medium-priced\n",
      "un-preferred\n",
      "people.do\n",
      "conditione\n",
      "reenie\n",
      "time/a\n",
      "35/day\n",
      "meals.servi\n",
      "-in\n",
      "girlsweekend\n",
      "complamentary\n",
      "frequently-\n",
      "ny‚ù§\n",
      "hotelnot\n",
      "‡∑Ä‡∑í‡∂≠‡∂ª‡∂∏‡∂∫‡∑í\n",
      "summert\n",
      "hotelsev\n",
      "service=perfection\n",
      "retu\n",
      "cleanroo\n",
      "redecora\n",
      "don¬¥\n",
      "crui\n",
      "cabbie18\n",
      "beresfor\n",
      "nice..typic\n",
      "disappointsattentive\n",
      ".away\n",
      "misrepresentations-when\n",
      "five-ho\n",
      "excellen\n",
      "wi/fi\n",
      "un-used\n",
      "flai\n",
      "enrag\n",
      "delano-january\n",
      "deigo\n",
      "see/do\n",
      "distast\n",
      "accomda\n",
      "bother.not\n",
      "hotel-new\n",
      "colassal\n",
      "unsatified\n",
      "fandabydozy\n",
      "business/p\n",
      "hotell\n",
      "maid/clea\n",
      "oquen\n",
      "summat\n",
      "service100m\n",
      "conference.allocated\n",
      "outpriced\n",
      "ooooohhh\n",
      "franciscvo\n",
      "goiing\n",
      "DG.DG/DG\n",
      "service/dirty\n",
      "maypac\n",
      "acoommodations\n",
      "..oh\n",
      "relations/serv\n",
      "york..excellent\n",
      "surroundings/excellent\n",
      "19t\n",
      "davkincaid\n",
      ".got\n",
      "place.grwat\n",
      "1'st\n",
      "sympa\n",
      "stay-outstanding\n",
      "hubberooroo\n",
      "containin\n",
      "collap\n",
      "nights.o\n",
      "thursda\n",
      "touristing\n",
      "revoew\n",
      "peacefull\n",
      "members/owners\n",
      "jq\n",
      "memorabi\n",
      "located.m\n",
      "dancheva\n",
      "germa\n",
      "sistercation\n",
      "days/nig\n",
      "exstended\n",
      "ok.they\n",
      "repli\n",
      "2998p\n",
      "money-skip\n",
      "ehouse\n",
      "quazigirl\n",
      "bcx\n",
      "city/exception\n",
      "disappointer\n",
      "off-the-strip\n",
      "biten\n",
      "3.30pm\n",
      "roomsno\n",
      "itthe\n",
      "returne\n",
      "pool/bar\n",
      "dumo\n",
      "tuesday/w\n",
      "originall\n",
      "caesares\n",
      "shelbu\n",
      "warvick\n",
      "fanc\n",
      "location**price***so-so\n",
      "efficien\n",
      "appropriatel\n",
      "1500/night\n",
      "ourselv\n",
      "cool/chic\n",
      "shortcom\n",
      ".more\n",
      "at75\n",
      "waitres\n",
      "shawaiz\n",
      "phind\n",
      "vicer\n",
      "priceline.co\n",
      "trekies\n",
      "business/fun\n",
      "sceond\n",
      "knickerb\n",
      "2015the\n",
      "¬£DGDG.DGDG\n",
      "exxelent\n",
      "lindsa\n",
      "this..\n",
      "stlye\n",
      "schwar\n",
      "lagardia\n",
      "elae\n",
      "hotel/dining/show\n",
      "going/nice\n",
      "street/windows\n",
      "overnigh\n",
      "choice+value\n",
      "evolving/confused\n",
      "apologis\n",
      "horr√≠vel\n",
      "riovisit\n",
      "doubletree-las\n",
      "businessin\n",
      "staynt\n",
      "pay.\n",
      "valuue\n",
      "unoin\n",
      "bcapl\n",
      "sep,2\n",
      "view'‚Ä¶or\n",
      "experieces\n",
      "crabbs\n",
      "holida\n",
      "anywherw\n",
      "getaway/\n",
      ".r\n",
      "wans't\n",
      "bellagio-wo\n",
      "undou\n",
      "vegas..south\n",
      "luxoury\n",
      "aapex/\n",
      "batchlorette\n",
      "standards-disappointed\n",
      "prime..\n",
      "fromsonoma\n",
      "creperi\n",
      "spa-\n",
      "must-try\n",
      "age..\n",
      "bigüçèüçé\n",
      "radiss\n",
      "afforadable\n",
      "shipping/edi\n",
      "we¬¥ll\n",
      "eve-\n",
      "inconvenien\n",
      "small/noisy\n",
      "aone\n",
      "aug/sept\n",
      "nights.on\n",
      "f******g\n",
      "interestin\n",
      "23-27th\n",
      "roomsgiven\n",
      "location/tiny\n",
      "solito\n",
      "textin\n",
      "gem..wonderful\n",
      "cozy/remodeled\n",
      "gatherin\n",
      "2nights\n",
      "return.nice\n",
      "awaitin\n",
      "a-w-e-s-o-m-e\n",
      "reno'ed\n",
      "okay‚Ä¶\n",
      "neighborough\n",
      "edgy-swanky\n",
      "keeping~\n",
      "findgood\n",
      "religiou\n",
      "adjustment-\n",
      "worht\n",
      "janky\n",
      "everone\n",
      "peacefum\n",
      "casiono\n",
      "jennife\n",
      "waltejr\n",
      "again‚Ä¶\n",
      "disgruntle\n",
      "headqu\n",
      "goodbed\n",
      "pleasanly\n",
      "crep\n",
      "indicati\n",
      "DGDGDG.DGDG+\n",
      "smelllllllll\n",
      "hote/casino\n",
      "avelkagio\n",
      "kappele\n",
      "hailies\n",
      "poorly-will\n",
      "wifi/coffee\n",
      "stopo\n",
      "european-\n",
      "nothi\n",
      "everything..pool..a\n",
      "locati√≥n\n",
      "trip.i\n",
      "theshoreham\n",
      "worksh\n",
      "fri-sun\n",
      "preety\n",
      "2398p\n",
      "laundr\n",
      "attitudey\n",
      "tonytax\n",
      "-fitness-\n",
      "illino\n",
      "doubletree-\n",
      "satued\n",
      "kitchy\n",
      "kingfischer\n",
      "hotel..terrible\n",
      "a-m-a\n",
      "-hotels\n",
      "propo\n",
      "hotel..close\n",
      "spolied\n",
      "100yds\n",
      "do't\n",
      "2017my\n",
      "loovvvves\n",
      "hotel.in\n",
      "evrywhere\n",
      "encore-\n",
      "◊ê◊ó◊ú◊î\n",
      ".don\n",
      "'burbs\n",
      "pub/bar\n",
      "greatfull\n",
      "mehhhhh\n",
      "becomin\n",
      "times/ye\n",
      "chicagoexperience\n",
      "clean-awesome\n",
      "'renovated\n",
      "upgradi\n",
      "walk-about\n",
      "selectin\n",
      "elegant..\n",
      "inadvertentl\n",
      "hotel-customer\n",
      "midnight.the\n",
      "birthdaty\n",
      "work/pleasure\n",
      "class-\n",
      "DGDG.DGDG-DGDG\n",
      "gaming-oriented\n",
      "lib18\n",
      "accoustic\n",
      "old-timey\n",
      "excellant\n",
      "watchimg\n",
      "conveniont\n",
      "fradulant\n",
      "romos\n",
      "amenities-\n",
      "bellaggio\n",
      "'exce\n",
      "movie-like\n",
      "furnitu\n",
      "..less\n",
      "tribeca/world\n",
      "jeanieb-front\n",
      "hoteltravelled\n",
      "hidden-away\n",
      "starf\n",
      "**the\n",
      "buzy\n",
      "vegasüòüüò≥\n",
      "maintenence\n",
      "sporche\n",
      "celing\n",
      "location-service-location\n",
      "sigh***\n",
      "boulebard\n",
      "neat.lighthouse\n",
      "dylan-\n",
      "hotel/food/comfort\n",
      "cost-conscious\n",
      "later‚Äîgreat\n",
      "spot..bring\n",
      "roomsfree\n",
      "distincti\n",
      "pre-fligh\n",
      "time/conference\n",
      "hororible\n",
      "DGDGDG¬∞\n",
      "desapointmen\n",
      "down-arrow\n",
      "hotelr\n",
      "-housekeep\n",
      "ariving\n",
      "vacatipn\n",
      "said-i\n",
      "h√®re\n",
      "super-\n",
      "carniva\n",
      "maintenance/service\n",
      "diamond/seven\n",
      "ggffghhytt5\n",
      "playgro\n",
      "twenty/thirtysomethings\n",
      "chelsea/flower\n",
      "hotel***\n",
      "clubquarters\n",
      "staff/excellent\n",
      "amenities-ditto\n",
      "sportsbook/service\n",
      "dunsonator\n",
      "ratius\n",
      "300/night\n",
      "visit..\n",
      "pleace\n",
      "experiend\n",
      "convenient/pleasant\n",
      "ÏÉùÍ∞ÅÌïòÎ©¥\n",
      "luyanda\n",
      "crowde\n",
      "unfotunately\n",
      "langh\n",
      "indoo\n",
      "situatio\n",
      "safe..none\n",
      "awesime\n",
      "midtwon\n",
      "eco-schtick\n",
      "'h\n",
      "location/location/location\n",
      "dissapointed-\n",
      "roompoor\n",
      "pool-medioc\n",
      "verrybad\n",
      "‚Ä¢.fantastic.‚Ä¢\n",
      "chundury\n",
      "alpharoom\n",
      "/price\n",
      "metto\n",
      "7day\n",
      "service/reception\n",
      "casinon\n",
      "16th..\n",
      "coachroaches\n",
      "welcomming\n",
      "suites-redux\n",
      "florida/bahama\n",
      "c.a.a\n",
      "mindf\n",
      "9/10/18nice\n",
      "venetian-\n",
      "predomi\n",
      "noisy.i\n",
      "thievs\n",
      "businesslik\n",
      "w/stay\n",
      "locatie\n",
      "concierge/box\n",
      "grum\n",
      "nighs\n",
      "serjik\n",
      "rc-san\n",
      "..hotels\n",
      "purly\n",
      "timebeautiful\n",
      "pharoh\n",
      "service/great\n",
      "weeee\n",
      "out\\n\n",
      "hotel.brand\n",
      "tantica\n",
      "coffee/\n",
      "mistoo\n",
      "splendid-witha\n",
      "keeped\n",
      "augustustower\n",
      "‚Ä¢‚Ä¢‚Ä¢perfect\n",
      "3/5i\n",
      "hotelÔºÅ\n",
      "design/parties\n",
      "ny-way\n",
      "ritz-ca\n",
      "funky/cool\n",
      "dhane\n",
      "100yrs\n",
      "instalation\n",
      "travlin\n",
      "tesort\n",
      "staff/convenient\n",
      "hotel-f\n",
      "locationg\n",
      "privileg\n",
      "DGDGDG/DGDGDG\n",
      "comfortalbe\n",
      "siz\n",
      "custumer\n",
      "home-feeling\n",
      ".outstanding\n",
      "milwaukee-b\n",
      "weekshad\n",
      "refurbishedrrooms\n",
      "tired/old\n",
      "securi\n",
      "withhilton\n",
      "undern\n",
      "streen\n",
      "wunnerful\n",
      "property/great\n",
      "resort..\n",
      "nights.pros\n",
      "service.great\n",
      "8th-\n",
      "3x16\n",
      "tonig\n",
      "semina\n",
      "‚ô•Ô∏è‚ô•Ô∏è‚ô•Ô∏è\n",
      "rip-of\n",
      "city.s\n",
      "views/happy\n",
      "cc4242cc\n",
      "earthshattering\n",
      "welcome/che\n",
      "sophistica\n",
      "hftp\n",
      "resot\n",
      "non-glitzy\n",
      "elyess\n",
      "hotelüòä\n",
      "housekeeping/ser\n",
      "haagenson\n",
      "once/twice\n",
      "so-so-soho\n",
      "parking/it\n",
      "expiriance\n",
      "k-cups\n",
      "parasoul\n",
      "mhah\n",
      "patroniz\n",
      "realiable\n",
      "flaminfo\n",
      "departin\n",
      "improvement-\n",
      "cons-the\n",
      "subpar.hotel\n",
      "üëé\n",
      "poten\n",
      "location/amenities\n",
      "homewo\n",
      "no-f\n",
      "cj48\n",
      "money-hungry\n",
      "extended-famil\n",
      "juibilee\n",
      "'pet\n",
      "loved..\n",
      "ourstanding\n",
      ".pristine\n",
      "1-i\n",
      "economy-luxury\n",
      "3pm-\n",
      "flaqmingo\n",
      "mid-b'way\n",
      "wedding/management\n",
      "speical\n",
      "everything.\n",
      "expen\n",
      "renovat\n",
      "convie\n",
      "clean-check-\n",
      "carriagehouse\n",
      "septe\n",
      "peacef\n",
      "player/buffet\n",
      "trendy-nice\n",
      "..well\n",
      "reputati\n",
      "embarcardero\n",
      "eco-minded\n",
      "acceptable-its\n",
      "'it\n",
      "funera\n",
      "angelese\n",
      "polishi\n",
      "francisvo\n",
      "opoinion\n",
      "probuct\n",
      "nickel-and-diming\n",
      "dhnyc\n",
      "rooms/linens\n",
      "devastatin\n",
      "cute/trendy\n",
      "pricey-\n",
      "extende\n",
      "skysuits\n",
      "hiltion\n",
      "attractional\n",
      "prechecked\n",
      "book-ending\n",
      "luxery\n",
      "theee\n",
      "excectutive\n",
      "better/–Ω–æ–≤—ã–π\n",
      "bonnie/barbara\n",
      "airl\n",
      "teenag\n",
      "hithe\n",
      "balall\n",
      "valaue\n",
      "burn'em\n",
      "persoanl\n",
      "ranie\n",
      "foodi\n",
      "familytrip\n",
      "shopping-\n",
      "area/sho\n",
      "quality-price\n",
      "vegas-first\n",
      "neeham\n",
      "accommadations\n",
      "mini-su\n",
      "service/location\n",
      "'city\n",
      "researchin\n",
      "experienceeveryone\n",
      "afterno\n",
      "transf\n",
      "r-lou\n",
      "'upgrade\n",
      "remodelin\n",
      "wordclass\n",
      "design-minded\n",
      "DGDGDGDG.\n",
      "DG/DGDGDGDG-DG/DG\n",
      "supposedl\n",
      "so/s\n",
      "substanc\n",
      "experienceüòç\n",
      "grievences\n",
      "execelent\n",
      "madely\n",
      "hotel/casion\n",
      "excelant\n",
      "orleons\n",
      "good‚Ä¶..\n",
      "üåÉ\n",
      "1ho\n",
      "hampt\n",
      "w/out\n",
      "f.d\n",
      "valinetime\n",
      "pool/we\n",
      "carefil\n",
      "motel-level\n",
      "disappointment-corporate\n",
      "offf\n",
      "meticulo\n",
      "2nd/3rd\n",
      "room/service\n",
      "timeshar\n",
      "bed.non-smoking\n",
      "deligt\n",
      "overchaged\n",
      "relaxa\n",
      "wore-out\n",
      "street/b\n",
      "nostagia\n",
      "b'way\n",
      "interconti\n",
      "stylish/leaves\n",
      "prosgood\n",
      "awsome\n",
      "rlounge\n",
      "suite-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stoja\n",
      "licatloc\n",
      "broug\n",
      "in/cattle\n",
      "does-what-it-says-on-the-tin\n",
      "famley\n",
      "shabby-chic\n",
      "staff/new\n",
      "christmas-time\n",
      "sutuated\n",
      "ohare\n",
      "desk/manager\n",
      "stay.love\n",
      "surched\n",
      "excellent-in\n",
      "memori\n",
      "bookedinto\n",
      "phnominal\n",
      "engla\n",
      "rooms-large\n",
      "sh*\n",
      "8:30pm\n",
      "iroquoi\n",
      "londonhou\n",
      "average/lacki\n",
      "comedy/magic\n",
      "linlcon\n",
      "hotel/casinos\n",
      "tip-top\n",
      "square.roo\n",
      "weeken\n",
      "DG*++++\n",
      "visitüëéüèΩ\n",
      "oversatisfied\n",
      "vacati\n",
      "br√ªl√©e\n",
      "feb'15\n",
      "'bite\n",
      "mother/da\n",
      "floor.the\n",
      "17yr\n",
      "go-too\n",
      "midel\n",
      "square=\n",
      "departmen\n",
      "grand-daugh\n",
      "hvacrman\n",
      "conformab\n",
      "enjoued\n",
      "'two\n",
      "macarrones\n",
      "hotelson\n",
      "theater-\n",
      "foid\n",
      "surprise.the\n",
      "nyc-excellent\n",
      "breakfastbuffet\n",
      "does'n\n",
      "uncared-fori\n",
      "easey\n",
      "location/price/ambience\n",
      "480/night\n",
      "—É–¥–æ–±–Ω—ã–π\n",
      "may04\n",
      "room=niceroom\n",
      "'living\n",
      "wydham\n",
      "clean..but\n",
      "eurp\n",
      "10/min\n",
      "unfriendliest\n",
      "location..friendly\n",
      "a-m-a-z-i-n-g\n",
      "betwe\n",
      "view..\n",
      "ubeatable\n",
      "applebees\n",
      "sigiture\n",
      "stag/bachelor\n",
      "strrip\n",
      "except‚Ä¶\n",
      "vacation+concert\n",
      "betwen41st\n",
      "perfect.time\n",
      "cenntral\n",
      "location.near\n",
      "we'e\n",
      "clientelle\n",
      "new/fresh/clean/safe\n",
      "deliciousl\n",
      "showerhand\n",
      "priice\n",
      "vibran\n",
      "mini-rooms\n",
      "01.cb.10a\n",
      "deodo\n",
      "abasolutely\n",
      "downtown~clean-comfort\n",
      "replic\n",
      "likel\n",
      "salisbu\n",
      "welcome-line\n",
      "inn-tri\n",
      ".planet\n",
      "slippi\n",
      "americana-san\n",
      "clean..modern..reasonably\n",
      "conduc\n",
      "..between\n",
      "geesh\n",
      "v.p\n",
      "closenes\n",
      "ultim\n",
      "carpet-very\n",
      "pyramid/illuminati\n",
      "karatbars\n",
      "adequare\n",
      "service..thank\n",
      "modern/chick\n",
      "poetry-in-motion\n",
      "20s-30s\n",
      "20is\n",
      "hotelperfect\n",
      "wallpa\n",
      "already-occupied\n",
      ".even\n",
      "-convenient\n",
      "first-date\n",
      "hotel.las\n",
      "graci\n",
      "online-\n",
      "w/end\n",
      "fitzpatricksthi\n",
      "octavious\n",
      "doubletree-chelsea\n",
      "communica\n",
      "pool/hot\n",
      "favouable\n",
      "river/statue\n",
      "fintastic\n",
      "self-parkin\n",
      "trip/trade\n",
      "views.lovely\n",
      "minimali\n",
      "excellent„ÄÇ\n",
      "tripüëçüá∫üá∏\n",
      "service-\n",
      "roombut\n",
      "style/design\n",
      "springh\n",
      "despit\n",
      "vacationi\n",
      "nightm\n",
      "impec\n",
      "vivting\n",
      "nice.bu\n",
      "‚ô•\n",
      "trainin\n",
      "specificall\n",
      "value..\n",
      "mid-floor\n",
      "conveneint\n",
      "blacjack\n",
      "famou\n",
      "iruss\n",
      "virgi\n",
      "sj76\n",
      "dream..\n",
      "prebooked\n",
      "mccormik\n",
      "beüòúüòúüòúüòÇüòÇüëçüëç\n",
      "valenversary\n",
      "fly/drive\n",
      "rerfurb\n",
      "unfortunelty\n",
      "üíü\n",
      "newely\n",
      "''+\n",
      "money-grabbing\n",
      "view/smok\n",
      "bar/l\n",
      "accommodatio\n",
      "hotel-wonderful\n",
      "famiuly\n",
      "disappointment.sheets\n",
      "room/bed\n",
      "anymor\n",
      "theate\n",
      "disre\n",
      "expirence\n",
      "servived\n",
      "mandalay/delano\n",
      "biocare\n",
      "awhi\n",
      "environment-\n",
      "distrikt-our\n",
      "DG-DGDG/DG-DGDG\n",
      "unexpensive\n",
      "forr\n",
      "crav\n",
      "innot\n",
      "4‚≠êÔ∏èsoho\n",
      "redr\n",
      "..probably\n",
      "jan13-jan16\n",
      "poor/even\n",
      "clean.comm\n",
      "jeniffer\n",
      "k-town\n",
      "stay.clean\n",
      "machinesco\n",
      "city/hotel\n",
      "integ\n",
      ".ic\n",
      "figur\n",
      "europeansoccer\n",
      "backof\n",
      "experice\n",
      "diamo\n",
      "lenf\n",
      "plessant\n",
      "heloful\n",
      "perfect.location\n",
      "contructive\n",
      "vegas't\n",
      "vegation\n",
      "exceptionall\n",
      "üòôüòôüòô\n",
      "voctorian\n",
      "hoteltonight\n",
      "time-yet\n",
      "you~\n",
      "w/strip\n",
      "DG-DG-\n",
      "ok.th\n",
      "concuss\n",
      "manhattan/\n",
      "kaub\n",
      "single-ply\n",
      "cared/knew\n",
      "ŸÖŸÖŸäÿ≤\n",
      "afforable\n",
      "convention/hotel\n",
      "pokir\n",
      "stars-great\n",
      "hotel-casino\n",
      "/helpful\n",
      "sdsharon33\n",
      "sauberkeit\n",
      "service/location/room\n",
      "nights.thank\n",
      "couples-\n",
      "vicago\n",
      "can'b\n",
      "strip-\n",
      ".this\n",
      "deliber\n",
      "distri\n",
      "djanel\n",
      "ventilati\n",
      "70/night\n",
      "eexcexcellent\n",
      "nagget..\n",
      "innyc\n",
      "convenient/comfortable\n",
      "Ïã§ÏàòÎ°ú\n",
      "excelelnt\n",
      "'pure\n",
      "ill-kempt\n",
      "room‚Äîtwo\n",
      "mess..\n",
      "buffet-wow\n",
      "roomselev\n",
      "hoter\n",
      "long-t\n",
      "vacaystay\n",
      "conditioner+\n",
      "***brilliant\n",
      "stopp\n",
      "managementthe\n",
      "**first\n",
      "nickel-n-diming\n",
      "consitently\n",
      "occupa\n",
      "amamzing\n",
      "location-questionable\n",
      "pillows..\n",
      "cmfortable\n",
      "harrshs\n",
      "egh\n",
      "staff.ro\n",
      "hado\n",
      "flamiingo\n",
      "tho‚Ä¶\n",
      "definiti\n",
      "dishearteni\n",
      "autogr\n",
      "sal..\n",
      "diffi\n",
      "picwick\n",
      "brother-in\n",
      "pacif\n",
      "DGDGDGDGüèÖ\n",
      "noices\n",
      ",but\n",
      "shortcomi\n",
      "poolever\n",
      "location-uber\n",
      "aptl\n",
      "chem-dry\n",
      "service..rude\n",
      "flamming\n",
      "launi\n",
      "gregnaz\n",
      "contienc\n",
      "spri\n",
      "uper\n",
      "be-ware\n",
      "'supervisor\n",
      "madamewe\n",
      "simpleroom\n",
      "bacherlotte\n",
      "positiveslocation\n",
      "6:45am\n",
      "abfriday\n",
      "enjojed\n",
      "staff/amazing\n",
      "unprof\n",
      "exex\n",
      "improvin\n",
      "delightf\n",
      "cosistant\n",
      "aaway\n",
      "elepha\n",
      "service.r\n",
      "viewa\n",
      "teio\n",
      "carwright\n",
      "outdate\n",
      "overhyped-\n",
      "m413\n",
      "sundayfunday\n",
      "location~clean~friendly\n",
      "p/h\n",
      "servic\n",
      "3.5k\n",
      "realex\n",
      "outdates\n",
      "cousey\n",
      "waitsta\n",
      "wonderfulplace\n",
      "sindey\n",
      "interior-clean\n",
      "hilghly\n",
      "dakma\n",
      "pros*excellent\n",
      "spru\n",
      "great..j\n",
      "compensa\n",
      "flamingooooo\n",
      "newes\n",
      "brahem\n",
      "easy.great\n",
      "postitives\n",
      "capab\n",
      "wonderflu\n",
      "positives1\n",
      "businrds\n",
      "bedsflush\n",
      "preg\n",
      "sleep-destroying\n",
      "apprecitave\n",
      "timeshare/rci\n",
      "valie\n",
      "family-get-away\n",
      "quirkyness\n",
      "overley\n",
      "signature..slightly\n",
      "vegasssssssssss\n",
      "sight-seers\n",
      "üëåüëå\n",
      "small.the\n",
      "ÊúçÂä°ÂæàÁÉÇ\n",
      "crapped\n",
      "value-above\n",
      "npatel\n",
      "breating\n",
      "wxcellent\n",
      "6.45pm\n",
      "1.took\n",
      "42th\n",
      "inexpensiveness\n",
      "trrib\n",
      "swissho\n",
      "s***\n",
      "afvc\n",
      "'passable\n",
      "..with\n",
      "frontfron\n",
      "stale-smell\n",
      "cool..\n",
      "condtion\n",
      "nostallgic\n",
      "fri/sat\n",
      "akways\n",
      "chicago-downtown\n",
      "nyc/manhat\n",
      "movie-\n",
      "gurlz\n",
      "partylite\n",
      "dissappointments\n",
      "DG/DG/DGDGDG\n",
      "divalicious\n",
      "wydnham\n",
      "incredibke\n",
      "conscie\n",
      "encounted\n",
      "home-like\n",
      "26-oc\n",
      "rates-decent\n",
      "perfectible\n",
      "vacation/farewell\n",
      "nowhe\n",
      "shattere\n",
      "üíé\n",
      "qute\n",
      "wyhdh\n",
      "kind..\n",
      "laquinta\n",
      "flinstone\n",
      "..last\n",
      "standards-\n",
      "lookingh\n",
      "business/leisure\n",
      "1637we\n",
      ".period\n",
      "wedding/vacation\n",
      "vstayed\n",
      "you'r\n",
      "location.t\n",
      "zett\n",
      "famile\n",
      "smallwe\n",
      "gambler/drinker/smoker\n",
      "betrer\n",
      "service/thin\n",
      "acconidations\n",
      "prices-\n",
      "door/lock\n",
      "unnece\n",
      "in-room-dining\n",
      "DG‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è\n",
      "restr\n",
      "DG/DGDG/DGDG..\n",
      "petfect\n",
      "optiion\n",
      "16t\n",
      "ÂæàÂ•ΩÁöÑÈÖíÂ∫ó‰ΩÜ\n",
      "*check\n",
      "luxury..\n",
      "pre-apa\n",
      "conveenient\n",
      "service-lisa\n",
      "mylife\n",
      "cafe-great\n",
      "disappointi\n",
      "disgus\n",
      "emiddle\n",
      "qlub\n",
      "digusting\n",
      "today.gre\n",
      "locion\n",
      "tjis\n",
      "goodhad\n",
      "son-in-\n",
      "great-dog\n",
      "conges\n",
      "anniv\n",
      "cesaers\n",
      "tremen\n",
      "location.great\n",
      "unfr\n",
      "pools-l\n",
      "nycproslo\n",
      "quality.mind\n",
      "chechin\n",
      "pre-email\n",
      "inside/outside\n",
      "hotel..grea\n",
      "mroe\n",
      "prperty\n",
      "tuscan/euro\n",
      "stay/experience\n",
      "relatio\n",
      "pre-pr\n",
      "building/bay\n",
      "compla\n",
      "servuces\n",
      "ph.we\n",
      "foodvana\n",
      "under-sta\n",
      "chearges\n",
      "dissatify\n",
      "locationonline\n",
      "fashoned\n",
      "gregs\n",
      "shoe-horn\n",
      "expetrience\n",
      "wonderf\n",
      "no-star\n",
      "jimbob\n",
      "chicagl/magnificent\n",
      "glit\n",
      "diseas\n",
      "buck-\n",
      "ahmazing\n",
      "amtra\n",
      "kitchenett\n",
      "piped-in\n",
      "rooms/floors\n",
      "lighti\n",
      "churracos\n",
      "get-a-away\n",
      "209.stayed\n",
      "night..\n",
      "mid-dece\n",
      "vegsa\n",
      "hopk\n",
      "casinoand\n",
      "üòÉüëç\n",
      "chandeli\n",
      "mostof\n",
      "ingr\n",
      "christmas/50th\n",
      "necessity..\n",
      "burgonde\n",
      "06th\n",
      "service.no\n",
      "business.rooms\n",
      "fantasitc\n",
      "renwic\n",
      "nidakid\n",
      "18yr\n",
      ".thank\n",
      "thansks\n",
      "stayit\n",
      "mid-rang\n",
      "yrop\n",
      "beautifull\n",
      "forrward\n",
      "rude-bait\n",
      "bastarx\n",
      "family/business\n",
      "'da\n",
      "responsibili\n",
      "streeterv\n",
      "reservation.booked\n",
      "youtu\n",
      "broadw\n",
      "staff..pleasant\n",
      "inclusi\n",
      "gouzola\n",
      "everythings\n",
      "roomslon\n",
      ".long\n",
      "bathr\n",
      "pool/\n",
      "accomodatio\n",
      "don*t\n",
      "angieb\n",
      "nycaug2017\n",
      "ms.zean\n",
      "out-standing\n",
      "john/linda\n",
      "dashanda\n",
      "view-great\n",
      "vaca/b-day\n",
      "mr.very\n",
      "locationon\n",
      "monkies\n",
      "hooplah\n",
      "gooooooooood\n",
      "tusca\n",
      "2k17\n",
      "type-of-way\n",
      "unexisti\n",
      "twin-bed\n",
      "non-wo\n",
      "beeter\n",
      "service/\n",
      "valetkey\n",
      "redifined\n",
      "ustoa\n",
      "cheezy\n",
      "beautiful~\n",
      "daysinn\n",
      "experiencee\n",
      "hotel..great\n",
      "cacovich\n",
      "greal\n",
      "vacation.th\n",
      "l.ove\n",
      "ahhhnold\n",
      ",excellent\n",
      "appartmen\n",
      "fantistic\n",
      "roadtr\n",
      "eith\n",
      "steal.a\n",
      "spreding\n",
      "hugeeeeeeeee\n",
      "stay-poor\n",
      "mid-range/budget\n",
      ".sh\n",
      "sacram\n",
      "staff..katie\n",
      "service..perfect\n",
      "üí©\n",
      "expericence\n",
      "shala55\n",
      "seinfe\n",
      "likes-\n",
      "uncomfo\n",
      "lovesince\n",
      "shawesh\n",
      "volum\n",
      "businessny\n",
      "mdfk\n",
      "arizon\n",
      "sillicon\n",
      "unnecess\n",
      "wifes\n",
      "experienceüòäüòä\n",
      "differen\n",
      "herec\n",
      "check-inn\n",
      "leavi\n",
      "quality-for-money\n",
      "n-hood\n",
      "poor321\n",
      "sanper\n",
      "sightse\n",
      "fablous\n",
      "positive-\n",
      "granddame\n",
      "whatever/whenever\n",
      "chicer\n",
      "hotel.spacious\n",
      "clean.eve\n",
      "visit/property\n",
      "cenrer\n",
      "luxarious\n",
      "t00\n",
      "aight\n",
      "üíï\n",
      "not-so-great\n",
      "weekendthank\n",
      "stay..would\n",
      "deperately\n",
      "convienence\n",
      "assistanc\n",
      "always-\n",
      "staff/housekeeping\n",
      "ezxcellent\n",
      "marriott/spg\n",
      "st-\n",
      "hmmmh\n",
      "attrib\n",
      "◊ê◊†◊©◊ô◊ù\n",
      "katzenber\n",
      "4nightsi\n",
      "happeni\n",
      "weekendüéºüéº\n",
      "mon-\n",
      "alriiiight\n",
      "teency\n",
      "wkc\n",
      "anniversary-\n",
      "dime-ing\n",
      "service/very\n",
      "resturaunt\n",
      "franciscco\n",
      "smached\n",
      "yoset\n",
      "hotels.co\n",
      "hoterl\n",
      "caesas\n",
      "tripy\n",
      "valet-\n",
      "procceses\n",
      "'gift\n",
      "toddlers/young\n",
      "viewless\n",
      "it¬¥\n",
      "area.ex\n",
      "registerin\n",
      "tgings\n",
      "terrib\n",
      "location/service\n",
      "weak-\n",
      "overprieced\n",
      "loxation\n",
      "staff/roo\n",
      "facilities/location\n",
      "mcdaag\n",
      "pre-theater\n",
      "nighjt\n",
      "rooms..when\n",
      "excitemant\n",
      "custoe\n",
      "together/\n",
      "plessintly\n",
      "transportation.the\n",
      "palazzo/venetian\n",
      "saty\n",
      "morocoo\n",
      "thereve\n",
      "could/should\n",
      "apacious\n",
      "noisyÔºÅÔºÅÔºÅ\n",
      "run-down..\n",
      "surpa\n",
      "„Çµ„Éº„Éì„Çπ„ÅØÊó•Êú¨„Å®„Åè„Çâ„Åπ„Å¶„Åó„Åæ„ÅÜ„Å®ÊîπÂñÑÁÇπ„ÅØÂ§ö„ÄÖ„ÅÇ„Çä„Åæ„Åô„Åå„ÄÅ„Å®\n",
      "cuty\n",
      "good-not\n",
      "equidist\n",
      "soemwhere\n",
      "panora\n",
      "stars.i\n",
      "1-nig\n",
      "mid-feb\n",
      "classsic\n",
      "29/night\n",
      "last..\n",
      "experienceuloopll\n",
      "no-s\n",
      "the.staff\n",
      "recenlty\n",
      "congr\n",
      "sollution\n",
      "itself-room\n",
      "4nts\n",
      "facility-great\n",
      "wynn-amazing\n",
      "consulat\n",
      "stantdard\n",
      "bonified\n",
      "timeshared\n",
      "yorknew\n",
      "swimm\n",
      "theifs\n",
      "mider\n",
      ".stuffy\n",
      "5mn\n",
      "righti\n",
      "..excellence\n",
      "spa.sma\n",
      "'nuff\n",
      "notcas\n",
      "allaha\n",
      "manhatty\n",
      "homewor\n",
      "exeptiona\n",
      "anizia\n",
      "amste\n",
      "iwatch\n",
      "scadanavian\n",
      "v√≠siting\n",
      "fopr\n",
      "caffei\n",
      "lobby/front\n",
      "pkace\n",
      "hotlel\n",
      ".extremely\n",
      "review..rooms\n",
      "parcc\n",
      "*****excellent\n",
      "cocktail/cabaret\n",
      "yrk\n",
      "investers\n",
      "beauriful\n",
      "staff.just\n",
      "paris.the\n",
      "rpice\n",
      "peopleplenty\n",
      "staff/service\n",
      "nazlija\n",
      "‚úÖ-\n",
      "arkansa\n",
      "tavelodge\n",
      "goldengirls14\n",
      "strip.parking\n",
      "histo\n",
      "room.-noise\n",
      "chinashop53\n",
      "entrance-\n",
      "york-urban\n",
      "poolarea\n",
      "tryp-\n",
      "nrew\n",
      "ohtalker\n",
      "christmas/nye\n",
      "„Çè„Åñ„Çè„Åñhomepage„Åßexecutiv\n",
      "terrible-stay\n",
      "disappoining\n",
      "exceptioanl\n",
      "lost/\n",
      "commercial/bu\n",
      "25/day\n",
      "looove\n",
      "stay/customer\n",
      "comunicatin\n",
      "superboo\n",
      "microwav\n",
      "laroc\n",
      "wet-dream\n",
      "wverything\n",
      "'pensioners\n",
      "novotal\n",
      "hreat\n",
      "reeboed\n",
      "annoyingl\n",
      ".hall\n",
      "cicag\n",
      "un-friendly\n",
      "luxry\n",
      "ferie\n",
      "ditry\n",
      "golden.book\n",
      "wayyyyyyy\n",
      "getaw\n",
      "dsecu\n",
      "restorati\n",
      "notori\n",
      "easy-goin\n",
      "certai\n",
      "well-s\n",
      "un-trump\n",
      "location‚Ä¶good\n",
      "anneversery\n",
      "luxury/service\n",
      "avarege\n",
      "average/below\n",
      "mis-treatmen\n",
      "recevatio\n",
      "nowacc\n",
      "aug13\n",
      "trippled\n",
      "location=perfectprice=perfectwe\n",
      "hapend\n",
      "start-great\n",
      "arractions\n",
      "fall-shorts\n",
      "plent\n",
      "chicago/\n",
      "americ\n",
      "wyngate\n",
      "priece\n",
      "european-type\n",
      "omg-\n",
      "frustrat\n",
      "park/near\n",
      "location.location.location\n",
      "ricieri\n",
      "insi\n",
      "/boutique\n",
      "..loved\n",
      "atl‚Äî-\n",
      "thourou\n",
      "highes\n",
      "app¬¥s\n",
      "embarc\n",
      "roomsrooms\n",
      "wjh\n",
      "reachi\n",
      "***theft\n",
      "fremont/old\n",
      "diasppointed\n",
      "deceving\n",
      "haussma\n",
      "center-\n",
      "overhall\n",
      "jamed\n",
      "12:00am\n",
      "iroquios\n",
      "stay..almost\n",
      "advertis\n",
      "mid-upscale\n",
      "locationof\n",
      "only..\n",
      "supern\n",
      "guest-f\n",
      "lvmgmgrand\n",
      "üòù\n",
      "helpful.from\n",
      "bachlorett\n",
      "alternatine\n",
      "foxtails\n",
      "adventage\n",
      "harmesh\n",
      "moneyall\n",
      "renovation-but\n",
      "refundale\n",
      "-gem\n",
      "perfectlocation\n",
      "paridise\n",
      "first-timer\n",
      "service-great\n",
      "middleaged\n",
      "firstly.the\n",
      "nightsfamil\n",
      "kossiwa\n",
      "non-tourists\n",
      "fifteens\n",
      "rooms/elevators\n",
      "lovfe\n",
      "kevjen98\n",
      "business/personal/birthday/perfect\n",
      "seving\n",
      "catersour\n",
      "loacatoin\n",
      "eperience\n",
      "prooer\n",
      "omlets\n",
      "..since\n",
      "times..great\n",
      "earli\n",
      "\\ntha\n",
      "gambleing\n",
      "awful..very\n",
      "family/\n",
      "beenin\n",
      "theaterland\n",
      "qmary2\n",
      "unbe\n",
      "brother..\n",
      "xceeded\n",
      "frsn\n",
      "us22\n",
      "DGDGDG.DG\n",
      "hands-d\n",
      "down-t\n",
      "teeneger\n",
      "**not\n",
      "old-worldly\n",
      "daybe\n",
      "5miles\n",
      "..she\n",
      "find.3rd\n",
      "redee\n",
      "flels\n",
      "paidfor\n",
      "lv/summerlin\n",
      "highlighte\n",
      "employeed\n",
      "hospitality/consistent\n",
      "jan.'15\n",
      "un-hampton\n",
      "buidli\n",
      "dated-but\n",
      "comfortablewell\n",
      "gtrat\n",
      "comfortable-glad\n",
      "wesj\n",
      "üóΩüé≠\n",
      "nond\n",
      "spewin\n",
      "concierce\n",
      "nicelt\n",
      "organiz\n",
      "first-of-the-year\n",
      "francisco/\n",
      "chambe\n",
      "view.servic\n",
      "roylaton\n",
      "2015.reception\n",
      "1-july\n",
      "eeeeeww\n",
      "lexingron\n",
      "staffupon\n",
      "co-worke\n",
      "-one\n",
      "kimh\n",
      "modern/\n",
      "2yrs\n",
      "conceriege\n",
      "small-roomed\n",
      "6am-10p\n",
      "recognised/\n",
      "conditioni\n",
      "hotels.c\n",
      "cheaps\n",
      "fairfie\n",
      "nyfw\n",
      "loce\n",
      "üò†üò†üò†\n",
      "over-sold\n",
      "DGDG-DG-DGDGDGDG\n",
      "here..we\n",
      "acno\n",
      "largeother\n",
      "interio\n",
      "canx\n",
      "strip.q\n",
      "greenwi\n",
      "bedrooms.if\n",
      "ÔΩñÔΩÖÔΩíÔΩô\n",
      "service/food\n",
      "24-28th\n",
      "expensiveÔºånoisyÔºånot\n",
      "ideall\n",
      "botique\n",
      "hotel.will\n",
      "proplems\n",
      "bedlinen\n",
      "waldorf-as\n",
      "wxpected\n",
      "playcation\n",
      "yery\n",
      "worthwhile..thats\n",
      "overnigt\n",
      "deks\n",
      "dmokey\n",
      "w.h.i.v.s.i.v\n",
      "fun/birthday\n",
      "kelye\n",
      "deser\n",
      "comfort.cl\n",
      "establishmen\n",
      "breakfest\n",
      "18-25th\n",
      "vaegas\n",
      "upwe\n",
      "five-\n",
      "re-\n",
      "poolyr\n",
      "recomen\n",
      "coonections\n",
      "distination\n",
      "uncompliahed\n",
      "location..many\n",
      "qick\n",
      "wasgreat\n",
      "aweshom\n",
      "knikerbocker\n",
      "aggressiv\n",
      "stay-ca\n",
      "abolu\n",
      "extradordinarily\n",
      "value-nice\n",
      "girlsfriends\n",
      "stylsih\n",
      "nyork\n",
      "expsri\n",
      "assinged\n",
      "change~\n",
      "bluuuuu\n",
      "yeork\n",
      "-restaurant\n",
      "roommicrowav\n",
      "cpuld\n",
      "rockefelle\n",
      "üïã\n",
      "kidding..this\n",
      "lovacation\n",
      "sophisticat\n",
      "manhathan\n",
      "unrenovated\n",
      "-lousy\n",
      "timshare\n",
      "non-guest\n",
      "..rather\n",
      "extraor\n",
      "Ô∏èÔ∏èbeautiful\n",
      "metic\n",
      "unloadin\n",
      ".could\n",
      "retro..in\n",
      "3-card\n",
      "scandina\n",
      "unflexible\n",
      "district/wtc\n",
      "dispicable\n",
      "fashionab\n",
      "faovrite\n",
      "casino-engulfed\n",
      "exceluxent\n",
      "wiseshe\n",
      "years7\n",
      "hotel/unpretty\n",
      "bettet\n",
      "characte\n",
      "bizzar\n",
      "family-stay\n",
      "mohamemed\n",
      ".poor\n",
      "live.y\n",
      "tower/casino\n",
      "mainl\n",
      "sleepe\n",
      "cormik\n",
      "superbow\n",
      "staay\n",
      "DG/DG/DGDG-DG/DGDG/\n",
      "club..\n",
      "luxirious\n",
      "‚Ä¶.superb\n",
      "pleasurefilled\n",
      "goldiest\n",
      "positives-the\n",
      "localization-\n",
      "establishm\n",
      "check_in\n",
      "fhr\n",
      "quintesse\n",
      "staycation\n",
      "start:1\n",
      "retro/modern\n",
      "ave/river\n",
      "kabib\n",
      "best‚Äîthe\n",
      "special/just\n",
      "hmmm..\n",
      "afternon\n",
      "reseptionstaff\n",
      "conern\n",
      "chargeed\n",
      "reember\n",
      "room-redwood\n",
      "gramercy-\n",
      "romantric\n",
      "phyiscal\n",
      "georgem\n",
      "recommendlocation\n",
      "supreb\n",
      "mgm.when\n",
      "chucky13\n",
      "investm\n",
      "4a.m\n",
      "-construction\n",
      "experiencin\n",
      "excellrnt\n",
      "cherk\n",
      "location.vegas\n",
      "announ\n",
      "papmered\n",
      "convienien\n",
      "siimply\n",
      "cleani\n",
      "cessat\n",
      "horrableplace\n",
      "o.k\n",
      "roof-deck\n",
      "all-good\n",
      "scenenery\n",
      "plamtastic\n",
      "jotel\n",
      "ghostbar\n",
      "vibing\n",
      "bedvery\n",
      "bateri\n",
      "frills/outdated\n",
      "DGDG\n",
      "highr\n",
      ".gear\n",
      "ausgezeichnet\n",
      "applys\n",
      "strech\n",
      "centrer\n",
      "not-so-\n",
      "fght\n",
      "fainfpij\n",
      "traffi\n",
      "pthis\n",
      "poshy\n",
      "6:00pm\n",
      "non-service\n",
      "salllys\n",
      "refri\n",
      "bussl\n",
      "anonymo\n",
      "bars/nigh\n",
      "non-elegant\n",
      "kids/team\n",
      "lovrly\n",
      "mom/daugher\n",
      "elevenpast\n",
      "\\n5\n",
      "entertaining.ever\n",
      "280/night\n",
      "hotel/spacious\n",
      "anniversary/convention\n",
      "fellin\n",
      "royalit\n",
      "strip/good\n",
      "infr\n",
      "s.e.m.a\n",
      "theme-staff\n",
      "-strip\n",
      "room-amazing\n",
      "diamond/\n",
      "sheburne\n",
      "mid-t\n",
      "deco/boutique\n",
      "stayüòéüòé\n",
      "convenien\n",
      "catchin\n",
      "vwgas\n",
      "mahem\n",
      "staffstayed\n",
      "arrrrrrr\n",
      "b+\n",
      "tribec\n",
      "superparking\n",
      "48hrs\n",
      "ritzier\n",
      "brittny\n",
      "everthin\n",
      "yuuuuge\n",
      "to/leaving\n",
      "chic-modern\n",
      "famiiiilyyy\n",
      "pot-smoking\n",
      "umbr\n",
      "work/family\n",
      "horrif\n",
      "sarge1961\n",
      "criti\n",
      "‚Ä¶.the\n",
      "york-sized\n",
      "mid-lev\n",
      "seasons-las\n",
      "ditkas\n",
      "vegasfail\n",
      "hurte\n",
      "business/\n",
      "stripg\n",
      "dicided\n",
      "bally's-\n",
      "hotel.com\n",
      "manhattan..\n",
      "wayyy\n",
      "hancok\n",
      "..n\n",
      "inn/magnificent\n",
      "cathell\n",
      "regency-\n",
      "deffenatl\n",
      "fremont/dow\n",
      "authenti\n",
      "yoself\n",
      "triplover\n",
      "starff\n",
      "manadalay\n",
      "four-s\n",
      "tropicanna\n",
      "business/ple\n",
      "friendlyvery\n",
      "nycgetting\n",
      "7hours\n",
      "atrractions\n",
      "fantasticmont\n",
      "miniscul\n",
      "sqy\n",
      "location..watch\n",
      "fri-mon\n",
      "washingt\n",
      "incrediblly\n",
      "sanitatio\n",
      "bathro\n",
      "lakef\n",
      "bicsi\n",
      "intox\n",
      "üî•\n",
      "informati\n",
      "thougtfull\n",
      "hotel/convention\n",
      "size-more\n",
      "wilsonbaga\n",
      "writte\n",
      "locationget\n",
      "location.nice\n",
      ".üòâ\n",
      "tournement\n",
      "establis\n",
      "knicerbockers\n",
      "abviously\n",
      "exepectations\n",
      "263.55/night\n",
      "didn'y\n",
      "staffno\n",
      "baccha\n",
      "anniversary..\n",
      "location/services\n",
      "broaway\n",
      "locationlovely\n",
      "foundary\n",
      "3hours\n",
      "w57th\n",
      "delmy\n",
      "cost/performance\n",
      "eroemce\n",
      "basic/boutique\n",
      "contemporaly\n",
      "apprication\n",
      "town.your\n",
      "DGDG.DGDG.\n",
      "all-sweet\n",
      "pacello\n",
      "luxoright\n",
      "stayüéàüéÇüôå\n",
      "cleaned-up\n",
      "receiv\n",
      "stay=great\n",
      "love..love..ray..len\n",
      "clean..as\n",
      "matheus-eng\n",
      "refirbished\n",
      "recomended\n",
      "trip/college\n",
      "develera\n",
      "dtla\n",
      "vouc\n",
      "compelted\n",
      "weeka\n",
      "lovayed\n",
      "unusu\n",
      "cosotmer\n",
      "roughl\n",
      "assortmen\n",
      "responsibil\n",
      "service*5\n",
      ".except\n",
      "-understanding\n",
      "someu\n",
      "squareeeee\n",
      "nice..\n",
      "overpriced.my\n",
      "greas\n",
      "'hospitality\n",
      "resortfee\n",
      "pre-baby\n",
      "ceasa\n",
      "mdtown\n",
      "stay-great\n",
      "clean/safe/courteous/comfortable\n",
      "wareh\n",
      "nokturnal\n",
      "plze\n",
      "57r\n",
      "veghas\n",
      "inn-manhattan/\n",
      "eecently\n",
      "sydell\n",
      "mini-break\n",
      "expa\n",
      "natashia\n",
      "hotel-outstanding\n",
      "like/something\n",
      "horribl\n",
      "‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏ègreat\n",
      "reseption\n",
      "pullou\n",
      "1-feb4\n",
      "butbstained\n",
      "repu\n",
      "theflamingo\n",
      "reststop\n",
      "fountainview\n",
      "location-beware\n",
      "positivel\n",
      "anniversary/valentine\n",
      "appartem\n",
      "getaway/attended\n",
      "rooms-best\n",
      "place.would\n",
      "pluses-\n",
      "delarno\n",
      "gem**\n",
      "11-15th\n",
      "full-ser\n",
      "tourney-wo\n",
      "caruscos\n",
      "in-city\n",
      "excellent„ÄÇgood\n",
      "dissapointment\n",
      "campt\n",
      "here..as\n",
      "breautif\n",
      "midtown/park\n",
      "co-\n",
      "3nts\n",
      "14t\n",
      "stay/close\n",
      "positives+got\n",
      "clean/staff/service\n",
      "myse\n",
      "prioriti\n",
      "free.sport\n",
      "carlo/park\n",
      "subwaystat\n",
      "jawdropping\n",
      "excperience\n",
      "üÜó\n",
      "rightsized\n",
      "renovations..\n",
      "working-bad\n",
      "wheelcharfriendly\n",
      "liberty/ellis\n",
      "muchevery\n",
      "skylo\n",
      "300da\n",
      "raffaelo\n",
      "22nd-28th\n",
      "fieldhous\n",
      "bed-\n",
      "midnig\n",
      "graduate/came\n",
      "hoteli\n",
      "average..at\n",
      "money-value\n",
      "traeler\n",
      "preferen\n",
      "dyrip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abdull\n",
      "glorio\n",
      "food/good\n",
      "mgmü¶Å\n",
      "'cr\n",
      "supershutt\n",
      "anniversar\n",
      "trip-3days\n",
      "pre-pay\n",
      "wellingto\n",
      "service‚Ä¶\n",
      "9-year-ol\n",
      "small/clean\n",
      "5words\n",
      "morrea\n",
      "unsatisifed\n",
      "pacage\n",
      "stay-cay\n",
      "westhou\n",
      "convienently\n",
      "benjamin-nyc\n",
      "accessable\n",
      "hotel/reso\n",
      "shoppingplaced\n",
      "vadara\n",
      "vacation/husband\n",
      "polazzo\n",
      "non-5\n",
      "sportsbetting\n",
      "compex\n",
      "instagrammer\n",
      ".a\n",
      "march,20\n",
      "business/pleasur\n",
      "suite-type\n",
      "premeir\n",
      "ac-fan\n",
      "curtio\n",
      "well-eq\n",
      "one-br\n",
      "vegas.b\n",
      "phlv\n",
      "persone\n",
      "moniqu\n",
      "‚ù§Ô∏èchicago\n",
      "4mo\n",
      "football/poker\n",
      "sinb\n",
      "ameritania-\n",
      "motorhotel\n",
      "counte\n",
      "likeacaes\n",
      "visit/customer\n",
      "sink-\n",
      "eldis\n",
      "pros/cons\n",
      "glass/\n",
      "2016.we\n",
      "DG.DG.DGDG\n",
      "impressve\n",
      "disappointef\n",
      "amenitiesit\n",
      "outd\n",
      "japnese\n",
      "son-in-laws\n",
      "/refund\n",
      "jazz-fueld\n",
      "comparab\n",
      "comf\n",
      "stay..fantastic\n",
      "nickerbocker\n",
      "quiet-seek\n",
      "gaurantees\n",
      "compac\n",
      "chintan\n",
      "oftent\n",
      "lhotels\n",
      "four-nigh\n",
      "t.mobile\n",
      "internationa\n",
      "experienceüëç\n",
      "outdated/noisy\n",
      "virginatlanti\n",
      "ÏúÑÏπòÎûë\n",
      "location+spacious\n",
      "disqusted\n",
      "professsional\n",
      "updated.we\n",
      "visit-may\n",
      "unaccomodating\n",
      "confe\n",
      "bigguns\n",
      "further-this\n",
      "◊û◊ô◊ß◊ï◊ù\n",
      "odd/smokey\n",
      "family-tr\n",
      "wowzer\n",
      "reccomen\n",
      "quite.\n",
      "tournamnent\n",
      "hotek\n",
      "pwrfect\n",
      "excellenr\n",
      "location.roo\n",
      "'rolling\n",
      "gold-member\n",
      "'su\n",
      "'ball\n",
      "ecoerience\n",
      "secondtime\n",
      "13th-15th\n",
      "off-seas\n",
      "client√®l\n",
      "differentl\n",
      "money1st\n",
      "accomidations\n",
      "sitting/lounge\n",
      "breaf\n",
      "soho/tribec\n",
      "europeam\n",
      "dibly\n",
      "..except\n",
      "p.f\n",
      "love..love..love\n",
      "parree\n",
      "cesra\n",
      "w57\n",
      "staff‚Ä¶‚Ä¶\n",
      "DG/DGDG/DGDG/DGDG\n",
      "fsh/san\n",
      "nice.extrem\n",
      "caesarrs\n",
      "dissappoin\n",
      "-gc\n",
      "southsho\n",
      "embass\n",
      "hotel/value\n",
      "misfortu\n",
      "bevsvegas\n",
      "profitab\n",
      "concierge/\n",
      "noiyung\n",
      "one.i\n",
      "10nts\n",
      "accessiblity\n",
      "hgvclub\n",
      "2.staff\n",
      "lioved\n",
      "stayüëç\n",
      "definitey\n",
      "venetian-style\n",
      "upstat\n",
      "enviorment\n",
      "girlfr\n",
      "cons..\n",
      "beutif\n",
      "perfect¬°¬°\n",
      "imagine..\n",
      "buxor\n",
      "„Ç≥„Çπ„ÉëÊÇ™„ÅÑ\n",
      "de'nile\n",
      "superb11\n",
      "location.bi\n",
      "puyk1960\n",
      "time.ac\n",
      "starwoodhhotel\n",
      "hightly\n",
      "crecit\n",
      "excal\n",
      "depenable\n",
      "lovelyi\n",
      "personally-\n",
      "accomidati\n",
      "location/terrible\n",
      "godfre\n",
      "one-of-a\n",
      "go-to-hotel\n",
      "fami\n",
      "circu\n",
      "finishi\n",
      "2k18\n",
      "beauitful\n",
      "atenci√≥n\n",
      "location~~terr\n",
      "vac.~travel\n",
      "..as\n",
      "insid\n",
      "incomparab\n",
      "d'ci\n",
      ".another\n",
      "üéº\n",
      "wondrful\n",
      "gopinathan\n",
      "residenc\n",
      "enexpected\n",
      "city/times\n",
      "strip‚Ä¢\n",
      "Í∞îÎçîÎãà\n",
      "carefu\n",
      "inviting/excellent\n",
      "jigman\n",
      "location-enjoyed\n",
      "magnifici\n",
      "ageeat\n",
      "firreworks\n",
      "powell/hyde\n",
      "ameritani\n",
      "cleam\n",
      "clean/friendly/courteous\n",
      "mesme\n",
      "yrsfather\n",
      "bestspot\n",
      "iconi\n",
      "DGDGDGDG.DGDG\n",
      "awesomeand\n",
      "oracleopenw\n",
      "o'sheas\n",
      "twentyfun\n",
      "weekend-excellent\n",
      "adventu\n",
      "mprovement\n",
      "all.the\n",
      "ticki\n",
      "requireme\n",
      "offeri\n",
      "vacation/\n",
      "satio\n",
      "money.good\n",
      "126-room\n",
      "foold\n",
      "unorganize\n",
      "service/large\n",
      "overboo\n",
      "delan-no\n",
      "lackin\n",
      "22month\n",
      "bellecalire\n",
      "mid-manhatten\n",
      "stress-free\n",
      "magaz\n",
      "print..\n",
      "spot..\n",
      "location_\n",
      "'service\n",
      "sasified\n",
      "upgard\n",
      "clean/modern\n",
      "-j\n",
      "auctio\n",
      "furb\n",
      "w/the\n",
      "terrace-terrible\n",
      "'superior\n",
      "ftom\n",
      "area.n\n",
      "cutkli\n",
      "hardwood/laminate\n",
      "rectifie\n",
      "book.com\n",
      "centralpark\n",
      "funby\n",
      "comforatable\n",
      "waterpreas\n",
      "underpriced..\n",
      "vacation..\n",
      "stay-due\n",
      "distrikit\n",
      "recommend-\n",
      "chic-ago\n",
      "mskettering\n",
      "aesthe\n",
      "swtiched\n",
      "custome\n",
      "üíñüíñparis\n",
      "bonu\n",
      "anniverssry\n",
      "service..fantastic\n",
      "to.great\n",
      "somea\n",
      "expedia.ca\n",
      "vegas-m\n",
      "room.b\n",
      "stay/convenient\n",
      "kids-friendly\n",
      "rikm\n",
      "resloved\n",
      "paris-dise\n",
      "roll-a-way\n",
      "staff/fantastic\n",
      "mechanica\n",
      "word..exceptional\n",
      "crowdbut\n",
      "discust\n",
      "pbus\n",
      "cigaretts\n",
      "einfach\n",
      "avenu\n",
      "car-do\n",
      "delighfully\n",
      "adjo\n",
      "extrordinary\n",
      "location..right\n",
      "hot-cold-hot-cold-hot-cold\n",
      "great.great\n",
      "bellmen/valet\n",
      "pacakage\n",
      "skyli\n",
      "solo/y\n",
      "fllamingo\n",
      "sidew\n",
      "people-resort\n",
      "crumby\n",
      "shamira\n",
      "worstgate\n",
      "dosshouse\n",
      "cuisi\n",
      "48hr\n",
      "topcharge\n",
      "imaculate\n",
      "imfar\n",
      "oppule\n",
      "bithday\n",
      "property..\n",
      "value.and.location\n",
      "exactley\n",
      "adventuredome\n",
      "locationbar\n",
      "timer..\n",
      "liftetime\n",
      "ex-n\n",
      "..right\n",
      "enjoythe\n",
      "diapointed\n",
      "grandki\n",
      "moretlc\n",
      "ver√§ndertem\n",
      "phisically\n",
      "placenice\n",
      "exoerienc\n",
      "7-8min\n",
      "centreal\n",
      "stay-least\n",
      "vadar\n",
      "lift-rooms\n",
      "affec\n",
      "straightforwa\n",
      "impresed\n",
      "rangers/yankees\n",
      "ny-sized\n",
      "uncomforable\n",
      "..so\n",
      "peferct\n",
      "centerwas\n",
      "lodgi\n",
      "points‚Ä¶\n",
      "11th-15th\n",
      "quility\n",
      "service/clean\n",
      "gwen.jas\n",
      "impersonal/average\n",
      "desk/check\n",
      "'humanity\n",
      "stay.excalibur\n",
      "sunnyaz\n",
      "mega-hotel\n",
      "cpomfortable\n",
      "samr\n",
      "üôà\n",
      "park..paris\n",
      "facilitirs\n",
      "non-resort\n",
      "taxi-\n",
      "cenury\n",
      "damilini\n",
      "exellent\n",
      "stay/disappointed\n",
      "/4th\n",
      "tdw0716\n",
      "disappointed/will\n",
      "true-\n",
      "service.\n",
      "dƒ±≈üƒ±nda\n",
      "upscale.great\n",
      "defenitely\n",
      "chargi\n",
      "managme\n",
      "manager/service\n",
      "guestroo\n",
      "gise\n",
      "room205\n",
      "bigbluesbender\n",
      "-goo\n",
      "d-las\n",
      "gorgeus\n",
      "DGDG.DGDG\n",
      "check-in/o\n",
      "elegace\n",
      "surre\n",
      "noisyyyyyyyyyyyyyyyyyyyyyyyyyyyy\n",
      "stay.location\n",
      "doublretree\n",
      "faborite\n",
      "bedrm\n",
      "cute/quirky/convenient\n",
      "marathon-friendly\n",
      ".paris\n",
      "creativ\n",
      "10.20pm\n",
      "rudies\n",
      "style..\n",
      "hallo-\n",
      "distrct\n",
      "studenty\n",
      "atmospheretip\n",
      "mediterranian\n",
      "king/\n",
      "step..\n",
      "rect\n",
      "buttone\n",
      "favoriates\n",
      "vibr\n",
      "jusr\n",
      "-way\n",
      "embracadero\n",
      "palazo-\n",
      "location..but\n",
      "parksouth\n",
      "suite/not\n",
      "all/bad\n",
      "-chromecast\n",
      "bontique\n",
      "framily\n",
      "checjking\n",
      "reviewwe\n",
      "ecohappy\n",
      "chrysl\n",
      "one-bedroo\n",
      "downstain\n",
      "worke\n",
      "bient√¥t\n",
      "incou\n",
      "difficult/expensiv\n",
      "room/tournaments\n",
      "daysq\n",
      "frienly\n",
      "varm\n",
      "recom\n",
      "febr\n",
      "city/bay\n",
      "hhp\n",
      "touches-jazz\n",
      "showxase\n",
      "check-o\n",
      "convensi\n",
      "do-dah\n",
      "tohotel\n",
      "emelda\n",
      "husband.my\n",
      "non-renova\n",
      "ocatvius\n",
      "july-\n",
      "conce\n",
      "festejo\n",
      "\\nbirthday\n",
      "knicks/warriors\n",
      "noyvh\n",
      "britis\n",
      "trurn-aroun\n",
      "well-worth\n",
      "minte\n",
      "33r\n",
      "kimptons-\n",
      "midwa\n",
      "roomroom\n",
      "one-nigh\n",
      "treate\n",
      "everlights\n",
      "fesort\n",
      "non-big\n",
      "hotel/z\n",
      "unden\n",
      ".dont\n",
      "grante\n",
      "jacuzz\n",
      "itwa\n",
      "üòçüòçüòç\n",
      "mother/daughter/granddaughter\n",
      "bedroom/\n",
      "wynne/encore\n",
      "staff/problems\n",
      "brillent\n",
      "luggagehelp\n",
      "reservasation\n",
      "nights.during\n",
      "experinced\n",
      "non-smok\n",
      "satisf\n",
      "chick-in\n",
      "exampl\n",
      "organizati\n",
      "welc\n",
      "benefits.from\n",
      "day/4\n",
      "hampton/hil\n",
      "stayenj\n",
      "quintesessential\n",
      "thanksgiv\n",
      "accomodations.constan\n",
      "rooms/mini\n",
      "relax..\n",
      "upgrated\n",
      "ambassado\n",
      "welcome.e\n",
      "rush/gold\n",
      "rooms-smokey\n",
      "cartwrigh\n",
      "terrifie\n",
      "lincoln-an\n",
      "locatijn\n",
      "DGDG/DG-DG\n",
      "staff=\n",
      "paris-like\n",
      "ÔΩÖÔΩòÔΩÉÔΩÖÔΩåÔΩåÔΩÖÔΩéÔΩî\n",
      "handtca\n",
      "staff-awesome\n",
      "preparation/notary\n",
      "return..found\n",
      "conditionning\n",
      "zeppel\n",
      "uncrowd\n",
      "waldorf=asto\n",
      "great.very\n",
      "gottcha\n",
      "inn/herald\n",
      "\\planet\n",
      "strak\n",
      "toooo\n",
      "discoverist\n",
      "moneywe\n",
      "üëçüèø\n",
      "zoribe\n",
      "harrah's-horseshoe\n",
      "ofsome\n",
      "non-gamb\n",
      "mmmmmmmm\n",
      "confortabl\n",
      "‚úàÔ∏èüá∫üá∏üí∞üëçüç∫üç∏üòÇ\n",
      "music-\n",
      "hotel/facilities\n",
      "do-\n",
      "◊û◊ï◊©◊ú◊ù\n",
      "accessability\n",
      "careful-holiday\n",
      "excelsnt\n",
      "loacyed\n",
      "anywhe\n",
      ".food\n",
      "5days/\n",
      "two-ni\n",
      "resort/sp\n",
      "honeymoon/travelling\n",
      "'every\n",
      "groups/f\n",
      "mainte\n",
      ".fam\n",
      "ahve\n",
      "asrt\n",
      "cormick\n",
      "24th-2\n",
      "origina\n",
      "non-ma\n",
      "street/empire\n",
      "9.30pm\n",
      "centralmanha\n",
      "accomdation\n",
      "mid-janurary\n",
      "locataion\n",
      "wolfpack2015\n",
      "zen-tastic\n",
      "vegas-sad\n",
      "100-super\n",
      "excellentthe\n",
      "review..3\n",
      "ÊúÄÈ´ò„ÅÆ„Éõ„ÉÜ„É´\n",
      "particul\n",
      "24-27t\n",
      "bacchan\n",
      "'attr\n",
      "events:22,000\n",
      "'missing\n",
      "DGDG-DGDG\n",
      "loveing\n",
      "glowi\n",
      "spacioius\n",
      "5nig\n",
      "-convention\n",
      "restorat\n",
      "dlocation\n",
      "share..\n",
      "fellita\n",
      "nice..loved\n",
      "caviat\n",
      "boardering\n",
      "contemporary-feeling\n",
      "shappy\n",
      "location-hip\n",
      "descrip\n",
      "shaquan\n",
      "**due\n",
      "business/family\n",
      "..donna\n",
      "wantin\n",
      "pooooor\n",
      "üëçüèª\n",
      "runnnn\n",
      "fenomen\n",
      "geoups\n",
      "michae\n",
      "ballaigo\n",
      "nighe\n",
      "3:45pm\n",
      "breakfast/brunch\n",
      "maxwe\n",
      "choongl\n",
      "up-\n",
      "16las\n",
      "arrea\n",
      "hardes\n",
      "undergon\n",
      "point.s\n",
      "4-mar\n",
      "nights.my\n",
      "appointm\n",
      "days.room\n",
      "wickerpark\n",
      "vegasand\n",
      "porti\n",
      "friendlyand\n",
      "game=\n",
      "up-grading\n",
      "mid-w\n",
      "place.the\n",
      "rooms/poor\n",
      "includd\n",
      "recommmend\n",
      "seaf\n",
      "here-a\n",
      "misinfor\n",
      "platinum..not\n",
      "grandmot\n",
      "swis\n",
      "choosin\n",
      "ridicilous\n",
      "pheno\n",
      "cellu\n",
      "family-friendl\n",
      "pepole\n",
      "inhallation\n",
      "roomserv\n",
      "amont\n",
      "place..even\n",
      "ongoin\n",
      "assyrian-swede\n",
      "sahara.since\n",
      "palace-las\n",
      "10-y\n",
      "newly-built\n",
      "months-\n",
      "vegas.room\n",
      "twice,3\n",
      "located-c\n",
      "hrh‚òÜ‚òÜ\n",
      "yeaaa\n",
      "wowwe\n",
      "a.mck\n",
      "caese\n",
      "space/kitchen\n",
      "location-spacious\n",
      "hoteal\n",
      "architecture/interior\n",
      "sudde\n",
      "pool-st\n",
      "payi\n",
      "less-well-known\n",
      "roomssuper\n",
      "hotrl\n",
      "onine\n",
      "airpor\n",
      "soft..\n",
      "nyc.th\n",
      "locationservice\n",
      "dikweni\n",
      "magn√≠fica\n",
      "treati\n",
      "expl\n",
      "feedb\n",
      "hampto\n",
      "sf/hotel\n",
      "compleet\n",
      "rediculas\n",
      "snowday\n",
      "ooohhh\n",
      "vodo\n",
      "buisn\n",
      "execut\n",
      "spectaular\n",
      "fablus\n",
      "expecterd\n",
      "librarianish\n",
      "jubi\n",
      "aatisfied\n",
      "vastl\n",
      "belllagio\n",
      "pre-payin\n",
      "valuea\n",
      "clh\n",
      "soho-\n",
      "napasinger\n",
      "roomone\n",
      "everything‚Ä¶\n",
      "alwaysüëçüëç\n",
      "'upgrades\n",
      "embas\n",
      "invasiv\n",
      "re-defines\n",
      "satisifactory\n",
      "definiately\n",
      "park-view\n",
      "amenities/ergonomics\n",
      "awful..nice\n",
      "diisgusting\n",
      ".continuing\n",
      "comfora\n",
      "rehersal\n",
      "faciliti\n",
      "phantastic\n",
      "greeded\n",
      "eperinces\n",
      "incompete\n",
      "ny‚ù§Ô∏è\n",
      "roosneedssomehelp\n",
      "christams\n",
      "frount\n",
      "okkaayyy\n",
      "x-holi\n",
      "vegas/family\n",
      "piccolissime\n",
      "tempor\n",
      "hiexpress\n",
      "crommy\n",
      "fancy-\n",
      "washclot\n",
      "super-clea\n",
      "quiet-\n",
      "honestl\n",
      "hvacr\n",
      "lake/city\n",
      "questionabl\n",
      "vegas/zion\n",
      "overall-loved\n",
      "marrogia\n",
      "obsta\n",
      "qucik\n",
      ".worth\n",
      "yuckiest\n",
      "facelift-fre\n",
      "revalation\n",
      "ü§î\n",
      "1orange\n",
      "location‚Äîtime\n",
      "trepid\n",
      "1-great\n",
      "7-star\n",
      "suply\n",
      "accomodations-no\n",
      "head-banging\n",
      "outastanding\n",
      "sawc\n",
      "waych\n",
      "disabilitiy\n",
      "locations/staff\n",
      "üéâüéäüéà\n",
      "cozy/european\n",
      "toddlin\n",
      "tub-\n",
      "theme/convenient\n",
      "returning-\n",
      "sublim\n",
      "caref\n",
      "hamdicap\n",
      "location:5/5bathroom:3/3lo\n",
      "casino..we\n",
      "general-my\n",
      "3night/4day\n",
      "reci\n",
      "appriciatte\n",
      "vacstion\n",
      "taxs\n",
      "opportuni\n",
      "alexsa\n",
      "locationha\n",
      "consecu\n",
      "high-comfort\n",
      "pearl/gold/platinum\n",
      "mortie\n",
      "acees\n",
      "honeymo\n",
      "conference/convention\n",
      "735pm\n",
      "loooove\n",
      "m.o.d\n",
      "agantok\n",
      "hiltonhonors\n",
      "congrstion\n",
      "disapointing\n",
      "chnaged\n",
      "'real\n",
      "hotelwas\n",
      "recreat\n",
      "excalib\n",
      "perfectwe\n",
      "‰æøÂà©„Å™Á´ãÂú∞„ÄÅ„Éï„É¨„É≥„Éâ„É™„Éº„Å™„Çπ„Çø„ÉÉ„Éï\n",
      "property-excellent\n",
      "charactor\n",
      "bedbu\n",
      "remodled\n",
      "overpriced/underwhelmed\n",
      "disired\n",
      "definate\n",
      "carlton/central\n",
      "supernice\n",
      "atitude\n",
      "shottty\n",
      "situauted\n",
      "selectio\n",
      "service/nice\n",
      ".places\n",
      "good..fridge\n",
      "staff/immaculate\n",
      "location/loud\n",
      "epito\n",
      "servicel\n",
      "kongres\n",
      "bell/lugg\n",
      "birthday/anniversary/thanksgiving\n",
      "hotel-large\n",
      "spa/salon\n",
      "hi-\n",
      "downtowm\n",
      "0place\n",
      "beware~no\n",
      "hotelhotel\n",
      "requ\n",
      "well-\n",
      "czr\n",
      "stayclean\n",
      "downfa\n",
      "whyndam\n",
      "exquisiteness\n",
      "twenty-somethings\n",
      "2018the\n",
      "retro-feel\n",
      "amesome\n",
      "ainz79\n",
      "DG.DGDG.DGDG\n",
      "sp√©cialy\n",
      "yearl\n",
      "hotels/resorts\n",
      "withs\n",
      "DG/DGDG/DGDG-DGDG/DG/DG\n",
      "uncleane\n",
      "sanctua\n",
      "e-\n",
      "-asking\n",
      "food.very\n",
      "locationextremely\n",
      "sharif-\n",
      "location/not\n",
      "wahington\n",
      "family.of\n",
      "helpes\n",
      "curre\n",
      "not-so-friendly\n",
      "days.g\n",
      "accommodationu\n",
      "3.5-star\n",
      "addit\n",
      "bedt\n",
      "hip.\n",
      "mid-str\n",
      "309deci\n",
      "north/near\n",
      "banglades\n",
      "procedu\n",
      "beyo\n",
      "non-cancel\n",
      "carpets-\n",
      "crampy\n",
      "masqeraude\n",
      "m.o\n",
      "glimps\n",
      "bayarea\n",
      "morw\n",
      "colse\n",
      "august-\n",
      "26hrs\n",
      "locals-casino\n",
      "disapoointing\n",
      "stsy\n",
      "bally-high\n",
      "summarymy\n",
      "amusin\n",
      "betterüòï\n",
      "scarpett\n",
      "food/food\n",
      "strip****\n",
      "displea\n",
      "pristin\n",
      "titl\n",
      "fantasticdog\n",
      "matained\n",
      "everybod\n",
      "dessign\n",
      "arou\n",
      "2-double\n",
      "gimic\n",
      "chique\n",
      "ü§ï\n",
      "sfay\n",
      "rooms/lobby\n",
      "honori\n",
      "√∂hman\n",
      "a-meh-ritania\n",
      "10-star\n",
      "fivedou\n",
      "splen\n",
      "price/convenience\n",
      "rooml\n",
      "b/fast\n",
      "hotel/spa/gym\n",
      "inn-chelse\n",
      "probobly\n",
      "plesantly\n",
      "hiraizum\n",
      "amentities\n",
      "chsngrf\n",
      "-want\n",
      "speciali\n",
      "61/day\n",
      "tgectears\n",
      "good.bu\n",
      "myrecent\n",
      "desription\n",
      "off-strip\n",
      "startrek\n",
      "disappointg\n",
      "pseudo-luxury\n",
      "over-indulgent\n",
      "mywi\n",
      "fally\n",
      "Ï¢ãÏùå\n",
      "23nd\n",
      ".at\n",
      "venenzia\n",
      "satying\n",
      "heck..\n",
      "hipster/cool\n",
      "8/1/2016o\n",
      ".sui\n",
      "crumbwell\n",
      "understatemen\n",
      "4day\n",
      "ncchc\n",
      "15year\n",
      "stayi\n",
      ",eront\n",
      "priceÔºÅÔºÅÔºÅ\n",
      "firmer..or\n",
      "peice\n",
      "in-tow\n",
      "nights.room\n",
      "throw-back\n",
      "nightc\n",
      "herit\n",
      "conviniently\n",
      "locationally\n",
      "stellarservice\n",
      "makesh\n",
      "invi\n",
      "myrnad\n",
      "wascrazy\n",
      "hontel\n",
      "at-airport\n",
      "vobrant\n",
      "discr\n",
      "beaufitul\n",
      "celebration/spring\n",
      "confortabile\n",
      "shennagins\n",
      "increas\n",
      "goingto\n",
      "memora\n",
      "signals-what\n",
      "getway\n",
      "april-2017\n",
      "friendlines\n",
      "star..\n",
      "Ï¢ãÏïòÏäµÎãàÎã§\n",
      "great.center\n",
      "excellent.foo\n",
      "exexcelle\n",
      "situ√©\n",
      "thatbi\n",
      "manadaly\n",
      "'your\n",
      "11yea\n",
      "whrenever\n",
      "girlf\n",
      "reservred\n",
      "reserv\n",
      "6ft-11inches\n",
      "3-dy\n",
      "phenoix\n",
      "five-sta\n",
      "sensiti\n",
      "resort/hotel\n",
      "minimalis\n",
      "restaurant/hot\n",
      "idcon\n",
      "iwce\n",
      "strateg\n",
      "mid-tow\n",
      "automot\n",
      "suspec\n",
      "franciscon\n",
      "priiceline\n",
      "'feel\n",
      "deco-styled\n",
      "rock'n\n",
      ".main\n",
      "staff***\n",
      "inexpensive..\n",
      "precize\n",
      "ciry\n",
      "awayif\n",
      "ago.it\n",
      "mondalay\n",
      "87-90/n\n",
      "upscale-no\n",
      "etique\n",
      "positve\n",
      "family/group\n",
      "destinstion\n",
      "adagi\n",
      "paradise.did\n",
      "accces\n",
      "mascitti\n",
      "fan-atic\n",
      "antwhere\n",
      "unabl\n",
      "over-t\n",
      "teplaced\n",
      "welcommed\n",
      "-should\n",
      "spring/winter\n",
      "nickl\n",
      "2/21/2017thi\n",
      "mall/excellent\n",
      "beegees\n",
      "viw\n",
      "'green\n",
      "southwe\n",
      "execp\n",
      "place.great\n",
      "amazi\n",
      "four-st\n",
      ".frien\n",
      "elevators..\n",
      "-beautiful\n",
      "mandolay\n",
      "stayüëçüëçüëç\n",
      "regist\n",
      "rusti\n",
      "adult-weekend\n",
      "deal/tr√®s\n",
      "great-the\n",
      "tarick\n",
      "location..the\n",
      "bellecla\n",
      "madiso\n",
      "encore/wyn\n",
      "indteresting\n",
      "first..\n",
      "re-newed\n",
      "francsico\n",
      "aaaa+++\n",
      "1ye\n",
      "kickerbocke\n",
      "w48th\n",
      "deffinetle\n",
      "to/in\n",
      "decor:1960s\n",
      "n.s\n",
      "~the\n",
      "location.very\n",
      "britneyhollywood\n",
      "builde\n",
      "enjoyful\n",
      "facility.great\n",
      "bikefest\n",
      "value.ea\n",
      "staie\n",
      "unsui\n",
      "hotel/experience\n",
      "beijin\n",
      "keitha732\n",
      "postives\n",
      "game.need\n",
      "decollette\n",
      "service/friendly\n",
      "sprin\n",
      "nice.i\n",
      "wynn-lasvegas\n",
      "drabl\n",
      "awsme\n",
      "bdays\n",
      ".missed\n",
      "platinum/life\n",
      "paradisw\n",
      "helpful-\n",
      "exprerience\n",
      "500usd+\n",
      ".ju\n",
      "location.short\n",
      "facialist\n",
      "midtown-times\n",
      "whatf\n",
      "hotel.v\n",
      "hyatt/mccormick\n",
      "drake-wow\n",
      "besviken\n",
      "amaazing\n",
      "experiencie\n",
      "atmoshpere\n",
      "ngsprecious\n",
      "offerings/events\n",
      "tavaras\n",
      "worki\n",
      "reliabl\n",
      "helpfulnice\n",
      "envigorating\n",
      "wrigleyvi\n",
      "efficiant\n",
      "staffhad\n",
      "fabüëåüèº\n",
      "not-much-goi\n",
      "ozkurt\n",
      "28-jan\n",
      "conveniently-located\n",
      "orbiz\n",
      "downtown/highline\n",
      "thnx\n",
      "anot\n",
      "simoly\n",
      "time/stay\n",
      "waldorf=astoria\n",
      "bookingdotcom\n",
      "un-fare\n",
      "washer/dryer\n",
      "location.food\n",
      "onenight\n",
      "courty\n",
      "dyst\n",
      "rooms.-n\n",
      "ÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩ\n",
      "uber/\n",
      ".bev\n",
      "good-l\n",
      "win/wynn\n",
      "godd\n",
      ".towers\n",
      "mommahuddy\n",
      "unprofessional/trained\n",
      "squarec\n",
      "concept..\n",
      "'love\n",
      "roomsand\n",
      "üá∫üá∏\n",
      "kzlebel\n",
      "need/request\n",
      "‚Ä¶that\n",
      "exterrior\n",
      "choppercon\n",
      "overf\n",
      "ciews\n",
      "airfare/hotel\n",
      "overb\n",
      "overwell\n",
      "stay.w\n",
      "'welcome\n",
      "bad/great\n",
      "planen\n",
      "triple-header\n",
      "metgrill\n",
      "andaz-ing\n",
      "foger\n",
      "-make\n",
      "booking.com\n",
      "1.i\n",
      "trumpness\n",
      "wharff\n",
      "greathowie\n",
      "tovegas\n",
      "vcation\n",
      "expietence\n",
      "issues/loud\n",
      "hopes..was\n",
      "calibe\n",
      "pract\n",
      "shonna\n",
      "price/terrible\n",
      "prepar\n",
      "mansfi\n",
      "definitley\n",
      "walka\n",
      "cromswell\n",
      "buffet/nice\n",
      "clean/good\n",
      "origial\n",
      "cercan√≠a\n",
      "front-door\n",
      "collrge\n",
      "inncident\n",
      "days:3\n",
      "chi-raq\n",
      "pleasedsoutherner\n",
      "hellomy\n",
      "nice~\n",
      "produc\n",
      "-however\n",
      "h√§rliga\n",
      "crommwell\n",
      "family/quadruple\n",
      "vanetian/palazo\n",
      "trafi\n",
      "valet/cleanliness\n",
      "rooms.quiet\n",
      "espacaily\n",
      "overloade\n",
      "flush/\n",
      "interior.nea\n",
      "unethi\n",
      "besthouse\n",
      "at.lovely\n",
      "perft\n",
      "'pending\n",
      "location.third\n",
      "pleasureable\n",
      "unrefinished\n",
      "accomada\n",
      "+s/-s.\n",
      "martinque\n",
      "frontde\n",
      "fabtastuc\n",
      "pricing.the\n",
      ".once\n",
      "maintenan\n",
      "iamrenewed\n",
      "do-si-do\n",
      "20yr\n",
      "motel8\n",
      "empir\n",
      "ssusa\n",
      "pros-relatively\n",
      "july3rd\n",
      "restasis\n",
      "blu-not\n",
      "hotel/quiet\n",
      "horra\n",
      "williows\n",
      "suite~an\n",
      "chiloop\n",
      "less-than-ideal\n",
      "amazinging\n",
      "room/location\n",
      "disappointent\n",
      "hotel/suites\n",
      "signific\n",
      "1-be\n",
      "'b\n",
      "distinctiv\n",
      "'facilitie\n",
      "visitng\n",
      "a'short\n",
      "agradecimiento\n",
      "meeting=great\n",
      "yoooou\n",
      "tuesd\n",
      "beautiul\n",
      "begin‚Ä¶‚Ä¶my\n",
      "maide\n",
      "daughters-\n",
      "neglige\n",
      "henri..\n",
      "disappoinment\n",
      "re-reviewed\n",
      "strolli\n",
      "suite.gave\n",
      "interconnec\n",
      "so..so\n",
      "myv\n",
      "meliorate\n",
      "discountte\n",
      "lady-nisha\n",
      "ac/heating\n",
      "botel\n",
      "retrevial\n",
      "slow-\n",
      "advertising-\n",
      "professinal\n",
      "ny.it\n",
      "updating.the\n",
      "casinoin\n",
      "realgoldfinger\n",
      "vsit\n",
      "sportsbar\n",
      "w.i.t\n",
      "tourist-b\n",
      "screa\n",
      "sun-tu\n",
      "finishin\n",
      "hecto\n",
      "updating/staff\n",
      "bicchieri\n",
      "swind\n",
      "hospoitality\n",
      "keepi\n",
      "adante\n",
      "230am\n",
      "chicago-1st\n",
      "nortside\n",
      "stop.i\n",
      "parking-inclu\n",
      "hoteljus\n",
      "yegas\n",
      "overc\n",
      "djt\n",
      "awawy\n",
      "carlyl\n",
      "commenci\n",
      "blood.on\n",
      "‚ù§Ô∏ènyc\n",
      "vegas.best\n",
      "1000ft\n",
      "airma\n",
      "staffcourteous\n",
      "flowride\n",
      "calvacade\n",
      "rate-quality\n",
      "not-so-warm\n",
      "courti\n",
      "upsid\n",
      "onvenient\n",
      "attitu\n",
      "days/night\n",
      "vacation/busines\n",
      "i'mnot\n",
      "vert=y\n",
      "coulple\n",
      "vanil\n",
      "prestige-ous\n",
      "serviv\n",
      "system/manage\n",
      "fixy\n",
      "somewh\n",
      "goldcoast\n",
      "ofcour\n",
      "platninum\n",
      "valuable.room\n",
      "yanique\n",
      "numbere\n",
      "wanderin\n",
      "sfo_\n",
      "wonderufl\n",
      "boitique\n",
      "situaton\n",
      "claustrophob\n",
      "transformi\n",
      "image..\n",
      "ammentite\n",
      "outstanding-great\n",
      "w/free\n",
      "pleasan\n",
      "negitives\n",
      "guaran\n",
      "adju\n",
      "put-out/rude\n",
      "returnin\n",
      "motorlodge\n",
      "belagiwow\n",
      "'le\n",
      "get-\n",
      "letd\n",
      "rooms.1\n",
      "beatifull\n",
      "superbvery\n",
      "problem..\n",
      "bbff\n",
      "marvy\n",
      "beautifully-run\n",
      "midtown.clean\n",
      "downtown/fd\n",
      "custosmer\n",
      "adjoinin\n",
      "front-offi\n",
      "spendid\n",
      "excetional\n",
      "proslarge\n",
      "employee-beth\n",
      "newyo\n",
      "penny-pinched\n",
      "casinoless\n",
      "liday\n",
      "roomconvenient\n",
      "stars‚Äîi\n",
      "stay/location\n",
      "lounge-\n",
      "mothermayi\n",
      "fromour\n",
      "limpian\n",
      "spacius\n",
      "old-fashion\n",
      "b***h\n",
      "donatel\n",
      "disadvan\n",
      "supri\n",
      "granddaug\n",
      "glitchs\n",
      "farakos\n",
      "satifcation\n",
      "pizz-zazz\n",
      "hotel/hallway\n",
      "excellent..and\n",
      "york.stay\n",
      "artus-cantin\n",
      "smallis\n",
      "cash-only\n",
      "ldw/50th\n",
      "woweveryone\n",
      "place-but\n",
      "re-emphasize\n",
      "2551psew\n",
      "incentives/dining\n",
      "underated\n",
      "overpriced/\n",
      "staffnear\n",
      "Âú®ÈÄôÈñìÈ£ØÂ∫óÂæÖ‰∫ÜËøë4Â§©Ôºå‰ΩÜÂ∞çÈ£ØÂ∫óÁúüÁöÑÂæàÂ§±ÊúõÔºåÂæû‰∏ÄÈÄ≤ÈñÄ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wles\n",
      "major/dealbreaking\n",
      "prac\n",
      "affordabl\n",
      "unci\n",
      "3d/2n\n",
      "pubilc\n",
      "1-night\n",
      "transporta\n",
      "5-6times\n",
      "c244\n",
      "crappier\n",
      "waayyyyy\n",
      "locatuon\n",
      "ts-\n",
      "times/bad\n",
      "DGDG.DGDG.DGDG\n",
      "wedding/weekend\n",
      "home.i\n",
      "rooos\n",
      "comforrable\n",
      "mistate\n",
      "location/unique\n",
      "fun-time\n",
      "self-marketed\n",
      "poolgreat\n",
      "brilliant..\n",
      "disappointmentike\n",
      "DG.DG*\n",
      "imterior\n",
      "smallif\n",
      "neighborhood-y\n",
      "chondhuny\n",
      "misit\n",
      "'dressed-up\n",
      "uph\n",
      "sleeples\n",
      "undergroun\n",
      "great.l\n",
      ".understated\n",
      "debatin\n",
      "staped\n",
      "grandc\n",
      "15hrs\n",
      "executi\n",
      "accompani\n",
      "disapppointing\n",
      "stay-service\n",
      "fithy\n",
      "accomidat\n",
      "long..th\n",
      "fqs\n",
      "DG***\n",
      "aaaaaaaa\n",
      "nowher\n",
      "happyhour4\n",
      "busy/small\n",
      "pro-s\n",
      "classicplace\n",
      "custpmer\n",
      "unparalelled\n",
      "wehavebeen\n",
      "updated/remodeled\n",
      "casablanca2018\n",
      "conscio\n",
      "manhattan/fi\n",
      "manday\n",
      "reccomm\n",
      "helllllo\n",
      "midtown/chelsea\n",
      "hard-partier\n",
      "father/\n",
      "donj't\n",
      "resevations\n",
      "professionel\n",
      "rooms.everything\n",
      "non-gamble\n",
      "nextdoo\n",
      "linq/high\n",
      "superzoo18\n",
      "guest-room\n",
      "influ\n",
      "unpretentio\n",
      "westho\n",
      "apartment/hotel\n",
      "nightlifegord\n",
      "v-ball\n",
      "amenities.lots\n",
      "exquis\n",
      "tea/coff\n",
      "iüíñradio\n",
      "‚ù§Ô∏èof\n",
      "enjoi\n",
      "semi-con\n",
      "night/four\n",
      "mccaren\n",
      "ahhmaazing\n",
      "triciak\n",
      "compted\n",
      "macstay\n",
      "approachab\n",
      "expertisse\n",
      "carrige\n",
      "bars/resta\n",
      "/kept\n",
      "inva\n",
      "timeshare/\n",
      "enmough\n",
      "pitbu\n",
      "mmy\n",
      "downdown\n",
      "ntire\n",
      "pick-\n",
      "notif\n",
      "availab\n",
      "desappointment\n",
      "center/casino\n",
      "galliv\n",
      "atmsphre\n",
      "lakevi\n",
      "dalog\n",
      "refreashing\n",
      "birchalls\n",
      "modern-themed\n",
      "desk/recommendations\n",
      ".worst\n",
      "..fantastic\n",
      "leather/mirrored\n",
      "refgirator\n",
      "accommodation.it\n",
      "..to\n",
      "centally\n",
      "pleasent\n",
      "goodvalue\n",
      "apartment/ho\n",
      "üåüüèÜ\n",
      "h.ll\n",
      "locals-only\n",
      "elsewhe\n",
      "‚äï\n",
      "/casino\n",
      "admisphere\n",
      "excalibour\n",
      "chicago/downtown\n",
      "location.no\n",
      "56-years\n",
      "celebrationreception\n",
      "accountabil\n",
      "rooms.gorgeous\n",
      "bombthe\n",
      "gorgegous\n",
      "specail\n",
      "families-\n",
      "disappointed/\n",
      "well-kn\n",
      "honeymoo\n",
      "Ô∏èawesome\n",
      "lonnette\n",
      "tbh\n",
      "the19\n",
      "ofcentral\n",
      "heare\n",
      "mega-hotels\n",
      "uncare\n",
      "pre-stocked\n",
      "weeknig\n",
      "ahhhhhh\n",
      "strip.i\n",
      "cigarrete\n",
      "heatin\n",
      "holiday‚úàÔ∏èüá∫üá∏\n",
      "best-\n",
      "disrup\n",
      "exis\n",
      "g-force78\n",
      "good/clean\n",
      "serce/faci\n",
      "stuff/renovation\n",
      "deoc\n",
      "issue/incon\n",
      "upgrading-we\n",
      "repe\n",
      "jahadia\n",
      "¬£DG,DGDGDG\n",
      "sadde\n",
      "price.the\n",
      "comeing\n",
      "rokm\n",
      "fam.fun\n",
      "peninsul\n",
      "staff..man\n",
      "pallazzo\n",
      "unpar\n",
      "value-add\n",
      "hobson-frohock\n",
      "/hotel\n",
      "in.keys\n",
      "cell-like\n",
      ".bad\n",
      "vistor\n",
      "aug.17-21\n",
      "attitudes.tired\n",
      "stubbings/bryan\n",
      "design-oriented\n",
      "a++cleanline\n",
      "on/near\n",
      "off-stri\n",
      "renovatipn\n",
      "thegami\n",
      "needi\n",
      "average/ok\n",
      "questiona\n",
      "days.great\n",
      "dominc\n",
      "promisin\n",
      "spendies\n",
      "opulance\n",
      "service/immaculate\n",
      "ecxellent\n",
      "chicago-o'hare\n",
      "coupleofnights\n",
      "flamingo=terrible\n",
      "perfect.everything\n",
      "fairchi\n",
      "*warning*\n",
      "overproced\n",
      "over-nighter\n",
      "consistentcy\n",
      "twnty\n",
      "service-okay\n",
      "codegreen\n",
      "outdated..\n",
      "slic\n",
      "experienceonly\n",
      "giraff\n",
      "cleanline\n",
      "overwhleming\n",
      "surpri\n",
      "attendez\n",
      "convinient\n",
      "everyroom\n",
      "rivernorth\n",
      "price/trip\n",
      "atvetised\n",
      "inroo\n",
      "conference-goers\n",
      "firend\n",
      "quadru\n",
      "hotel/\n",
      "octavi\n",
      "wooohoohohohho\n",
      "family..its\n",
      "grandvac\n",
      "menbe\n",
      "weent\n",
      "ummmm\n",
      "ritzs\n",
      "aria.com\n",
      "game/\n",
      "üë∞\n",
      "swiisotel\n",
      "/closet/coffin/cag\n",
      "likabl\n",
      "monorail/decent\n",
      "hipster-ific\n",
      "rooom\n",
      "mohammed/dolly\n",
      "anniversary/50th\n",
      "cateri\n",
      "imho\n",
      "niceüòÄ\n",
      "ollllllllldddddd\n",
      "tremendou\n",
      "edvardo\n",
      "stagf\n",
      "üò°üëéüëéüëéüëé\n",
      "agaon\n",
      "immediately****\n",
      "forewver\n",
      "februari\n",
      "downstown\n",
      "resortist\n",
      "advantages:1\n",
      "notimpressed\n",
      "updown\n",
      "tranformation\n",
      "DG.DGDGDG.DGDGDG\n",
      "expernce\n",
      "at.per\n",
      "breakfast/me\n",
      "palozzo-jan\n",
      "town-\n",
      "vacation/m\n",
      "location-expensive\n",
      "vegs\n",
      "techn\n",
      "staybeautiful\n",
      "'che\n",
      "domestice\n",
      ".fab\n",
      "tripadviso\n",
      "service.co\n",
      "stay.helpful\n",
      "accuracy/staff\n",
      "firstl\n",
      "yaaaay\n",
      "kindeness\n",
      "interier\n",
      "located.we\n",
      "blding\n",
      "üëèüèº\n",
      ".casino\n",
      "pnenomenal\n",
      "cancellati\n",
      "dubcova\n",
      "stopov\n",
      "chicaglo\n",
      "aggressi\n",
      "deal.loc\n",
      "enterance\n",
      "treasure..\n",
      "hige\n",
      "trut\n",
      "midtown-a\n",
      "auddri\n",
      "for-\n",
      "amazing‚Äî\n",
      "bigrickyny\n",
      "utm√§rkt\n",
      "hotel-serene\n",
      "hotelfriendly\n",
      "responsiven\n",
      "appea\n",
      ".walki\n",
      "anniversary\\nour\n",
      "great.furnishing\n",
      "frequentl\n",
      "paridise..\n",
      "pleasantl\n",
      "strip+no\n",
      "underpleased\n",
      "cosmopitan\n",
      "boilerpl\n",
      "completly\n",
      "service/bad\n",
      "poisioning\n",
      ".our\n",
      "overwh\n",
      "valetines\n",
      "bahston\n",
      "veey\n",
      "restau\n",
      "expirienceclean\n",
      "goodits\n",
      "custover\n",
      "hyatt-regency\n",
      ".other\n",
      "vegas..better\n",
      "prooperty\n",
      "normaly\n",
      "staff/unique\n",
      "cesers\n",
      "¬°a\n",
      "charm-filled\n",
      "possitive\n",
      "2018i\n",
      "nicegood\n",
      "truns\n",
      "place..great\n",
      "attendin\n",
      "break-winter\n",
      "option.easy\n",
      "rewards=total\n",
      "uugghh\n",
      "ganseb\n",
      "bouj\n",
      "somepla\n",
      "ill-maintained\n",
      "tornament\n",
      "varleny\n",
      "immaculat\n",
      "imaginabl\n",
      "ungrand\n",
      "rcommended\n",
      "DG/DG-DG/DGDG/DGDG\n",
      "tthis\n",
      "hotel..smack\n",
      "windowbox\n",
      "m.k\n",
      "supercentral\n",
      "porr\n",
      "fritz-hotel\n",
      "vegas‚Äî\n",
      "trump-\n",
      "primest\n",
      "trip~not\n",
      "business-y\n",
      "positive/fun/enjoyable\n",
      "service-fantastic\n",
      "weejend\n",
      "location/clean/spacious\n",
      "world-cla\n",
      "m/x\n",
      "room.cle\n",
      "location.n\n",
      "hanckock\n",
      "rcsf\n",
      "kenyetta\n",
      "money-true\n",
      "peices\n",
      "handicappe\n",
      "hotel-off\n",
      "usua\n",
      "'newer\n",
      "quiant\n",
      "experen\n",
      "issue..\n",
      "niceÔºå\n",
      "pfrice\n",
      "logation\n",
      "whingers\n",
      "birdthday\n",
      "DGDG.DGDG/DGDG.DGDG\n",
      "atparis\n",
      "convenetion\n",
      "5'oclock\n",
      "reveiwing\n",
      "thursday-friday\n",
      "vegas..excellent\n",
      "handi-capper\n",
      "magsny\n",
      "andd\n",
      "jalvar\n",
      "unbelievabl\n",
      "eurpoe\n",
      "‚Ä¢i\n",
      "starwood/spg\n",
      "differnt\n",
      "difinetly\n",
      "halpful\n",
      "broa\n",
      "expectations/internet\n",
      "cartelli\n",
      "fidgeon\n",
      "w-o-n-d-e-r-f-u-l\n",
      "naughti\n",
      "disorganized..\n",
      "kingmurphy\n",
      "mad.sq\n",
      "beyond-martin\n",
      "tooooo\n",
      "/excellent\n",
      "flamingooooooo\n",
      "one..\n",
      "bathroom.2\n",
      "'ci\n",
      "housew\n",
      "consis\n",
      "value..nice\n",
      "disapoints\n",
      "gondala\n",
      "schr√§ger\n",
      "terible\n",
      "inn-avenue\n",
      "thebellagio\n",
      "looki\n",
      "rookm\n",
      "isnot\n",
      "unfriendli\n",
      "180/night\n",
      "syna\n",
      "downtown/river\n",
      "days/5\n",
      "coffee/water\n",
      "dump-no\n",
      "jummy\n",
      "üëçüòä\n",
      "hotel-however\n",
      "bedroons\n",
      "superclean\n",
      "centrically\n",
      "weekend‚ÄºÔ∏è\n",
      "amosphere\n",
      "begas\n",
      "3.5star\n",
      "perfeito\n",
      "*room\n",
      "amazing.people\n",
      "2-nig\n",
      "wellingnton\n",
      "'deluxe\n",
      "/stag\n",
      "birthday/mother\n",
      "pleasu\n",
      "la.to\n",
      "DGDG/DGDG-DGDG/DGDG/DGDG\n",
      "boutiqe\n",
      "policy-\n",
      "chelsea/penn\n",
      "-loved\n",
      "westg\n",
      "hotels.comrequ\n",
      "..be\n",
      "fantastic-locat\n",
      "justvdoe\n",
      "forgott\n",
      "fivei\n",
      "managemet\n",
      "luxorwas\n",
      "location..needs\n",
      "choce\n",
      "redecor\n",
      "refur\n",
      "hotel1-\n",
      "loooooong\n",
      "hton\n",
      "chicagohqtrip\n",
      "packages-\n",
      "nlice\n",
      "accomodating/hel\n",
      "professionalis\n",
      "mother/daughters\n",
      "sept_2015\n",
      "greated\n",
      "comparis\n",
      "excali-broken\n",
      "restaurant-\n",
      "notthing\n",
      "ventstoo\n",
      "studiosmallshadrest\n",
      "preferre\n",
      "unpleasan\n",
      "accomod\n",
      "sq.mt\n",
      "DG.DG-\n",
      "young/fresh\n",
      "DG‚ÄìDG\n",
      "solom\n",
      "gound\n",
      "mid-mahnattan\n",
      "hrand\n",
      "jws\n",
      "neighborhood/safe\n",
      "experience-\n",
      "reputat\n",
      "veonica\n",
      "getaway/date\n",
      "price/qual\n",
      "ratings-comfort\n",
      "comfy/good\n",
      "extremelely\n",
      "honeymoon/\n",
      "location.larger\n",
      "recog\n",
      "couteous\n",
      "reallly\n",
      "cormfortable\n",
      "no-fr\n",
      "booo\n",
      "celerations\n",
      "palae\n",
      "waldorf-worthit\n",
      "strip.b\n",
      "mainta\n",
      "uncofortable\n",
      "relaxation/celebration\n",
      "littrle\n",
      "accustome\n",
      "service.excellent\n",
      "arrival-no\n",
      "verti\n",
      ".dela-yes\n",
      "flam-azing\n",
      "town/bowery\n",
      "awesome..me\n",
      "gerod\n",
      "lcatuon\n",
      "annnivery\n",
      "november2016\n",
      "restaruants\n",
      "villians\n",
      "fornt\n",
      "vraiment\n",
      "twiceif\n",
      "july18-21\n",
      "place.sta\n",
      "terat\n",
      "DGDG/DGDG-DGDG-DGDG\n",
      "*awesome\n",
      "pro-a\n",
      "gastby\n",
      "theater-central\n",
      "podmom\n",
      "grandmother/grand\n",
      "ocamp\n",
      "demorizi\n",
      "theadventuredrome\n",
      "nyc.great\n",
      "..room\n",
      "cooperativ\n",
      "üòî\n",
      "wongama\n",
      "weekend.\n",
      "misslong\n",
      "upper-east\n",
      "suites/apartments\n",
      "grocery.treasure\n",
      "'sales\n",
      ".truly\n",
      "aware..\n",
      "queeen\n",
      "knickerboc\n",
      "ny-size\n",
      "service/fraudulent\n",
      "buzio\n",
      "clubin\n",
      "freem\n",
      "rexlaxing\n",
      "hundr\n",
      "..at\n",
      "progra\n",
      "bdny\n",
      "square/th\n",
      "unsave\n",
      "placs\n",
      "place.food\n",
      "shahwsome\n",
      ".definitely\n",
      ".cheaper\n",
      "ro9m\n",
      "9pm..\n",
      "4thüá∫üá∏\n",
      "cheak\n",
      "elevato\n",
      "good.helpful\n",
      "bar/pool\n",
      "moaners\n",
      "broadyay\n",
      "stayexcellent\n",
      "service/manager\n",
      "average/good\n",
      "below-aver\n",
      "nagm\n",
      "ckears\n",
      "averahe\n",
      "outstanding..\n",
      "budget-frie\n",
      "stren\n",
      "..for\n",
      "hotelsin\n",
      "one/two\n",
      "friently\n",
      "buffycoat\n",
      "mrw\n",
      "1a.m\n",
      "DGDG/DG/DGDGDGDG\n",
      "le-vel\n",
      "shoping\n",
      "shiney.the\n",
      "totoal\n",
      "anoying\n",
      "check-in/key-pick-up\n",
      "hotel‚Ä¶accommoda\n",
      "fresh/modern/business\n",
      "pushi\n",
      "cleanne\n",
      "sanctuar\n",
      "awesoooome\n",
      "hipish\n",
      "mamchine\n",
      "monora\n",
      "service.and\n",
      "imy\n",
      "‚Ä¢comfortable\n",
      "trip-bookvip\n",
      "chocoate\n",
      "penhouse\n",
      "mid-renovation\n",
      "adelai\n",
      "comfart\n",
      "400dlls\n",
      ".almost\n",
      "centerlize\n",
      "rust-ic\n",
      "non-hipst\n",
      "copier/golf\n",
      "g-great\n",
      "ever/best\n",
      "feelling\n",
      "bellecl\n",
      "applie\n",
      "engangment\n",
      "souh\n",
      "bar/re\n",
      "extoriona\n",
      "bsmith\n",
      "fdriendl\n",
      "good~\n",
      "uninhabi\n",
      "elegant-beautiful\n",
      "faaaaaaarrrrrr\n",
      "nathali\n",
      "location-perfect\n",
      "‚ù§Ô∏èüëçüèª\n",
      "tower.no\n",
      "perfectÔºå\n",
      "hotel.lobby\n",
      "hattal\n",
      "anyhing\n",
      "centur\n",
      "amneties\n",
      "spa+salon\n",
      "dated-\n",
      "talki\n",
      "distrist\n",
      "cheapti\n",
      "classe/astonishment\n",
      "..not\n",
      "transpor\n",
      "stay-aria\n",
      "concert-first\n",
      "crazy-long\n",
      "plahyed\n",
      "conference/training\n",
      "incompleted\n",
      "rockerfeller\n",
      "rtorblems\n",
      "approachabl\n",
      "hotel/area\n",
      "e-check-in\n",
      "premis\n",
      "jgreen\n",
      "xina\n",
      "perfet\n",
      "amazing..from\n",
      "upgrade/\n",
      "trip.first\n",
      "lineup-\n",
      "mr.richard\n",
      "staff..tight\n",
      "undoub\n",
      "midis\n",
      "convin\n",
      "ffrom\n",
      "claostrophobic\n",
      "huuuuuuuuuuggggge\n",
      "fitnes\n",
      "polishe\n",
      "5ni\n",
      "excelsio\n",
      "beds/great\n",
      "post-\n",
      "i¬¥ll\n",
      "getatway\n",
      "besst\n",
      "üëçüèºüëçüèºüëçüèºüëçüèº\n",
      "hyatt..\n",
      "desmidt\n",
      "accettabile\n",
      "weddng\n",
      "specifica\n",
      "encounte\n",
      "botheri\n",
      "birthaday\n",
      "friendly-smoke\n",
      "eldib\n",
      "elabo\n",
      "staff/rooms/location\n",
      "elysee-great\n",
      "londonh\n",
      "..both\n",
      "couople\n",
      "smelled/dirty\n",
      "renovatived\n",
      "'frisco\n",
      "..shared\n",
      "dtree\n",
      "norwa\n",
      "high-rent\n",
      "üíéüíé\n",
      "perfectly.si\n",
      ".had\n",
      "riverfont\n",
      "**omg\n",
      "trum\n",
      "doveseyez\n",
      "up/drop\n",
      "a-c-e\n",
      "party'er\n",
      "weekned\n",
      "thishoel\n",
      "bisola\n",
      "'destination\n",
      "eent\n",
      "allpool\n",
      "st-r\n",
      "bafoono\n",
      "llllllllllllllllllllllllllllllllllllllllllllll\n",
      "get..which\n",
      "vanilla-scented\n",
      "enjoyi\n",
      "brudda\n",
      "stay-cation\n",
      "'coolest\n",
      "insufficie\n",
      "busiess\n",
      "moderb\n",
      "shocke\n",
      "chain-smoker\n",
      "familys\n",
      "double-paned\n",
      "c/in\n",
      "amazng\n",
      "thanwhen\n",
      "ecneirepxe\n",
      "terrible/not\n",
      "worrie\n",
      "swisotel\n",
      "especaill\n",
      "coronate\n",
      "not-so-happy-\n",
      "marriott/wyndham\n",
      "breafest\n",
      "gem-great\n",
      "eventi.iwa\n",
      "lovily\n",
      "hotel-pay\n",
      "sighseein\n",
      "fluf\n",
      "Â¶ÇÊûú\n",
      "nice/technologically\n",
      "inconvien\n",
      "appointmen\n",
      "254/night\n",
      "negat\n",
      "overh\n",
      "return.biggest\n",
      "pina-check-\n",
      "location.s\n",
      "huge~\n",
      "fantastichotel\n",
      "christine/c\n",
      "'charming\n",
      "thaank\n",
      "hotel\\nin\n",
      "adriann\n",
      "travled\n",
      "kimpron\n",
      "procrs\n",
      "acogedor\n",
      "chowdh\n",
      "located.check\n",
      "underwhelemed\n",
      "2011.t\n",
      "subperb\n",
      "almost‚Ä¶‚Ä¶\n",
      "marritt\n",
      "contad\n",
      "diape\n",
      "hotel.if\n",
      "great.the\n",
      "option..\n",
      "one-nigtht\n",
      "niceplace\n",
      "starte\n",
      "well-si\n",
      "palmomar\n",
      "in..we\n",
      "non-renovat\n",
      "stay-sky\n",
      "locationüëå\n",
      "small‚Äîbut\n",
      "coisas\n",
      "loctio\n",
      "fantastic-the\n",
      "smelly..\n",
      "-hot\n",
      "soho-good\n",
      "central/un\n",
      "promissed\n",
      "slghtly\n",
      "review\\nwit\n",
      "flamingo/fop\n",
      "retro-yet-modern\n",
      "knowledgeabl\n",
      "recomanded\n",
      "emaculen\n",
      "bensinn\n",
      "'trumps\n",
      "hotel..felt\n",
      "masquer\n",
      "excitetment\n",
      "plasent\n",
      "hotel/c\n",
      "drream\n",
      "assesor\n",
      "dana-thankyou\n",
      "canyon..nice\n",
      "jackhammering\n",
      "perecr\n",
      "vacation/honeymoon\n",
      "ikr\n",
      "hotel~\n",
      "uncomfort\n",
      "whil3\n",
      "definatly\n",
      "nanet\n",
      "bother‚Ä¶\n",
      "reataurant\n",
      "increasabl\n",
      "awesome.for\n",
      "^_\n",
      "momement\n",
      "wallp\n",
      "old-vs-new\n",
      "week..what\n",
      "great.pros\n",
      "wote\n",
      "guest-friendly\n",
      "propably\n",
      "cncierg\n",
      "place-some\n",
      "joddy\n",
      "andrew/\n",
      "objectiv\n",
      "hotel-great\n",
      "design/\n",
      "chowduny\n",
      "reaked\n",
      "girfriend\n",
      "separa\n",
      "jady\n",
      "strutture\n",
      "location.easy\n",
      "-comfy\n",
      "unnec\n",
      "telev\n",
      "implies..\n",
      "mchotel\n",
      "manhattanl\n",
      "caessar\n",
      "placy\n",
      "peiced\n",
      "itsuperfriendly\n",
      "riped\n",
      "plsce\n",
      "..total\n",
      "legionaires\n",
      "tolera\n",
      "enjoyable.good\n",
      "sttay\n",
      "DGDGDGDG-DGDG-DGDG\n",
      "no..\n",
      "28t\n",
      "room.2\n",
      "prostitu\n",
      "üôèüèΩ\n",
      "fracisco\n",
      ".ay\n",
      "aaahhhhh\n",
      "amaizig\n",
      "timewarp\n",
      "becaus\n",
      "hawtho\n",
      "spacious-\n",
      "suncoas\n",
      "'now\n",
      "elecci√≥n\n",
      "moly..great\n",
      "veagas\n",
      "avg/good\n",
      "downtwon\n",
      "fliiping\n",
      "somem\n",
      "amizing\n",
      "spacious/studio\n",
      "1230pm\n",
      "disrespecte\n",
      "renovation-worst\n",
      "above-a\n",
      "less-than-perfect\n",
      "effortl\n",
      "5-star-rated\n",
      "quintia\n",
      "awesome/room\n",
      "metropoli\n",
      "review-\n",
      "prestine\n",
      "lexor\n",
      "barklay\n",
      "2018..checking\n",
      "wifinice\n",
      "-avoid\n",
      "great-nieces\n",
      "attitud\n",
      "30/day\n",
      "betweet\n",
      "vwrybstrategic\n",
      "'busy\n",
      "üëåüèªüôåüèºüòùüéâ\n",
      "hollyw\n",
      "extream\n",
      "kapanadze\n",
      "hotc\n",
      "'rough\n",
      "weekendcation\n",
      "-see\n",
      "apple-\n",
      "room.area\n",
      "large/\n",
      "nights/5\n",
      ".does\n",
      "mondern\n",
      "pallazawow\n",
      "landm\n",
      "'comforting\n",
      "confrences\n",
      "stephanie-\n",
      "anime.con\n",
      "whoahs\n",
      "stayvin\n",
      "holuday\n",
      "heret\n",
      "monarc\n",
      "impresses..\n",
      "meatp\n",
      "dimensio\n",
      "fisherman¬¥s\n",
      "mvci\n",
      "review**a\n",
      ".some\n",
      "nyc-ridgefield-boston\n",
      "mgm-\n",
      "4-nig\n",
      "amenities-this\n",
      "stay..r\n",
      "+\\-\n",
      "belagio\n",
      "laskaros\n",
      "conveinient\n",
      "accuratel\n",
      "location-noisy\n",
      "location/attractive\n",
      "claustraphobic\n",
      "execu\n",
      "night.buffet\n",
      "up-to-dat\n",
      "incredible-i\n",
      "5-days\n",
      "for.i\n",
      "djspoon\n",
      "7000/night\n",
      "5mt\n",
      "chownhuny\n",
      "andrews-menifeeiii\n",
      "*************beware\n",
      "anniverssary\n",
      "jmj\n",
      "venetian/p\n",
      "fashined\n",
      "lobby/dirty\n",
      "fantastik\n",
      "lexu\n",
      "theme/mission\n",
      "coffeema\n",
      "roomfriendly\n",
      "*if*\n",
      "ÂÄ§ÊÆµ„ÇíËÄÉ„Åà„Çã„Å®\n",
      "bedroo\n",
      "astoundin\n",
      "nashv\n",
      "silveton\n",
      "managem\n",
      "i|o\n",
      "flaingo\n",
      "large/chain\n",
      "charmming\n",
      "quies\n",
      "experience.very\n",
      "wasvgreat\n",
      "multip\n",
      "earthecho\n",
      "surpriseüíï\n",
      "in/c\n",
      "stay‚Ä¶impeccable\n",
      "friendly-helpful\n",
      "amazing‚ù§\n",
      "locationrooms\n",
      "rude/unpleasent\n",
      "att3nding\n",
      "hotel-hail\n",
      "sunbe\n",
      "under-designed\n",
      "hotel-ca\n",
      "nights.-\n",
      "5tg\n",
      "buissnessand\n",
      "..comfortable\n",
      "turrible\n",
      "thankgiving\n",
      "periodi\n",
      "edmontonians\n",
      "day/m\n",
      "atmopshere\n",
      "steakh\n",
      "disappo\n",
      "winterholiday\n",
      "repfest\n",
      "minimu\n",
      "service/extremely\n",
      "service.good\n",
      "scuz\n",
      "home.from\n",
      "fabtech\n",
      "miam\n",
      "rundown-looking\n",
      "fifty.\n",
      "honeym\n",
      "chioces\n",
      "werkin\n",
      "besthotel\n",
      "requests-\n",
      "estuve\n",
      "tiny-tiny\n",
      "kewl\n",
      "wyyn\n",
      "fine.bed\n",
      "rooms‚Äîand\n",
      "6ft7\n",
      "crsvr\n",
      "bang..double\n",
      "'lively\n",
      "gravit\n",
      "belliago\n",
      "depar\n",
      "lifeitme\n",
      "bor2run\n",
      "restuarants\n",
      "review-fantastic\n",
      "vegsas\n",
      "lunc\n",
      "barstaff\n",
      "super-frien\n",
      "saturda\n",
      "DG/DG/\n",
      "nightli\n",
      "work.had\n",
      "very-very\n",
      "sgain\n",
      "oniy\n",
      "ho0t\n",
      "DGDG/DGDG/DGDG\n",
      "cammerron\n",
      "16th-\n",
      "equipmen\n",
      "vevas\n",
      "non-touristy\n",
      "m-\n",
      "member-business\n",
      "averaage\n",
      "mannha\n",
      "bothere\n",
      "üëåüëçüëå\n",
      "ole_gordo\n",
      "hotelpros\n",
      "skysuite\n",
      "s'ok\n",
      "w/our\n",
      "love‚ù§Ô∏è\n",
      "scene..\n",
      "agian\n",
      "located..subways\n",
      "compariso\n",
      "lued\n",
      "oursel\n",
      "terrazo\n",
      "view/noisy\n",
      "DGDG/DGDG/DGDG-DGDG/DGDG/DGDG\n",
      "family-o\n",
      "break-eve\n",
      "travle\n",
      "youza\n",
      "yasel\n",
      "doterra\n",
      "fitzp\n",
      "'off-strip\n",
      "winfpdow\n",
      "location„ÄÇbut\n",
      "road.the\n",
      "greathotel\n",
      "localizatio\n",
      "fairf\n",
      "'club\n",
      "internet/phone\n",
      "dinella\n",
      "fine-apple\n",
      "bewares\n",
      "relationsh\n",
      "view/nice\n",
      "stay..we\n",
      "ytip\n",
      "possile\n",
      "chrismax\n",
      "standar\n",
      "was/am\n",
      "spacio\n",
      "hotel..room\n",
      "visitors-\n",
      "necessar\n",
      "ddle\n",
      ".hitel\n",
      "travelo\n",
      "w\\e\n",
      "tripl\n",
      "arrivin\n",
      "berjaoui\n",
      "in-pleas\n",
      "befone\n",
      "DGDG.\n",
      "no-fuss\n",
      "staycatio\n",
      "exspirenece\n",
      "overching\n",
      "a.room\n",
      "ething\n",
      "actractive\n",
      "..disappointed\n",
      "restauraunt\n",
      "1be\n",
      "persp\n",
      "revies\n",
      "supert\n",
      "welcomin\n",
      "pre-holid\n",
      "mehga\n",
      "linq-great\n",
      "me-cation\n",
      "thought-thru\n",
      "28hours\n",
      "staff/poor\n",
      "lollapaloserour\n",
      "megal\n",
      "disappointed-stay\n",
      "fitzpatr\n",
      "nice\\nplace\n",
      "hawaii-like\n",
      "hotel/suite\n",
      "slow..\n",
      "suckie\n",
      "flamingoceline\n",
      "mainstree\n",
      "place..had\n",
      "raffae\n",
      "-ve\n",
      "ÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩ\n",
      "apart-hotel\n",
      "sale..\n",
      "1518a\n",
      "general..\n",
      "disapppinted\n",
      "DG/DGDG\n",
      "pros-after\n",
      "location-location\n",
      "cinvenient\n",
      "atmosphere/room\n",
      "cleann\n",
      "boondo\n",
      "sistas\n",
      "aiuto\n",
      "februa\n",
      "everytime..everytime\n",
      "besty\n",
      "v.good\n",
      "datenice\n",
      "uodating\n",
      "smelle\n",
      "hotelfirst\n",
      "blueg\n",
      "efficiency-type\n",
      "sevice.clean\n",
      "indiscutabl\n",
      "positives-\n",
      "christmas-\n",
      "holleywood\n",
      "drainag\n",
      "goldenist\n",
      "aneritania\n",
      "stay\n",
      "water-slide\n",
      "neighbou\n",
      ".shhh\n",
      "2rio\n",
      "babymomma\n",
      "pricey..\n",
      "/will\n",
      "centrla\n",
      "faithfu\n",
      "clean.\n",
      "film\\nat\n",
      "adorable/exceeded\n",
      "yesterd\n",
      "two..\n",
      "tea/c\n",
      "casino-themed\n",
      "credit/refund\n",
      "yesis\n",
      "knees-to-the-wall\n",
      "couldn't/have\n",
      "servicem\n",
      "npsa\n",
      "okelevators\n",
      "traels\n",
      "theatre-going\n",
      "snuc\n",
      "vanit\n",
      "restric\n",
      "location..walkable\n",
      "time/okay\n",
      "DGDG-DGDG/DGDGDGDG\n",
      "straightforw\n",
      "pros-ce\n",
      "alharbi\n",
      ".you\n",
      "..one\n",
      "period..i\n",
      "septemb\n",
      "housekeeping‚Ä¶very\n",
      "price/hidden\n",
      "fundame\n",
      "expi\n",
      "acurate\n",
      "free-smoking\n",
      "loop/michigan\n",
      "shambles-\n",
      "exactlly\n",
      "fireshow\n",
      "immpressive\n",
      "approxim\n",
      "well-ke\n",
      "‚öÄ\n",
      "acrossed\n",
      "franciscos\n",
      "vegasss\n",
      "seafo\n",
      "salisbery\n",
      "impossibly-spacious\n",
      "bachelor/ba\n",
      "disgusti\n",
      "'assulted\n",
      "overvall\n",
      "square.i\n",
      "beds/pi\n",
      "conference/exhib\n",
      "miricle\n",
      "mallgreat\n",
      "snow..l\n",
      "pos/cons\n",
      "food-\n",
      "one-ni\n",
      "exqu\n",
      "meetingsvery\n",
      "great-and\n",
      "location/reasonable\n",
      "expiere\n",
      "6th-left\n",
      "100meter\n",
      "uggghhh\n",
      "broadca\n",
      "'ki\n",
      "glauer\n",
      "17-19th\n",
      "dilligent\n",
      "qtrs\n",
      "roofto\n",
      "would'v\n",
      "sub-pa\n",
      "swisshotel\n",
      "looke\n",
      "afforfable\n",
      "pac12\n",
      ".nyc\n",
      "exce\n",
      "husdo\n",
      "..maybe\n",
      ".lovely\n",
      "pissah\n",
      "31-feb4\n",
      "years/trip\n",
      "wonderfuln\n",
      "bestg\n",
      "street-poor\n",
      "adinson\n",
      "acce\n",
      "rotat\n",
      "austrailia\n",
      "19-23rd\n",
      "04th\n",
      "services/staff\n",
      "stepha\n",
      "inve\n",
      "..sorry\n",
      "happines\n",
      "+ves\n",
      "nicely..\n",
      "fitpatrick\n",
      "hospitality-\n",
      "clean.can\n",
      "themsel\n",
      "yorkw\n",
      "music/djs\n",
      "innovat\n",
      "harbor-facing\n",
      "first-time-sta\n",
      "srtip\n",
      "roomcentralg\n",
      "smidg\n",
      "DGDGDGDG-DGDGDG\n",
      "coordinat\n",
      "hotel/services\n",
      "setting..\n",
      "thewit-chicago\n",
      "kramerish\n",
      "stratosfear\n",
      "yayyyyy\n",
      ".horrible\n",
      "chape\n",
      "nov.29-dec3/16\n",
      "money/did\n",
      "ago.every\n",
      "¬£DGDG\n",
      "excellentalways\n",
      "modera\n",
      "defenetly\n",
      "staff-room\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swiming\n",
      "compassio\n",
      "DGDG:DGDG.\n",
      "eiffl\n",
      "baymont\n",
      "businbess\n",
      "loavtion\n",
      "suggetions\n",
      "surprised..\n",
      "means-we\n",
      "after..\n",
      "dump.dirty\n",
      "caeasars\n",
      "complemen\n",
      "under-w-helming\n",
      "complaints‚Ä¶\n",
      "good-very\n",
      "'ti\n",
      "cathedr\n",
      "awesome-\n",
      "but..constructi\n",
      "old-feeling\n",
      "connectiv\n",
      "spaaaaaaaahhhhh\n",
      "superb-\n",
      "w/friends\n",
      "milenort\n",
      "samc\n",
      "work/vacation\n",
      "perhap\n",
      "annonomous\n",
      "'chand\n",
      "-some\n",
      "8th-11th\n",
      "neede\n",
      "stay.we\n",
      "‚úîÔ∏èexcel\n",
      "j-l\n",
      "ÏµúÍ≥†ÏùòÏÑúÎπÑÏä§\n",
      "unfun\n",
      "i'be\n",
      "norwegi\n",
      "clean..not\n",
      "again-2016\n",
      "enjoyble\n",
      "view..+\n",
      "good-the\n",
      "empirence\n",
      "marvelou\n",
      "fiherman\n",
      "4-night\n",
      "a/chille\n",
      "choosed\n",
      "e-mai\n",
      "perfection-\n",
      "scammy\n",
      "york.i\n",
      "/bachelor\n",
      "calfan\n",
      "cosmopolitan-vegas\n",
      "gamblers.you\n",
      "place.\n",
      ".talbot\n",
      "thanksigiving\n",
      "ritz-\n",
      "hoteland\n",
      "redelijk\n",
      "whoopeee\n",
      "show-allegro\n",
      "great\\ncookies\n",
      "congeste\n",
      "location-clos\n",
      "5-st\n",
      "excellentr\n",
      "fabby\n",
      "-superb\n",
      "siblin\n",
      "dowtown\n",
      "non-luxury\n",
      "coming..\n",
      "hideen\n",
      "delmonicos\n",
      "desk/jeremiah\n",
      "walsh-perron\n",
      "park/lakeview\n",
      "englan\n",
      "spotlessl\n",
      "mccor\n",
      "ideallocation\n",
      "flamingo=location\n",
      "propale\n",
      "rooms..but\n",
      "costmer\n",
      "luxury+spacious+awesome\n",
      "fab.pool\n",
      "unforgiveablely\n",
      "kocation\n",
      "tayed\n",
      "luxurious/staff\n",
      "prosstaffcl\n",
      "ostentatiousness\n",
      "atomsphere\n",
      "room1\n",
      "acknowl\n",
      "bellm\n",
      "clean/replace\n",
      "üòû\n",
      "bus/train\n",
      "cramped..great\n",
      "linq.w\n",
      "breakfast/bar\n",
      "vacation/work\n",
      "here.staff\n",
      "\\m/\n",
      "perfecy\n",
      "pricey-good\n",
      "presen\n",
      "beautoful\n",
      "foremos\n",
      "decent/average\n",
      "'discount\n",
      "conside\n",
      "floor..\n",
      "greatllocation\n",
      "wynntastic\n",
      "blizzardy\n",
      "disappointed..a\n",
      "ceremo\n",
      "alllll\n",
      "lower-key\n",
      "comfort/service\n",
      "wegas\n",
      "everythi\n",
      "location-pricey\n",
      "youthhostel\n",
      "impossibl\n",
      "'us\n",
      "transameri\n",
      "location/room\n",
      "staff.nice\n",
      "diva-rific\n",
      "stric\n",
      "again-\n",
      "martnique\n",
      "location-fantastic\n",
      "..super\n",
      "japanese-90ies-vibe\n",
      "'they\n",
      "~impressive\n",
      "greaves-howard\n",
      "lay-over\n",
      "greatroom\n",
      "'90ties\n",
      "5i\n",
      "DG‚≠ê\n",
      "parki\n",
      "sosupersam\n",
      "+happy\n",
      "beautifulit\n",
      "hip2besquare\n",
      "'bucket\n",
      "fsbr29\n",
      "great.they\n",
      "belleclare\n",
      "outdated.hallways\n",
      "staffver\n",
      "hotelcleanaccommodating\n",
      "jackelyn\n",
      "Â•¢ËèØÁöÑÈÖíÂ∫óÔºåË¶™ÂàáÁöÑÊúçÂãô\n",
      "chicagov\n",
      "well-appoin\n",
      "roubado\n",
      "ofcthe\n",
      "prestig\n",
      "ineffitient\n",
      "definintely\n",
      "pleope\n",
      "whenvwe\n",
      "chelsea/flatiron\n",
      "departm\n",
      "nice.upon\n",
      "boutique/sexy\n",
      "roomand\n",
      "lost/stolen\n",
      "wency\n",
      "..stayed\n",
      "aftually\n",
      "bed/bedding\n",
      "dista\n",
      "pariis\n",
      "bar/roof\n",
      "trip.room\n",
      "bugers\n",
      "place..oups\n",
      "vaforite\n",
      "ago..\n",
      "-okay\n",
      "stag/staggette\n",
      "453-superior\n",
      "suite-nicest\n",
      "bad..events\n",
      "50yr\n",
      "infraestructure\n",
      "wowwwww\n",
      "thoroug\n",
      "drills/maint\n",
      "summervacation2016\n",
      "diamond-friendly\n",
      "fasst\n",
      "beat.tiny\n",
      "squa\n",
      "bel-hop\n",
      "shayena\n",
      "endly\n",
      "physicall\n",
      "stay.room\n",
      "bed-conviently\n",
      "-unprofessional\n",
      "luxurous\n",
      "anniversary/vacation\n",
      "fastroom\n",
      "-soho\n",
      "shortcomin\n",
      "after-work\n",
      "square/nob\n",
      "tomohawk\n",
      "hotel-all\n",
      "backbar\n",
      "◊ú◊†◊ô\n",
      "issues..be\n",
      "recommend-beautiful\n",
      "king-bed\n",
      "sepgetaway\n",
      "sriffe\n",
      "tonght\n",
      "paris-las\n",
      "nannying\n",
      "manbun\n",
      "nights.very\n",
      "licalisation\n",
      "friendline\n",
      "welcomeing\n",
      "hotel-perfect\n",
      "unquestionabl\n",
      "cnvenience\n",
      "ada-friendly\n",
      "donice\n",
      "speci\n",
      "grand-mother\n",
      "gettaa\n",
      "advance.a\n",
      "stay**loved\n",
      "rview\n",
      "celebratio\n",
      "21fist\n",
      "bonanzo\n",
      "good/breakfast\n",
      "credit/comp\n",
      "express-jus\n",
      "greatsisteradventure\n",
      "thishotel\n",
      "DGDGDGDG\n",
      "painfu\n",
      "nightsgreat\n",
      "accom\n",
      "w-tastic\n",
      "7th-11th4\n",
      "staybr\n",
      "loop/downtown\n",
      "disapponting\n",
      "twin-\n",
      "localiza\n",
      "hampton-soho\n",
      "local-ish\n",
      "defitnetly\n",
      "resort-close\n",
      "tessi\n",
      "√©clat\n",
      "awfull\n",
      "awkwar\n",
      "exxxxxcelent\n",
      "servicable\n",
      "luxor=\n",
      "sean-\n",
      "experoences\n",
      "surprisng\n",
      "faverty\n",
      "sugery\n",
      "hotel.its\n",
      "japaneese\n",
      "paharu\n",
      ".clean\n",
      "no-limits\n",
      "top-located\n",
      "vegetari\n",
      "fanata\n",
      "amaaaazing\n",
      "be~\n",
      "virkelig\n",
      "stayüéÑ\n",
      "amazingg\n",
      "18yrs\n",
      "creved\n",
      "treatme\n",
      "w/frien\n",
      "remodelat\n",
      "strip.\n",
      "dec25-dec31st\n",
      ".anywhere\n",
      "linq-las\n",
      "birthdays/halloween\n",
      "banjamin\n",
      "ny.good\n",
      "int'l\n",
      "friendas\n",
      "macines\n",
      "ny-city\n",
      "rooft\n",
      "breathren\n",
      "acid-trip\n",
      "non-club\n",
      "..we\n",
      "bidd\n",
      "casinoking\n",
      "location-exce\n",
      "girlfrien\n",
      "pool/hotel/casino/shops\n",
      "price-point\n",
      "ling-\n",
      "malfunct\n",
      "concierge/b\n",
      "place..it\n",
      "chƒôc\n",
      "foodno\n",
      "time.use\n",
      "meh..not\n",
      "way-\n",
      "personalsing\n",
      "supernov\n",
      "concert/plays\n",
      "on/\n",
      "locatiom\n",
      "remembe\n",
      ".wonderf\n",
      "mocation\n",
      "suite-loft\n",
      "ever.feel\n",
      "ÊàëÂÄë3ÊúàÂàùÂÖ•‰Ωè1ÊôöÔºåÈÄèÈÅéexpediaË®ÇÊàøÔºå‰∏çÂ§™Ë®òÂæóÊòØ‰ªÄÈ∫ºÊàøÂûã„ÄÇÊ´ÉÊ™ØÂêå\n",
      "nouvea\n",
      "duaghter\n",
      "nights.staff\n",
      "stay/upper\n",
      "environmen\n",
      "exceedingl\n",
      "mrs.allison\n",
      "britishspice\n",
      "rewarde\n",
      "phny\n",
      "contempoarary\n",
      "wonderfu\n",
      "staine\n",
      "performe\n",
      "mcle\n",
      "wife/2\n",
      ".las\n",
      "ahhhhhhhhhhhh\n",
      "bugs-2017\n",
      "premenant\n",
      "uber-vibrant\n",
      "strip-view\n",
      "arrangi\n",
      "1920/30s\n",
      "peasy\n",
      "money/unique\n",
      "fan-i\n",
      "possibiy\n",
      "gimmic\n",
      "floor/card\n",
      "points*\n",
      "one-be\n",
      "expected.very\n",
      "cartlton\n",
      "propertty\n",
      "busynes\n",
      "ever¬°¬°\n",
      "big.servi\n",
      "thewebergrill\n",
      "not-so-much\n",
      "greenw\n",
      "this.all\n",
      ".intercont\n",
      "vintage-way\n",
      "break.the\n",
      "ÔΩóÔΩÅÔΩì\n",
      ".four\n",
      "expei\n",
      "de-stress\n",
      ".lots\n",
      "simerl\n",
      "three-st\n",
      "prese\n",
      "perfect.\n",
      "work-relate\n",
      ".smaller\n",
      "cancoon\n",
      "-service\n",
      "rodrieguiz\n",
      "geta2way\n",
      "time.voo\n",
      "servicecould\n",
      "ny.the\n",
      "soyaya\n",
      "necess\n",
      "from-choos\n",
      "dedicati\n",
      "intsa-worthy\n",
      "branding-\n",
      "c's-\n",
      "excitement-disappointment\n",
      "confirme\n",
      "chicago==per\n",
      "veags\n",
      "discovere\n",
      "doentown\n",
      "a.beautiful\n",
      "surgi-center\n",
      "stay‚Äì\n",
      "convention-\n",
      "place.friendly\n",
      "explai\n",
      "üéà\n",
      "landice\n",
      "vwry\n",
      "ceremon\n",
      "quinner\n",
      "belleclaire..a\n",
      "getgo\n",
      "luxor..service\n",
      "2rooms\n",
      "smell..felt\n",
      "delanoooooo\n",
      "whar\n",
      "bridg\n",
      "fab-u-lous\n",
      "wallpape\n",
      "bosto\n",
      "hotel.co\n",
      "exceedin\n",
      "marrioo\n",
      "expe\n",
      "-hotel\n",
      "vegas/new\n",
      ".quite\n",
      "nght\n",
      "customet\n",
      "DGDG/DGDG-DGDG\n",
      "winterdal\n",
      "gmbling\n",
      "lobbie\n",
      "ubered\n",
      "louissaint\n",
      "ashle\n",
      "may/2018\n",
      "mllenium\n",
      "amost\n",
      "millienials\n",
      "doorstaff\n",
      "15minute\n",
      "shhhhhh\n",
      "motorcyc\n",
      "conead\n",
      "11:30am\n",
      "helpful.room\n",
      "chyr\n",
      "devrait\n",
      "roomsx\n",
      "englischin\n",
      "you'l\n",
      "cityrooms\n",
      "doormen\\\n",
      "thanksgivng\n",
      "presurgery\n",
      "suite/apartment\n",
      "unknowled\n",
      "ok‚Ä¶..\n",
      "suface\n",
      "location/va\n",
      "listenin\n",
      "chic.hgu\n",
      "pfizenma\n",
      "anyoneo\n",
      "jovelin\n",
      "cout\n",
      "~location\n",
      "unusa\n",
      "strastosphere\n",
      "grandchildr\n",
      "v/p\n",
      "afforadble\n",
      "pre-checkin\n",
      "disapointment\n",
      "luxor717\n",
      "2*we\n",
      "bleurgh\n",
      "-venetian\n",
      "horrible.un\n",
      "urgen\n",
      "unaut\n",
      "tea/coffee\n",
      "refreshement\n",
      "glory‚Ä¶\n",
      "bellisima\n",
      "hooteriffic\n",
      "ccc-aoe\n",
      "2611spotlessly\n",
      "mejorable\n",
      "orchest\n",
      "expansiv\n",
      "walkab\n",
      "'resort\n",
      "manhattan-soho\n",
      ".slow\n",
      "allerg\n",
      "casinohotels\n",
      "massage/rude\n",
      "true..\n",
      "-great\n",
      "dril\n",
      "rio.emp\n",
      "said-\n",
      "belve\n",
      "dgnewyork\n",
      "ameritiana\n",
      "professionali\n",
      "susssssh\n",
      "cathy/\n",
      "chicaho\n",
      "ezperience\n",
      "fade..\n",
      "combinatio\n",
      "kimpton/monaco\n",
      "courtnie\n",
      "paul.the\n",
      "experienceinn\n",
      "inepensive\n",
      "incompa\n",
      "streetervi\n",
      "'this\n",
      "trip-we\n",
      "filmin\n",
      "vanieta\n",
      "mildew-front\n",
      "locationl\n",
      "couple/\n",
      "hotel‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è\n",
      "friends/colleagues\n",
      "noosy\n",
      "staffgr\n",
      "bph-\n",
      "rating/\n",
      "historicsl\n",
      "mega-chain\n",
      "howev\n",
      "-non-\n",
      "dollared\n",
      "stars.nicest\n",
      "reat\n",
      ".elevato\n",
      "acurrat\n",
      "billiionaires\n",
      "strip.downside\n",
      "d-lightful\n",
      "incy\n",
      "stay.perf\n",
      "receptionst\n",
      "fiid\n",
      "w.57th\n",
      "starying\n",
      "superbe\n",
      "visit-extremely\n",
      "pleasure-\n",
      "non-fussy\n",
      "exceptiona\n",
      "loveit\n",
      "vice-vers\n",
      "yorkean\n",
      "trewards\n",
      "centr\n",
      "erzatz\n",
      "jovanny\n",
      "patio/rest\n",
      "speechless..\n",
      "bombogenesis\n",
      "amoun\n",
      "recommamded\n",
      "'waldorf\n",
      "look/style\n",
      "toake\n",
      ".close\n",
      "cicus\n",
      "imminities\n",
      "less-know\n",
      "extended-stay\n",
      "exiperience\n",
      "sevrvice\n",
      "sevent\n",
      "littl\n",
      "efrenel\n",
      "miage\n",
      "tanika/raymond\n",
      "asone\n",
      "casino/slow\n",
      "'high\n",
      "however..\n",
      "wonderful-\n",
      "ambience.it\n",
      "somth\n",
      "chanevan\n",
      "satisfactio\n",
      "properi\n",
      "euru-marcoc\n",
      "hands-reach\n",
      "manhattan-well\n",
      "roomloved\n",
      "herebooked\n",
      "outragious\n",
      "positivesit\n",
      "appointme\n",
      "dissatis\n",
      "overpriced/overrated\n",
      "complaits\n",
      "associat\n",
      "elaia\n",
      "vegas.fi\n",
      "appreciative/great\n",
      "pleasa\n",
      "recommen\n",
      "7th-floor\n",
      "24/night\n",
      "naaah\n",
      "absenc\n",
      "hotel.lincoln\n",
      "did'nt\n",
      "defnitely\n",
      "fitzpat\n",
      "cherpm\n",
      "likens-flowers\n",
      "wiiew\n",
      "building/hotel\n",
      "reservat\n",
      "whotel\n",
      "w/lots\n",
      "woow\n",
      "..th\n",
      "2-3ft\n",
      "mechicals\n",
      "nyph\n",
      "donext\n",
      "baymonte\n",
      "pleasanty\n",
      "wbaras\n",
      "hamptob\n",
      "visisted\n",
      "tea/\n",
      "22o\n",
      "helpful.there\n",
      "rooms-smoke-filled\n",
      "aaazing\n",
      "phenominal\n",
      "memeoril\n",
      "first.the\n",
      "termendous\n",
      "extrodinarly\n",
      "money-security\n",
      "laqunita\n",
      "friendli\n",
      "totsl\n",
      "nice.beaut\n",
      "impecca\n",
      "breakefast\n",
      "whooooooooooo\n",
      "flashest\n",
      "trrip\n",
      "timessq\n",
      "goodffun\n",
      "anothe\n",
      "two-w\n",
      "crossroa\n",
      "wervice\n",
      "..service\n",
      "16-20th\n",
      "cooooool\n",
      "excel-lance\n",
      "well-k\n",
      "hustle-n-bustle\n",
      "aside-\n",
      "skati\n",
      "violatio\n",
      "grood\n",
      "17-23rd\n",
      "location.room\n",
      "priva\n",
      "lounge/dining\n",
      "hotelpri\n",
      "demetrie\n",
      "novotel/accor\n",
      "amendities\n",
      "horriblest\n",
      "price-quality\n",
      "expectedthe\n",
      "w44\n",
      "rafeal\n",
      "cralo\n",
      "downtonw\n",
      "****everything\n",
      "iroquise\n",
      "miserab\n",
      "grand-\n",
      "herea\n",
      "palati\n",
      "non-sm\n",
      "tecuesco42\n",
      "DG-DG-DGDG\n",
      "adjoi\n",
      "like..\n",
      "apology/effort\n",
      "mile‚Ä¶\n",
      "good.i\n",
      "suggestions/\n",
      "encant√≥\n",
      "chicago/magnificant\n",
      "belligio\n",
      "courtyar\n",
      "updayed\n",
      "line..\n",
      "wyndam\n",
      "‚ô°\n",
      "nice‚Ä¶\n",
      "bar-focused\n",
      "mondrn\n",
      "-charge\n",
      "fairish\n",
      "yr.old\n",
      "charge..\n",
      "hollywoood\n",
      ".customer\n",
      "„Åä„Çπ„Çπ„É°„ÅÆ„Éõ„ÉÜ„É´ÔºÅ\n",
      "disaponted\n",
      "eccelent\n",
      "auss\n",
      "encou\n",
      "conventiently\n",
      "regardi\n",
      "pre/post\n",
      "promenada\n",
      "hhonor\n",
      "fransciso\n",
      "finesr\n",
      "f*\n",
      "mr.peter\n",
      "reveiw\n",
      "simpl\n",
      "westhous\n",
      "small.heat\n",
      "transportation-challenged\n",
      "tgis\n",
      "flirte\n",
      "malfunctione\n",
      "nicely-ma\n",
      "hotel-location\n",
      "wynn-las\n",
      "gamble-guess\n",
      "hide/exp\n",
      "2x.1\n",
      "readyno\n",
      "'makes\n",
      "denver-\n",
      "saturday.very\n",
      "ubicati\n",
      "zelouf\n",
      "service..good\n",
      "unexpe\n",
      "lanette\n",
      "DGDG/DG-DGDG/DG/DGDG\n",
      "clockhouse\n",
      "funseaker\n",
      "opulant\n",
      "vlaue\n",
      "hahaha\n",
      "caveats..\n",
      "joaq\n",
      "suties\n",
      "ny2017\n",
      "environme\n",
      "conditionin\n",
      "lexingt\n",
      "secre\n",
      "pamperd\n",
      "quwlity\n",
      "appmts\n",
      "ota/nylo\n",
      "cosmopilitan\n",
      "complain..\n",
      "sep2018\n",
      "greaat\n",
      "philharmonica\n",
      "wing-\n",
      "up.pa\n",
      "rooms..lighting\n",
      "taxe\n",
      "mohamned\n",
      "rooms.there\n",
      "probab\n",
      "opportun\n",
      "bosy\n",
      "contemp\n",
      "'wonderful\n",
      "once/tw\n",
      "ambass\n",
      "hollaaa\n",
      "buenisimo\n",
      "non-ga\n",
      "fun/chic\n",
      "atrocio\n",
      "two.nights\n",
      "pillows-\n",
      "may2015\n",
      "tiref\n",
      "stay-away\n",
      "silverton-las\n",
      "-1st\n",
      "hold-em\n",
      "d√©corgreat\n",
      "apartment..\n",
      "loyality\n",
      "bed-sized\n",
      "feie\n",
      "oppulent\n",
      "referre\n",
      "ultr\n",
      "the'r\n",
      "possibe\n",
      "visit-certainly\n",
      "it-will\n",
      "12days\n",
      "five-diamond\n",
      "-operation\n",
      "execel\n",
      "julieth\n",
      "thi8s\n",
      "chicacgo\n",
      "re-visite\n",
      "4night/5day\n",
      "wkend-\n",
      "unpleasent\n",
      "DGDG.DG\n",
      "okü§∑üèæ‚Äç‚ôÄÔ∏è\n",
      "cance\n",
      "..DG\n",
      "self-proclaim\n",
      "misleadin\n",
      "everyd\n",
      "milfor\n",
      "management/\n",
      "dresse\n",
      "weekend-had\n",
      "expect..\n",
      "hotel..tiny\n",
      "fanastic\n",
      "veoma\n",
      "food.beautful\n",
      "survay\n",
      "amerit\n",
      "street/wtc\n",
      "curtai\n",
      "diwntown\n",
      "exlellent\n",
      "mid-2016\n",
      "incredible..our\n",
      "neighbirhood\n",
      "unhelpfu\n",
      "incred\n",
      ".courtesy\n",
      "roadtrippin\n",
      "antoanela\n",
      "favor..\n",
      ".stunning\n",
      "1week\n",
      "air/hote\n",
      "exciteme\n",
      "honou\n",
      "nyc/senior\n",
      "-perfect\n",
      "rooms/deco\n",
      "cons:1\n",
      "ordin\n",
      "floor/c\n",
      "horrible.me\n",
      "40th-\n",
      "boutique-sty\n",
      "administrati\n",
      "circumst\n",
      "innsi\n",
      "sep1\n",
      "shhhhhhh\n",
      "crowds/casino\n",
      "jandm\n",
      "mysti\n",
      "tishlp\n",
      "agood\n",
      "venue/valet\n",
      "reinvente\n",
      "corrct\n",
      "expererience\n",
      "mss-but\n",
      "skylin\n",
      "tildon\n",
      "'more\n",
      "lamit\n",
      "priceing\n",
      "pro-perfect\n",
      "hottes\n",
      "thouh\n",
      "sork\n",
      "yutrip\n",
      "downtown/magnificent\n",
      "pamperred\n",
      "nyat\n",
      "but‚Ä¶housekeeping\n",
      "consierge\n",
      "subp\n",
      "in..checke\n",
      "miliha\n",
      "unfreindly\n",
      "okay_\n",
      "engery\n",
      "long-weeken\n",
      "mktg\n",
      "great-beds\n",
      "ph3\n",
      "inadequat\n",
      "flea-mingo\n",
      "clean.zoo\n",
      "acomodaci√≥n\n",
      "'luxury\n",
      "whent\n",
      "conveinent\n",
      "üëçüëèüòÜ\n",
      "retrospecs\n",
      "thereüôã‚Äç‚ôÇÔ∏èüëç\n",
      "anniverery\n",
      "mislea\n",
      "catchi\n",
      "nosie\n",
      "lacklus\n",
      "kication\n",
      "whereve\n",
      "mstika\n",
      "classifie\n",
      "a\\c\n",
      "price/pe\n",
      "groups/families\n",
      "under-staffed\n",
      "venice/st\n",
      "DGDG-DGDG-DG\n",
      "exeptionnal\n",
      "nikko-\n",
      "ÿßŸÑŸÉŸàŸäÿ™\n",
      "routi\n",
      "s-hole\n",
      "quin-tessential\n",
      "deteriation\n",
      ".larg\n",
      "didith\n",
      "with-it\n",
      "staff-murray\n",
      "mold/mildew\n",
      "ameritanian\n",
      "pececnik\n",
      "foodattentiv\n",
      "servicea\n",
      "maibach\n",
      "busy/crowded\n",
      "blury\n",
      "funct\n",
      "neartimes\n",
      "ofnever\n",
      "quintessentia\n",
      "caesar's..\n",
      "cooki\n",
      "availabi\n",
      "environnemental\n",
      "expectations‚Ä¶somewhat\n",
      "briteny\n",
      "unpredictab\n",
      "extr\n",
      "expectations..a\n",
      "towels/\n",
      "'bo\n",
      "bugs-horrible\n",
      "arriv\n",
      "in..the\n",
      "location..location..location..we\n",
      "bathrooms/good\n",
      "time..\n",
      "comfiest\n",
      "trip-nice\n",
      "6:00am\n",
      "2x/mont\n",
      "sixtx\n",
      "bfirst\n",
      "nights.booked\n",
      "nuclea\n",
      "amenities/serv\n",
      "ok.loc\n",
      "perspect\n",
      "attarctions\n",
      "magella\n",
      "chicago.my\n",
      "mnte\n",
      "pre-check\n",
      "hilton-san\n",
      "chrges\n",
      "vacation/awesome\n",
      "because..\n",
      "roomout\n",
      "madness-cosmo\n",
      "DG+\n",
      "daughter-i\n",
      "liveyourlegend\n",
      "mountain-view\n",
      "recen\n",
      "anniversary/w\n",
      "surv\n",
      "ok.pillows\n",
      "meatpacki\n",
      "30mins\n",
      "hilton-club\n",
      ".center\n",
      "curteous\n",
      "village/midtown\n",
      "staying‚Äã\n",
      "enchanging\n",
      "stickl\n",
      "holidau\n",
      "wonderful.always\n",
      ".service\n",
      "disappoined\n",
      "cqgc\n",
      "mazelle\n",
      "spotles\n",
      "mosc\n",
      "sf-union\n",
      "check-in/ch\n",
      "palazoo\n",
      "huge..\n",
      "price..great\n",
      "*bachelorette\n",
      "icims\n",
      "unkn\n",
      "carryin\n",
      "üò≤\n",
      "lv-\n",
      "deat\n",
      "spg/westin\n",
      "sanfranc\n",
      "ny.gre\n",
      "dungeo\n",
      "casinowith\n",
      "hotel..loved\n",
      "personn\n",
      "chilim\n",
      "scul\n",
      "meatpa\n",
      "up-marke\n",
      "christmas/25th\n",
      "food/servi\n",
      "amazong\n",
      "experieence\n",
      "alllllll\n",
      "wedding/\n",
      "breackfast\n",
      "airmiles.ca\n",
      "suneil\n",
      "okthe\n",
      "napa/vegas\n",
      "fanstytrue\n",
      "brkfst\n",
      "room/casino/food\n",
      "retreat_lodging\n",
      "atmosphere~\n",
      "oversi\n",
      "accomadions\n",
      "disinterst\n",
      "chicao\n",
      "/servi\n",
      "sinple\n",
      "home-away-from\n",
      "fancy..\n",
      "excellemt\n",
      "reservation/\n",
      "20/per\n",
      "vacations-trump\n",
      "upfron\n",
      "restaurants-\n",
      "start..\n",
      "anti-mediocre\n",
      "nov5-7,2016\n",
      "comfies\n",
      "accomodati\n",
      ".expected\n",
      "juky\n",
      "non-budget\n",
      "heavenly‚Ä¶\n",
      "grwt\n",
      "lynsie\n",
      "respi\n",
      "numbe\n",
      "resortv\n",
      "health-focus\n",
      "harrahs/caesars\n",
      "osheas\n",
      "v.s\n",
      "retreat-perfect\n",
      "ammazinnnnnnng\n",
      ".c\n",
      "great.purchaded\n",
      "indiffere\n",
      "luxur\n",
      "30/night\n",
      "casino-great\n",
      "suzzane\n",
      "graduatin\n",
      "reccomended\n",
      "reseanable\n",
      "caesar'so\n",
      "non-gamin\n",
      "reccomendations\n",
      "**smells\n",
      "luigislp\n",
      "lcor\n",
      "amazingly.the\n",
      "pheona\n",
      "truelly\n",
      "museum-visiting\n",
      "4pm.two\n",
      "2da\n",
      "museum-goer\n",
      "semashow\n",
      "tild\n",
      "intercontinent\n",
      "grogeous\n",
      "word..\n",
      "daysthe\n",
      "restauantt\n",
      "high-energ\n",
      "over-booking\n",
      "15-y\n",
      "jaccuzi\n",
      "prescript\n",
      "son-\n",
      "magucal\n",
      "yorl\n",
      "stilly\n",
      "abso\n",
      "reputa\n",
      "losen\n",
      "suite/service\n",
      "theives\n",
      "everywhe\n",
      "DGDG/DGDG/DG\n",
      "birthday/engagement\n",
      "welcon\n",
      "ofte\n",
      "woo-hoo\n",
      "deco-i\n",
      "teidra\n",
      "vistit\n",
      "extens\n",
      "conevnient\n",
      "mcdo\n",
      "highli\n",
      "ÏúÑÏπòÎäî\n",
      "sooooooooooooo\n",
      "11pm-4am\n",
      "povia\n",
      "disinte\n",
      "secret..it\n",
      "floor-to\n",
      "wyn-wyn\n",
      "andmachado\n",
      "mannatha\n",
      "un-new-yorkish\n",
      "n.a\n",
      "üíïüíïüíïüíï\n",
      "diwnhill\n",
      "service/resort\n",
      "*will*\n",
      "andnice\n",
      "rooms.\n",
      "business/platinum\n",
      "rio/vegas\n",
      "hotel-bad\n",
      "bathroomsmall\n",
      "pretention\n",
      ".t\n",
      "weekrnd\n",
      "victori\n",
      "cozy.very\n",
      "horrible*\n",
      "stay/wonderful\n",
      "orgn\n",
      "uhh..\n",
      "good/fremont\n",
      "resea\n",
      "xbenefit\n",
      "instrumen\n",
      "casablance\n",
      "verrrrrry\n",
      "travelod\n",
      "mostly.nothing\n",
      "6:50am\n",
      "needsd\n",
      "marshmellow\n",
      "n8ce\n",
      "expectationsions\n",
      "purpl\n",
      "hotels/casinos\n",
      "place/great\n",
      "loation\n",
      "moaziz34\n",
      "walkig\n",
      "hotel.th\n",
      "10/19/2018the\n",
      "service-outdated\n",
      "midern\n",
      "freelanc\n",
      "bday\n",
      "'reasonable\n",
      "'fiver\n",
      "nice..at\n",
      "ministe\n",
      "times..n\n",
      "ada-compliant\n",
      "convention/vacation\n",
      "sttayed\n",
      "room..once\n",
      "outsdanding\n",
      "locataded\n",
      "entertainme\n",
      "breakfast-\n",
      "hebt\n",
      "palace-live\n",
      "comfortabe\n",
      "check‚Äëin/room\n",
      "roksana\n",
      "functiona\n",
      "signifi\n",
      ".di\n",
      "quintissential\n",
      "whitehal\n",
      "stipi\n",
      "authen\n",
      "pool.clean\n",
      "alternati\n",
      "good.night\n",
      "staff/hotel/location\n",
      "franacisco\n",
      "mordern\n",
      "1br\n",
      "jimm\n",
      "18-yer-old\n",
      "wondwerful\n",
      "money-bar\n",
      "stey\n",
      "brib\n",
      "libbw\n",
      "uograde\n",
      "awesomness\n",
      "place3\n",
      "'corporate\n",
      "novedad\n",
      "unrefirbished\n",
      "millenn\n",
      "‚Ä¢just\n",
      "dell/emc\n",
      "allegr\n",
      "eco-friiendly\n",
      "competit\n",
      "yet..\n",
      "thirlling\n",
      "variou\n",
      "fraudulant\n",
      "pre-auth\n",
      "vdar-tastic\n",
      "rewardi\n",
      "claustrophobically\n",
      "hot=\n",
      "location-older\n",
      "injune\n",
      "mid-ran\n",
      ".already\n",
      "businiess\n",
      "describin\n",
      "connected-\n",
      "squarre\n",
      "hiseven\n",
      "terribke\n",
      "compe\n",
      "hotel..everything\n",
      "zmen\n",
      "roomalthough\n",
      "chelsea/high\n",
      "cgcs\n",
      "laguar\n",
      "59/night\n",
      "vegasi\n",
      "npise\n",
      "platnium\n",
      "center‚Äîsteps\n",
      ".tw\n",
      "livel\n",
      "51133.we\n",
      "marath\n",
      "end-of-week\n",
      "tower/\n",
      "hollidays\n",
      "madarin\n",
      "maje\n",
      "cario\n",
      "aberdourg\n",
      "bill‚Ä¶\n",
      "friednly\n",
      "rockefell\n",
      "mas-icna\n",
      "janaina\n",
      "hotel2\n",
      "non-weekend\n",
      "month-lo\n",
      "suite-amazing\n",
      "unbelieve\n",
      "'hipness\n",
      "location..amazing\n",
      "pallettes\n",
      "lakesh\n",
      "ackward\n",
      "budet\n",
      "thri\n",
      "refurnish\n",
      "location.staff\n",
      "last-\n",
      "inexpenive\n",
      "kenaya\n",
      "-disappointed\n",
      "expon\n",
      ".ev\n",
      "-sometim\n",
      "so/so\n",
      "gateaway\n",
      "vacay..\n",
      "un-las\n",
      "apprehen\n",
      "style/interior\n",
      "h***\n",
      "bilding\n",
      "placee\n",
      "bathroomgood\n",
      "doubletree/hilton\n",
      "location-exellent\n",
      "9am-5pm\n",
      "cheerific\n",
      "mar1-8\n",
      "-enormous\n",
      "dump.i\n",
      "ncsbn\n",
      "blacony\n",
      "bliz\n",
      "clean-safe-large\n",
      "comtempory\n",
      "guillerm\n",
      "clerks-awesome\n",
      "fashioners\n",
      "freder\n",
      "coolhotel-very\n",
      "8-yea\n",
      "anniverasy\n",
      "las-vegas\n",
      "corrwct\n",
      "relaxing/q\n",
      "adaptatio\n",
      "w/wonderful\n",
      "comfortaable\n",
      "gerardo..was\n",
      "modern-\n",
      "2-br\n",
      "feeli\n",
      "mineexpo\n",
      "chicago-dewitt\n",
      "eve-eve\n",
      "dirtyshower\n",
      "5ave\n",
      "refub\n",
      "jmac5777\n",
      "facility/\n",
      "tiney\n",
      "profesi\n",
      "oldworld\n",
      "vwegas\n",
      ".foo\n",
      "augustis\n",
      "execl\n",
      "amazinb\n",
      "thanx\n",
      "efficie\n",
      "holiday-\n",
      "lackl\n",
      "reservati\n",
      "stayed5nights\n",
      "location.exce\n",
      "jimmys\n",
      "terrible-\n",
      "distruct\n",
      "◊û◊ü◊¢◊ô◊ê\n",
      "fail..\n",
      "w/extended\n",
      "partiall\n",
      "marijuana-reeking\n",
      "ok..i\n",
      "kessleman\n",
      "sight-seei\n",
      "booktastic\n",
      "billbo\n",
      "iÃá\n",
      "..bit\n",
      "skept\n",
      "fine.shower\n",
      "souve\n",
      "mold-\n",
      "bus..\n",
      "hotels-the\n",
      "bulld\n",
      "member-\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conclu\n",
      "prosthe\n",
      "experienceroom\n",
      "complaint-great\n",
      "route66\n",
      "over-heated\n",
      "locartion\n",
      "casino‚ûï/\n",
      "in/check-out\n",
      "10dollars\n",
      "bad..\n",
      "redeeme\n",
      "experience:1-\n",
      "showers/scalding\n",
      "fancey\n",
      "exelente\n",
      "24yr\n",
      "everyon\n",
      "enjoyabe\n",
      "shevonne\n",
      "luxor.my\n",
      "+DGDG\n",
      "everything..\n",
      "recived\n",
      "handy..\n",
      "plus.rooms\n",
      "to.stay\n",
      "errible\n",
      "genreal\n",
      "terrifi\n",
      "ausome\n",
      "unreas\n",
      "quaility\n",
      "help/assistance\n",
      "enore\n",
      "poor-customer\n",
      "un-manhattan\n",
      "renowe\n",
      "snobb\n",
      ".very\n",
      "pret-a-manger\n",
      "candl\n",
      "overbooki\n",
      "liesure\n",
      "stay..stunning\n",
      "locationsmall\n",
      "janurary\n",
      "embarcade\n",
      "comple\n",
      "budget-friendly\n",
      "inadvert\n",
      "*extreme*\n",
      "room‚Äîthey\n",
      "hotel-\n",
      "location/return\n",
      "venetian/palazzo\n",
      "st.clair\n",
      "confirmat\n",
      "ÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩ\n",
      "..does\n",
      ".without\n",
      "farrrr\n",
      "fomo\n",
      "turds\n",
      "tastefu\n",
      "caffine\n",
      "yawwwnnnn\n",
      "now****\n",
      "locationn\n",
      "occa\n",
      "payouts-\n",
      "'beautiful\n",
      "rooms..bad\n",
      "135/night\n",
      "cali3060\n",
      "rooms/bathroo\n",
      "showin\n",
      "dissapointme\n",
      "visist\n",
      "complaints.room\n",
      "proced\n",
      "strykowski\n",
      "tweeks\n",
      "infrastruture\n",
      "recommenda\n",
      "self-park\n",
      "incidenta\n",
      "15.ro\n",
      "chainsmokers\n",
      "jan21\n",
      "4yo\n",
      "DGDG/DGDG-DGDG/DGDG/DG\n",
      "2016-befor\n",
      "stressf\n",
      "experience.1\n",
      "time-capsule\n",
      "agents..\n",
      "'amazing\n",
      "◊¢◊®◊ß◊©◊ê\n",
      "restroo\n",
      "unrenov\n",
      "feb-07-18\n",
      "again..reserv\n",
      "innovativ\n",
      "funtrip\n",
      "cyclinders\n",
      "location=perfection‚ù§\n",
      "‚ô•Ô∏è‚ô•Ô∏è\n",
      "lvüòÉ\n",
      "ptac\n",
      "thehotel\n",
      "location..location..location\n",
      "chillax\n",
      "75-ye\n",
      "uncreadibly\n",
      "penthouse1\n",
      "hugout\n",
      "perfect.staff\n",
      "pleasing-\n",
      "good.checking\n",
      "amazingness\n",
      "someth\n",
      "repair/ma\n",
      "cancell\n",
      "diappointed\n",
      "constructon\n",
      "jan.21,2018\n",
      "accomdating\n",
      "lobby/rooms\n",
      ".DG\n",
      "break-a\n",
      "nra-business\n",
      "grie\n",
      "espected\n",
      "themeing\n",
      "concie\n",
      ".jan\n",
      "atbally\n",
      "bestkeptsecretin\n",
      "last-minut\n",
      "contemporady\n",
      "harrars\n",
      "-quiet\n",
      "northriver\n",
      "tyrip\n",
      "olym\n",
      "attractiv\n",
      "staff/maintenance\n",
      "speakin\n",
      "recommendemed\n",
      "air-con\n",
      "bestie\n",
      "totel\n",
      "andjim\n",
      "DG/DG‚ÄîDG/DGDG\n",
      "remol\n",
      "unprofe\n",
      "residentia\n",
      "south-\n",
      "/quality\n",
      "internati\n",
      "1160..smelled\n",
      "vomity\n",
      "„Å©„Åì„Å´„ÅÑ„Åè„ÅÆ„ÇÇ‰æøÂà©„Å™Á´ãÂú∞„Å´„ÅÇ„Çã„ÄÅ„Çπ„Çø„Ç§„É™„ÉÉ„Ç∑„É•„Å™\n",
      "..honeymooned\n",
      "responsibility/\n",
      "stilish\n",
      "sister-i\n",
      "cromwell-a\n",
      "time'~\n",
      "loction\n",
      "break/\n",
      "ritz-ch\n",
      "pre-labor\n",
      "weekend/week\n",
      "qualtity\n",
      "shatia\n",
      "courteousness\n",
      "exlelent\n",
      "bachelore\n",
      "2.5hrs\n",
      "7year\n",
      "lurvey\n",
      "sponta\n",
      "'security\n",
      "responsi\n",
      "gamble.h\n",
      "post-holiday\n",
      "lcah\n",
      "hakkusan\n",
      "4-6x\n",
      "advenure\n",
      "'extra\n",
      "business/pers\n",
      "staff+\n",
      "confir\n",
      "redeve\n",
      "previllige\n",
      "'too\n",
      "sophisticated..lovely\n",
      "humanless\n",
      "experience..love\n",
      "slesifamily\n",
      "sparkl\n",
      "costo/ben\n",
      "kids-not\n",
      "apalling\n",
      ".new\n",
      "doorma\n",
      "‚úàÔ∏è‚úàÔ∏è‚úàÔ∏è‚úàÔ∏è\n",
      "ghane\n",
      "remember..\n",
      "yeara\n",
      "hrhs\n",
      "thiings\n",
      "location.the\n",
      "condo-style\n",
      "room/bathr\n",
      "refres\n",
      "disappointme\n",
      "bellagiothe\n",
      "adven\n",
      "floode\n",
      "again‚ù§Ô∏è\n",
      "re-visit\n",
      "dongy\n",
      "ritz-like\n",
      "ruthles\n",
      "here.\n",
      "categori\n",
      "step-mom\n",
      "overra\n",
      "doesn¬¥t\n",
      "quent\n",
      "londonhotel\n",
      "yr.\n",
      "well-thought\n",
      "lovely-\n",
      "stoppe\n",
      "thanksgi\n",
      "for‚Ä¶\n",
      "re-decorated\n",
      "-chea\n",
      "birthdayshenanigans\n",
      "redferno\n",
      "sujo\n",
      "bellongings\n",
      "clean.there\n",
      "a-swimming\n",
      "mascone\n",
      "omelett\n",
      "mavel\n",
      "qualiffied\n",
      "lobby/bar/hang\n",
      "go-tp\n",
      "proffesion\n",
      "wynn-an\n",
      "director/minibar\n",
      "wansent\n",
      "beautifulüòä\n",
      "expetional\n",
      "9:00pm\n",
      "chuffing\n",
      "accomandations\n",
      "hahaha..\n",
      "stay.there\n",
      "getting-\n",
      "rooms.loca\n",
      "sarbi\n",
      "pros:1.\n",
      "stay-good\n",
      "funcation\n",
      "restaurant-under\n",
      "..upon\n",
      "un-necessarily\n",
      "non-inclusive\n",
      "disjoi\n",
      "feb.16-20\n",
      "bussiness\n",
      "comfortabb\n",
      "neglact\n",
      "off-\n",
      "j.w\n",
      "friemds\n",
      "vacations-elara\n",
      "butchere\n",
      "scotl\n",
      "sheratons\n",
      "fint\n",
      "drapes/sheer\n",
      "one-bedro\n",
      "self-check-in\n",
      "nightmare‚Äã\n",
      "hi-this\n",
      "astmatic\n",
      "hoels\n",
      "discla\n",
      "makeov\n",
      "place.fe\n",
      "well-located\n",
      "-DGDG\n",
      "value/recent\n",
      "sanfus\n",
      "potential-\n",
      "low-k\n",
      "beware-bare\n",
      "excalibar\n",
      "overally\n",
      "construcion\n",
      "worth..i\n",
      "waiti\n",
      "'olde\n",
      "wellne\n",
      "remmington\n",
      "stay.n\n",
      "glamorou\n",
      "arrrrgonaut\n",
      "understa\n",
      "colde\n",
      "fabiol\n",
      "careful-they\n",
      "starlooks\n",
      "accomodations-\n",
      "drive-up\n",
      "functional..no\n",
      "moscon\n",
      "rooms/amenities\n",
      ".table\n",
      "exemplarl\n",
      "ill-repaired\n",
      "whoah\n",
      "conveinence\n",
      "drawback..\n",
      ".went\n",
      "nights/year\n",
      "zzzzzz\n",
      "york.we\n",
      ".an\n",
      "ceasr\n",
      "pfff\n",
      "ooutstanding\n",
      "nice/poor\n",
      "freeb\n",
      "absolu\n",
      "appreciativ\n",
      "disappointedi\n",
      "arnaque\n",
      "finanicia\n",
      "sigths\n",
      "mom/daughters\n",
      "ourwe\n",
      "sharon/aussies\n",
      "kios\n",
      "location.everything\n",
      "siggy\n",
      "comfortable-service\n",
      "nonexi\n",
      "funjust\n",
      "breakfas\n",
      "brthday\n",
      "unbeatably\n",
      "nicer..hotel\n",
      "service-disrespectful\n",
      "carv\n",
      "teeeny\n",
      "aveage\n",
      "DG-DGDGDGDGDG\n",
      "comfortablenega\n",
      "indepen\n",
      "hotel-budget\n",
      "respe\n",
      "problem-\n",
      "jackham\n",
      "locatin\n",
      "clean/beautiful\n",
      "nutshe\n",
      "wardolf\n",
      "doubleteee\n",
      "can¬¥t\n",
      "arived\n",
      "location-just\n",
      "hotel/superior\n",
      "approacha\n",
      "..ea\n",
      "tirered\n",
      "so-so..not\n",
      "cons-typical\n",
      "2th\n",
      "unaccomidating\n",
      "lasveg\n",
      "staff‚Ä¶\n",
      "d-u-m-p\n",
      "2017/3/2„Åã„Çâ3/5„Åæ„Åß\n",
      "w/amazing\n",
      "don'ts\n",
      "fieldhouss\n",
      "enjoable\n",
      "defic\n",
      "understat\n",
      "spacious..refrigerat\n",
      "once-grand\n",
      "greatcsray\n",
      "wingd\n",
      "imposs\n",
      "tired-\n",
      "hotel/no\n",
      "x-p\n",
      "tourist-style\n",
      "excellentwe\n",
      "gerting\n",
      "intereste\n",
      "mid-loop\n",
      "¬£DGDGDG\n",
      "frangeance\n",
      "canyon..\n",
      "wonderful.hotel\n",
      "sub-average\n",
      "schra\n",
      "football/sport\n",
      "embarcaderowe\n",
      "elysse\n",
      "irritations..\n",
      "disorgan\n",
      "dilapilated\n",
      "locationclose\n",
      "excellent.th\n",
      "reputaton\n",
      "location/price/parkingüòÄ\n",
      "clean.it\n",
      "incredibe\n",
      "unimpr\n",
      "marbl\n",
      "excellent***specifically\n",
      "evanti\n",
      "friendl\n",
      "terrible‚Ä¶\n",
      "inbad\n",
      "fifity\n",
      "conviently\n",
      "for-ever\n",
      "tripexcell\n",
      "towers.first\n",
      "service/quality\n",
      "mid-ja\n",
      "alround\n",
      "-where\n",
      "22st\n",
      "+++\n",
      "fantastic~\n",
      "selec\n",
      "crownplaza\n",
      "in..\n",
      "t.i\n",
      "2-doub\n",
      "44oz\n",
      "aamazing\n",
      "neighborhood-close\n",
      "incomodo\n",
      "exlente\n",
      "place-best\n",
      "nyc.had\n",
      "spaces/nice\n",
      "comfirtable\n",
      ".equivalent\n",
      "*uk\n",
      "service..and\n",
      "improvment\n",
      "pre-chri\n",
      "april.we\n",
      "hotel.this\n",
      "famiky\n",
      "jmjhannon\n",
      "badl\n",
      "super-large\n",
      "akward\n",
      "stay..lots\n",
      "woma\n",
      "lcated\n",
      "milenorth‚Ä¶good\n",
      "suxor\n",
      "proirity\n",
      "marqui\n",
      "aug.2016\n",
      "weekend/special\n",
      "chaming\n",
      "exellant\n",
      "starstaff\n",
      "okis\n",
      "non-private\n",
      "langahm\n",
      "Ë≥¢„ÅÑÈÅ∏Êäû„Åß„Åô\n",
      "durprise\n",
      "shelburn\n",
      "location.walk\n",
      "getaway/fantastic\n",
      "receptio\n",
      "twintastic\n",
      "setvice\n",
      "chiq\n",
      "+vegas\n",
      "interconnect2015\n",
      "drake-itude\n",
      "wynn/encor\n",
      "okroom\n",
      "reache\n",
      "greetin\n",
      "imperson\n",
      "lay-\n",
      "cnange\n",
      "4night\n",
      ".average\n",
      "checkin/checkout\n",
      "sneak-peak\n",
      ",it\n",
      "roomthe\n",
      "vslue\n",
      "DG.DGDG.DGDG-DGDG.DGDG.DGDG\n",
      "sylish\n",
      "hotel/timeshare\n",
      "choice//\n",
      "thebmarriott\n",
      "locationsuper\n",
      "bame\n",
      "2016-july\n",
      "meani\n",
      "luxurythe\n",
      "hotel/fabulous\n",
      "-warm\n",
      "fƒ±r\n",
      "'center\n",
      "reteat\n",
      "manhattan/chelsea\n",
      "promotiona\n",
      "bally's-july\n",
      "2017.i\n",
      ".omg\n",
      "say-\n",
      "55t\n",
      "memerable\n",
      "hopefu\n",
      "experience*****\n",
      "hotel/room/staff\n",
      "appi\n",
      "price-performance\n",
      "stripwise\n",
      "quiter\n",
      "exceptionable\n",
      "unfogetable\n",
      "isstill\n",
      "rooms-no\n",
      "retaurant\n",
      "hotel.city\n",
      "5*hotel\n",
      "suck-hol\n",
      "space_convenience_service\n",
      "superdeal\n",
      "apof\n",
      "friends/golf\n",
      "restruants\n",
      "gladl\n",
      "ÌñÑÌäºÏù∏\n",
      "advanc\n",
      "javitis\n",
      "working.t\n",
      "truthtripper\n",
      "purifi\n",
      "enojoyed\n",
      "qwirks\n",
      "tolodge\n",
      "enjoied\n",
      "world's.greatest.staff\n",
      "chinatown-\n",
      "desig\n",
      "family-moon\n",
      "unecessarily\n",
      "family..\n",
      "lyndia\n",
      "bi-yearly\n",
      "unusual/very\n",
      "slaywithrae\n",
      "unuseable\n",
      "vegasüòä\n",
      "honeymoon/1st\n",
      "par-\n",
      "isgreviews\n",
      "price/location/service5-10min\n",
      "comodid\n",
      "millenians\n",
      "disappointed..\n",
      "m442\n",
      "literally-\n",
      "nycüá∫üá∏\n",
      "excellent.we\n",
      "vinta\n",
      "dancing..\n",
      "waaaaaaaay\n",
      "collection-\n",
      "gorls\n",
      "dowhill\n",
      "disresp\n",
      "yesss\n",
      "state/\n",
      "lovlie\n",
      "amazying\n",
      "ultra-hip\n",
      "august/start\n",
      "staff-should\n",
      "'pleasant\n",
      "sch√∂nes\n",
      "appartment-complex\n",
      "location/average\n",
      "chicago/magnificent\n",
      "gatsby_esque\n",
      "notifed\n",
      "impromteau\n",
      "again,3rd\n",
      "pre-reserva\n",
      "fligh\n",
      "highly-ren\n",
      "'museums\n",
      "unw\n",
      "room/price/serv\n",
      "intenet\n",
      "fullove\n",
      "compulsator\n",
      "place-please\n",
      "room..but\n",
      "mini-\n",
      "hotel/ho\n",
      "excelent/been\n",
      "n.o\n",
      "timewe\n",
      "news/bad\n",
      "non-function\n",
      "fabulour\n",
      "hotelt\n",
      "lounge/\n",
      "nightclubby\n",
      "perfectly-positioned\n",
      "up-charge\n",
      "huday\n",
      "hamiton\n",
      "cannont\n",
      "friendly/cool\n",
      "hotel-to-go\n",
      "firsttime\n",
      "hubsters\n",
      ".snow\n",
      "better-stayed\n",
      "yourse\n",
      "inexper\n",
      "DG.DG/DGDG\n",
      "definitiely\n",
      "v.expensive\n",
      "baby/kod\n",
      "special-tacked\n",
      "service/we\n",
      "15-20t\n",
      "placew\n",
      "famil\n",
      "paris-new\n",
      "palms-glad\n",
      "great.good\n",
      ".wonderful\n",
      "yummm\n",
      "insulati\n",
      "12th-18th\n",
      "'shelter\n",
      "experimente\n",
      "supossed\n",
      "hellothe\n",
      "possibilitie\n",
      "turisto\n",
      "adnanmed\n",
      "stay..at\n",
      "near-strip\n",
      "belverdere\n",
      "hotel-house\n",
      "kyree\n",
      "/1st\n",
      "beliggenhet\n",
      "hotelbut\n",
      "strugglin\n",
      "hiltonrun\n",
      "illnesd\n",
      "gravitat\n",
      "28th/\n",
      "located-four\n",
      "place.ideal\n",
      "tremend\n",
      "non-lodging\n",
      ".start\n",
      "service/microscopic\n",
      "nemory\n",
      "working/pumping\n",
      "üëçüèªüëçüèª\n",
      "sf\\n\n",
      "—Ü–µ–Ω—Ç—Ä–µ\n",
      "disaapointing\n",
      "experiebce\n",
      "someo\n",
      "ambaince\n",
      "dreak\n",
      "..go\n",
      "fabulos\n",
      "hotel..super\n",
      "microw\n",
      "concert-worst\n",
      "gambli\n",
      "dinni\n",
      "besto\n",
      "unexpecte\n",
      "crapy\n",
      "fjolla\n",
      "justic\n",
      "double-\n",
      "orgazined\n",
      "locatiion\n",
      "ipdates\n",
      "anaversay\n",
      "microho\n",
      "follow-u\n",
      "units/great\n",
      "occass\n",
      "minute.staff\n",
      "restaurant/loun\n",
      "bayy\n",
      "mitsy\n",
      "maddis\n",
      "comfortable.bath\n",
      "trollish\n",
      "fsmily\n",
      "sound-proof\n",
      "six-\n",
      "businessme\n",
      "great-jpc\n",
      "checkin/out\n",
      "upsell\n",
      "initiall\n",
      "nice-modern-clean\n",
      "tmes\n",
      "üíï‚ú®\n",
      "hotelthe\n",
      "rekax\n",
      "rafey\n",
      "buffet/restaurant\n",
      "stay-2015\n",
      "edges‚Ä¶\n",
      "absymal\n",
      "fasad\n",
      "..i\n",
      "cloub\n",
      ".enough\n",
      "inadv\n",
      "attendi\n",
      "expo-very\n",
      "ballys.sta\n",
      "wharft\n",
      "weeklend\n",
      "allison/steve\n",
      "betterthan\n",
      "location.oversized\n",
      "badest\n",
      "ph-fun\n",
      "DG:DGDG\n",
      "afordable\n",
      "fun-an-na\n",
      "we'l\n",
      "gliche\n",
      "marquiss\n",
      "inpersonal\n",
      "boutiq\n",
      "Ìï¥ÏÑú\n",
      "maddness\n",
      "experience-ever\n",
      "nprf\n",
      "waaayyy\n",
      "fleas/bugs\n",
      "nycüëçüèº\n",
      "steying\n",
      "mitchigan\n",
      "üò´\n",
      "view-\n",
      "..beyond\n",
      "stressfu\n",
      "whitch\n",
      "pool-view\n",
      "seyedneatollah\n",
      "light-sleepers\n",
      "5thavebue\n",
      "service.clean\n",
      "rooms/outdated\n",
      "mama/daughter\n",
      "-n-\n",
      "mittle\n",
      "^vacation\n",
      "outin\n",
      "ccommod\n",
      "average/not\n",
      "money-gr\n",
      "salisbur\n",
      "uderstand\n",
      "perfect.hote\n",
      "brunc\n",
      "fun/\n",
      "last-m\n",
      "subseequent\n",
      "far.located\n",
      "warfe\n",
      "octob\n",
      "bartendar\n",
      "+ve\n",
      "hoehner\n",
      "causght\n",
      "super-friendly\n",
      "avoiod\n",
      "soci\n",
      "b/\n",
      "excellent..princ\n",
      "eleant\n",
      "thiss\n",
      "poorl\n",
      "location-standard\n",
      "lovelyk\n",
      "icin\n",
      "airconditio\n",
      "fun-tastic\n",
      "rooms:4/5\n",
      "ill-managed\n",
      "reccomanded\n",
      "unexpeted\n",
      "neighburhood\n",
      "milowitz\n",
      "faimont\n",
      "cosplaying\n",
      "complicat\n",
      "rooms.last\n",
      "vacation-\n",
      "view-location-restaurant\n",
      "hotels/casi\n",
      "upgradingpool\n",
      "room/premium\n",
      "upper-mid\n",
      "calrton\n",
      "mcint\n",
      "girls/cousin\n",
      "'facilities\n",
      "suites/midtown\n",
      "hospility\n",
      "penny-pinching\n",
      "1.warning\n",
      "unrel\n",
      "service/view\n",
      "interv\n",
      "villa=\n",
      "conveniencesni\n",
      "locationfri\n",
      "hotellerie\n",
      "8month\n",
      "bwphs\n",
      "freandly\n",
      "desapointment\n",
      "radomly\n",
      "first-tim\n",
      "fries-but\n",
      "self-checkin\n",
      "thoughly\n",
      "coatsj\n",
      "manhattan-first\n",
      "quality-\n",
      "portugu√™swhe\n",
      "20t\n",
      "DGDGDGDG+\n",
      "strip-encore\n",
      "celebrat\n",
      "wedding/presidential\n",
      "w-times\n",
      "nicegym\n",
      "jck\n",
      "crowded/tight\n",
      "vocat\n",
      "excecutiv\n",
      "coffeeless\n",
      "neigbo\n",
      "..lovely\n",
      "miniba\n",
      "coerteous\n",
      "depressingk\n",
      "mercha\n",
      "hollywood-do\n",
      "service***\n",
      "unspecial\n",
      "*****\n",
      ".hotels\n",
      "opini\n",
      "rewatds\n",
      "langham-\n",
      "wxpwcted\n",
      "friendly..\n",
      "sub-\n",
      "modern/chic\n",
      "wellll\n",
      "DGDG-DGDG-DGDG-DGDG-DGDG-DGDG\n",
      "increduble\n",
      "points-wow\n",
      "side/lincoln\n",
      "locationvdara\n",
      "okay‚Äî\n",
      "pocketa\n",
      "conver\n",
      "biutique\n",
      "destina\n",
      "breakfast/food\n",
      "impressive-\n",
      "caveots\n",
      "equivalen\n",
      "wow'ed\n",
      "-bellisimo\n",
      "syster\n",
      "stinks/\n",
      "me\\m\n",
      "conference/leisure\n",
      "reccomned\n",
      "non-lux\n",
      "plumbing/\n",
      "wifi/gym\n",
      "excllent\n",
      "frust\n",
      "attenti\n",
      "age-spanning\n",
      "aside..\n",
      "w/breakfast\n",
      "bumpe\n",
      "hostel..\n",
      "benefits/poor\n",
      "ultra-luxury\n",
      "Ïù¥\n",
      "room24th\n",
      "..cough\n",
      "israyelyan\n",
      "york-lovely\n",
      "eco/green\n",
      "cpmc\n",
      "overall-great\n",
      "software/staff\n",
      "invit\n",
      "good-si\n",
      "stepdau\n",
      "suncoa\n",
      "9-30am\n",
      "construction/renovation\n",
      "briiliant\n",
      "beautirful\n",
      "disrict\n",
      "3nigh\n",
      "nececities\n",
      "moneh\n",
      "figu\n",
      "vennician\n",
      "priscil\n",
      "DG.\n",
      "average.rooms\n",
      "sherat\n",
      "excellent+\n",
      "break/birthday\n",
      "'vip+\n",
      "spaceno\n",
      "whenev\n",
      "freshing\n",
      "affo\n",
      "franscico\n",
      "excelllent\n",
      "dissapontment\n",
      "middle-\n",
      "nighte\n",
      "business-chic\n",
      "◊û◊¶◊ï◊ô◊ü\n",
      "hotel-on\n",
      "sauare\n",
      "days..was\n",
      "staff-perfect\n",
      "encorealways\n",
      "getawy\n",
      "w/some\n",
      "dbldbldbl\n",
      "less-foot-traffic\n",
      "placce\n",
      "-beware\n",
      "◊î◊¶◊ï◊ï◊™\n",
      "Î∞õÏßÄÎ™ªÌï¥\n",
      "üëéüèº\n",
      "ovarall\n",
      "exclusiv\n",
      "intermitten\n",
      "complants\n",
      "was..\n",
      "unadecuate\n",
      "silveron\n",
      "12-apr\n",
      "grandson-\n",
      "730am\n",
      "beautifulupon\n",
      "pre-napa\n",
      "ideal=\n",
      "adventerous\n",
      "kabuki-\n",
      "2017.it\n",
      "phone-\n",
      "caesers\n",
      "valet/bellman\n",
      "reciew\n",
      "so-good\n",
      "iheart\n",
      "christmasi\n",
      "luminosity.th\n",
      "better-than-expected\n",
      "respectfull\n",
      "..most\n",
      "unbelivelable\n",
      "flamimgo\n",
      "service/reco\n",
      "invalua\n",
      "than10\n",
      "generat\n",
      "fiftynyc-meet\n",
      "parking-\n",
      "mermorial\n",
      "inn/wild\n",
      "'ashley\n",
      "risonable\n",
      "2oth\n",
      "constrution\n",
      "towells\n",
      "-considering\n",
      "honeymoon.th\n",
      "thiefs\n",
      "roomsh\n",
      "creditcard\n",
      "5:06pm\n",
      "hotelto\n",
      "cansado\n",
      "contemporaryly\n",
      "baccar\n",
      "finacail\n",
      "globa\n",
      "old-folks\n",
      "staff.they\n",
      "hotel/executive\n",
      "diversay\n",
      "pennstation\n",
      "ÊâÄÊúâcable\n",
      "five-night\n",
      "minavycdr\n",
      "stay/vacation\n",
      "o'shays\n",
      "pennysilvania\n",
      "fast/terrible\n",
      "sray\n",
      "motel-like\n",
      "awesome.the\n",
      "stayüá∏üá≤\n",
      "annivasary\n",
      "nynylo\n",
      "queen/queen\n",
      "guysdid\n",
      "*beware*\n",
      "un-v\n",
      "price-service\n",
      "recommendedse\n",
      "gentrifie\n",
      "retired/educator\n",
      "Èô§‰∫ÜÂú∞ÁêÜ‰ΩçÁΩÆÊ≤°ÂÖ∂‰ªñ\n",
      "cetf\n",
      "okish\n",
      "cancele\n",
      "hktel\n",
      "29-jan3\n",
      "adja\n",
      "pet-perfect\n",
      "redtooth\n",
      "reviewthis\n",
      "johnson/mark\n",
      "loyalt\n",
      "weekdont\n",
      "bebette\n",
      "go-t\n",
      "christmastim\n",
      "success-\n",
      "food-in\n",
      "chelsea/wes\n",
      "cerser\n",
      "caesrs\n",
      "120f\n",
      "gutic-\n",
      "urhhh\n",
      "++++++\n",
      "i.m\n",
      "goodie..\n",
      "'fine\n",
      "cousins/siste\n",
      "exped\n",
      "üëèüèø\n",
      "crumbliing\n",
      "mediterra\n",
      "ananchronistic\n",
      "5yrs\n",
      "burgund\n",
      "locationthe\n",
      "reviewers..awesome\n",
      "min-vacation\n",
      "parfaitement\n",
      "aboa\n",
      "mid-twon\n",
      "excellent.check\n",
      "challengin\n",
      "dissapointing\n",
      "witih\n",
      "vegas¬¥\n",
      "queen-size\n",
      "argonau\n",
      "rspka007\n",
      "accommodatin\n",
      "guest..i\n",
      "usa/planet\n",
      "fabulious\n",
      "◊ï◊ô◊§◊î\n",
      "locationwonderful\n",
      "disappoitning\n",
      "handu\n",
      "**giv\n",
      "decent-sized\n",
      "anywa\n",
      "compareable\n",
      "286/night\n",
      "in-crowd\n",
      "beautiful.clean.safe.elegant\n",
      "slotomania\n",
      "unbear\n",
      "locationfro\n",
      "parkinghomeless\n",
      "hamptin\n",
      "wauuu\n",
      "midstrip\n",
      "fabulatous\n",
      "fauntains\n",
      "‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êamazing\n",
      "lovethis\n",
      "faceli\n",
      "8-13t\n",
      "bait-and-switc\n",
      "fails-\n",
      ".easy\n",
      "treyvon\n",
      "promena\n",
      "thesilverton\n",
      "certifica\n",
      "compr\n",
      "llov\n",
      "beaitiful\n",
      "handfu\n",
      "atmospehre\n",
      "here***\n",
      "deal-watch\n",
      "decadance\n",
      "signature/mgm\n",
      "staffcenter\n",
      "picku\n",
      "futrure\n",
      "bunc\n",
      "monday-thur\n",
      "location..fine\n",
      "altought\n",
      "bahahahaha\n",
      "lagg\n",
      "jul/\n",
      "impresstion\n",
      "ways.extra\n",
      "sshhh\n",
      "amazing/front\n",
      "curtain..\n",
      "horrendous.we\n",
      "claustroph\n",
      "loud/\n",
      "realto\n",
      "holel\n",
      "effial\n",
      "hohum\n",
      "park-nyc\n",
      "augustius\n",
      "argu\n",
      "attentitive\n",
      "y.e.s\n",
      "-dreadful\n",
      "nyvc\n",
      "3/24/15f\n",
      "-vegas\n",
      "joeii\n",
      "morde\n",
      "pre-renova\n",
      "shoppy\n",
      "4:30am\n",
      "somepl\n",
      "skiln\n",
      "gratit\n",
      "quarters-opposite\n",
      "snotty-acting\n",
      "cloudly\n",
      "hudson‚Ä¶\n",
      "wonderfuly\n",
      "ymp√§rist√∂\n",
      "balcny\n",
      "wfg\n",
      "location/super\n",
      "punchli\n",
      "third/fourt\n",
      "aceptable\n",
      "warning-\n",
      "eate\n",
      "seem-neve\n",
      "last-min\n",
      "impecable\n",
      "attainability\n",
      "disappoints.ter\n",
      "bad.furnit\n",
      "custmoer\n",
      "not-for-everyone\n",
      "rate/terrible\n",
      "eclecti\n",
      ".parking\n",
      ".exc\n",
      "recreatio\n",
      "buffest\n",
      "andiamos\n",
      "star-hahaha\n",
      "crem√©\n",
      "2br/5ba\n",
      "local.booked\n",
      "room/view\n",
      "watergood\n",
      "nglcc\n",
      "anythin\n",
      "botwl\n",
      "vacacions\n",
      "highlites\n",
      "resport\n",
      "feelei\n",
      "property/re-modeled\n",
      "servicesnegative\n",
      "place-would\n",
      "bellagi-best\n",
      "luxoir\n",
      "..par\n",
      "overhy\n",
      "friendly-reasona\n",
      "thers\n",
      "essexhouse\n",
      "onlin\n",
      "returant\n",
      "spacier\n",
      "22nd-\n",
      "cooloing\n",
      "concerirge\n",
      "roard\n",
      "fros√©\n",
      "mid.town.oasis\n",
      "febru\n",
      "exsperiances\n",
      "michaelan\n",
      "luxoryeah\n",
      "greatdeal\n",
      "downstair\n",
      "neighborhoos\n",
      "old-st\n",
      "'dive-bar\n",
      "lbor\n",
      "yorkish\n",
      "be..\n",
      "ultra-glamorous\n",
      "daughterts\n",
      "mainting\n",
      "early..\n",
      "daught\n",
      "nice.plenty\n",
      "rooms_great\n",
      "'peda\n",
      "fishe\n",
      "üòçüòçüòçüòç\n",
      "flor‚Ä¶..\n",
      "-rela\n",
      "jasonthis\n",
      "price/value\n",
      "smar\n",
      "ny-service\n",
      "localiz\n",
      "reletively\n",
      ".near\n",
      "22-29th\n",
      "location/great\n",
      "heredecent\n",
      "cholce\n",
      "anniversary/summer\n",
      "stay‚Ä¢‚Ä¢‚Ä¢\n",
      "rssort\n",
      "newish/clean\n",
      "viewin\n",
      "√§ntic\n",
      "..was\n",
      "subst\n",
      "much.be\n",
      "clean/comfortable\n",
      "croi\n",
      "convinie\n",
      "nigths\n",
      "üëåüèªüòÄ\n",
      "everyti\n",
      "casinos/hotels\n",
      "rekesh\n",
      "totaly\n",
      "introduc\n",
      "restaur\n",
      "whatelse\n",
      "v.i.p.s\n",
      "pricd\n",
      "watche\n",
      "on-point\n",
      "bookcon\n",
      "outse\n",
      "woowi\n",
      "phitos\n",
      "aircondi\n",
      "deliberatel\n",
      "recommendati\n",
      "staff/hard\n",
      "tolerat\n",
      "none-the-l\n",
      "unwe\n",
      "up-m\n",
      "learned-\n",
      "situtated\n",
      "wesgate\n",
      "-e\n",
      "eye/nest\n",
      ".yes\n",
      "greatm\n",
      "locstiin\n",
      "pre-arrrival\n",
      "relaxati\n",
      "aumiller\n",
      "ok..nothing\n",
      "caesartastic\n",
      "rhrough\n",
      "host/staff\n",
      "90ies\n",
      "corre√ß√£o\n",
      "franciscoi\n",
      "„Çø„Ç§„Éà„É´ÈÄö„Çä„ÄÅÂâçÊ≥ä„Å´‰Ωø„ÅÑ„Åæ„Åó„Åü„ÄÇ„Å™„ÅÆ„Åß„Ç´„Ç∏„Éé„Å™„Å©„ÇÇÂøÖË¶Å„Å™„Åó„ÄÇ\n",
      "~happy\n",
      "it.gr\n",
      "57st\n",
      "location/best\n",
      "better..\n",
      "disting\n",
      "stook\n",
      "drast\n",
      "empire-\n",
      "venetian..a.most\n",
      "-really-\n",
      "skylof\n",
      "servixe\n",
      "satyin\n",
      "..even\n",
      "vacationüòÑ\n",
      "continenta\n",
      "sataff-\n",
      "shmeasons\n",
      "talbo\n",
      "yuou\n",
      "temperture\n",
      "staff-nic\n",
      "bar/restau\n",
      "centrak\n",
      "goroom\n",
      "9yr\n",
      "gansevort\n",
      "winni\n",
      ".cheap\n",
      "desagradable\n",
      "here.we\n",
      "weenend\n",
      "everyrhin\n",
      "nycity\n",
      "hopfully\n",
      "fairm\n",
      ".check-i\n",
      "hotel/bad\n",
      "red/gr\n",
      "greete\n",
      "ashlei\n",
      "kampani\n",
      "convenintly\n",
      "pooland\n",
      "toxic/chemical\n",
      "trip.we\n",
      "edsion\n",
      "l-o-v-e-\n",
      "clarkstone\n",
      "ahotel\n",
      "amnenities\n",
      "pros+central\n",
      "****lo*c*a*t*i*o*n****\n",
      "ms.keys\n",
      "matur\n",
      "boutique-ish\n",
      "stevi\n",
      "gonner\n",
      "others-le\n",
      "acoomodations\n",
      "nutc\n",
      "..good\n",
      "routin\n",
      "tricholo\n",
      "proche\n",
      "un-personal\n",
      "equidit\n",
      "story-hotel\n",
      "enamou\n",
      "bellag\n",
      "convention/meeting\n",
      "property.lots\n",
      "chicago.this\n",
      "pooll\n",
      "challeng\n",
      "staff+room\n",
      "6.servic\n",
      "shoe-horned\n",
      "upbea\n",
      "well-delivered\n",
      "18yo\n",
      "bellig\n",
      "strip..by\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hotel..not\n",
      "stay.staff\n",
      "hotel-convient\n",
      "palmet\n",
      "not-so-posh\n",
      "recommend.everythi\n",
      "can¬¥\n",
      "leleand\n",
      "toliet\n",
      "mis-understanding\n",
      "outstanging\n",
      "sf..\n",
      "biggg\n",
      "comforrtable\n",
      "majest\n",
      "volun\n",
      "venient\n",
      "3/25/16-perfect\n",
      "kimptonink48\n",
      "people..would\n",
      ".its\n",
      "genereal\n",
      "staff-comfortable\n",
      "overfriendly\n",
      "poolage\n",
      "stay-well\n",
      "lovier\n",
      "england/ca\n",
      "vbegas\n",
      "tinis\n",
      "ruolluet\n",
      "econolodge\n",
      "just-about-there\n",
      "-undeniabl\n",
      "-DGDG/DG\n",
      "learningmate\n",
      "annaversary\n",
      "family/other\n",
      "2018g\n",
      "drawe\n",
      "spectacul\n",
      "always..a\n",
      "actuallly\n",
      "considerations..\n",
      "immedia\n",
      "entir\n",
      "rest-filled\n",
      "rio111\n",
      "clift-excellent\n",
      "packa\n",
      "staffi\n",
      "confererence\n",
      "marylynn\n",
      "comingg\n",
      "quality/toddler\n",
      "tweeking\n",
      "neighnourhood\n",
      "cwelch50\n",
      "walkies\n",
      "jun5-9\n",
      "24vhour\n",
      "de-humanization\n",
      "ttip\n",
      "hotel=\n",
      "fvery\n",
      "schoking\n",
      "hipster/i\n",
      "sigh-induc\n",
      "perks‚Ä¶\n",
      "hilton-\n",
      "coinci\n",
      "anovernight\n",
      "toptional\n",
      "hotwire.co\n",
      "deali\n",
      "wondeful\n",
      "ithis\n",
      "december/\n",
      "ourvdara\n",
      "egyptian-tastic\n",
      "value-priced\n",
      "stay-somewhat\n",
      "ÏúÑÏπòÍµø\n",
      "leisu\n",
      "DG+++\n",
      "sq-central\n",
      "locationbest\n",
      "l'core\n",
      "walkign\n",
      "expectationa\n",
      "hospit\n",
      "spoilled\n",
      "◊ë◊ó◊ï◊ù\n",
      "chic..that\n",
      "fundrasier\n",
      "pipe-\n",
      "view..service\n",
      "nabshow\n",
      "in-hospitable\n",
      "therepod\n",
      "s/caesar\n",
      "nycüá∫üá∏‚ù§Ô∏è\n",
      "cwmun\n",
      "staty\n",
      "location..especially\n",
      "usd575\n",
      "trevalyn\n",
      "spetacular\n",
      "palaz\n",
      "14-june\n",
      "month-both\n",
      "caesars..honest\n",
      "*san\n",
      "attening\n",
      "everyone.we\n",
      "wpuld\n",
      "..clean\n",
      "corporate-\n",
      "cost/confort\n",
      "alquraishi\n",
      "memorable..\n",
      "fragas\n",
      "spectaclular\n",
      "friendlliest\n",
      "wonderful-very\n",
      "tropicana~\n",
      "techno-dummies\n",
      "frine\n",
      "unkindly..\n",
      "tourin\n",
      "perfectly-located\n",
      "mondrain\n",
      "bed..\n",
      "eperiance\n",
      "extra-mile\n",
      "sculptur\n",
      "avalon.perfect\n",
      "adaggio\n",
      "mistown\n",
      "decid\n",
      "explorin\n",
      "1970¬¥s\n",
      "room.clean\n",
      "feb.1\n",
      "rroms\n",
      "piramyds\n",
      "celabration\n",
      "restuarant/bar\n",
      "coprporate\n",
      "conditioning-\n",
      "vancouv\n",
      "580/night\n",
      "vegasy\n",
      "hotel/rest\n",
      "wecoming\n",
      "informaton\n",
      "bemy\n",
      "currenly\n",
      "..ama\n",
      "lollapaloo\n",
      "l√§ge\n",
      "tahitti\n",
      "updgraded-\n",
      "msbc\n",
      "experioence\n",
      "locatation\n",
      "control4\n",
      "inn-pretty\n",
      "find-right\n",
      "musty**\n",
      "square/midto\n",
      "practicall\n",
      ".retirement\n",
      "people-great\n",
      "chateux\n",
      "intercons\n",
      "favou\n",
      "üëçüèªüëçüèªüëçüèª\n",
      "challenge/excellent\n",
      "barchelor\n",
      "comftable\n",
      "terrible/no\n",
      "delay-excellent\n",
      "underratedcasino\n",
      "exhi\n",
      "diasappoited\n",
      "phenomenous\n",
      "blackh\n",
      "service-spent\n",
      ".skip\n",
      "greeat\n",
      "dayclub/nightclub\n",
      "stinq\n",
      "prestigiou\n",
      ".if\n",
      "swiss√¥\n",
      "value-4-money\n",
      "super-comforta\n",
      "location\\nhotel\n",
      "-unc\n",
      "receptionish\n",
      "zurprises\n",
      "safe/enter\n",
      "dissapo8inted\n",
      "üò©\n",
      "may1\n",
      "whethe\n",
      "‚ù§ny\n",
      "singletree\n",
      "location-terrible\n",
      "********please\n",
      "healty\n",
      "joeman\n",
      "accomadatiom\n",
      "whatwe\n",
      "favoulous\n",
      "disapointed\n",
      "joke-\n",
      "fornwhat\n",
      "dreamfor\n",
      "inexpensiv\n",
      "stepso\n",
      "mansf\n",
      "accommodations+\n",
      "presidenti\n",
      ".laquinta\n",
      "1:30am\n",
      "ceacar\n",
      "jayso\n",
      "comfitable\n",
      "maitresse\n",
      "unconc\n",
      "friendly.the\n",
      "hayden-\n",
      "cooperfied\n",
      "everyway\n",
      "jenniferga\n",
      "localitzaci√≥\n",
      "in/o\n",
      "'t\n",
      "..staff\n",
      "visit.room\n",
      "staffclea\n",
      "motelüòÄ\n",
      "'touch\n",
      "son-in-la\n",
      "update-rock\n",
      "mccormi\n",
      "impeccab\n",
      "gracuation\n",
      "dollors\n",
      "silversm\n",
      "doorman/hotel\n",
      "notc\n",
      "pickup/dropoff\n",
      "clear-\n",
      "rest-\n",
      "exhau\n",
      "casino/conference\n",
      "arriving-\n",
      "i¬¥m\n",
      "..fred\n",
      "a++++++++\n",
      "roof-t\n",
      "after-stay\n",
      "loud-\n",
      "windgate\n",
      "egregiou\n",
      "‚ô•Ô∏è\n",
      "nyc.f\n",
      "nylo-nyc\n",
      "pre-party\n",
      "comfortable/great\n",
      "cleanning\n",
      "4-s\n",
      "-gone\n",
      "'lounge\n",
      "'forgetaboutit\n",
      "18thth\n",
      "value-minded\n",
      "adequate-affordable\n",
      "expierence\n",
      "Ÿàÿßÿ¨ÿßÿ≤Ÿá\n",
      "preponing\n",
      "affab\n",
      "view-wow\n",
      "wowwwwwwwwww\n",
      "negativ\n",
      "bedr\n",
      "roznieks\n",
      "wednesday-sat\n",
      "concierge/hospitality\n",
      "ceazars\n",
      "dissapointin\n",
      "walkim\n",
      "rayban\n",
      "stars.pros\n",
      "swaggy\n",
      "nlevinearnold\n",
      "over-praised\n",
      "specifie\n",
      "1-room\n",
      "visst\n",
      "underr\n",
      "tip-\n",
      "we'stayed\n",
      "quiiet\n",
      "locn\n",
      "sporti\n",
      "old-styl\n",
      "location/run\n",
      "hotel-negative\n",
      "summerlin/las\n",
      "rewar\n",
      "daughter-in-\n",
      "fantastiskt\n",
      "nearby-\n",
      "weekl\n",
      "brodway\n",
      "for..a\n",
      "eh-\n",
      "longshor\n",
      "worri\n",
      "inn-great\n",
      "'rocker\n",
      "experi\n",
      "undewhelming\n",
      "near-everything\n",
      "calcu\n",
      "rooms/fabulous\n",
      "virgosinvegas\n",
      "ecclectic\n",
      "entertainm\n",
      "stabdards\n",
      "enthusiastica\n",
      "sercurity\n",
      "under-the-rada\n",
      "vega-y\n",
      "bars/lobby\n",
      "bar-terr\n",
      "eound\n",
      "incomfortable\n",
      "complant\n",
      "4days\n",
      ",city\n",
      "restaurant/\n",
      "nights.perfect\n",
      "nud\n",
      "aaaammmaazing\n",
      "standard/qua\n",
      "algon\n",
      "..indifferent\n",
      "bellst\n",
      "location/neighborhood\n",
      "exto\n",
      "servicde\n",
      "shopping-st\n",
      "staff/location\n",
      "garanteed\n",
      "nacm\n",
      "best.staff\n",
      "coffee..\n",
      "remai\n",
      "34/night\n",
      "york/entral\n",
      "security/homeless\n",
      "daryls\n",
      "notr\n",
      "hotel..well\n",
      "vacanza\n",
      "hicks-\n",
      "thank-me\n",
      "‚òÜ‚òÜ‚òÜ‚òÜ‚òÜ\n",
      "soothi\n",
      "fair-ish\n",
      "howli\n",
      "cleanst\n",
      "sty-good\n",
      "ejoyed\n",
      "deff\n",
      "cusomter\n",
      "disetful\n",
      "nichele\n",
      "gem.the\n",
      "binions\n",
      "desired-spa\n",
      "wonderfull.bad\n",
      "river-facing\n",
      "allready\n",
      "booking.co\n",
      "windows/bal\n",
      "stress-fre\n",
      "nightttime\n",
      "n.ot\n",
      "siganture\n",
      "amazing.so\n",
      "unwelc\n",
      "tyhe\n",
      "dlje\n",
      "fine..i\n",
      "9night\n",
      "confusion/old\n",
      "scentsy\n",
      "road..\n",
      "emploees\n",
      "bathroom/\n",
      "freewa\n",
      "nicero\n",
      "reminiscint\n",
      "avearage\n",
      "1-hr\n",
      "tournament/\n",
      "review/update\n",
      "waay\n",
      "DGDG/DG-DG/DG\n",
      "sept.18\n",
      "atmoshphere\n",
      "booked.this\n",
      "elsewh\n",
      "fabo\n",
      "outl\n",
      "geniune\n",
      ".anyone\n",
      "Ïä§Ìä∏Î¶ΩÏóê\n",
      "co-w\n",
      "tyour\n",
      "goid\n",
      "eagle-soaring\n",
      "unhuman\n",
      "includi\n",
      "3801large\n",
      "city.we\n",
      ".recommended\n",
      "manhattan/midtown\n",
      "uuits\n",
      "5oth\n",
      "reconigze\n",
      "noisiness\n",
      "accomadate\n",
      "location/minor\n",
      "average/nice\n",
      "facility/big\n",
      "strip..but\n",
      "reasonably-priced\n",
      "amazing.prices\n",
      "birsk\n",
      "cabl\n",
      "weeking\n",
      "apartment-like\n",
      "hotel..all\n",
      "worthit\n",
      "poalce\n",
      "servise\n",
      "940am\n",
      "hotel/boutique\n",
      "incheckbalie\n",
      "comfortable..\n",
      "pleased-\n",
      "cigaret\n",
      "1:00am\n",
      "balag\n",
      "overpriced/small\n",
      "netowrk\n",
      "üòîvery\n",
      "üç∏no\n",
      "plann\n",
      "service/cleanliness\n",
      "negativeold\n",
      "smoke-fre\n",
      "hohell\n",
      "localiza√ßao\n",
      "klawson\n",
      "propbably\n",
      "locationgreat\n",
      "fantasticas\n",
      "sf10\n",
      "hoteck\n",
      "peacfully\n",
      "-he\n",
      "space/great\n",
      "casablanca-\n",
      "handerley\n",
      "tstsyred\n",
      "reduc\n",
      "four-plus\n",
      "üíã\n",
      "lameingo\n",
      "exceded\n",
      "yaaaaas\n",
      "disp\n",
      "woonderful\n",
      "..monte\n",
      ".free\n",
      "hotel-would\n",
      "horrendo\n",
      "servuve\n",
      "arrivai\n",
      "location-safety\n",
      "scohumacher\n",
      "Êúâ‰∫õÁÇíÔºå‰ΩÜÊàøÈñìÂæàÂ•ΩÂêÉÊù±Ë•øÔºå‰∏çÂ§úÂüéÔºåÂçäÂ§úËµ∞Ëëó‰πüË¶∫\n",
      "renovatio\n",
      "misleading/\n",
      ".hyatt\n",
      "hospeda\n",
      "offer-bring\n",
      "harraha\n",
      "vegas/ok\n",
      "wed-saturday\n",
      "üôèüòçüåπ\n",
      "eveeything\n",
      "from-the-movies\n",
      "conventient\n",
      "washers/drye\n",
      "squae\n",
      "orchar\n",
      "cupo\n",
      "louisian\n",
      "mah-velous\n",
      "beware-striking\n",
      "decentj\n",
      "nycc\n",
      "imprressive\n",
      "coffeemake\n",
      "xburlesque\n",
      "teasure\n",
      "st.patty\n",
      "frills'-\n",
      "sidnez\n",
      "godeluxe\n",
      "destinat\n",
      "üò©üò©üò©üò©üò©üò©\n",
      "delario\n",
      "room..staff\n",
      "excellenent\n",
      "looko\n",
      "faultering\n",
      "celebra\n",
      "hotel-terrific\n",
      "curtans\n",
      "hyatt-but-please\n",
      "‚Äîcentrally\n",
      "location-room\n",
      "shavonne\n",
      "termi\n",
      "..thanks\n",
      "ventilatio\n",
      "rmoney\n",
      "caersa\n",
      "empoyees\n",
      "interview/look\n",
      "jan2015\n",
      "nice/mo\n",
      "friendly/helpu\n",
      "s.f\n",
      "fun/joyful\n",
      "art/science\n",
      "jobelle\n",
      "careful***\n",
      "üíÉüíÉ\n",
      "boking\n",
      "2-queen\n",
      "location/small\n",
      "pawnstars\n",
      "belfas\n",
      "grand-west\n",
      "staff.2\n",
      "convenietly\n",
      "1030ish\n",
      "..complimentary\n",
      "winerie\n",
      "service-as\n",
      "westhouse\n",
      "twen\n",
      "ahh..\n",
      "not-so-hidden\n",
      "stay-supberb\n",
      "ifandrew\n",
      "immediat\n",
      "disigned\n",
      ".big\n",
      "hawkinswe\n",
      "amenabl\n",
      "glamou\n",
      "strugg\n",
      "steri\n",
      "rude/uninformed\n",
      "consstayed\n",
      "familly\n",
      "resort/las\n",
      "malfunc\n",
      "minitue\n",
      "fab..hotel\n",
      "decision..\n",
      "good-depends\n",
      "researche\n",
      "nyci\n",
      "in..easy\n",
      "wayy\n",
      "westsidee\n",
      "moth-infested\n",
      "absoulte\n",
      "makeo\n",
      "exelant\n",
      "..none\n",
      "worcation\n",
      "jml3\n",
      "bacherolette\n",
      "negive\n",
      "tree/creme\n",
      "luxrious\n",
      "occas\n",
      "abhorent\n",
      "mettings/stay\n",
      "failt\n",
      "saquare\n",
      "'facade\n",
      "DGDG/DG-DGDG/\n",
      "happy/friendly/hardworking\n",
      "shrya\n",
      "blkdiamond\n",
      "mod/industrial\n",
      "there..it\n",
      "location-best\n",
      "unhelp\n",
      "cindys\n",
      "..j\n",
      "-almost-\n",
      "me/my\n",
      "room/sports\n",
      "price/valie\n",
      "excruciatingl\n",
      "occup\n",
      "negitive\n",
      "recieptionist\n",
      "rosno\n",
      "unconventi\n",
      "knowledgeab\n",
      "rooms.friendly\n",
      "consruction\n",
      "general1\n",
      "300+/night\n",
      "about.boo\n",
      "fiilings\n",
      "hotel.perfect\n",
      "shoppi\n",
      "palazz\n",
      "marathon/birthday\n",
      "-gambling\n",
      "theift\n",
      "immensley\n",
      "could'nt\n",
      "outstandding\n",
      "glops\n",
      "want2seeall\n",
      "5-n\n",
      "holid\n",
      "looked/f\n",
      "bawbags\n",
      "amusem\n",
      "funnes\n",
      "september/\n",
      "overpack\n",
      "surviv\n",
      "worldwid\n",
      "chetta-sechi\n",
      "ceasares\n",
      "fun/hip\n",
      "better/more\n",
      "neilio\n",
      "night/t\n",
      "superzoo\n",
      "gershberg\n",
      "hotel.good\n",
      "unpro\n",
      "confrence/\n",
      "show-boat\n",
      "glor\n",
      "staypineapple\n",
      "confirma\n",
      "atractions\n",
      "viaggi\n",
      "odds/good\n",
      "cosmopoliton\n",
      "forjust\n",
      ".kinda\n",
      "twogeriatics\n",
      "overcrowed\n",
      "bohemien\n",
      "*****five\n",
      "location.fantastic\n",
      "mall..\n",
      "kettering/vacation\n",
      "flashin\n",
      "rodgers-new\n",
      "chairman/presidents\n",
      ".DGDG.DGDG\n",
      "aria=fantastic\n",
      "brooken\n",
      "great.not\n",
      "trepidati\n",
      "285/night\n",
      "..do\n",
      "funky-cool\n",
      "-opposite\n",
      "boutiquie\n",
      "wynn'n\n",
      "exquisit\n",
      "excelleny\n",
      "noise/perfect\n",
      "fantastic-spacious\n",
      "caesras\n",
      "skatin\n",
      "modern-elegant\n",
      "collassals\n",
      "mmodernized\n",
      "arival\n",
      "vegas.we\n",
      "parkf\n",
      "performance/missteps\n",
      "kncki\n",
      "concerge\n",
      ".nothing\n",
      "reservations.com\n",
      "business-orientated\n",
      "effec\n",
      "calebro-kuder\n",
      "staffe\n",
      "owni\n",
      "2xqueen\n",
      "business..\n",
      "pros*great\n",
      "6-type\n",
      "greeaatt\n",
      "westga\n",
      "entrance..\n",
      "fashional\n",
      "0.th\n",
      "stressy\n",
      "recommend.great\n",
      "allowa\n",
      "coopera\n",
      "exciting..fun\n",
      "'ok\n",
      "price-location\n",
      "mini-suite\n",
      "morticai\n",
      "reapon\n",
      "woof-ka\n",
      "6:30a\n",
      "wow.i\n",
      "gallery/museum\n",
      "comofr\n",
      "blacktienotie\n",
      "rude/terrible\n",
      "amazaing\n",
      "price-performance-ratio\n",
      "vacay/business\n",
      "cost/quality\n",
      "carrin\n",
      "prized-\n",
      "agreable\n",
      "ada-\n",
      "snow-day\n",
      "ttrip\n",
      "bed/mattress\n",
      "marcien\n",
      "reviews..average\n",
      "thiis\n",
      "delighters\n",
      "caricon\n",
      "-line\n",
      "groc\n",
      "Ë±™ËèØ„Å™Ê∞óÂàÜ„Å´Êµ∏„Çå„Åæ„Åô\n",
      "california-july\n",
      "withi\n",
      "propery\n",
      "newto\n",
      "impressions..\n",
      "diva-licious\n",
      "hotel..unhappy\n",
      "commiss\n",
      "basic‚Ä¶\n",
      "good-but\n",
      "nabilia\n",
      "yite\n",
      "champag\n",
      "dirthy\n",
      "stsff\n",
      "wadas\n",
      "dedicided\n",
      "jewlers\n",
      "mid-high\n",
      "favaorite\n",
      "campto\n",
      "balley\n",
      "unpara\n",
      "clean..great\n",
      "vegas2\n",
      "plus..\n",
      "dahlback\n",
      "17th-\n",
      "robby-\n",
      "down-\n",
      "everywhere_for\n",
      "flamingdo\n",
      "waaayyyyy\n",
      "libati\n",
      "10:30pm\n",
      "stylebest\n",
      "travel-family\n",
      "1sr\n",
      "anyo\n",
      "budget..\n",
      "summer2015\n",
      "room-simple\n",
      "loveluxor\n",
      "check-in.queued\n",
      "prices..\n",
      "üíú\n",
      "deal/great\n",
      "havng\n",
      "victor/marie\n",
      "eternizing\n",
      "soho-cool-hotel\n",
      "recentley\n",
      "visiting/sightseein\n",
      "extraordinay\n",
      "/noisy\n",
      "staff.-\n",
      "resor5\n",
      "plghace\n",
      "kdog\n",
      "üëë\n",
      "sahulcik\n",
      "hubbie\n",
      "thisn\n",
      "handwritt\n",
      "blemis\n",
      "great/david\n",
      "service..toped\n",
      "greatj\n",
      "where/what/price\n",
      "square/grand\n",
      "yeah.so\n",
      "bigggg\n",
      "subt\n",
      "attived\n",
      "relaxtion\n",
      "hmmmm..\n",
      "4202-deluxe\n",
      "hyv√§\n",
      "saw..\n",
      "sixte\n",
      "rooms/interior\n",
      "japanto\n",
      "transp\n",
      "us-but\n",
      "buillding\n",
      "suite\\ngreat\n",
      "servicegood\n",
      "amaaaaaaaazing\n",
      "w.great\n",
      "sls-still\n",
      "nyers\n",
      "1928when\n",
      "xpole\n",
      "impecabl\n",
      "bathi\n",
      "doorste\n",
      "hyatt-chicago\n",
      "non-downtown\n",
      "üíí\n",
      "48t\n",
      "friendly=\n",
      "teeny-tiny\n",
      "neighborin\n",
      "particularl\n",
      "central/downtown\n",
      "e-check\n",
      "four-poster\n",
      "vegasno\n",
      "unfami\n",
      "price-convenient\n",
      "pre-stay\n",
      "greatfully\n",
      "stayy\n",
      "eveyln\n",
      "outting\n",
      "terrible/avoid\n",
      "tourists..30\n",
      "flamingling\n",
      "wkend\n",
      "hitc\n",
      "trip.everything\n",
      "ofered\n",
      "answere\n",
      "crowdie\n",
      "quslity\n",
      "summer/wsop\n",
      "high-range\n",
      "average-rated\n",
      "price-nice\n",
      "boutique-hotel\n",
      "main/public\n",
      "rewiew\n",
      "waterfr\n",
      "perpis\n",
      "viabrant\n",
      "tournamnet\n",
      "suites-chicago\n",
      "dishwash\n",
      "regardl\n",
      "outdi\n",
      "garidelli\n",
      "starw\n",
      "rain-like\n",
      "'premie\n",
      "flaza\n",
      "shampoo/conditioner/soap\n",
      "squer\n",
      "roll-themed\n",
      "downside-\n",
      "suburbanit\n",
      "claustrophia\n",
      "situatedstaff\n",
      "zarkana\n",
      "theater/midtown\n",
      "affordable/comfortable\n",
      "clean/staff\n",
      "rooms./gaming\n",
      "delish\n",
      "nevr\n",
      "beautifu\n",
      "qyality\n",
      "instea\n",
      "familu\n",
      "non-descri\n",
      "anddddd\n",
      "2bath\n",
      "up.great\n",
      "event.the\n",
      "stilverynice\n",
      "'far\n",
      "c.c\n",
      "adver\n",
      "cirus\n",
      "coments\n",
      "thanks.my\n",
      "jarlin\n",
      "clean/non\n",
      "thank-yous\n",
      "fimzie\n",
      "whatso\n",
      "chancell\n",
      "high-r\n",
      "chicagotraveller\n",
      ".where\n",
      "vacation.we\n",
      "at16\n",
      "downt\n",
      "sohotel.there\n",
      "DG.DG-DG.DG\n",
      "brokei\n",
      "property/good\n",
      "trumpific\n",
      "Í∞ÄÍ≤©ÎåÄÎäî\n",
      "expereice\n",
      "pre-bo\n",
      "steven-event\n",
      "night.location\n",
      "hospital-\n",
      "beatuiful\n",
      "-reasonable\n",
      "intransparente\n",
      "followthru\n",
      "verdic\n",
      "seferi\n",
      "offre\n",
      "bachellor\n",
      "disappointing.no\n",
      "DGDG.DGDG.DGDG.\n",
      "iun\n",
      "8:30-9:00pm\n",
      ",very\n",
      "hotel.right\n",
      "conveneant\n",
      "wonderful.the\n",
      "uniqu\n",
      "jeanieb\n",
      "overnight-ed\n",
      "17-20th\n",
      "here.my\n",
      "quality/luxury\n",
      "breaffast\n",
      "black-windowed\n",
      "‚Ä¢\n",
      "food/b\n",
      "330pm\n",
      "marckesano\n",
      "c2e2\n",
      "vegus\n",
      "recreatin\n",
      "pros/\n",
      "bellaigo\n",
      "fwy\n",
      "plalace\n",
      "posh..\n",
      "suggest-\n",
      "soho/lower\n",
      "cleant\n",
      "palazzzo\n",
      "money-even\n",
      "offcourse\n",
      "cost-benefict\n",
      "pricefail\n",
      "price/location/value\n",
      "+/+fresh\n",
      "w/fami\n",
      "hotelroom\n",
      "chuckb\n",
      "bitiqy\n",
      "continuin\n",
      "money„ÄÇ\n",
      "reaort\n",
      "yeshaira\n",
      "aircondioner\n",
      "staff/location/accommodations\n",
      "niyce\n",
      "va\\gas\n",
      "experiwnce\n",
      "trrrible\n",
      "gataway\n",
      "two-and\n",
      "casino=no\n",
      "appli\n",
      "downit\n",
      "vegas/red\n",
      "DGDGDGDGDG.DGDG\n",
      "smoke.the\n",
      "likeacaesar\n",
      "re-oponed\n",
      "‰æøÂà©„ÅßÊ∏ÖÊΩî\n",
      "quality/cost\n",
      "minib\n",
      "-herald\n",
      "awesomenss\n",
      "implem\n",
      "reviews-\n",
      "hotel.waiting\n",
      "hotelvegas\n",
      "DG/DGDG/DGDGDGDG-DG/DG/DGDGDGDG\n",
      "moneylo\n",
      "delicous\n",
      "ambassador/advocate\n",
      "docusig\n",
      "appeare\n",
      "spanish/crafts\n",
      "Ìé∏Î¶¨Ìï®\n",
      "centter\n",
      "scho\n",
      "hotel-not\n",
      "webloved\n",
      "go-\n",
      "shouldnt\n",
      "resourt\n",
      "surroun\n",
      "weekend/hotel\n",
      "hotelgorgeou\n",
      "tooo\n",
      "pagent\n",
      "dont't\n",
      "seemless\n",
      "bazzone\n",
      "universit\n",
      "service-telephone\n",
      "strip..authentic\n",
      "rasly\n",
      "2018on\n",
      "DG++\n",
      "seriousl\n",
      "stay.easy\n",
      "schoo\n",
      "congre\n",
      "betond\n",
      "corpor\n",
      "condo-type\n",
      "lobbyrooms\n",
      "maintained.the\n",
      "otel\n",
      "experianc\n",
      "checked-\n",
      "citoy\n",
      "nice.security\n",
      "industrial/boutique\n",
      "difference-your\n",
      "fahter\n",
      "illeava\n",
      "inn/rude\n",
      "tech-heavy\n",
      "ti.e\n",
      "off-price\n",
      "sigh..\n",
      "exquiste\n",
      "eveni\n",
      "argonaughty\n",
      "*i\n",
      "bakasyon\n",
      "infle\n",
      "nonsm\n",
      "correc\n",
      "yhis\n",
      "usabmx\n",
      "manhat\n",
      "asupurb\n",
      "DG/DGDG/DGDG\n",
      "special-people\n",
      "homw\n",
      "re-occuring\n",
      "nandranie\n",
      "mindüéπüéºüé∑\n",
      "pleasant.host\n",
      "glorydays\n",
      "enoyable\n",
      "..period\n",
      "thanksgivin\n",
      "christmas/\n",
      "ataff\n",
      "instagr\n",
      "south-of-the-strip\n",
      "knov\n",
      "october.ro\n",
      "marriotti\n",
      "fabtastic\n",
      "checkgrea\n",
      "ceassr\n",
      "square/central\n",
      "fairfield/financia\n",
      "7yr\n",
      "barn-door\n",
      "mininimalist\n",
      "excitemen\n",
      "hiotel\n",
      "comparitively\n",
      "reburb\n",
      "mothers/daughters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bride/gro\n",
      "proact\n",
      "fun.wa\n",
      "sophi\n",
      "burgu\n",
      "venuefor\n",
      "born/raised\n",
      "amanzing\n",
      ".maybe\n",
      "anticipa\n",
      "central-ish\n",
      "impeccabl\n",
      "vacaction\n",
      "chicsgo\n",
      "cromw\n",
      "recoment\n",
      "staycat\n",
      "ughhhh\n",
      "negotiat\n",
      "–æ—Ç–µ–ª—å\n",
      "fantastic‚Äîac\n",
      "park.\n",
      "2days.it\n",
      "aminities\n",
      "palace-november\n",
      "staybig\n",
      "greatservice\n",
      "ipanem\n",
      "location-review\n",
      "cssino\n",
      "nearby-t\n",
      "eight-con\n",
      "breez\n",
      "DGDG-DG\n",
      "purel\n",
      "azcochon\n",
      "loop-\n",
      "perfect/convenient\n",
      "tryi\n",
      "signature-\n",
      "multi-age\n",
      "days.if\n",
      "guac\n",
      "-an\n",
      "w/daughter\n",
      "traveler/neighborhood\n",
      "getawawy\n",
      "disapppointed\n",
      "unsu\n",
      "food-great\n",
      "/minnesota\n",
      "convnient\n",
      "location-excellent\n",
      ".baby\n",
      "i'ved\n",
      "imts0918\n",
      "paris-be\n",
      "sofitel-live\n",
      "hackasan\n",
      "huuuuge\n",
      "mixt\n",
      "2month\n",
      "unreasonalbe\n",
      "new/very\n",
      "mustava\n",
      "coloardo\n",
      "Ï¢ãÏùÄÍ±¥\n",
      "near/or\n",
      "‚ûñ\n",
      "'vegas\n",
      "detractions\n",
      "co-ed/\n",
      "accesab\n",
      "experience.cool\n",
      "unedible\n",
      "daysphone\n",
      "hotelrom\n",
      "manhatttan\n",
      "flamindon'tgo\n",
      "dacoer\n",
      "waiters/waitresses\n",
      "check-in/chck-out\n",
      "christma\n",
      "hotel.ve\n",
      "diffent\n",
      "do/see\n",
      "staff-we\n",
      "view/service\n",
      "squick\n",
      "delatorre\n",
      "early-year\n",
      "double-e\n",
      "key'ed\n",
      ".DG/DGDG\n",
      "waste-gate\n",
      "hapmton\n",
      "2st\n",
      "imats\n",
      "stay..very\n",
      "service/size\n",
      "patinium\n",
      "2000.afte\n",
      "turne\n",
      "tail-rip\n",
      "allneeds\n",
      "greatn\n",
      "e28\n",
      "imposi\n",
      "montrial\n",
      "1-heating\n",
      "bashair\n",
      "-had\n",
      "it-\n",
      "fantatsic\n",
      "dinesha\n",
      "inc48\n",
      "trip.as\n",
      "thermost\n",
      "stay-cation/getaway\n",
      "durty\n",
      "impressed..terrible\n",
      "redrocks\n",
      "confus\n",
      "w/privacy\n",
      "quicktrip\n",
      "overnit\n",
      "travelbag\n",
      "sdtaff\n",
      "gradulation\n",
      "hands-\n",
      "nannied\n",
      "semi-dodgy\n",
      "nice.the\n",
      "chic/sexy\n",
      "hotel.friendly\n",
      "autom\n",
      "resti\n",
      "price/performance\n",
      "5thstay\n",
      "traveller-\n",
      "2,5km\n",
      "798.ro\n",
      "reception/lobby\n",
      "waitr\n",
      "filini\n",
      "for3\n",
      "nyc-a\n",
      "bravo~\n",
      "hitek\n",
      "‚úÖ\n",
      "insufficien\n",
      "ecperience\n",
      "havibg\n",
      "üèà\n",
      "style/price\n",
      "extraord\n",
      "grammercy\n",
      "harbo\n",
      "convenienc\n",
      "anotherwise\n",
      "over-exceeded\n",
      "looooong\n",
      "hayd\n",
      "oversells\n",
      "excellent.cautio\n",
      "amzaing\n",
      "things:1\n",
      "aude-line\n",
      "tedius\n",
      "steepe\n",
      "untra\n",
      "kysos-\n",
      "jbfrommi\n",
      "old/modern\n",
      "iÃánsufficient\n",
      "qunitastic\n",
      "misleadi\n",
      "apartment-l\n",
      "Ëá™Áî±„ÅÆÂ•≥Á•û„Å®„É™„ÉÉ„ÉÑ„Ç´„Éº„É´„Éà„É≥\n",
      "point-perfect\n",
      "two-\n",
      "housekeeeping\n",
      "cofffeeman\n",
      "time-excellent\n",
      "day/\n",
      "+speechless\n",
      "perfect.best\n",
      "ordi\n",
      "clubbin\n",
      "thompson10\n",
      "tusc\n",
      "outstanding.r\n",
      "m√∫ltiples\n",
      "locaton\n",
      "vegan-friendly\n",
      "vacation/wedding\n",
      "up-graded\n",
      "ugly..\n",
      "weekend-great\n",
      "ellegant\n",
      "vacaycay\n",
      "prol\n",
      "fleischacker\n",
      "bevera\n",
      "incide\n",
      "rught\n",
      "non-i\n",
      "tomstay\n",
      "door/wall\n",
      "attentitve\n",
      "aug.15-18th\n",
      "inconven\n",
      "boystown/lincoln\n",
      "menopa\n",
      "üôèüèæ\n",
      "maratho\n",
      "cassablanca\n",
      "clifting\n",
      "amazing-they\n",
      "phenomen\n",
      "encor\n",
      "fun/friendly\n",
      "obrigada\n",
      "accroas\n",
      "tech/business\n",
      "enjoyed.our\n",
      "greeter/bellman\n",
      "carltion\n",
      "gustavi\n",
      "7t\n",
      "one-stop-\n",
      "park/chicago\n",
      "deversey\n",
      "befd\n",
      "heywood18\n",
      "**amazing\n",
      "'do\n",
      "luxoriou\n",
      "cancellttion\n",
      "palace-\n",
      "hotels.w\n",
      "paris/vegas\n",
      "ducks/\n",
      "yes-bu\n",
      "/awe\n",
      "and/o\n",
      "crowds.excellen\n",
      "okeydokey\n",
      "packages/\n",
      "euro-elegance\n",
      "2block\n",
      "unfortun\n",
      "scrummy\n",
      "ambienc\n",
      "marina/union\n",
      "back..already\n",
      "friday-saturday-sunday\n",
      "perfe√ßt\n",
      "hotel/resort/casino\n",
      "alri\n",
      "vagas\n",
      "chatwa\n",
      "in.g\n",
      "good..the\n",
      "familiary\n",
      "lighting/layout\n",
      "departu\n",
      ".mediocre\n",
      "rome/vegas\n",
      "day/two\n",
      "dions\n",
      "dissapo\n",
      "embarca\n",
      "anothet\n",
      "cockr\n",
      "'perfect\n",
      "people=more\n",
      "investmen\n",
      "i'ts\n",
      "standard..\n",
      "hootel\n",
      "*shrugs*\n",
      "couldve\n",
      "wynn-a\n",
      "convenioently\n",
      "inkeeper\n",
      "initi\n",
      "vanitys\n",
      "unvalued\n",
      "medioc\n",
      "..very\n",
      "anniversary+raw\n",
      "vactions\n",
      "'nyc\n",
      "fror\n",
      "roomüëç\n",
      "exquisi\n",
      ".disappointed\n",
      "..that\n",
      "omarivania\n",
      "screenrn\n",
      ".59st\n",
      "pre-visit\n",
      "porperty\n",
      "hotel.13\n",
      "shic\n",
      "clean-tid\n",
      "finincial\n",
      "nice.grea\n",
      "deracted\n",
      "safe/clean\n",
      "breakfast..\n",
      "location-right\n",
      "chelesa\n",
      "pool/waterslide\n",
      "famliy\n",
      "klienfelds\n",
      "showssnack\n",
      "crampe\n",
      "repeatedl\n",
      "DG/DG‚≠êÔ∏è\n",
      "hotelüòÉ\n",
      "nights.arrived\n",
      "worse‚Äã\n",
      "frivelous\n",
      "staffstrong\n",
      "process/staff\n",
      "annivserary\n",
      "iesha\n",
      "mandlay\n",
      "'premier\n",
      "horrend\n",
      "-things\n",
      "ever1\n",
      "a++++++\n",
      "refrigirator\n",
      "vibe/environment\n",
      "t√•rn\n",
      "id√©al\n",
      "spacios\n",
      "seminar.hyat\n",
      "s-era\n",
      "service..hotel\n",
      "looing\n",
      "hotel.big\n",
      "gracfully\n",
      "pozesky\n",
      "service..great\n",
      "horrible..\n",
      "thorins\n",
      "jurgielewicz\n",
      "**fyi\n",
      "hotelf\n",
      "diferent\n",
      "promoti\n",
      "weat\n",
      "at.\n",
      "annul√©e\n",
      "trjp\n",
      "amazing..location..so\n",
      "expedi\n",
      "vcay\n",
      "amzaming\n",
      "üçé\n",
      "loveeed\n",
      "da-bomb.com\n",
      "DGDGDG/\n",
      "location-\n",
      "-near\n",
      "non-chain\n",
      "dissappointe\n",
      "cocktail/housekeepin\n",
      "bridgel\n",
      "loud/party\n",
      "perefect\n",
      "price-worthy\n",
      "graaaaand\n",
      "antiq\n",
      "derek=awesome\n",
      "service/comminication\n",
      "wallpap\n",
      "privatebank\n",
      "2brm\n",
      "returned.we\n",
      "accomodating-business\n",
      ".nice\n",
      "hotelas\n",
      "waterfron\n",
      "biz/\n",
      "1304rooms\n",
      "2017the\n",
      "else..cold\n",
      "people/wonderfully\n",
      "fosho\n",
      "daytripper\n",
      "nycer\n",
      "city-view\n",
      "desk/workspace\n",
      "location/history\n",
      "'l\n",
      "enthusisastic\n",
      "in.it\n",
      "furiou\n",
      "extravganza\n",
      "huuuge\n",
      "lmpeccable\n",
      "rio-\n",
      "jakiya\n",
      "nearl\n",
      "lsr321\n",
      "12-30/1-1-2017cracked\n",
      "zelos-\n",
      "nautically-\n",
      "buffet/harrah\n",
      "portrade\n",
      "w/hilton\n",
      "stumbl\n",
      "circuscircus\n",
      "parkc\n",
      "j√©ssica\n",
      "perfekt\n",
      "stoled\n",
      "not-so-nice\n",
      "unfortu\n",
      "right.gr\n",
      "perfekt..but\n",
      "amiabl\n",
      "disreppair\n",
      "2ba\n",
      "wymm\n",
      "elfinesce\n",
      "ciaio\n",
      "wewe\n",
      "confrence\n",
      "hereüê©\n",
      "flight-\n",
      "room+excellent\n",
      "üéÑüéÖüèª\n",
      "agradecimento\n",
      "disgusting-\n",
      "protel\n",
      "'babymoon\n",
      "pet-frien\n",
      "manhatten\n",
      "greatess\n",
      "bathtu\n",
      "harrahsloved\n",
      "-just\n",
      "directl\n",
      "1:45pm\n",
      "overha\n",
      ".o\n",
      "spendor\n",
      "teading\n",
      "inkmy\n",
      "tamei\n",
      "eventi‚Äîwh\n",
      "concet\n",
      "hotel-staff-location-stay\n",
      "dissappoined\n",
      "ny/vegas\n",
      "wunderful\n",
      "wingat\n",
      "üëçüèºüëçüèº\n",
      "musky-smell\n",
      "pros-casino\n",
      "location-fabulous\n",
      "catere\n",
      "eleglance\n",
      "ravenswood/andersonville\n",
      "aaaaah-mazing\n",
      "vegas2015\n",
      "book-lover\n",
      "holidays-100617-150617\n",
      "brrrrrrrrrr\n",
      "accommadating\n",
      "flaming-no\n",
      "flimingos\n",
      "exhausti\n",
      "parefect\n",
      "architec\n",
      "smapiece\n",
      "..yes\n",
      "chts\n",
      "boyfrend\n",
      "propertywith\n",
      "strenghts\n",
      "vsiting\n",
      "promtions\n",
      "mid-novemb\n",
      "wellservice\n",
      "hotel-we\n",
      "decible\n",
      ".crazy\n",
      "imaginati\n",
      "pric\n",
      "4.00.pm\n",
      "again.\n",
      "time/hote\n",
      "'DGDGDGDG\n",
      "meatpac\n",
      "way//called\n",
      "earplu\n",
      "searc\n",
      "hidde\n",
      "best.trip.ever\n",
      "satisfacti\n",
      "pamperin\n",
      "value/view\n",
      "looooovvvve\n",
      "boutique-i\n",
      "unforg\n",
      "april-get-away\n",
      "resort-awesome\n",
      "üôåüèΩ\n",
      "bachelor/\n",
      "onstrip\n",
      "conferance\n",
      "prosstaff\n",
      "pool.they\n",
      "◊û◊¢◊ï◊ú◊î\n",
      "'meh\n",
      "aftet\n",
      "great.de\n",
      "vacation.the\n",
      "9t\n",
      "resem\n",
      "wall-no\n",
      "nights/2d\n",
      "myma\n",
      "dubiou\n",
      "yoork\n",
      "basic..\n",
      "time‚Ä¶\n",
      "hardro\n",
      "febarrivalmet\n",
      "hellowe\n",
      "hotel/concierge\n",
      "trv-isco2017\n",
      "manattan\n",
      "ayone\n",
      "understaffe\n",
      "blacksher\n",
      "comforytable\n",
      "naturall\n",
      "old/new\n",
      "quaity\n",
      "location/excellent\n",
      "unacceptabl\n",
      "wakling\n",
      "weeknesses\n",
      "amest\n",
      "ungla\n",
      "remodeling.√†\n",
      "holtel\n",
      "overmarketed\n",
      "okaysis\n",
      "webpa\n",
      "value/budget\n",
      "stripwa\n",
      "fashione\n",
      "evrithing\n",
      "helpfu\n",
      "affordable-\n",
      "tournemant\n",
      "horrefull\n",
      "flamingno\n",
      "20/day\n",
      "mgm-special\n",
      "enjoyÔºÅÔºÅ\n",
      "tr√©s\n",
      "chille\n",
      "thatt\n",
      "fremo\n",
      "providin\n",
      "w41\n",
      "hfma\n",
      "unprofes\n",
      "nugge\n",
      "luxortrip\n",
      "pros‚Äî\n",
      "extas\n",
      "wynn/en\n",
      "marusi\n",
      "staff-biggest\n",
      "wfii\n",
      "long-\n",
      "pliantly\n",
      "hoove\n",
      "impresse\n",
      "fleischacker/flamingo\n",
      "responsib\n",
      "„Å©„Åì„Å´Ë°å„Åè„Å´„ÇÇ‰æøÂà©„Å™Á´ãÂú∞„Åß„ÄÅ„Éõ„ÉÜ„É´„Çπ„Çø„ÉÉ„Éï„ÇÇ„Éï„É¨„É≥„Éâ„É™„Éº\n",
      "aweeome\n",
      "beliago\n",
      "after-checkout\n",
      "spacieuse\n",
      "28booked\n",
      "marquis-great\n",
      "davvero\n",
      "swtich\n",
      "yuork\n",
      "desparation\n",
      "strivin\n",
      "ambassa\n",
      "bright-\n",
      "north-shore\n",
      "claustr\n",
      "-should-\n",
      "sraff\n",
      "DG.DGDG.DGDG-DG.DGDG.DGDG\n",
      "faie\n",
      "topno\n",
      "week-l\n",
      "a+++\n",
      "ferien\n",
      "satrs\n",
      "wynn\\encore\n",
      "hgvc1\n",
      "exempl\n",
      "row.is\n",
      "life..\n",
      "clsds\n",
      "room-n\n",
      "up-to-\n",
      "runied\n",
      "editon\n",
      "circumsta\n",
      "rapheal\n",
      "experience-ruined\n",
      ".but\n",
      "strip/\n",
      "hotel.well\n",
      "well-decorated\n",
      ".chec\n",
      "stripthe\n",
      "'happen\n",
      "prosoutstand\n",
      "public-ly\n",
      "applein\n",
      "coupke\n",
      "2cnd\n",
      "luxar\n",
      "901p\n",
      "before-during\n",
      "5stars\n",
      "rooms..really\n",
      "gansevoor\n",
      "hotel..or\n",
      "308/5000i\n",
      "centraly\n",
      "republ\n",
      "extraordi\n",
      "laug\n",
      "kmahine\n",
      "free/casino\n",
      "idean\n",
      "unneces\n",
      "jack-hammmering\n",
      "tekit\n",
      "daddyberrys\n",
      "desination\n",
      ".allow\n",
      "cleanhotel\n",
      "bonkersness\n",
      "housely\n",
      "wow..what\n",
      "60thanniversary/father\n",
      "expectedto\n",
      "cons-rooms\n",
      "business/leis\n",
      "sefcurity\n",
      "try..\n",
      "-cost-\n",
      "beuatifull\n",
      "authorit\n",
      "cut-back\n",
      "marrake\n",
      "cambria-chelsea\n",
      ".fabulous\n",
      "üëéüèª\n",
      "begin..the\n",
      "refrigera\n",
      "palace..beautiful\n",
      "fiind\n",
      "2weeks\n",
      "whw\n",
      "regsitration\n",
      "hhhyyyuyyyyyyyyyygtttg\n",
      "nyc..first\n",
      "nutsh\n",
      "5*pluses\n",
      "property-refurbished\n",
      "location.r\n",
      "aniniversary\n",
      "birthday/super\n",
      "23-30th\n",
      "immaculatel\n",
      "hotel.staf\n",
      "everq\n",
      "location/accomodations/food\n",
      "calsberg\n",
      "voluntee\n",
      "hoteluse\n",
      "****aaa\n",
      "not-so-good\n",
      "aria=\n",
      "a-/b+\n",
      "laquita\n",
      "am-az-ing\n",
      "llove\n",
      "skeevy\n",
      "DG/DG/DG\n",
      "valu√©\n",
      "pre-co\n",
      "place/excellent\n",
      "7y\n",
      "mulb\n",
      ".tast\n",
      "lighting/\n",
      "awe3some\n",
      "design/amenities/staff\n",
      "oupricing\n",
      "unschedul\n",
      "2015-mayweather/paquio\n",
      "sewag\n",
      "lisa.ashley\n",
      "stylishes\n",
      "interta\n",
      "getaway/vacation\n",
      "pennsylvania-\n",
      "cityce\n",
      "molster\n",
      "perfect1\n",
      "cardhol\n",
      "nobleden\n",
      "wynnworld\n",
      "griffdog\n",
      "athl\n",
      "ashl\n",
      "room/roof\n",
      "chicargo\n",
      "bilyana\n",
      "small..\n",
      "fantatstic\n",
      "stinki\n",
      "ratison\n",
      "friendly/\n",
      "indigo-go-go\n",
      "ubicacions\n",
      "galm\n",
      "beware-go\n",
      "dimonds\n",
      "toursits\n",
      "service-horrible\n",
      "disappointed~\n",
      "'shinning\n",
      "..usually\n",
      "mohamaad\n",
      "iroqouo\n",
      "gread\n",
      "donot\n",
      "mgm..\n",
      "tajness\n",
      "loacation\n",
      "location+great\n",
      "lusury\n",
      "whene\n",
      "villageis\n",
      "entertainmen\n",
      "cartwr\n",
      "cityüíé\n",
      "overworke\n",
      "servicemin\n",
      "expectacular\n",
      "toughtfullness\n",
      "checkboxes\n",
      "network-\n",
      "dog-\n",
      "-end\n",
      "68/night\n",
      "three.dec\n",
      "nyv\n",
      "6-8am\n",
      "stifing\n",
      "clean-updated\n",
      "-DGDG/DGDG\n",
      "perfect~\n",
      "clean.cent\n",
      "stay-va\n",
      "pluses1\n",
      "hotelgr\n",
      "supergreatamazing\n",
      "castle-l\n",
      "stay.this\n",
      "hi-rise\n",
      "timerooms\n",
      "price/service/location\n",
      "lcoati\n",
      "re-modle\n",
      "raulsten\n",
      "affinia\n",
      "visitin\n",
      "crrazy\n",
      "produ\n",
      "seedie\n",
      "aerdnas\n",
      "birthday-survivorship\n",
      "everything-\n",
      "dr.a\n",
      "heating/\n",
      "s.are\n",
      "two-bed\n",
      "palazco\n",
      "rosemon\n",
      "sonope\n",
      "favs\n",
      "extraordinare\n",
      "everrrr\n",
      "awkwa\n",
      "yes-\n",
      "hollywood/\n",
      "skokey\n",
      "place-comfortable\n",
      "bellgaio\n",
      "ruind\n",
      "latte/espre\n",
      "m.life\n",
      "harrrah\n",
      "fabbb\n",
      "tranquilty\n",
      "exceutive\n",
      "blocke\n",
      "bedgreat\n",
      "way2go\n",
      "viisited\n",
      "plaaaaaaaaace\n",
      "Áú†„Çâ„Å™„ÅÑ„Éõ„ÉÜ„É´\n",
      "girlfriend.she\n",
      "kimton\n",
      "poket\n",
      "cleanfelt\n",
      "administe\n",
      "timecapsule\n",
      "rushane\n",
      "east-coa\n",
      "working/poor\n",
      "friends/couples\n",
      "1-n\n",
      "seasonss\n",
      "noisy.too\n",
      "coventions\n",
      "stay-elevators\n",
      "work.staff\n",
      "ervice\n",
      "futuri\n",
      "lodg\n",
      "smallpros-\n",
      "edclv\n",
      "staff..wow\n",
      "trumpified\n",
      "amaazzziiinnggg\n",
      "emabassy\n",
      "rooms/bath\n",
      "1405i\n",
      "doubletreee\n",
      "fthe\n",
      "üá∫üá∏july\n",
      "location‚Äîview\n",
      "vacation‚Äã\n",
      "ascp\n",
      "disppoi\n",
      "|wonderful\n",
      "exceptable\n",
      "bball\n",
      "ar-no\n",
      "buiding\n",
      "custermor\n",
      "ipinema\n",
      "incredidle\n",
      "awazing\n",
      "grrrreat\n",
      "great..but\n",
      "restüëç\n",
      "double-room\n",
      "itse\n",
      "ny.here\n",
      "near-perfe\n",
      "amazing/fun\n",
      "loud/outdated\n",
      "bentle\n",
      "educode\n",
      "manifique\n",
      "hotelexcellent\n",
      "fairmo\n",
      "from11\n",
      "farbto\n",
      "bvegas\n",
      "rooms.modern\n",
      "yougot\n",
      "14y\n",
      "deposit/interesting\n",
      "daughter/mother\n",
      "defnate\n",
      "bacj\n",
      "unfrien\n",
      "forw\n",
      "bally-palooze\n",
      "post-renovation\n",
      "walkaba\n",
      "health-\n",
      "rennovations\n",
      "ahhhhmmaaazzziiinnggg\n",
      "air-freshener\n",
      "club-tower\n",
      "cutomer\n",
      "quarters/river\n",
      ".not\n",
      "dubli\n",
      "awesome¬®\n",
      "room/experience\n",
      "chanta\n",
      "game/valentine\n",
      "in-check\n",
      "work-\n",
      "moxy‚Äîfrom\n",
      "circassia/quintilles\n",
      "no-cancellation\n",
      "mundog\n",
      "tensen\n",
      "'sui\n",
      "room-very\n",
      "b=very\n",
      "deninetly\n",
      "stay..great\n",
      "moderno.camere\n",
      "28/night\n",
      "staye\n",
      "part2\n",
      "filmset\n",
      "a-o\n",
      "positive+\n",
      "girlsfriend\n",
      "sleep-stuffy\n",
      "multipl\n",
      "3-nite\n",
      "luxwhore\n",
      "'litt\n",
      "11:01am\n",
      "soliel\n",
      "findin\n",
      "scarso\n",
      "pricin\n",
      "stategically\n",
      ".happened\n",
      "recomnded\n",
      "travel-\n",
      "ismeta-rest\n",
      "'new\n",
      "extremehike\n",
      "casino-best\n",
      "lobby/bar\n",
      "impressisons\n",
      "vdisappointed\n",
      "nyc.the\n",
      "dtlv\n",
      "diwn\n",
      "ckeab\n",
      "happaning\n",
      "visit-great\n",
      "shreame\n",
      "lexin\n",
      "avoid-avoid-avoid\n",
      "factu\n",
      "room..\n",
      "usin\n",
      "wyndhams\n",
      "misserable\n",
      "non-mote\n",
      "whorld\n",
      "strio\n",
      "crosb\n",
      "ididnt\n",
      "meh‚Ä¶\n",
      "contem\n",
      "cleen\n",
      "misera\n",
      "litterally\n",
      "antione\n",
      "locali\n",
      "engagement/anniversary\n",
      "place.clean\n",
      "sumerlin\n",
      "hotel.pros-\n",
      "value/money\n",
      "broadway/times\n",
      "personnal\n",
      "missleaded\n",
      "location+good\n",
      "vegas-y\n",
      "accomatio\n",
      "nicest-\n",
      "regeritating\n",
      "oriced\n",
      "work/leisure\n",
      "childho\n",
      "silversmi\n",
      "money-\n",
      "lovethe\n",
      "ghirarde\n",
      "unparalle\n",
      "diry\n",
      "cool/charming/mediocre\n",
      "opportunitie\n",
      "admirale\n",
      "üòé\n",
      "reasonbly\n",
      "alwauys\n",
      "adjace\n",
      "caesaer\n",
      "everu\n",
      "in-less\n",
      "fantsatic\n",
      "tonyc\n",
      "worldmark\n",
      "location-location-\n",
      "jomarthreads\n",
      "down/smokey\n",
      "yeaars\n",
      "referbishment\n",
      "ariellee\n",
      "experienece\n",
      "sthis\n",
      "hotel-service-\n",
      "hotel.they\n",
      "lobby/door\n",
      "amaazzinnnggg\n",
      "familymoon\n",
      "centric-fisherman\n",
      "matie\n",
      ".suite\n",
      "smelly/dirty\n",
      "off-the-be\n",
      "co-lo\n",
      "b-way\n",
      "..they\n",
      "rediculous\n",
      "yrs-old\n",
      "millinium\n",
      "ozzing\n",
      "'main\n",
      "nighta\n",
      "swissot\n",
      "boliv\n",
      "‡∏Å‡∏≤‡∏£‡∏ó‡πà‡∏≠‡∏á‡πÄ‡∏ó‡∏µ‡∏¢‡∏ß\n",
      "skillls\n",
      "**overcharges**\n",
      "glamas\n",
      "yotk\n",
      "clasa\n",
      "theeee\n",
      "rooftopgreat\n",
      "andrew-\n",
      "6p.m\n",
      "shanetta\n",
      "registrat\n",
      "at-january\n",
      "/m\n",
      "syversen\n",
      "s.masterman-\n",
      "lacerva\n",
      "f√®el\n",
      "iinsuf\n",
      "spectecular\n",
      "chicago-south/universit\n",
      "ooolllld\n",
      "overtrendy\n",
      "mellinium\n",
      "mid-m\n",
      "casino/bummer\n",
      "holidat\n",
      "linq-loved\n",
      "worldtravler\n",
      "experience..for\n",
      "tƒ±mes\n",
      "birthday/march\n",
      "oct.1\n",
      "outragous\n",
      "***nice\n",
      "propell\n",
      "shellburne\n",
      "avon39\n",
      "wonerful\n",
      "-they\n",
      "dide\n",
      "upscale/\n",
      "floodin\n",
      "can't-be-beat\n",
      "DG/DG/DGDG-DG/DG/DGDG\n",
      "foun\n",
      "georgous\n",
      "accomidated\n",
      "upper-end\n",
      "aqual\n",
      "sutt\n",
      "14-18sep2018\n",
      "aura..freindly\n",
      "thorughtout\n",
      "pool-facing\n",
      "chikago\n",
      "receptionis\n",
      "expeirnce\n",
      "location-river\n",
      "husbandand\n",
      "roalty\n",
      "variet\n",
      "indiv\n",
      "comfortatable\n",
      "29t\n",
      "'newly\n",
      "feldhiem\n",
      "monday-frida\n",
      "personal/business\n",
      "'class\n",
      "DGDG/DGDG/DGDG-DGDG/DGDG/\n",
      "upfro\n",
      "***not\n",
      "levona\n",
      "ispent\n",
      "hide-a-bed\n",
      "DGDGDGDG/DG\n",
      "treasur\n",
      "flaire\n",
      "valued..\n",
      "hicc\n",
      "lounge-wow\n",
      "nosisy\n",
      "vegas-sumer-2016\n",
      "buff√©\n",
      "vicery\n",
      "chatw\n",
      "hi-end\n",
      "ssssllllloooooowwwwww\n",
      "half-m\n",
      "smller\n",
      "amenities-you\n",
      "excellent-only\n",
      "accesability\n",
      "sepera\n",
      "parklovers\n",
      "hyattrocks\n",
      "generatio\n",
      "pool-confusing\n",
      "husbu\n",
      "unbeleivable\n",
      "nicevweekene\n",
      "shelb\n",
      "high-qua\n",
      "eevent\n",
      "luxorious\n",
      "lwelch\n",
      "restaurants+\n",
      "so..\n",
      "sugge\n",
      "nationali\n",
      "big.pool\n",
      "appeara\n",
      "midway/chicago\n",
      "_^\n",
      "travel/short\n",
      ".eveyon\n",
      "professional/great\n",
      "Í≤âÎ™®ÏäµÎßå\n",
      "centrali\n",
      "soldie\n",
      "overall-\n",
      "touristi\n",
      "bisit\n",
      "helpuff\n",
      "courteouswifi\n",
      "flamin-go\n",
      "definietley\n",
      ".oooo\n",
      "close.to\n",
      "splendide\n",
      "wesr\n",
      "parking.clean\n",
      "gaurd\n",
      "DGDGDG‚Ç¨\n",
      "siminars_june\n",
      "adventur\n",
      "mother/d\n",
      "good/not\n",
      "rooms-average\n",
      "lovee\n",
      "smoky-good\n",
      "-master\n",
      "renovation/staycation\n",
      "unreasona\n",
      "trish88\n",
      "rooms.inviti\n",
      "manhattan-chelsea\n",
      "mgm/ufc\n",
      "renuion\n",
      "Ë¶≥ÂäáÁõÆÁöÑÂêë„Åç„ÅÆ„Éõ„ÉÜ„É´\n",
      "nightsta\n",
      "allmy\n",
      "location.comfortable\n",
      "rmef\n",
      "unhapp\n",
      "everyonestayed\n",
      "requestin\n",
      "daycation\n",
      "soxs\n",
      ".vegas\n",
      "quiality\n",
      "pro:1.\n",
      "pretensi\n",
      "previousely\n",
      "boutiquish\n",
      "sanfran\n",
      "brief-we\n",
      "convieniently\n",
      "location/basic\n",
      "super-luxe\n",
      "qrts\n",
      "night.had\n",
      "a-maz-ingggg\n",
      "location/horrible\n",
      "thebest\n",
      "excellect\n",
      "6.30pm\n",
      "goodfriendly\n",
      "super-con\n",
      "luving\n",
      "celebraton\n",
      "broadway/\n",
      "disappointing-not\n",
      "advertised/reserved\n",
      "c-\n",
      "blockag\n",
      "rateings\n",
      "anyot\n",
      "impressionsalthoug\n",
      "airbn\n",
      "fiftee\n",
      "st.-r√©gis\n",
      "grandviews\n",
      "what¬¥s\n",
      "angelina/gio\n",
      "facility/lobby\n",
      "excellent-no\n",
      "positiom\n",
      "grandchil\n",
      "28-30th\n",
      "-18th\n",
      "negligen\n",
      "accomadated\n",
      "axio\n",
      ".boutique\n",
      "cityv\n",
      "splatinum\n",
      "kimtpon\n",
      "jackhamming\n",
      "happended\n",
      ".fo\n",
      "update/upgrade\n",
      "restarants\n",
      "DGDG-DGDG-\n",
      "bellagio~\n",
      "conse\n",
      "dictio\n",
      "my17\n",
      "2days\n",
      "incredible..al\n",
      "otoro\n",
      "reveiew\n",
      "resort-clean\n",
      "stacation\n",
      "..would\n",
      "hyattsf\n",
      "wit.t\n",
      "smlie\n",
      "higg.we\n",
      "unfortunat\n",
      "brida\n",
      "posh/brooding-type\n",
      "„É≠„Ç±„Éº„Ç∑„Éß„É≥„ÅØÊúÄÈ´ò„Åß„Åô„Åå\n",
      "harbor/hudso\n",
      "tiphani\n",
      "diamont\n",
      "DGDG/DGDG/DGDG-DGDG/DGDG/DG\n",
      "option-conveniently\n",
      "partiro\n",
      "otherwise..fun\n",
      "connectio\n",
      "god-the\n",
      "creati\n",
      "nangie\n",
      "-good\n",
      "rexently\n",
      "..awes\n",
      "room/decor\n",
      "place‚ù§Ô∏èÔ∏è\n",
      "beve\n",
      "22-f.\n",
      "10/2014and\n",
      "tournamenr\n",
      "wait/ripoff/poor\n",
      "patrio\n",
      ".and\n",
      "colliseum\n",
      "recommandations\n",
      "injuly\n",
      "ok~\n",
      "confor\n",
      "19th-23rd\n",
      "slots-a-1\n",
      "registe\n",
      "mini-las\n",
      "wedding-\n",
      "spe0acially\n",
      "undermet\n",
      "perfectly-designed\n",
      "conveniet\n",
      "arrangeme\n",
      "simplis\n",
      "maintance/engineer\n",
      "privile\n",
      "oldes\n",
      "resid\n",
      "youself\n",
      "*******\n",
      "hotel.p\n",
      "perfectlocat\n",
      "ghiradelli\n",
      "room/comforter\n",
      "fabreeze\n",
      "vdara..the\n",
      "astoundi\n",
      "whis\n",
      "visitt\n",
      "grandedame\n",
      "looong\n",
      "need.if\n",
      "european-like\n",
      "terriic\n",
      "quality,15m\n",
      "self-servic\n",
      "prix-qualite\n",
      "accommadation\n",
      "contempla\n",
      "freat\n",
      "7nig\n",
      "stres\n",
      "sdjtx\n",
      "new.hospitable.well-situated\n",
      "serviceminded\n",
      "/reunion/\n",
      "food/drink\n",
      "cepress\n",
      "ibooked\n",
      "marese\n",
      "time-warp\n",
      "back~\n",
      "'my\n",
      "vistq\n",
      "signeture\n",
      "vegasescc\n",
      "screami\n",
      "refurb/redo\n",
      "caut\n",
      "retured\n",
      "renam\n",
      "desilusion\n",
      "manhattan.t\n",
      "colou\n",
      "monque\n",
      "retreat/great\n",
      "stayü§ô\n",
      "acary\n",
      "knowi\n",
      "york-n\n",
      "phishin\n",
      "solidly-built\n",
      "great.if\n",
      "air/heating\n",
      "re-energiz\n",
      "cpts\n",
      "brilant\n",
      "*horrible\n",
      "combina\n",
      "ceaszars\n",
      "trip-fab\n",
      "ex-mil\n",
      "city..\n",
      "post-valentine\n",
      ".action\n",
      ".wanted\n",
      "recommend.\n",
      "26may\n",
      "bountif\n",
      "negociated\n",
      "vorgiatzid\n",
      "kensi\n",
      "reccomebd\n",
      "hotel-skip\n",
      "giraffe-an\n",
      "texaslady\n",
      "abb2018\n",
      "absolutelly\n",
      "udpated\n",
      "argona\n",
      "cleanthe\n",
      "location.w\n",
      "guranteed\n",
      "propert\n",
      "10need\n",
      "unempowered\n",
      "moneypit\n",
      "lollapa\n",
      "-location-\n",
      "tanielle\n",
      "room.43\n",
      "btinging\n",
      "ladiessecon\n",
      "|very\n",
      "amazingbuilding\n",
      "hotel-chicaco\n",
      "mccarram\n",
      "elegants\n",
      "venuereat\n",
      "beautifulroom\n",
      "tourna\n",
      "ikea-loving\n",
      "roshon\n",
      "stewarthotel\n",
      "thid\n",
      "accessi\n",
      "good-love\n",
      "vonyel\n",
      "dispite\n",
      "airpads\n",
      "tryone\n",
      "xcell\n",
      ".reasonably\n",
      "bevause\n",
      "ok-we\n",
      "under-producing\n",
      "ritz-carlto\n",
      "excalibur-not\n",
      "*so*\n",
      "accommading\n",
      "hideway\n",
      "lrooms\n",
      "definat\n",
      "wow~\n",
      "resortbeautiful\n",
      "upcharges\n",
      "tradtion\n",
      "customer/\n",
      "mgmthe\n",
      "desk/reservations\n",
      "hotel.great\n",
      "ü§®\n",
      "hotel.b\n",
      "property-bravo\n",
      "stay.\n",
      "ahh-mazing\n",
      "tunne\n",
      "amenities=very\n",
      "02-april\n",
      "exspensive\n",
      "notch-\n",
      "sreally\n",
      "perefct\n",
      "pleasue\n",
      "locatione\n",
      "nuggett/\n",
      "superio\n",
      "**i\n",
      "scandaloso\n",
      "persidio\n",
      "avroom\n",
      "blackston\n",
      "6:30ish\n",
      "irel\n",
      "good/bad\n",
      "platin\n",
      "-DGDGDG\n",
      "walk/bus\n",
      "kitchenet\n",
      "cofortable\n",
      "minina\n",
      "milta\n",
      "fine/staff\n",
      "leeds-certified\n",
      "average-to-good\n",
      "betty-raphael\n",
      "implie\n",
      "helpful..s\n",
      "pre-booking\n",
      "preferrable\n",
      "overa\n",
      "locationnear\n",
      "secretivegas\n",
      "cisit\n",
      "preferenc\n",
      "atriu\n",
      "elab\n",
      "***horrible\n",
      "califo\n",
      "satiesfied\n",
      "cleanin\n",
      "manjatta\n",
      "luxury-tech\n",
      "hotel.hotel\n",
      "visotor\n",
      "centic\n",
      "accordin\n",
      "non-touri\n",
      "buildt\n",
      "honney\n",
      "bringi\n",
      "gelegen\n",
      "exsperience\n",
      "defen\n",
      "stay-n-play\n",
      "sophy~\n",
      "omni-ficent\n",
      "dorm/sight\n",
      "deatil\n",
      "again..again\n",
      "thrille\n",
      "outra\n",
      "decoratin\n",
      "semi-luxe\n",
      "coupl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "furo-style\n",
      "refreshmen\n",
      "howevery\n",
      "birsen\n",
      "city-hotel\n",
      "funny/hip\n",
      "manczynski\n",
      "marijuan\n",
      "salespe\n",
      "safety..\n",
      "dirti\n",
      "towera\n",
      "fantasti\n",
      "children.th\n",
      "enoiggh\n",
      "australi\n",
      "resolv\n",
      "roomto\n",
      "staff/rooms\n",
      "energ\n",
      "fabuloud\n",
      "fanstastic\n",
      "encore/\n",
      "abdolutely\n",
      "location1\n",
      "-giant\n",
      "'decent\n",
      "team.loved\n",
      "hyats\n",
      "neighbourho\n",
      "strip-joint\n",
      "wi-f\n",
      ".n\n",
      "aweso\n",
      "4-nights\n",
      "notes/tips/thoughts\n",
      "horror-\n",
      "nosiy\n",
      "DGDGDGDG-\n",
      "highly.mi\n",
      "franswa\n",
      "stravelers\n",
      "convienience\n",
      "amentias\n",
      "quenn\n",
      "nnice\n",
      "disclosure..\n",
      "charg\n",
      "merid\n",
      "nyhilton\n",
      "11th-1\n",
      "~~\n",
      "mcdermed\n",
      "nyc-benjamin\n",
      "..just\n",
      "restauarants\n",
      "unimpre\n",
      "7-5to\n",
      "4-beds\n",
      "meh-ok\n",
      "weekni\n",
      "fremontstreet\n",
      "slurge\n",
      "how/when\n",
      "un-even\n",
      "'transylvania\n",
      "injapan\n",
      "defferred\n",
      "old-is\n",
      "unhygenic\n",
      "unbeata\n",
      "travel-circus\n",
      "woukd\n",
      "tur√≠sticos\n",
      "scrubbin\n",
      "ballagio\n",
      "rooms/bathr\n",
      "place..nothing\n",
      "disappointrd\n",
      "bizarr\n",
      "good.location\n",
      "room/decent\n",
      "freemon\n",
      "26th-28\n",
      "vry\n",
      "un-cleanliness\n",
      "grandfastic\n",
      "hideawa\n",
      "ummmmmm\n",
      "liz..\n",
      "fun.we\n",
      "shower..\n",
      "modern/c\n",
      "trully\n",
      "semi-discovered\n",
      "josely\n",
      "selfparking\n",
      "inspir\n",
      "snowny\n",
      "d√©class√©\n",
      "stripbuffet\n",
      "twin..\n",
      "empeccable\n",
      "fruit-inf\n",
      "interviewin\n",
      "ctfo\n",
      "surprised.nestled\n",
      "omgabsolut\n",
      "handica\n",
      "froofy\n",
      "floods-\n",
      "hotelwould\n",
      "hotel‚Ä¶not\n",
      "expet\n",
      "hoppi\n",
      "grand-sons\n",
      "pepose\n",
      "only-odd\n",
      "stay.quiet\n",
      "casino/images\n",
      "recor\n",
      "jubil\n",
      "location-rig\n",
      "back-of-the-house\n",
      "11yr\n",
      "sioux-per\n",
      "apply..\n",
      "600/ni\n",
      "jaquays\n",
      "hotelit\n",
      "eug\n",
      "girlstrip\n",
      "pay.ex\n",
      "bandwith\n",
      "so-would\n",
      "consiege\n",
      "view/shabby\n",
      "flamingp\n",
      "week¬¥s\n",
      "gueat\n",
      "annualtrip\n",
      "not-yet-remo\n",
      "somehwere\n",
      "greap\n",
      "*late\n",
      "disaapointed\n",
      "linq-ed\n",
      "year..lasts\n",
      "-terrible\n",
      "maintaine\n",
      "reputatio\n",
      "nicee\n",
      "wanderfull\n",
      "Â§ß„Åç„Åè„ÅÇ„Çä„Åæ„Åõ„Çì„Åå„ÄÅÂø´ÈÅ©„Å™„Éõ„ÉÜ„É´„Åß„Åó„Åü\n",
      "w/coffee\n",
      "themselve\n",
      "cleanmost\n",
      "srb/mason\n",
      "creamer-\n",
      "one‚Ä¶never\n",
      "staff.room\n",
      "weste\n",
      "trito\n",
      "snobishn\n",
      "convenance~\n",
      "wife.s\n",
      "lvgaming\n",
      "rooftoop\n",
      "part-the\n",
      "recommandatin\n",
      "seaml\n",
      "place‚Ä¶\n",
      "twentys\n",
      "location..mid\n",
      "familytime\n",
      "selfie\n",
      "welsome\n",
      "serviceg\n",
      "nonsens\n",
      "strip.it\n",
      "southe\n",
      "loocation\n",
      "nice/clean\n",
      "45/night\n",
      "closeset\n",
      "splendoriferous\n",
      "07/23/16man\n",
      "understandi\n",
      "unbeatab\n",
      "hallowee\n",
      "mazing\n",
      "hitelwalking\n",
      "mrgg-la-quinta-inn-\n",
      "times+\n",
      "beatiful\n",
      "was.boring\n",
      "leats\n",
      "renovation-\n",
      "groups/meetings\n",
      "akmed\n",
      "repurpo\n",
      "hostelesque\n",
      "koreantown\n",
      "nice/helpful\n",
      "decisi\n",
      "ahhhhqua\n",
      "yetif\n",
      "rooms..large\n",
      "disatified\n",
      "carlt\n",
      "there..\n",
      "complane\n",
      "tuscany-location\n",
      "location.tired\n",
      "~wonderful\n",
      "paris-site\n",
      "dark/dim\n",
      "foregoi\n",
      "anemities\n",
      "'budge\n",
      "rikigi\n",
      "extan\n",
      "dingy-\n",
      "chioice\n",
      "suites..\n",
      "'higher\n",
      "backgro\n",
      "testaurant\n",
      "in-compassionate\n",
      "june/2018\n",
      "trequent\n",
      "thisis\n",
      "*the*\n",
      "rounder..\n",
      "enou\n",
      "fees/lousey\n",
      "skibumohio\n",
      "communi\n",
      "septvisit\n",
      "'family\n",
      "conviention\n",
      "stay-thank\n",
      "exttemely\n",
      "ÂÖ•‰ΩèÂáØÊÇ¶4Â§©\n",
      "sight2\n",
      "roomsatten\n",
      "vatcation\n",
      "pleasant/considered\n",
      "saragoza\n",
      "experienced-\n",
      "/or\n",
      "expexcted\n",
      "flamindontgo\n",
      "thursday1\n",
      "restautants\n",
      "smally\n",
      "mordenisation\n",
      "barkbusters\n",
      "recommnded\n",
      "floyd-pac\n",
      "petrossia\n",
      "graduatio\n",
      "veryfriendly\n",
      "p√©si\n",
      "exepreince\n",
      "night-give\n",
      "practico\n",
      "'breakfast\n",
      "uprgraded\n",
      "alread\n",
      "positive:24/7\n",
      "quick-pay\n",
      "riolasvegas\n",
      "-money\n",
      "anniversary/bday\n",
      "chi-t\n",
      "stay.stay\n",
      "inconsistance\n",
      "campbel\n",
      "definetily\n",
      "-effortless\n",
      "6-7t\n",
      ".after\n",
      "greatttt\n",
      "warbuck\n",
      "activerty\n",
      "gymna\n",
      "value/great\n",
      "interactio\n",
      "dreamforc\n",
      "veiws\n",
      "ammennties\n",
      "expida.ca\n",
      "themgm\n",
      "'w\n",
      "playgr\n",
      "worthwh\n",
      "redecorat\n",
      "needssome\n",
      "downtu\n",
      "problems:1.\n",
      "oustandind\n",
      "retaliat\n",
      "cq-\n",
      "expectatio\n",
      "peninsu\n",
      "üëçüèªüá∫üá∏üóΩ\n",
      "sufficie\n",
      "inspecti\n",
      "excellent-quiet\n",
      "'grow\n",
      "air-\n",
      "..only\n",
      "technolo\n",
      "-reno\n",
      "pyramid.\n",
      "suite-beaut\n",
      "plesant\n",
      "renevating\n",
      "caesars-that\n",
      "refinery..\n",
      "n√Ωc\n",
      "june/beginnin\n",
      "well-ma\n",
      "-professional\n",
      "excit\n",
      "voic\n",
      "coug\n",
      "substantiall\n",
      "grand-vacation\n",
      "stephe\n",
      "fiez\n",
      "dependabl\n",
      "drake..as\n",
      "time..would\n",
      "unsuita\n",
      "nicemo\n",
      "96st\n",
      "shoppng\n",
      "‚Äç\n",
      "trafal\n",
      "satisfing\n",
      "pelago.staff\n",
      "best..ve\n",
      "garantees\n",
      "fee*\n",
      "noelani\n",
      "'life\n",
      "parties/great\n",
      "train/el\n",
      "fascin\n",
      "fnatastisch\n",
      "location.clos\n",
      "station/garment\n",
      "62th\n",
      "coffee/donut\n",
      "sevr\n",
      "enjoye\n",
      "expectattions\n",
      "exactl\n",
      "trip-hotel\n",
      "loft-style\n",
      "overpiced\n",
      "upprr\n",
      "visit-not\n",
      "non-fu\n",
      "'dont\n",
      "treat-\n",
      "Í¥úÏ∞ÆÏïòÏäµÎãàÎã§\n",
      "post-thanksgiving\n",
      "list/\n",
      "meeti\n",
      "a/\n",
      "‰∫îÊòüÁ∫ßÊúçÂä°\n",
      "roger-\n",
      "non-whale\n",
      "people/great\n",
      "room.not\n",
      "blueyorkcity\n",
      "receptionless\n",
      "smithcrrsl\n",
      "tom‚Äº‚Äº‚Äº\n",
      "pleasure-worst\n",
      "holdiay\n",
      "12-yr.\n",
      "picass\n",
      "once-fine\n",
      "unexpect\n",
      "hiltonon\n",
      "adequa\n",
      "emerils\n",
      "confusio\n",
      "umani\n",
      "alriiiiight\n",
      "minut\n",
      "new-ist\n",
      "terrifyin\n",
      "pleaseure\n",
      ".deb\n",
      "helloarlo\n",
      "15/day\n",
      "mid-stip\n",
      "49th/lexington\n",
      "japane\n",
      "ever.we\n",
      "intersolar\n",
      "pegsnysta\n",
      "weekly-\n",
      "'regular\n",
      "amartin50\n",
      "pros1\n",
      "restauant\n",
      "back/nasty\n",
      "dump..\n",
      "tranquill\n",
      "fantastic-now\n",
      "hakasan\n",
      "ny-great\n",
      "cleanye\n",
      "old.doesn\n",
      "bi-word\n",
      "recomm\n",
      "llocation\n",
      "pered\n",
      "definitelly\n",
      "lekandjessie\n",
      "half-done\n",
      "repairs/renovations\n",
      "DG:DG\n",
      "otherwis\n",
      "photo/video/family/business\n",
      "stcyr\n",
      "trip..a\n",
      "manhaton\n",
      "hotel/inhospitable\n",
      "regardle\n",
      "grac\n",
      "unor\n",
      "inconvient\n",
      "graeat\n",
      "caesa\n",
      "situationed\n",
      "bobcean\n",
      "brithday\n",
      "look/business\n",
      "'five\n",
      "activitie\n",
      "outstanding-\n",
      "absoultely\n",
      "toge\n",
      "feidnly\n",
      "everagain\n",
      "spoi\n",
      "besties\n",
      "renovartion\n",
      "placeto\n",
      "perrenial\n",
      "riotfest\n",
      "hdden\n",
      "aaahhhh\n",
      "getawayüòä\n",
      "couboard\n",
      "enjo\n",
      "bumm\n",
      "ladie\n",
      "no.1\n",
      "location.lovely\n",
      "jaquizzi\n",
      "‚Ç¨DGDGDG\n",
      "towerscle\n",
      "reunion.great\n",
      "nice-sized\n",
      "bug-in-the-be\n",
      "travello\n",
      "casinogood\n",
      "palazzo-\n",
      "small.staff\n",
      "minite\n",
      "situateted\n",
      "hy36\n",
      "deskk\n",
      "all-suit\n",
      "party/extended\n",
      "soho-tribeca\n",
      "9:30pm\n",
      "üëçüèæüëçüèæ\n",
      "3-star-fe\n",
      "melow\n",
      "rebr\n",
      "-bus\n",
      "horriable\n",
      "tourn\n",
      "aound\n",
      "grame\n",
      "luke-warm\n",
      "convinien\n",
      "sportsbook/racebook\n",
      "place-hyde\n",
      "un-helpful\n",
      "cupof\n",
      "2-nights\n",
      "elog\n",
      "further..\n",
      "birthday/new\n",
      ".misleading\n",
      "nickeled\n",
      "exeeded\n",
      "and..\n",
      "conference/having\n",
      "behin\n",
      "leclub\n",
      "barbequearea\n",
      "macana\n",
      "biig\n",
      "conserv\n",
      "bentely\n",
      "tomandalay\n",
      "thight\n",
      "40th+\n",
      "kindne\n",
      "centrally-\n",
      "bisc\n",
      "avenueconfortable\n",
      "discreetl\n",
      "day/birthday\n",
      "hotel-neighborhood\n",
      "aaran\n",
      "fishrman'wahrf\n",
      "outdat\n",
      "bfore\n",
      "rooms.hard\n",
      "empl\n",
      ".way\n",
      "touris\n",
      "gdfr\n",
      "fabijon\n",
      "fast.room\n",
      "location-solid\n",
      "queality\n",
      "e-mag\n",
      "nighrs\n",
      "locationmos\n",
      "harrahis\n",
      "thursday-mon\n",
      "money.staff\n",
      "quick-stop\n",
      "bookedbooked\n",
      "knowled\n",
      "atmosphere/nice\n",
      "nautical-great\n",
      "aestheticall\n",
      "outstanding.fantastic\n",
      "finebut\n",
      "rennov\n",
      "unfunctional\n",
      "'wildcat\n",
      "wednesda\n",
      "staycations\n",
      "location++++\n",
      "sejour-\n",
      "kids/family\n",
      "ottima\n",
      "drasticall\n",
      "6nd\n",
      "service-poor\n",
      "weekendüá∫üá∏üí•\n",
      "casinoüòä\n",
      "jubillee\n",
      ".started\n",
      "beautyfull\n",
      "proslocationlarge\n",
      "beatuful\n",
      "room‚Ä¶terrible\n",
      "interestesting\n",
      "disrega\n",
      "kitchette\n",
      "massiv\n",
      "strip..turn\n",
      "weekenight\n",
      "nynyas\n",
      "o'cl\n",
      "birthdayüéâüéâüéâ\n",
      "thirs\n",
      "invegas\n",
      "smelli\n",
      "rooms.clos\n",
      "remembere\n",
      "ellismania\n",
      "unorg\n",
      "men√∫\n",
      "stratospher\n",
      "bouique\n",
      "anniversary/40th\n",
      "good-nothing\n",
      "silversmit\n",
      "underdelivers\n",
      "tdwi\n",
      "anniversary/\n",
      "hhonours\n",
      "üïå\n",
      "carefull\n",
      "ymmy\n",
      "drinkers-\n",
      "pzzazz\n",
      "i¬¥ve\n",
      "arrogan\n",
      "stayable\n",
      "purc\n",
      "located..\n",
      "outstnanding\n",
      "smoke-fr\n",
      "ammenaties\n",
      "intenti\n",
      "windo\n",
      "bar/restaur\n",
      "wedding/stay\n",
      "travel/lifes\n",
      "break-\n",
      "hotal\n",
      "hypo-allergenic\n",
      "gym/spa\n",
      "endles\n",
      "ritz-y\n",
      "..from\n",
      ".pl\n",
      "charmi\n",
      "profesionalism\n",
      "radzewon\n",
      "manhattens\n",
      "wawwww\n",
      "ocassion\n",
      "ameni\n",
      "traverllers\n",
      "hyatt-times\n",
      "recommendedüôÇüôÇ\n",
      "inkcredible\n",
      "service/security\n",
      "functi\n",
      "theater-focused\n",
      "bally'sis\n",
      "espres\n",
      "stay1111\n",
      "guest/\n",
      "shoebox-sized\n",
      "hellz\n",
      "pathatic\n",
      "full..\n",
      "enagic\n",
      "wed-fri\n",
      "modern-feel\n",
      "golf/gam\n",
      "bests.only\n",
      "..huh\n",
      "ballyhs\n",
      "stay11111\n",
      "everythkng\n",
      "neutral/fair\n",
      "unfortunatey\n",
      "chicago-3/9\n",
      "ventian\n",
      "wow.staff\n",
      "fragranced\n",
      "ksheds\n",
      "2x25\n",
      "family/kid\n",
      ".were\n",
      "me¬∑di¬∑oc¬∑ri¬∑ty\n",
      "accentuat\n",
      "kimbely\n",
      "pre-checking\n",
      "acccess\n",
      "stay..nice\n",
      "stayalways\n",
      "'mansfield\n",
      "colorfu\n",
      "beds/rooms\n",
      "funkytime\n",
      "gambeling\n",
      "remodeli\n",
      "thirt\n",
      "***do\n",
      "francisico\n",
      "mrmrs\n",
      "in/ou\n",
      "comfortable/budget\n",
      "tradi\n",
      ".copper\n",
      "additi\n",
      "15/night\n",
      "westins\n",
      "hassl\n",
      "practi\n",
      "datedori\n",
      "pre-family\n",
      "excellent..co\n",
      "weill-corn\n",
      "dupped\n",
      "crasj\n",
      "staing\n",
      "kabaddie\n",
      "downtown.room\n",
      "11a.m\n",
      "smalli\n",
      ".must\n",
      "bouthique\n",
      "'sexy\n",
      "dissapoin\n",
      "/jan\n",
      "desevers\n",
      "frienliness\n",
      "45t\n",
      "overloo\n",
      "nicefood\n",
      "'sky\n",
      "raddiso\n",
      "delano/mandalay\n",
      "tresaure\n",
      "w/perks\n",
      "business/vaca\n",
      "..rudy\n",
      "ideal.b\n",
      "luncheo\n",
      "twonighter\n",
      "Ìò∏ÌÖîÏùò\n",
      "shoe-box\n",
      "broadyway\n",
      "chanakira\n",
      "lobby/check\n",
      "nyc-9/11\n",
      "dec.2015\n",
      "busine\n",
      "receo\n",
      "staff/reception\n",
      "need..no\n",
      "skinflints\n",
      "evening/weekend\n",
      "underdeparted\n",
      "unpleasently\n",
      "servcie\n",
      "satisfiera\n",
      "üåüüåüüåü\n",
      "bsta\n",
      "detroitian\n",
      "cleean\n",
      "dispappointment\n",
      "holidsy\n",
      "room\\bat\n",
      "lex.the\n",
      "libat\n",
      "‚ô´\n",
      "presidenial\n",
      "f√©rias\n",
      "numerou\n",
      "usualthe\n",
      "trip-suites\n",
      "minifridge\n",
      "hotel..the\n",
      "skeptica\n",
      "desapoited\n",
      "nices\n",
      "turistical\n",
      "squea\n",
      "out.one\n",
      "lactose-free\n",
      "best..centrally\n",
      "lotel/great\n",
      "casua\n",
      "zooland\n",
      "stripp\n",
      "ü§û\n",
      "inexoensive\n",
      "on-s\n",
      "thhome\n",
      "ttaveler\n",
      "DGDG-DGDGDGDG\n",
      "elevaors\n",
      "l-u-x-u-r-y\n",
      "-super\n",
      "resort-like\n",
      "overpric\n",
      "chicafo\n",
      "lodge-feel\n",
      "beware..i\n",
      "*in\n",
      "rooms/rooftop\n",
      "work/new\n",
      "fatastic\n",
      "charges-would\n",
      "adjoini\n",
      "helliday\n",
      "üòë\n",
      "all..\n",
      "aarrr\n",
      "*DG.DG*\n",
      "splish-splash\n",
      "enthu\n",
      "wonderful.host\n",
      "midtown/\n",
      "notrump2018\n",
      "post-work\n",
      "soliels\n",
      "laaaaas\n",
      "airport-like\n",
      "ritc\n",
      "disappointed.roo\n",
      "king-\n",
      "way.grea\n",
      "niiiiiiiice\n",
      "business/tourist\n",
      "chicago'esque\n",
      "top-no\n",
      "tunin\n",
      "‚ù§love\n",
      "pet-friendliness\n",
      "omoide\n",
      "teamsanford\n",
      "2:08am\n",
      "playmill\n",
      "signatu\n",
      "immac\n",
      "'light\n",
      "francicsco\n",
      "extensivel\n",
      "apartmenthotel\n",
      "ghis\n",
      "****perfect\n",
      "wedding-july\n",
      "amzing\n",
      "-long\n",
      "vegasüôÅ\n",
      "excellenc\n",
      "small..ac\n",
      "avallble\n",
      "bestloca\n",
      "countinu\n",
      "visit..wo\n",
      "disg\n",
      "styl\n",
      "60min\n",
      "island..unti\n",
      "DGDG-DGDG/DGDG/DGDGDGDG\n",
      "froz\n",
      "pineapple-riffic\n",
      "pedanti\n",
      "afvclub\n",
      "vavation\n",
      ".jus\n",
      "fanominal\n",
      "over..\n",
      "rooms=mediocre\n",
      "companio\n",
      "jubele\n",
      "kind-of\n",
      "nights.i\n",
      "945am\n",
      "favouri\n",
      ".cos√¨\n",
      "jewelbox\n",
      "linq/january\n",
      "anniversary-ruined\n",
      "dumpster/loading\n",
      "malandra\n",
      "priceworthy\n",
      "beautyful\n",
      "awseome\n",
      "times..gabriel\n",
      "1-star\n",
      "nazamy\n",
      "wooooooooooo\n",
      "sahati\n",
      "diamonds/star\n",
      "üá∫üá∏üá´üá∑üá¨üáß\n",
      "convinietly\n",
      "no-little\n",
      "estrategic\n",
      "loaction\n",
      "down-side\n",
      "secuirty\n",
      "2bedroom\n",
      "fixins\n",
      "on..\n",
      "previousl\n",
      "hotel/las\n",
      "whhhaaaattt\n",
      "***bed\n",
      "location-no\n",
      "apaam18\n",
      "howeve\n",
      "re-redone\n",
      "v-e-e-e-ery\n",
      "opera-goers\n",
      "r.o\n",
      "reivew\n",
      "approa\n",
      "trendyish\n",
      "room/no\n",
      "strip.ex\n",
      "comfortabi\n",
      "apero\n",
      "good..\n",
      "photophobic\n",
      "centere\n",
      "half-maratho\n",
      "qualitity\n",
      "tranqu\n",
      "nymathe\n",
      "prostitues\n",
      "conferenc\n",
      "down-at-heels\n",
      "rejuvinating\n",
      "smoo\n",
      "medieval-ness\n",
      "uber-hipster\n",
      "bayoumy\n",
      "showe\n",
      "gracefully-aged\n",
      "denyin\n",
      "sping\n",
      "/evitatelo\n",
      "usual-excellent\n",
      "fantastisk\n",
      "writi\n",
      "fllor\n",
      "hackling\n",
      "taxi/uber\n",
      "hotel..stinks\n",
      "staffsmall\n",
      "hubster\n",
      "19may\n",
      "alltogether\n",
      "waybreakfast\n",
      "lodgin\n",
      "soho-hotel\n",
      "1-to\n",
      "üéµüéµüéµ\n",
      "two-nig\n",
      "well-mainta\n",
      "30hrs\n",
      "joselyne\n",
      "excellance\n",
      "trendy/great\n",
      "charleny\n",
      "crowdbette\n",
      "shanelle\n",
      "‰æ°Ê†º„Å®Âø´ÈÅ©„Åï„ÅÆ„Éê„É©„É≥„Çπ„ÅåÂÑ™„Çå„Å¶„ÅÑ„Åæ„Åô„ÄÇ„Ç®„Ç¢„Ç≥„É≥„ÅØ„Å§„ÅÑ„Å¶„ÅÑ„Åæ„Åõ„Çì„Åß„Åó„Åü„Åå„ÄÅ30‚ÑÉ„ÅÆÊó•\n",
      "2-da\n",
      "staffsense\n",
      "hotel/beautiful\n",
      "friday-monday\n",
      "jankiest\n",
      "dunn-\n",
      "paace\n",
      "overbookin\n",
      "enviromen\n",
      "elydia\n",
      "eveyrthing\n",
      "service‚ò∫\n",
      "iÔ∏è\n",
      "tournam\n",
      "safeclos\n",
      "◊í◊ë◊ï◊î◊î\n",
      "september..family\n",
      "propertymodern\n",
      "flamingo/wi-fi\n",
      "underwhelms\n",
      "december.the\n",
      "o'h\n",
      "baske\n",
      "holloy\n",
      "bed-decent\n",
      "bang9\n",
      "immen\n",
      "'coming\n",
      "trip-excellent\n",
      "regency-mccormack\n",
      "vibe.professi\n",
      "horel\n",
      "fastes\n",
      "repet\n",
      "queenroom\n",
      "time.we\n",
      "kuddos\n",
      "rooms‚Äîservice\n",
      "amminities\n",
      "..ever\n",
      "first-\n",
      "mmmmmmm\n",
      "thunderst\n",
      "complementarily\n",
      "gianletta\n",
      "holllywo\n",
      "boooking\n",
      "enjoymenb\n",
      "absolulety\n",
      "hotel/motel/inn\n",
      "eexcellent\n",
      "acrophobes\n",
      "cost-resort\n",
      "suddenl\n",
      "shopping/cu\n",
      "terrilble\n",
      "location/\n",
      "‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏èthe\n",
      "inprovement\n",
      "jalles\n",
      "adwoa\n",
      "lovvvvvvved\n",
      "trip-elton\n",
      "property-small\n",
      "ocation\n",
      "bexp\n",
      "everrrrrrr\n",
      "üíÅüíÅ\n",
      "experiene\n",
      "melhorar\n",
      "occuyin\n",
      "visit.ro\n",
      "locationüíú\n",
      "hotel-far\n",
      "saemin\n",
      "anadaz\n",
      "karpowicz\n",
      "doormans\n",
      "11:45pm\n",
      "expecati\n",
      "view/spacious\n",
      "tostay\n",
      "handsdown\n",
      "tanesha\n",
      "uofc\n",
      "allthough\n",
      "exclaibur\n",
      "arcad\n",
      "2y\n",
      "acm/50th\n",
      "exleant\n",
      "vintage..\n",
      "11h\n",
      "recommeded\n",
      "stay.centrally\n",
      "casino.r\n",
      "amemities\n",
      "comportable\n",
      "ok-\n",
      "cheepest\n",
      "untight\n",
      "mini-getaway\n",
      "delano..\n",
      "overides\n",
      "amounst\n",
      "rooms.when\n",
      "trraveler\n",
      "petre-alina\n",
      "location.subway\n",
      "place/\n",
      "omplete\n",
      "fantsy\n",
      "facikities\n",
      "day/nite\n",
      "fruitbat12\n",
      "me..\n",
      "truy\n",
      "opu\n",
      "hotelie\n",
      "*rooms*\n",
      "stongly\n",
      "thecroom\n",
      "hgi/ny-tsc\n",
      "could.park\n",
      "nyma\n",
      "up-selling\n",
      "fabulours\n",
      "perfect..but\n",
      "modern/i\n",
      "'hard\n",
      "marrriott\n",
      "defini\n",
      "celebration..not\n",
      "excalibutt\n",
      "accommondations\n",
      "vibey\n",
      "somefrie\n",
      "poweri\n",
      "suvey\n",
      "expectedame\n",
      "treatüéàüéà\n",
      "jarus\n",
      "-enjo\n",
      "beautiful/\n",
      "well-p\n",
      "definaly\n",
      "cocker-roaches\n",
      "basketb\n",
      "indidgo\n",
      "confusing/misleading\n",
      "upside:1.\n",
      "creise\n",
      "superficia\n",
      "stayed.negative\n",
      "fogar\n",
      "ballt\n",
      "-maybe\n",
      "absloutely\n",
      "luxiry\n",
      "michellejoy\n",
      "deal..\n",
      "-and\n",
      "abnor\n",
      "comfatable\n",
      "grandda\n",
      "'guards\n",
      "3rd-10th\n",
      "DGDG/DGDG-DGDG/DGDG\n",
      ".make\n",
      "decidi\n",
      "gentlema\n",
      "üëåüèº\n",
      "roundet\n",
      "..ahhh\n",
      "alllllllll\n",
      "yorkers..bo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haraah\n",
      "lpace\n",
      "off/girls\n",
      "'f\n",
      "bungalo\n",
      "linens~all\n",
      "dtrip\n",
      "rennovating\n",
      "woke-up\n",
      "thesoho\n",
      "csan\n",
      "elara/planet\n",
      "1*service/amenities\n",
      "again-sam\n",
      "understatedly\n",
      "staff..great\n",
      "taiyon\n",
      "squard\n",
      "issues-moths\n",
      "timothie\n",
      "deffo\n",
      "yorki\n",
      "room'service\n",
      "alwats\n",
      "DG/DGDG-DG/DGDG\n",
      "souless\n",
      "redic\n",
      "t-\n",
      "cabana**5\n",
      "nights.was\n",
      "passible\n",
      "soreil\n",
      "luxury-not\n",
      "***tip****\n",
      "fancisco\n",
      "chelsea-hampton\n",
      "japanes\n",
      "cosfs\n",
      "casino/resort\n",
      "lammah\n",
      "skys\n",
      "shorehman\n",
      "drill..\n",
      "luggua\n",
      "21'st\n",
      ".th\n",
      "soleil-love\n",
      "expected.co\n",
      "luxory\n",
      "price/quality\n",
      "underwhel\n",
      "cautiou\n",
      "daughter'visit\n",
      "diappoinring\n",
      "'get\n",
      "elderl\n",
      "comfortablethe\n",
      "confortevole\n",
      "location-the\n",
      "attitude..\n",
      "avertising\n",
      "houeskee\n",
      "deskgave\n",
      "whaoou\n",
      "problm\n",
      "/close\n",
      "worst..\n",
      "repersentive\n",
      "1bedroom\n",
      "experien\n",
      "expoerience\n",
      "exentric\n",
      "bally¬¥s\n",
      "night/game\n",
      "staff/unexplained\n",
      "spetermeber\n",
      "atmospheri\n",
      "cockro\n",
      "kumaire\n",
      "thirte\n",
      "disappointment..\n",
      "decisio\n",
      "wow-we\n",
      "belagg\n",
      "axcellent\n",
      "requtation\n",
      "waaayyyy\n",
      "asume\n",
      "clean.as\n",
      "nepomucene\n",
      "cuouple\n",
      "ËèØÂÉë\n",
      "clarificatio\n",
      "exer\n",
      "aliyyah\n",
      "hiltn\n",
      "thiw\n",
      "mobili\n",
      "poophole\n",
      "car..\n",
      "3.30p\n",
      "health-nuts\n",
      "20.aug\n",
      ".kimpt\n",
      "daytripper03\n",
      "reviewer.nice\n",
      "tendere\n",
      "parthena\n",
      "updating~~\n",
      "improvments\n",
      "kabam\n",
      "427/5000recep\n",
      "enfor\n",
      "decieving\n",
      "wasca\n",
      "5nice\n",
      "night-dirty\n",
      "grandezza\n",
      "carriag\n",
      "'nothing\n",
      "citizenmmmmmmmmmmmmmmmmmm\n",
      "room+serice\n",
      "room..clean\n",
      "apprehensi\n",
      "nigthmare\n",
      "simple-\n",
      ".that\n",
      "w/reservation\n",
      "recommened\n",
      ".especially\n",
      "gansevoo\n",
      "honirs\n",
      "fairmon\n",
      "vibes..\n",
      "ameritanina\n",
      "mergermarket\n",
      "compleme\n",
      "hotel.-\n",
      "12am-3am*\n",
      "kronosworks\n",
      "overcharge/bad\n",
      "again..and\n",
      "effortles\n",
      ".before\n",
      "17-305do\n",
      "proximit\n",
      "vacantion\n",
      "bqck\n",
      "12coff\n",
      "bellman/\n",
      "silv\n",
      "cleannes\n",
      "one-place-has-it-all\n",
      "appearanc\n",
      "farth\n",
      "food-loud\n",
      "location/fantastic\n",
      "accommodtion\n",
      "howing\n",
      "dafney\n",
      "d√©c\n",
      "herewi\n",
      "paris1\n",
      "michelangel\n",
      "occupie\n",
      "tv/internet\n",
      "a*m*a*z*i*n*g\n",
      "mohamme\n",
      "caming\n",
      "inn-fi\n",
      "dated.e\n",
      "hodiernal\n",
      "uskomatt\n",
      "kwam\n",
      "put-it\n",
      "5atar\n",
      "courteous/helpful\n",
      "pleeeeease\n",
      "h-i-g-h-l-y\n",
      "capacio\n",
      "DGDG/DG-DG/DGDG\n",
      "5-nigh\n",
      "sporad\n",
      "competitively-pri\n",
      "imprumptu\n",
      "intercont\n",
      "goodhotel\n",
      "venetian/palazz\n",
      "wartho\n",
      "fri/sa\n",
      "bathroom/closet\n",
      "apartamos\n",
      "bus/amtr\n",
      "watei\n",
      "joint..but\n",
      "warrio\n",
      "beautifuk\n",
      "awkwardnes\n",
      "nashid\n",
      "recommended.the\n",
      "business/pleas\n",
      "locationÔºåreasonable\n",
      "everyonejust\n",
      "18year\n",
      "drov\n",
      "hotele\n",
      "anniversery\n",
      "location/fine\n",
      "takeven\n",
      "swo\n",
      "toddler-friendly\n",
      "wazoooo\n",
      "beautiful/stunning\n",
      "tayla\n",
      "silverston\n",
      "panor\n",
      "winte\n",
      "nice.it\n",
      "bargin\n",
      "conra\n",
      "radissson\n",
      "best-better\n",
      "hollday\n",
      "pier-area\n",
      "trip/ford\n",
      "rennovation\n",
      "beware.\\nsub\n",
      "milwau\n",
      "sunrise/sunset\n",
      "unfortunatley\n",
      "lifetim\n",
      "central/\n",
      "90ties\n",
      "'surpr\n",
      "grosssssss\n",
      "escalat\n",
      "hepful\n",
      "weddong\n",
      "budge-minded\n",
      "nightmare/atmosphere\n",
      "affe\n",
      "cleaned.bed\n",
      "dimesas\n",
      "locsation\n",
      "bally's..\n",
      "hereüôÇ\n",
      "cunstruction\n",
      "..offered\n",
      "westi\n",
      "untrustworthy..\n",
      "dream-midtown\n",
      "vergas\n",
      "eye-opener\n",
      "-location\n",
      "manla\n",
      "somethi\n",
      ".simply\n",
      "imex\n",
      ".ca\n",
      "slots-\n",
      "soho/chinatown\n",
      "underwhelm\n",
      "fee-wyndham\n",
      "everything‚Äîthe\n",
      "amtrac\n",
      "impromtu\n",
      "butle\n",
      "luxor-april\n",
      "19-22pros\n",
      "sincerily\n",
      "reno/san\n",
      "mother/daughte\n",
      "cyle\n",
      "hyatt‚Ä¶\n",
      "palatia\n",
      "strip'quiet\n",
      "visitn\n",
      "hotelin\n",
      "findng\n",
      "childh\n",
      "proffesional\n",
      "paula/vernon\n",
      "conversatio\n",
      "best.birthday.ever\n",
      "awefull\n",
      "after-thought\n",
      "phrench\n",
      "museum/memorial\n",
      "gustando\n",
      "favorite-\n",
      "grateful..to\n",
      "unfortuna\n",
      "webe\n",
      "compt\n",
      "emobidemebt\n",
      "startign\n",
      "snafu-\n",
      "hhad\n",
      "celebration/birthdays\n",
      "spaceit\n",
      "yes..motel\n",
      "cucafo\n",
      "2me\n",
      "-deteriorating\n",
      "relaible\n",
      "hotel/flight\n",
      "passag\n",
      "convenience-\n",
      "49lex\n",
      "matb\n",
      "beach/ve\n",
      "relu\n",
      "time-still\n",
      "meeting/se\n",
      "atmoshere\n",
      "detecti\n",
      "choice..great\n",
      "sucks..\n",
      "unmaintaned\n",
      "room/overpriced\n",
      "..wil\n",
      "distrubing\n",
      "juat\n",
      "poorthe\n",
      "location/service/accommodations\n",
      "parc5\n",
      "-oasis\n",
      "average‚Ä¶\n",
      "tinyville\n",
      "wosp\n",
      "multipull\n",
      "dungeon-like\n",
      "3rd-6th\n",
      "sweeet\n",
      "resort/3rd\n",
      "calist\n",
      "provokin\n",
      "forzen\n",
      "soribel\n",
      "luxdont\n",
      "hiit\n",
      "standou\n",
      "hotelstaying\n",
      "hotel.goo\n",
      "shortc\n",
      "minature\n",
      "benzin\n",
      "place.top\n",
      "tower.we\n",
      "aparently\n",
      "ever.after\n",
      "cheapticke\n",
      "relaxing/r\n",
      "60t\n",
      "prices-average\n",
      ".short\n",
      "7-class\n",
      "eprice\n",
      "pyram\n",
      "lvcc\n",
      "cleaniness\n",
      "seasons/las\n",
      "robberies-stay\n",
      "beds.st\n",
      "oportunity\n",
      "hollowood\n",
      "bellys\n",
      "'younger\n",
      "boyfie\n",
      "precruise\n",
      "ubicacion\n",
      "omel\n",
      "8bb\n",
      "tuesda\n",
      "willia\n",
      "mannhatten\n",
      "cooooolllll\n",
      "16hrs\n",
      "edition-\n",
      "xalos\n",
      "fees-\n",
      "walterb\n",
      "treasue\n",
      "floorwoke\n",
      "luxuryvegas\n",
      "picke\n",
      "amazingserv\n",
      "bedsthe\n",
      "'DGDG\n",
      "hoonymoon\n",
      ".oh\n",
      "..in\n",
      "nice/but\n",
      "accomida\n",
      "snea\n",
      "fancy.i\n",
      "bacinos\n",
      "unsurpa\n",
      "pointscheck\n",
      "acfe\n",
      "slamm\n",
      "„É°„Éà„É≠„Ç´„Éº„ÉâÂ§ßÊ¥ªË∫ç„ÅßÊªûÂú®„ÇíÊ•Ω„Åó„Åø„Åæ„Åó„Åü\n",
      "oct/nov\n",
      "mohhamad\n",
      "ofca\n",
      "stagette\n",
      "attai\n",
      "jan.-17\n",
      "dissappoint\n",
      "unfortuneate\n",
      "getwaway\n",
      "vegas-\n",
      "paper2018\n",
      "accommodations/location\n",
      "wicked/hamilton/li\n",
      "more/new\n",
      "330.00/ni\n",
      "away/pac-12\n",
      "‚Äãit\n",
      "wynn/encore\n",
      "location/more\n",
      "good:1.\n",
      "twilly\n",
      "tri-st\n",
      "sa√±rvic\n",
      "centric-\n",
      "service.a\n",
      "acctg\n",
      "-predictable\n",
      "lovely-comfy\n",
      "carniville\n",
      "clean/spacious\n",
      "piecs\n",
      "alantis\n",
      "friendly/hospita\n",
      "lound\n",
      "happie\n",
      "room/staff\n",
      "scou\n",
      "wedding/gambling\n",
      "in/come\n",
      "excellentclean\n",
      "well-main\n",
      "discourteo\n",
      "floors/carpet\n",
      "blackou\n",
      "exceris\n",
      "salesp\n",
      "comprehe\n",
      "notfor\n",
      "d-vino\n",
      "wifi/internet\n",
      "canno\n",
      "misleaded\n",
      "burgr\n",
      "dreamalikeroofbar\n",
      "inlas\n",
      "jamme\n",
      "riduculous\n",
      "a-month-long\n",
      "kimpto\n",
      "sofisticatied\n",
      "great-locatio\n",
      "sheration\n",
      "marathone\n",
      "european/uk\n",
      ".grade\n",
      "DGDGDGDG-DGDGDGDG.\n",
      "hotel.\n",
      "alhcyon\n",
      "dbarrow\n",
      "supose\n",
      "tand\n",
      "makemidai\n",
      "getawa\n",
      "egiptian\n",
      "adeq\n",
      "midevil\n",
      "cedys\n",
      "breat\n",
      "kelv\n",
      "DGDG/DGDG-DGDG/DGDG/DGDGDGDG\n",
      "rock/n\n",
      "staion\n",
      "location-parking\n",
      "cubbys\n",
      "ascore\n",
      "mardigras\n",
      "must-stay\n",
      "hotel33\n",
      "2018.the\n",
      "substit\n",
      "redtag\n",
      "+hotel\n",
      "sofabed\n",
      "hotel-c\n",
      "location-even\n",
      "sandova\n",
      "pay-out\n",
      "rude-\n",
      "hollywoo\n",
      "whithall\n",
      "grandchi\n",
      "explemplifes\n",
      "'well-taken-care\n",
      "sf/\n",
      "1/2star\n",
      "disappointed..horrible\n",
      "exelenct\n",
      "anselona\n",
      "DG/DG-DG/\n",
      "everyt\n",
      "relocat\n",
      "faff\n",
      "exzellent\n",
      "resort/average\n",
      "heard/re\n",
      "pet-\n",
      "buttoo\n",
      "giraffe-it\n",
      "walkabilit\n",
      "alert..\n",
      "suppl√©mentaires\n",
      "promotio\n",
      "chemic\n",
      "view/hotel\n",
      "3/26/2016-pleasant\n",
      "surprized\n",
      "unusua\n",
      "inconveni\n",
      "crowdly\n",
      "djfjtififjdnsnxnfndj\n",
      "l/4\n",
      "somya\n",
      "doubetree\n",
      "privledge\n",
      "mistak\n",
      "outatanding\n",
      "service/amenities\n",
      "business-minded\n",
      "must-experience\n",
      "quintessenti\n",
      "dwtn\n",
      "eligany\n",
      "recommend.very\n",
      "hotelclose\n",
      "labrynth\n",
      "apprehensiv\n",
      "staffgreat\n",
      ".let\n",
      ".superb\n",
      "well-located-\n",
      "helic\n",
      "only2\n",
      "wowie\n",
      "horrible/indifferen\n",
      "gorgeous/quiet/well\n",
      "-hotell\n",
      "finest-\n",
      "row-nyc\n",
      "smellls\n",
      "18-evelina\n",
      "solu\n",
      "square-excellent\n",
      "strlp\n",
      "ehh\n",
      "price/qualit\n",
      "lengedary\n",
      "cood\n",
      "30+taxes\n",
      "timaty\n",
      "ipre\n",
      "son/d\n",
      "squre\n",
      "furnature\n",
      "pickleball\n",
      "less-than-average\n",
      "celebratin\n",
      "bboudolf\n",
      "3x4m\n",
      "kickerbocker\n",
      "locationclean\n",
      "yotelerrific\n",
      "price=high\n",
      "65-ye\n",
      ".greater\n",
      "plus..the\n",
      "rooms:3/5\n",
      "bravi\n",
      "..ok\n",
      "iverpriced\n",
      "lobby-fabulous\n",
      "acknowledgem\n",
      "ho-hum\n",
      "wounderful\n",
      "35t\n",
      "hotels/c\n",
      "venetian**\n",
      "pros*location\n",
      "uchicago\n",
      "whathe\n",
      "üëç‚ú®üåü\n",
      "contemproary\n",
      "doorm\n",
      "pre-pa\n",
      "bathoom\n",
      "gongrats\n",
      "cubs/braves\n",
      "courtyard/herald\n",
      "village.i\n",
      "exprrience\n",
      "servicefantastic\n",
      "great.rooms\n",
      "emili\n",
      "bidget\n",
      "off-sit\n",
      "fitness-center\n",
      "ameritania\n",
      "recenly\n",
      "hermanattorney\n",
      "bland-looking\n",
      "sepember\n",
      "double-tree\n",
      "programme-smallish\n",
      "harware\n",
      "verh\n",
      "all-\n",
      "remodel=great\n",
      "wonderful-roomy\n",
      "designal\n",
      "average/family\n",
      "prosperlw\n",
      "unannouced\n",
      "designhotel\n",
      "roomm\n",
      "sdfsdfvsc\n",
      "lecayation\n",
      "luxurious‚Äîmaybe\n",
      "-right\n",
      "dealbreake\n",
      "smellu\n",
      "vegas2017\n",
      "staff..disappointing\n",
      "teriffic\n",
      "traini\n",
      "exterodnery\n",
      "fatili\n",
      "days.after\n",
      "..fun\n",
      "eatteries\n",
      "spou\n",
      "üéâ\n",
      "3star\n",
      "unhea\n",
      "rewads\n",
      "cleaning/renovating\n",
      "westide\n",
      "styley\n",
      "outstandin\n",
      "jayisvegas\n",
      "aweful\n",
      "at.very\n",
      "ÏßÅÏõêÎì§Ïù¥\n",
      "non-smo\n",
      "juar\n",
      "positionlovely\n",
      "comfortable/affordable\n",
      "covention\n",
      "un-special\n",
      "ngice\n",
      "guests-no\n",
      "getti\n",
      "fabulous.the\n",
      "livley\n",
      "vegas-what\n",
      "stayüòä\n",
      "stayvery\n",
      "arthitis\n",
      "location.onl\n",
      "hearti\n",
      "invitin\n",
      "expect..clean\n",
      "tswift\n",
      "stayd\n",
      "lobby/bar/resta\n",
      "sevices\n",
      "budjet\n",
      "9and\n",
      "tripadvi\n",
      "getta\n",
      "bullc\n",
      "stuffyoldspot\n",
      "vamboose\n",
      "berkshi\n",
      "alexan\n",
      "unqu\n",
      "uncomfy\n",
      "citie\n",
      "rate/r\n",
      "congratullations\n",
      "satisfication\n",
      "accr\n",
      "showers/pricy\n",
      "feature.came\n",
      "conociendo\n",
      "cafe/restaurant\n",
      "aparthotel\n",
      "clean/comfy\n",
      "travellodge\n",
      "days.when\n",
      "..what\n",
      "untl\n",
      "pre-pu\n",
      "terrace-estate\n",
      "exchan\n",
      "worksclubhou\n",
      "wynn..the\n",
      "5:45am\n",
      "rocky..\n",
      "feb.2\n",
      "doubltree\n",
      "üéâüôèüèΩ\n",
      "adreane\n",
      "anonimus\n",
      "location/property\n",
      "un-believably\n",
      ".terrible\n",
      "price-place\n",
      "comopolita\n",
      "bogu\n",
      "simple-the\n",
      "chekced\n",
      "beauftul\n",
      "parkng\n",
      "'wont\n",
      "nonsupportive\n",
      "showi\n",
      "time..seafood\n",
      "hotel/sad\n",
      "rainb\n",
      "üòí\n",
      "-get\n",
      "nouveaut√©s\n",
      "localizati\n",
      "progr\n",
      "wishe\n",
      "unbeliavable\n",
      "DG'DG\n",
      "stay/exceeded\n",
      "14-21st\n",
      "bloomi\n",
      "non-strip\n",
      "spcaious\n",
      "service.yet\n",
      "booses\n",
      "centralon\n",
      "..small\n",
      "property/horrific\n",
      "embarra\n",
      "details/amenities/location\n",
      "incredable\n",
      "newyorkcity\n",
      "lareg\n",
      "1nigh\n",
      "category..\n",
      "huddob\n",
      "allowe\n",
      "roulett\n",
      "*lie*\n",
      "rememb\n",
      "summeri\n",
      "'heads\n",
      "thev2\n",
      "good..some\n",
      "warick\n",
      "basketba\n",
      "3-generation\n",
      "worn/o\n",
      "minescule\n",
      "reqd\n",
      "in2\n",
      "rooms/appartments\n",
      "2nd-5th\n",
      "boujee\n",
      "unprofesional\n",
      "butttttt\n",
      "deliverry\n",
      "layov\n",
      "to-go\n",
      "grandciew\n",
      "vegas-yeah\n",
      "w/two\n",
      "ufinished\n",
      "-clean\n",
      "locationj\n",
      "arrivi\n",
      "york-nomad\n",
      "considerabl\n",
      "week.rooms\n",
      "bussiness/leisure\n",
      "'burgundy\n",
      "ambiance.classic\n",
      "hotel/pool/casino\n",
      "resorr/\n",
      "maintanace\n",
      "blistery\n",
      "mini-moon\n",
      "prais\n",
      "barcl\n",
      "yourk\n",
      "ok/decent\n",
      "stff\n",
      "kation\n",
      "excali\n",
      "amenties\n",
      "execpt\n",
      "well-updat\n",
      "nickle-and\n",
      "heared\n",
      "peop\n",
      "concerne\n",
      "moonlightlady77\n",
      "perfect+\n",
      "cheeseboard\n",
      "location-average\n",
      "*s.\n",
      "12-per\n",
      "unbeatabl\n",
      "*spacious\n",
      "swiftl\n",
      "retur\n",
      "migh\n",
      "over-\n",
      "sophisti\n",
      ".on\n",
      "rfect\n",
      "queena\n",
      "updati\n",
      "businesd\n",
      "unpleasant.the\n",
      "stated-\n",
      "thomascoo\n",
      "loyees\n",
      "b2v\n",
      "alterntive\n",
      ".gorgeous\n",
      "'de\n",
      "bewar\n",
      "hotel-stay\n",
      "view‚Ä¶its\n",
      "reluctan\n",
      "weekend-even\n",
      "neighbo\n",
      "budget-minded\n",
      "support/zero\n",
      ".may\n",
      "vacationin\n",
      "heating/aircon\n",
      "sept..trip\n",
      "ÔΩàÔΩèÔΩïÔΩìÔΩÖÔΩãÔΩÖÔΩÖÔΩêÔΩÖÔΩí\n",
      "meeh\n",
      "orienta\n",
      "highrolle\n",
      "olgi\n",
      "exud\n",
      "awayh\n",
      "hotelst\n",
      "bwrn\n",
      "whst\n",
      "obnox\n",
      "hotel/casiono\n",
      "cristina.t\n",
      "smith.the\n",
      "driv\n",
      "staff.ol\n",
      "alishi\n",
      "‚Ä¢never‚Ä¢\n",
      "discer\n",
      "staff..rooms\n",
      "6nts\n",
      "undergoi\n",
      "'nob\n",
      "mlahh\n",
      "eh..probably\n",
      "back-packers\n",
      "complai\n",
      ".much\n",
      "gansevo\n",
      "exchage\n",
      "quin-tes-sen-tial\n",
      "on-par\n",
      "belate\n",
      "faciliry\n",
      "n.y.c\n",
      "cleansecure\n",
      "positive:1.\n",
      "hospitality.\\nju\n",
      "family-\n",
      "stori\n",
      "knowlegable\n",
      "expectstions\n",
      "non-welcoming\n",
      "safety/service\n",
      "wtcone\n",
      "stewa\n",
      "omah\n",
      "street/downtown\n",
      "expectations-\n",
      "freez\n",
      "kwancheewa\n",
      "getaway-\n",
      "weekendd\n",
      "visua\n",
      "fifty-some\n",
      "vegas‚Ä¶..we\n",
      "moverse\n",
      "atendimento\n",
      "monumen\n",
      "~truly\n",
      "furnishings/decor\n",
      "ri-oh-no\n",
      "commencin\n",
      "mgmgrand\n",
      "stenc\n",
      "hotel-the\n",
      "anddevon\n",
      "hotel/not\n",
      "room/wonderful\n",
      "fee,18\n",
      "chisled\n",
      "sophitel\n",
      "wonderful.it\n",
      "breeak\n",
      "regularl\n",
      "2018.it\n",
      "positivescomfortable\n",
      "renovated..\n",
      "uncomparable\n",
      "partne\n",
      "sophistacated\n",
      "in-ro\n",
      "medium/large\n",
      "hotel..fabulous\n",
      "üëç\n",
      "vegastraveller\n",
      "nicw\n",
      "bronto-hotel\n",
      "rumkae\n",
      "homefeeling\n",
      "baby-friendl\n",
      "service-amazing\n",
      "mehhhh\n",
      "night-\n",
      "love..love..l\n",
      "tropicannot\n",
      "exceptional/front\n",
      "square.norm\n",
      "topclass\n",
      "anouther\n",
      "midwest-a\n",
      "return..\n",
      "wehave\n",
      "environm\n",
      "exceptionsl\n",
      "headquar\n",
      "loude\n",
      ".gold\n",
      "guestwow\n",
      "..unbelievably\n",
      "fountai\n",
      "..arrived\n",
      "rooms-personn\n",
      "king/queen\n",
      "***new\n",
      "lobby/entrance\n",
      "intresting\n",
      "dadbeh\n",
      "paople\n",
      "york/vegas\n",
      "aepi\n",
      "cleangr\n",
      "party-michael\n",
      "stay.fancy\n",
      "ameneties\n",
      "80¬¥s\n",
      "iÃánnside\n",
      "family~\n",
      "location-competitive\n",
      "breakfat\n",
      "hotel.close\n",
      "11x11\n",
      "depressiing\n",
      "area/\n",
      "suare\n",
      "DGDG.DGDG/DGDG\n",
      "brazil.chicago\n",
      "..also\n",
      "gallavanting\n",
      "strip..great\n",
      "17r\n",
      "night.great\n",
      "good-restaurants\n",
      "disorga\n",
      "directio\n",
      "casino/dining\n",
      "yes‚Ä¶i\n",
      "week.c\n",
      "roomwith\n",
      "design-centric\n",
      "lapt\n",
      "fabukous\n",
      "reluct\n",
      "gine\n",
      "price*\n",
      "financial/world\n",
      "sr2018\n",
      "finnest\n",
      "wedding/50th\n",
      "nightslocation\n",
      "celestiho\n",
      "ived\n",
      "hotelclean\n",
      "localsfor\n",
      "well-establi\n",
      "fruendky\n",
      "but-good\n",
      "37w\n",
      "roomscomfy\n",
      "◊û\n",
      "value/price\n",
      "aslways\n",
      "-times\n",
      "locationand\n",
      "old-sty\n",
      "2017/winter\n",
      "boojie\n",
      "yilliam\n",
      "front-desk\n",
      "recomend\n",
      "casinol\n",
      "-boo\n",
      "fabulas\n",
      "kazowie\n",
      "‚òÄÔ∏èvegas\n",
      "chgo\n",
      "'management\n",
      "property..kind\n",
      "possilbly\n",
      "experie\n",
      "pool.hate\n",
      "nyrs\n",
      "gathe\n",
      "half-pleasure\n",
      "exceptionly\n",
      "hotel/friendly\n",
      "visito\n",
      "consecutiv\n",
      "expeirienc\n",
      "courtious\n",
      "autog\n",
      "12y\n",
      "'base\n",
      "vacationwe\n",
      "purrfect\n",
      "trip/family\n",
      "waaaay\n",
      "excellentlocation\n",
      "rates/deals\n",
      "re-p\n",
      "pristi\n",
      "floo\n",
      "pluseswe\n",
      "closen\n",
      "stonet\n",
      "-my\n",
      "treck\n",
      "goidcand\n",
      "iv'e\n",
      "desappointig\n",
      "bellagio-5\n",
      "accommodation-\n",
      "soundproofno\n",
      "stratsphere\n",
      "sanfransiso\n",
      "dvdn\n",
      "fabulou\n",
      "treacey\n",
      "semi-frequent\n",
      "cacation\n",
      "some.rooms\n",
      "m.g.m\n",
      "crai\n",
      "17h-21s\n",
      "intercontinentals\n",
      "tablott\n",
      "‚Äîquiet\n",
      "kevi\n",
      "exstra\n",
      "6-nights\n",
      ".was\n",
      "hotel-okay\n",
      "ambassbor\n",
      "11:00pm\n",
      "cunninghamm\n",
      "bussle\n",
      "courtyard-y\n",
      "regul\n",
      "about40\n",
      "find.\n",
      "attractio\n",
      "breakfastexellent\n",
      "situatated\n",
      "innthe\n",
      "wyndha\n",
      ".nothin\n",
      "3.00pm\n",
      "location/value\n",
      "service-would\n",
      "pharohcious\n",
      "location/air-conditioning\n",
      "fraudule\n",
      "wall\\nnot\n",
      "3:30am\n",
      "detailsbarten\n",
      "comcast.net\n",
      "undescript\n",
      "small/average/\n",
      "convini\n",
      "gitlab\n",
      "spruc\n",
      "chica-go\n",
      ",could\n",
      "nightsour\n",
      "limted\n",
      "deal/location/rooms\n",
      "beginsa\n",
      "indogo\n",
      "daugh\n",
      "herep\n",
      "team.i\n",
      "bed-pillows\n",
      "updating..\n",
      "road.we\n",
      "3rd-7\n",
      "priceli\n",
      "mini-honeymoon\n",
      "20something\n",
      "sculp\n",
      "nikko/sa\n",
      "comentario\n",
      "satisfiedstaf\n",
      "staycamoon\n",
      "peoplefi\n",
      "affordabilty\n",
      ".reall\n",
      "..thi\n",
      "nday\n",
      "nlake\n",
      "+really\n",
      "disappointm\n",
      "older/average\n",
      "placr\n",
      "enjoyin\n",
      "expr\n",
      "dirty..you\n",
      "Ë∂ÖÂÄº\n",
      "toiletrie\n",
      "1-2x\n",
      "sprie\n",
      "there~~~\n",
      "well-staffed\n",
      "tadisson\n",
      "-/\n",
      "jack-\n",
      "-DG/DG\n",
      "slightl\n",
      "thedez72\n",
      "service-cyril\n",
      "befo\n",
      "freindly\n",
      "ÏúÑÏπòÏùò\n",
      "tandmmelbourne\n",
      "evertrying\n",
      "waitre\n",
      "outsanding\n",
      "else-across\n",
      "uniquel\n",
      "grief..\n",
      "dalmasi\n",
      "noise-proof\n",
      "check-in/check-ou\n",
      "refriger\n",
      "worderful\n",
      "greenwhich\n",
      "sleep/hangout\n",
      "governme\n",
      "excisting\n",
      "fift\n",
      "attentive/\n",
      "anniverasary\n",
      "portemonnaie\n",
      "50'th\n",
      "stayed1/30/2015\n",
      "roomma\n",
      "mondr\n",
      "staff-interesting\n",
      "errm\n",
      "vrey\n",
      "dovest\n",
      "t-moblie\n",
      "prosbeautiful\n",
      "desgin\n",
      "hightlight\n",
      "foremo\n",
      "hotelfar\n",
      "2601p\n",
      "DG-DG/DG*\n",
      "swiss√¥tel-chicago\n",
      "1st-5th\n",
      "radison\n",
      "nyc-basic\n",
      "vegas.the\n",
      "formi\n",
      "vegas.great\n",
      "easy/quick\n",
      "well-converted\n",
      "tech-minded\n",
      "friendlyüòä\n",
      "hangi\n",
      "chlsea\n",
      "DG-DG\n",
      ".centra\n",
      "üëèüèªüëèüèªüëèüèªüëèüèªüëèüèªüëèüèªüëèüèª\n",
      ".go\n",
      "severall\n",
      "b'fast\n",
      "dinner/th\n",
      "music..this\n",
      "midwee\n",
      "lvtc\n",
      "mammo\n",
      ".can\n",
      "fully-equipped\n",
      "nicebreakfast\n",
      "tumes\n",
      "recal\n",
      ".gone\n",
      "linq'ed\n",
      "play.every\n",
      "hanicap\n",
      "renaissanc\n",
      "refus\n",
      "1hotel\n",
      "value-\n",
      "conditi\n",
      "procedur\n",
      "gooda\n",
      "lackings\n",
      "bsbve\n",
      "timessqaure\n",
      "want-to-be\n",
      "antwonne\n",
      "low-bu\n",
      "kandjcanada\n",
      "nashvi\n",
      "dige\n",
      "what/where\n",
      "statosphere\n",
      "amabassador\n",
      "bellagii\n",
      "sooooo-ho\n",
      "town/gold\n",
      "nesteled\n",
      "location.but\n",
      ".ni\n",
      "location/comfortable\n",
      "bellma\n",
      "\\value\n",
      "themselv\n",
      "'stri\n",
      "oxellana\n",
      "fine.the\n",
      "truned\n",
      "you/great\n",
      "sapace\n",
      "value/awesome\n",
      "execllent\n",
      "knic\n",
      "november2015\n",
      "fiendly\n",
      "great1\n",
      "wowowowow\n",
      "coldth\n",
      "birthday/anni\n",
      "***fantastic\n",
      "approp\n",
      "terry.beechwood\n",
      "weekedn\n",
      "paddys\n",
      "abrunch\n",
      "world-mark\n",
      "drinke\n",
      "six-nigh\n",
      "floater/supervis\n",
      "amazing.s\n",
      "second/third\n",
      "comfy/clean\n",
      "tempegal\n",
      "stripfree\n",
      "redeemin\n",
      "embodie\n",
      "sohos\n",
      "realaxing\n",
      "hotals\n",
      "recetption\n",
      "countin\n",
      "tenill\n",
      "beauiful\n",
      "cumberso\n",
      "salespers\n",
      "londom\n",
      "irritati\n",
      "poxy\n",
      "ti.all\n",
      "housekeeping/maintenanc\n",
      "disbel\n",
      "/good\n",
      "in/front\n",
      "oftimes\n",
      "staff/rules\n",
      "registratio\n",
      "doucheynes\n",
      "**compare\n",
      "nugg\n",
      "5-sta\n",
      "amendies\n",
      "l-o-v-e\n",
      "husband/wif\n",
      "d/t\n",
      "komfortable\n",
      "dembek\n",
      "overall‚Äã\n",
      "moneystaff\n",
      ".'but\n",
      "telk\n",
      "night-stay\n",
      "boyfrien\n",
      "soilder\n",
      "pass-\n",
      "enterin\n",
      "locationminus\n",
      "nights.its\n",
      "hotel¬°¬°¬°\n",
      "member~we\n",
      "regr\n",
      "/cold\n",
      "toatally\n",
      "non-timeshare\n",
      "interphex\n",
      "here.it\n",
      "eggplant/char\n",
      "hotel.large\n",
      "acharm\n",
      "impressedseeing\n",
      "b.j\n",
      "fransisc\n",
      "loctation-\n",
      "exxxtraordinaire\n",
      "imilda\n",
      "swan'derful\n",
      "halfw\n",
      "location.th\n",
      "bodybuild\n",
      "service..\n",
      "location/updated\n",
      "cogna\n",
      "poiints\n",
      "-parls\n",
      "harrara\n",
      "üíïüíïüíï\n",
      "thems\n",
      "5-c\n",
      "'putting\n",
      "parkor\n",
      "nyc.amazi\n",
      "renevations\n",
      "unparralleled\n",
      "apartment-\n",
      "plact\n",
      "pregrand\n",
      "w/service\n",
      "..survives\n",
      "undergood\n",
      "nice.a\n",
      "watchout\n",
      "rippoff\n",
      "pluse\n",
      "thelinq\n",
      "work/fun/family-great\n",
      "pompou\n",
      "night.no\n",
      "eccetic\n",
      "indifferent/seemed\n",
      "marina/fisheman\n",
      "unforgetable\n",
      "bumby\n",
      "a-changing\n",
      "flexibl\n",
      "excepti\n",
      "tryed\n",
      "5pm-6pm\n",
      "friday/saturda\n",
      ".overpriced\n",
      "utmos\n",
      "joke..\n",
      "staysome\n",
      "desk/mgmt\n",
      "stay/loved\n",
      "check-in.great\n",
      "connecte\n",
      "mejude\n",
      "pseudo-luxe\n",
      "benie\n",
      "awasome\n",
      "gremli\n",
      "'nuf\n",
      "day..\n",
      "lobasso\n",
      "celbrating\n",
      "pensionne\n",
      "weeekend\n",
      "overnight-there\n",
      "theater-going\n",
      "watchfull\n",
      "extrava\n",
      "me.t\n",
      "faily\n",
      "availabili\n",
      "decor/atmo\n",
      "replacemen\n",
      "location.excellent\n",
      "knd\n",
      "periodicall\n",
      "avereage\n",
      "uncsw61\n",
      "thepeninsulanewyork\n",
      "exp√©riences\n",
      "tlc..\n",
      "*location\n",
      "gorgoues\n",
      "coveniently\n",
      "dirtydrug\n",
      "acmazing\n",
      "techies/business\n",
      "construci\n",
      "superbbbb\n",
      "together-\n",
      "home..visit\n",
      "woldy\n",
      "comon\n",
      "location-centrally\n",
      "there.rooms\n",
      ".bring\n",
      "suprice\n",
      "vdara..\n",
      "younder\n",
      "amertiania\n",
      "updating/dirty\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "un-affordable\n",
      "circus-perfect\n",
      "ffor\n",
      "unforget\n",
      "absoluteley\n",
      "verall\n",
      "either..\n",
      "honestly‚Ä¶..t\n",
      "2-s\n",
      "nyw\n",
      "worstinlv\n",
      "merm\n",
      "6yr\n",
      "idk\n",
      "'goldi\n",
      "reloca\n",
      "decived\n",
      "wellnes\n",
      "DGDG-DGDG/DGDG\n",
      "vegas-summerlin\n",
      "breakfast/location\n",
      "üåü\n",
      "further‚Ä¶..\n",
      "street/water\n",
      "properry\n",
      "mark100101\n",
      "downgr\n",
      "'sleeper\n",
      "soumia\n",
      "bueatif\n",
      "250/night\n",
      "location.location\n",
      "spectac\n",
      "sounth\n",
      "anniversry\n",
      "central..\n",
      "price..\n",
      "value/excellent\n",
      "deco/m\n",
      "fantasticly\n",
      "-fabulous\n",
      "trumpto\n",
      "üòòlove\n",
      "service2\n",
      "-DG-DG.DG\n",
      "excelentisimo\n",
      "room/restroom\n",
      "bday/x-mas\n",
      "roomausti\n",
      "shocki\n",
      "berrygirls\n",
      "mother/daughter/sister\n",
      "fri-sat\n",
      "ppai\n",
      "signif\n",
      "masterpie\n",
      "air/h\n",
      "over-night\n",
      "columbi\n",
      "rentivated\n",
      "wch\n",
      "3-nights\n",
      "service/food/amenities\n",
      "vgood\n",
      "overpo\n",
      "serveral\n",
      "choic\n",
      "uncom\n",
      "postioned\n",
      "hotelrooms\n",
      "property/better\n",
      "3-ni\n",
      "courteou\n",
      "trinit\n",
      "centerf\n",
      "scared..\n",
      "maequis\n",
      "great/check-in\n",
      "renessance\n",
      "trip-advisors\n",
      "gustavs\n",
      "bueatifu\n",
      "overdelivers\n",
      "po-no\n",
      "mixed-bag\n",
      "location..nice\n",
      "ritz/marr\n",
      ".-\n",
      "'on\n",
      "etccasino\n",
      "midtown-great\n",
      "aveag\n",
      "terrifc\n",
      "park/time\n",
      "b.w\n",
      "west/hells\n",
      "experience-best\n",
      "entertai\n",
      "casino-no\n",
      "cardamon\n",
      "iroquo\n",
      "hairdr\n",
      "expanisive\n",
      "homeles\n",
      "anither\n",
      "nouse\n",
      "closel\n",
      "w/ou\n",
      "room.h\n",
      "clean/cute\n",
      "sister-in\n",
      "5th-12th\n",
      "utlets\n",
      "superprobably\n",
      "perpared\n",
      "decied\n",
      "overhypef\n",
      "start.when\n",
      "guest-servic\n",
      "apearance\n",
      "hoorter\n",
      "property-awesome\n",
      "vedors\n",
      "superstay\n",
      "chelse\n",
      "priceles\n",
      "remode\n",
      "month.june\n",
      "elese\n",
      "36t\n",
      "bigmatzaball\n",
      "brealfast\n",
      "confefence\n",
      "weekendedu\n",
      "surcharg\n",
      "casino-did\n",
      "freeha\n",
      "ü§ó\n",
      "DGDGDG/DG\n",
      "besttrip\n",
      "overpriced-\n",
      "qualif\n",
      "again‚Äîwith\n",
      "tonigh\n",
      "hiltonclub\n",
      "remodeo\n",
      "disappontments\n",
      "everal\n",
      "business/couple\n",
      "renovation/construction\n",
      "4times\n",
      "experinece\n",
      "cancelon\n",
      "ginourmous\n",
      "unha\n",
      "droppe\n",
      "penthous\n",
      "resis\n",
      "donnot\n",
      "-home\n",
      "aschyan\n",
      "DG/DG-DG/DG\n",
      "wynn-anytime\n",
      "european-feel\n",
      "understandard\n",
      "vacatoin\n",
      "coud't\n",
      "gustopo\n",
      ".bed\n",
      "goess\n",
      "alise.we\n",
      "'trendy\n",
      "absinth\n",
      "w-lan\n",
      "-sarbi\n",
      "favoraite\n",
      "explendid\n",
      "wowsome\n",
      "‚ûïro\n",
      "want..\n",
      "80t\n",
      "spg/marriot\n",
      "restaurang\n",
      "hotello\n",
      ",small\n",
      "caesar's.star\n",
      "rocks/studi\n",
      "stay..friendly/profes\n",
      "phenomenal..\n",
      "nicwe\n",
      "ok-very\n",
      "accomadat\n",
      "midtown-\n",
      "everythng\n",
      "shop/blyss\n",
      "end-az-we-knew-it\n",
      "rooms/reasonable\n",
      "stay‚ò∫\n",
      "fantastic-\n",
      "dicriminates\n",
      "tourist-y\n",
      "vegastrip\n",
      "11:00am\n",
      "managed/well\n",
      "whitrehall\n",
      "say..\n",
      "vegas.\n",
      "ehvc\n",
      "omg..what\n",
      "mountain/a\n",
      "yohenny\n",
      "location..however\n",
      "nyorker\n",
      "proximidade\n",
      ".quiet\n",
      "hayatt\n",
      "romanti\n",
      "grandm\n",
      "400/night\n",
      "aniv\n",
      "comforatble\n",
      "2/bag\n",
      "boutique..for\n",
      "tdw0716x\n",
      "crampec\n",
      "introducto\n",
      "boyf\n",
      "16yr\n",
      "bathless\n",
      "üß°\n",
      "wharfmy\n",
      "withphon\n",
      "re-modele\n",
      "futu\n",
      "gansevoortlife\n",
      "aaahhhhmazing\n",
      "convenient-ish\n",
      "deliande\n",
      "super-hip\n",
      "-certainly\n",
      "ulti\n",
      "shazzam\n",
      "effectiv\n",
      "spontanious\n",
      "much.soph\n",
      "medicocre\n",
      "Ï°∞Í∏à\n",
      "marquies\n",
      "dysfuncti\n",
      "thoughtfu\n",
      "deriso\n",
      "tonfind\n",
      "greatro\n",
      "dealers.p\n",
      "thursday-s\n",
      "wofi\n",
      "reasona\n",
      "intrique\n",
      "gentlem\n",
      "excellent.service\n",
      "comps/rewards\n",
      "medioker\n",
      "-daughter\n",
      "revonations\n",
      "..there\n",
      "circus-still\n",
      "endl\n",
      "bay=the\n",
      "assistent\n",
      "fabulousity\n",
      "amenities.staff\n",
      "majes\n",
      ".are\n",
      "opitome\n",
      "residen\n",
      "family..california\n",
      "hawthone\n",
      "appreh\n",
      "day.well\n",
      "flaimngo\n",
      "/husband\n",
      "-spacious\n",
      "fricken\n",
      "foidcourt\n",
      "biz/getaway\n",
      "smack-da\n",
      "locatioin\n",
      "relia\n",
      "customerr\n",
      "meatpackin\n",
      "'startled\n",
      "frisc\n",
      "comfee\n",
      "witnesse\n",
      "hicheck\n",
      "-or\n",
      "aderah\n",
      "emaculate\n",
      "positives..\n",
      "redoux\n",
      "enoughp\n",
      "10.pros\n",
      "5+star\n",
      "burgun\n",
      "crowni\n",
      "inappropria\n",
      "broadwalk\n",
      "dinera\n",
      "reqest\n",
      "pre-ch\n",
      "mystichotel\n",
      "'special\n",
      "apartm\n",
      "asthough\n",
      "jotyrrell\n",
      "choicr\n",
      "fabulosity\n",
      "day/president\n",
      "hickups\n",
      "business/get-a-way\n",
      ".ab\n",
      "‚òÜtop-notch‚òÜ\n",
      "baseboar\n",
      "dippie\n",
      "mydisplays\n",
      "youto\n",
      "midtown-centrally\n",
      "hyatt-mlife\n",
      "farthe\n",
      "5-nig\n",
      "togh\n",
      "w=worst\n",
      "nons\n",
      "again..they\n",
      "hiltoon\n",
      "rediciously\n",
      "staying/pl\n",
      "view/sunlight\n",
      "perspective-\n",
      "location/room/breakfast\n",
      "v-dog\n",
      "boist\n",
      "atlanti\n",
      "uber-chic\n",
      "frustra\n",
      "DGDGDG‚Ä¢\n",
      "inn/chelsea\n",
      "inclinators\n",
      "services/\n",
      "15th-18t\n",
      "-es\n",
      "rovig\n",
      "retuu\n",
      "boysto\n",
      "üíû\n",
      "younique\n",
      "don'tt\n",
      "hideawaynew\n",
      "Ïù¥Î¶ÑÏù¥\n",
      "lvnv\n",
      "dad.my\n",
      "choosi\n",
      "spot-\n",
      "great/grand\n",
      "reunion-22\n",
      "twio\n",
      "retr\n",
      "hotel/restaurant\n",
      "nneighborhood\n",
      "reviewquick\n",
      "alveroll\n",
      "maintai\n",
      "stay.peopl\n",
      "◊ï◊ô◊ï◊™◊®\n",
      "janua\n",
      "hospitslity\n",
      "colleagu\n",
      "cq..\n",
      "lhh\n",
      "londonhouse\n",
      "rooms/horrible\n",
      ".bathroom\n",
      "lobby-yikes\n",
      "satisfactor\n",
      "pretty-\n",
      "club-\n",
      "casino.clean\n",
      "airf\n",
      "gettaway\n",
      "ovverpriced\n",
      "6days\n",
      "looooooved\n",
      "best-ests\n",
      "accaptable\n",
      "bygoe\n",
      "feathe\n",
      "relax-great\n",
      "e.hotel\n",
      "-overpriced\n",
      "spatious\n",
      "agr√©able\n",
      "intriguing..\n",
      "expectionther\n",
      "super-great\n",
      "1:00pm\n",
      "it..\n",
      "22hr\n",
      "wow-place\n",
      "family-versary\n",
      "5day\n",
      "surpised-\n",
      "in-\n",
      "atmorsphere\n",
      "madde\n",
      "favorite-stay\n",
      "'miracle\n",
      "admidst\n",
      "recepti\n",
      "stsyed\n",
      "perfor\n",
      "downhill..\n",
      "uniq\n",
      "stay.everything\n",
      "staffcl\n",
      "sex-driven\n",
      "-excellent\n",
      "hotelerie\n",
      "re-modeled\n",
      "staff.w\n",
      "screw-up\n",
      "knocki\n",
      "reslove\n",
      "palazzo/ve\n",
      "side*\n",
      "siteseeing\n",
      "casino-nice\n",
      "sqau\n",
      "favilities\n",
      ",steve\n",
      "almost-boutique\n",
      "-DG/DGDG\n",
      "timse\n",
      "joetells\n",
      "claustrophobics\n",
      "pyalo\n",
      "breakfastcoffe\n",
      "new/clean\n",
      "disguste\n",
      "weeks.check\n",
      "extravgrant\n",
      "nov/\n",
      "lobby/casino\n",
      "lisa/\n",
      "impact-stellar\n",
      "intimes\n",
      "*****from\n",
      "ashleyb\n",
      "cheapin\n",
      "hospitab\n",
      "overll\n",
      "rooms.an\n",
      "ÌÅ¨Í∏∞ÏôÄ\n",
      "augus\n",
      "foaming-at-the-mouth\n",
      "avarage\n",
      "moneyshow\n",
      "squarefantasti\n",
      "convenvient\n",
      "review-april\n",
      "chuckl\n",
      "luxuriou\n",
      "rooms/friendly\n",
      "favourote\n",
      "pravi\n",
      "iinadeq\n",
      "2015..first\n",
      ".goo\n",
      "location.surrounded\n",
      "-indulgence\n",
      "alwahs\n",
      "coatxben\n",
      "staz\n",
      "hilton26thstreetnyc‚Ä¢a+\n",
      "not-even-trained\n",
      "sofiyel\n",
      "muhammeed\n",
      "o.m.g\n",
      "l.e.a.d\n",
      "diamond/five\n",
      "sensati\n",
      "appealin\n",
      "post-snowstorm\n",
      "accommodations/experience\n",
      "money2\n",
      "left-fie\n",
      "famiily\n",
      "delighte\n",
      "revieu\n",
      "2n/3d\n",
      "noisy.no\n",
      "queen-queen\n",
      ".grrreeaat\n",
      "revu\n",
      "m'lady\n",
      "downpl\n",
      "immagination\n",
      "octavous\n",
      "showroom-spazmatics-cocktail\n",
      "relaxi\n",
      "ü§©\n",
      "refre\n",
      "ny2018\n",
      "valet-parke\n",
      "hunti\n",
      "notich\n",
      "work-first\n",
      "8yr\n",
      ".magnificent\n",
      "five+\n",
      "boutoque\n",
      "cleanersüò∑\n",
      "hotel-nice\n",
      "bachache\n",
      "trumo\n",
      "raini\n",
      "hotel/clean/big\n",
      "boxworks\n",
      "everybo\n",
      "57t\n",
      "amazing-\n",
      "pre-\n",
      "stay..highly\n",
      "unfriendly/rude\n",
      "grand-daddy\n",
      "location.helpful\n",
      "it.great\n",
      "sherry-netherland\n",
      "swua\n",
      "located.rooms\n",
      "carrefull\n",
      "shopping/fun\n",
      "dirtybird\n",
      "impectable\n",
      "sfcm\n",
      "nylo-a\n",
      "excelkent\n",
      "‚àö‚àö‚àö\n",
      "venician\n",
      "fredenly\n",
      "location30\n",
      "üîº\n",
      "..m\n",
      "queens-nice\n",
      "amazing.relaxing\n",
      "üóΩ\n",
      "receptioni\n",
      "rejuvenat\n",
      "/one\n",
      "drinky\n",
      "dreamforce\n",
      "granview\n",
      "updating/\n",
      "it.however\n",
      "7:45pm\n",
      "propertu\n",
      ".wish\n",
      "girli\n",
      "tjmes\n",
      "hostel-lik\n",
      "compar\n",
      "reno/update\n",
      ".unbelievabl\n",
      "'irving\n",
      "price/good\n",
      "1.check\n",
      "skyridge\n",
      "cabbing\n",
      "reliable-feels\n",
      "haptom\n",
      "convential\n",
      "hotel.new\n",
      "piramid\n",
      "comfy..rooms\n",
      "goodnot\n",
      "mukemmel-\n",
      "penin\n",
      "baseba\n",
      "public..\n",
      "staystaff\n",
      "t-mobil\n",
      "rumel\n",
      "hotel/location/restaurant\n",
      "orleans-off\n",
      "spa/pool\n",
      "staycation/birthday\n",
      "classy..beautiful\n",
      "cristmas\n",
      "out-of-\n",
      "hotel..medium\n",
      "ascetically\n",
      "righteours\n",
      "üëçüèºüëçüèºüëçüèº\n",
      ".pretty\n",
      "quallity\n",
      "'mini-moon\n",
      "vondo\n",
      "hotel..lobby\n",
      "wedding/honeymoon/anniversary\n",
      "all-wow\n",
      "evacuat\n",
      "locale-\n",
      "location/three\n",
      "feb18\n",
      "nauseat\n",
      "milenium\n",
      "locatoin\n",
      "staff/manageme\n",
      "evryone\n",
      "week.u\n",
      "lonby\n",
      "desk/re\n",
      "addm\n",
      "westgate-sportsbook\n",
      "visir\n",
      "homealers\n",
      "chocolatini\n",
      "necessit\n",
      "terriific\n",
      "‚òπÔ∏èÔ∏è\n",
      "price-good\n",
      "hotel.fan\n",
      "modern-loo\n",
      "francisco.th\n",
      "hesitan\n",
      "exvcellent\n",
      "overcharing\n",
      "avoidi\n",
      "sizegood\n",
      "well-loca\n",
      "red-y\n",
      "dingy..room\n",
      "'great\n",
      "disappointed-average\n",
      "specacular\n",
      "n.y.ye\n",
      "buckto\n",
      "unhelpf\n",
      "cost-benifits\n",
      "argouna\n",
      "location/hotel/casino\n",
      "property/rooftop\n",
      "espa√±olexcellent\n",
      "fraudlent\n",
      "joella\n",
      "47t\n",
      "nyer\n",
      "unrightfully\n",
      "trade/freedom\n",
      "fallbreak\n",
      "way.now\n",
      "hotel/condos\n",
      "skippies\n",
      "perfo\n",
      "pool/cabana\n",
      "upgrade-\n",
      "cestomer\n",
      "facilitie\n",
      "chestnu\n",
      "embassey\n",
      ",not\n",
      "moment.t\n",
      "dreamüòç\n",
      "incorrec\n",
      "post-conference\n",
      "eleveators\n",
      "legionaire\n",
      "serve-not\n",
      "madn\n",
      "medina/june\n",
      "bashua\n",
      "relat\n",
      "co-joined\n",
      "herestaff\n",
      "totimes\n",
      "***dated\n",
      "podem\n",
      "never-ag\n",
      "warning-never\n",
      "uninvitin\n",
      "districty\n",
      "time-wow\n",
      "on-lin\n",
      "peoperty\n",
      "'fabulous\n",
      ".theirs\n",
      "evenlyn\n",
      "washisle5\n",
      "donto\n",
      "highlyyy\n",
      "noise-filled\n",
      "DG-DGDG-DG\n",
      "360/night\n",
      "unit.h\n",
      "consu\n",
      "lavegas\n",
      "keepe\n",
      "rooms/de\n",
      "paridse\n",
      "lovely/\n",
      "enojyed\n",
      "magmile\n",
      "monor\n",
      "bi-coastal\n",
      "falmingo\n",
      "magnific\n",
      "tuisse\n",
      "laqui\n",
      "mjkaty\n",
      "janelly\n",
      "exeptional\n",
      "gesicht\n",
      "deposti\n",
      "ever.rude\n",
      "stay-\n",
      ".leon\n",
      ".comfy\n",
      "cocert\n",
      "reactio\n",
      "22nd-26th\n",
      "goodm\n",
      "om-mazing\n",
      "easter/spring\n",
      "offer-i\n",
      "inpressions\n",
      "reservi\n",
      "bewa\n",
      "'bates\n",
      "commoti\n",
      "funkest\n",
      "awsom\n",
      "broadway/time\n",
      "aimons\n",
      "until..\n",
      "supportcheck\n",
      "neevvvveeeerrrr\n",
      "large/clean\n",
      "savvina\n",
      "say-this\n",
      "developi\n",
      "ritz-carlt\n",
      "modern/maintained\n",
      "vegas-flamingo\n",
      "placeÔøΩÔøΩÔøΩÔøΩÔøΩ\n",
      "liife\n",
      "sept.2015\n",
      "viewbig\n",
      "hotel‚Äîgreat\n",
      "ancie\n",
      "spoy\n",
      "comfortable-as\n",
      "perfect/location\n",
      "kitchen.a\n",
      "extrao\n",
      "location..location\n",
      "dizz\n",
      "non-cookie\n",
      "everywhere..\n",
      "hotel,5\n",
      "addebito\n",
      "ligging\n",
      "gnkx\n",
      "h17\n",
      "specisl\n",
      "nhsmun\n",
      "northwe\n",
      "location.comfy\n",
      "would/\n",
      "degre\n",
      "sconnect\n",
      "equival\n",
      "overrated..\n",
      "ofcou\n",
      "convenience/luxury\n",
      "work/convention\n",
      "wildberr\n",
      "cloase\n",
      "indian-inspired\n",
      "3-star***\n",
      "postin\n",
      "alawein\n",
      "peolpe\n",
      "nevert\n",
      "accomindating\n",
      "motherofthegroomparty\n",
      "hgvc\n",
      "unplea\n",
      "homele\n",
      "centric1\n",
      "endulgance\n",
      "play-ground\n",
      "magnamous\n",
      "/date\n",
      "houseke\n",
      "views/location/rooms/everything\n",
      "feb/20\n",
      "decad\n",
      "jubilie\n",
      "allanfront\n",
      "gentelman\n",
      "meridie\n",
      "accomoding\n",
      "hamtpon\n",
      "brianvery\n",
      "'paradise\n",
      "recompe\n",
      "heater/ac\n",
      "vibs\n",
      "houtel\n",
      "-23rd\n",
      "availa\n",
      "integr\n",
      "j-town\n",
      "germaphobe\n",
      "location/experience\n",
      "rate-\n",
      "-marginal\n",
      "Ï¢ãÏäµÎãàÎã§\n",
      "reconnec\n",
      "walker2771\n",
      "desperatel\n",
      "good.however\n",
      "..dirty\n",
      "37t\n",
      "2-ed\n",
      "pleasean\n",
      "locatipn\n",
      "romali\n",
      "'deals\n",
      "sf-loved\n",
      "square/hells\n",
      "hoteltm\n",
      "clean/comfortable/\n",
      "luxtury\n",
      "to-\n",
      "decent..\n",
      "innsode\n",
      "square-fantastic\n",
      "execeeded\n",
      "centeralized\n",
      "hotttt\n",
      "2:10am\n",
      "improvement..front\n",
      "2nd-7th\n",
      "quitet\n",
      "arrving\n",
      "cleanl\n",
      "staythe\n",
      "sorroundings\n",
      "foreve\n",
      "single/business\n",
      "budget-concious\n",
      "carnegi\n",
      "accomid\n",
      "mounta\n",
      "blousey\n",
      "premie\n",
      "comforta\n",
      "everyonethis\n",
      "-food\n",
      "waaaw\n",
      "intr\n",
      "commioning\n",
      "regre\n",
      "conceir\n",
      "unsafety\n",
      "badp\n",
      "bay-view\n",
      "class/style\n",
      "medium-len\n",
      "whe6\n",
      "evetything\n",
      ".terr\n",
      "sister/aunt\n",
      "meassured\n",
      "experience..m\n",
      "otherw\n",
      "less-than-s\n",
      "benifits\n",
      "dirty/dingy\n",
      "fooms\n",
      "clasic\n",
      "dormesque\n",
      "dirtly\n",
      "restaurant/room\n",
      "superb.we\n",
      "shortages.n\n",
      "-show\n",
      "hotelsan\n",
      "s3xy\n",
      "perfect*\n",
      "paradiseüå¥üå¥üå¥üå¥\n",
      "rionice\n",
      "harrah's..our\n",
      "j'adore\n",
      "anniversity\n",
      "excelen\n",
      "southw\n",
      "micro-boutique\n",
      "üëçüëçüëç\n",
      "authe\n",
      "convention-like\n",
      "concider\n",
      "priceywith\n",
      "greatloca\n",
      "fiar\n",
      "frigi\n",
      "out-of-dat\n",
      "hotel/awesome\n",
      "g-nugs\n",
      "improvable\n",
      "vacay\n",
      "bad-poor\n",
      "towels.room\n",
      "savoire\n",
      "ÊãâÊñØÁ∂≠Âä†ÊñØÂ§ßÈÅìÔΩû\n",
      "helenn\n",
      "x'mas\n",
      "liqu\n",
      "straigh\n",
      "snowed-in\n",
      "omno\n",
      "buisness/play\n",
      "****amazing\n",
      "affordab\n",
      "crazine\n",
      "applau\n",
      "upcharg\n",
      "trip/great\n",
      "grteat\n",
      "conventions/shopping\n",
      "trunorthwarranty\n",
      "-thursday\n",
      "nicew\n",
      "theme..\n",
      "cleanless\n",
      "greenwich/\n",
      "lovely.little.boutique\n",
      "ridic\n",
      "ashtr\n",
      "finiz\n",
      "ehhhhh\n",
      "vibe-\n",
      ".stays\n",
      "upselling\n",
      "fumes/iron/housekeeping/ice\n",
      "firstwe\n",
      "staycation/date\n",
      "3-sto\n",
      "dirty..\n",
      ".DGDG\n",
      "incompeten\n",
      "üòçüíñ\n",
      "nights.firs\n",
      "bewertungen\n",
      "a-ma-zing\n",
      "whelmed\n",
      "5mth\n",
      "non-gam\n",
      "furnishi\n",
      "visit.a\n",
      "unbeli\n",
      "clean.w\n",
      "rollerderby\n",
      "in/check\n",
      "wiev\n",
      "bedroom..\n",
      "idid\n",
      "cromwe\n",
      "slushie\n",
      "◊û◊ñ◊î\n",
      "impresssed.renovate\n",
      "city.ro\n",
      "ever~\n",
      "doubletee\n",
      "spolit\n",
      "posti\n",
      "inn-b\n",
      "cutelots\n",
      "in-r\n",
      "mega-hotel/casino\n",
      "least-l\n",
      "fitzpatri\n",
      "hemisphe\n",
      "exraordinary\n",
      "..been\n",
      "apartmentand\n",
      "disabl\n",
      ".take\n",
      "revoe\n",
      "intera\n",
      "underwhe\n",
      "excellent..location\n",
      "retre\n",
      "not-ke\n",
      "good-goo\n",
      "locstions\n",
      "tim.u\n",
      "uupon\n",
      "francisco..comfortable\n",
      "helpful.ro\n",
      "days.althoug\n",
      "non-baller\n",
      "nights.whils\n",
      "minusc\n",
      "eeewww\n",
      "hotel‚úàÔ∏èüöñüòÉ\n",
      "activity-\n",
      "boutique-with-\n",
      "..cant\n",
      "thenewvegas\n",
      "hipne\n",
      "notifica\n",
      "deeeeeeeeeesighnaaaaaaah\n",
      "aaaah\n",
      "art-d\n",
      "cathys\n",
      "expore\n",
      "agreat\n",
      "quick/g\n",
      "starsdoorme\n",
      "weekendgetaway\n",
      "wowwee..what\n",
      "laundrynapping\n",
      "¬£DGDGDG.DGDG\n",
      "-expensiv\n",
      "exp√©rience\n",
      "Ï¢ãÍ≥†\n",
      "amazingview\n",
      "neit\n",
      "terrible/frightening\n",
      "restor\n",
      "sq/rockefeller\n",
      "bsuiness\n",
      "wison\n",
      "√∂fters\n",
      "atmosphere/rooms/staff\n",
      "greatexperience\n",
      "agrand\n",
      "service/experience\n",
      "villiage\n",
      "entertaiiing\n",
      "afantastic\n",
      "experiendce\n",
      "wrong-\n",
      "allocat\n",
      "unsuperable\n",
      "drink-\n",
      "pineapple-icious\n",
      "7/18/17arrived\n",
      "marchume\n",
      "mini-condo\n",
      "leutakan\n",
      "'sliver\n",
      "price_close\n",
      "soltice\n",
      "inadver\n",
      "caution**\n",
      "eleg√¢ncia\n",
      "shouldve\n",
      "concret\n",
      "wento\n",
      "qualit\n",
      "m.b\n",
      "in/out..\n",
      "mayvegas2018\n",
      "husban\n",
      "4:45pm\n",
      "rippa\n",
      "arrggh\n",
      "jun2-9\n",
      "glamours\n",
      "hotel..\n",
      "lv2015\n",
      "aamzing\n",
      "frazi\n",
      "increible\n",
      "fantantasic\n",
      "attraktiv\n",
      "9:30ish\n",
      "dupper\n",
      "boutique-lite\n",
      "departure..seamless\n",
      "amazing.located\n",
      "location/underwhelming\n",
      "midtownÔºÅÔºÅÔºÅ\n",
      "conexpo2017\n",
      "frencisco\n",
      "hotel-just\n",
      "maintenece\n",
      "ehh.okay\n",
      "jubbly\n",
      "shabby.some\n",
      ".lar\n",
      "verycomfortable\n",
      "veery\n",
      "..basics\n",
      "reasobale\n",
      ".cleaner\n",
      "suite\\n2650\n",
      "convenance\n",
      "backg\n",
      "eeeknd\n",
      "soaki\n",
      "..love\n",
      "vegas.short\n",
      "standrd\n",
      ".there\n",
      "digngy\n",
      "◊©◊†◊ô◊ô◊î\n",
      "about1week.i\n",
      "it..the\n",
      "afterwork\n",
      "sucke\n",
      "mnice\n",
      "hortel\n",
      "stea\n",
      "withdr\n",
      "blame-the-guest\n",
      "uber-modern\n",
      "birthdat\n",
      "jlf\n",
      "check-i\n",
      "cleanfr\n",
      "üå≤\n",
      "nj/nyc\n",
      "‚Ä¶if\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blackhat\n",
      "timei\n",
      "bartende\n",
      "++++\n",
      "highy\n",
      "occassi\n",
      "lounge/restaurant\n",
      "invoicel\n",
      "sahhweet\n",
      "msbklyn\n",
      "reigistrat\n",
      "asian-inspired\n",
      "ÿ±ÿßÿ¶ÿπÿ©\n",
      "nfg\n",
      ".phone\n",
      "'westin\n",
      "outsid\n",
      "renovati\n",
      "kakkelakker\n",
      "'coupons\n",
      "zumunity\n",
      "inded\n",
      "menorial\n",
      "bycustomer\n",
      "*really*\n",
      "bigal\n",
      "indepe\n",
      "disinteres\n",
      "5the\n",
      "dotisha\n",
      "tournament/round\n",
      "pdma\n",
      "hospitality/rooms/gaming/entertainment\n",
      "unpdate\n",
      "defects.iro\n",
      "monol\n",
      "warning-this\n",
      "exactly..\n",
      "unles\n",
      "accessib\n",
      "rebbeca\n",
      "desgn\n",
      "beuaitful\n",
      "lacation\n",
      "hotel.st\n",
      "previoous\n",
      "hickup\n",
      "reslly\n",
      "route91\n",
      "carlsom\n",
      "subarashee\n",
      "wannabee\n",
      "unass\n",
      "fabu\n",
      "palom\n",
      "swirli\n",
      "value/stay\n",
      "unhear\n",
      "alalaiwi\n",
      "w/fun\n",
      "evrythi\n",
      "residual-yuck\n",
      "value/cool\n",
      "redox07\n",
      "acccommendations\n",
      "beds..\n",
      "expensive..\n",
      ",friendly\n",
      "improptu\n",
      "encor√©\n",
      "impoeccable\n",
      "accommod\n",
      "hotel.chic\n",
      "octber\n",
      "pre-aut\n",
      "backgroun\n",
      "days.happ\n",
      "9y\n",
      "bay.has\n",
      "paramou\n",
      "'strip\n",
      "kids‚Äîeasy\n",
      "building..\n",
      "handicapp\n",
      "down‚ùóÔ∏è\n",
      "embarrassin\n",
      "helpful.hash\n",
      "complain.the\n",
      "baisc\n",
      "westin.it\n",
      "stars.\n",
      "√©jszak√°k\n",
      "palalace\n",
      "parc55\n",
      "casablanc\n",
      "room/restaurants\n",
      "ckeck\n",
      "new/good\n",
      "locatiln\n",
      "mid-ap\n",
      "w22nd\n",
      "efficient-\n",
      "casino-free\n",
      "concious\n",
      "üëåüòÅ\n",
      "jtorsiello\n",
      "corteous\n",
      "value/\n",
      "mutiti\n",
      "wonderfulstay\n",
      "theh\n",
      "'personal\n",
      "calssic\n",
      "fine/nothing\n",
      "rooms.not\n",
      "rauc\n",
      "bellamich\n",
      "doughters\n",
      "locationeasy\n",
      "14-16th\n",
      "inn..\n",
      "over-rated\n",
      "hotel‚Äîour\n",
      "◊û◊ê◊ì.◊î◊û◊®◊ó◊ß\n",
      "with-in\n",
      "embrac\n",
      "magnifi\n",
      "siverton\n",
      "disappointiong\n",
      "shelbo\n",
      "revewed\n",
      "mccorm\n",
      "caug\n",
      "cambri\n",
      "stay.-\n",
      "naer\n",
      "DG-DGDG-DGDG-DG_DGDG-DGDG\n",
      "helpin\n",
      "'super\n",
      "home.went\n",
      "vegas-a\n",
      "old-stylishly\n",
      "overlookin\n",
      "establ\n",
      "phras\n",
      "betran\n",
      "points.-gorgeous\n",
      "coveri\n",
      "recepcionist\n",
      "imts/strike\n",
      "07th\n",
      "accomidation\n",
      "nyc.b\n",
      "location/hotel\n",
      "home..\n",
      "tinme\n",
      "buildning\n",
      "vegss\n",
      "awesome+\n",
      "veiw\n",
      "aweesome\n",
      "room.the\n",
      "w/good\n",
      "days/2\n",
      "5location\n",
      "velley\n",
      "gorgeousl\n",
      "cafetaria\n",
      "beccoming\n",
      "sorooms\n",
      "checkintook\n",
      "exquisite-\n",
      "fun‚Äîmade\n",
      "fabbffinnyc\n",
      "high-e\n",
      "hilton-what\n",
      "perforemance\n",
      "sahlu\n",
      "falsly\n",
      "location//renovated\n",
      "elegences\n",
      "weekin\n",
      "spadesss\n",
      "employees..\n",
      "huge-\n",
      "no.micro\n",
      "refridge\n",
      "pricewise\n",
      "superm\n",
      "dirty..worn\n",
      "wood-be-happy-to-stay-here-again\n",
      "hotel..slight\n",
      ".should\n",
      "campb\n",
      "slowely\n",
      "tuscany-beautiful\n",
      "magnifcient\n",
      "prefe\n",
      "vvacation\n",
      "dreamcant\n",
      "awesome.hotel\n",
      "kempinsky\n",
      "spectacuarly\n",
      "okayest\n",
      "borther\n",
      "craudy\n",
      "wrked\n",
      "locationbed\n",
      "stripour\n",
      "hotel..it\n",
      "fugitivies\n",
      "jackiem\n",
      "ambiance/ar\n",
      "competen\n",
      "retro-renovated\n",
      "rude.2\n",
      "recommend-stay\n",
      "wereassi\n",
      "overcharge-3\n",
      "DG.DGDGDG\n",
      "improvemtn\n",
      "ruinsit\n",
      "oroce\n",
      "suites-las\n",
      "sqr\n",
      "-simply\n",
      "digita\n",
      "maccallan\n",
      "itperfect\n",
      "osais\n",
      "beautiful-upsacle-clean\n",
      "differencee\n",
      "expriense\n",
      "whop\n",
      "avmc\n",
      "permiat\n",
      "hideaway..\n",
      "business/friends\n",
      "must-go\n",
      "here‚ù§Ô∏è\n",
      "faliure\n",
      "bdday\n",
      "mrs.bowman\n",
      "bliss‚Ä¶..\n",
      "maragritaville\n",
      "flagsh\n",
      "psrk\n",
      "mini-fridge\n",
      "tagli\n",
      "apartmen\n",
      "beingness\n",
      "depressingpositives\n",
      "a+++++++\n",
      "loced\n",
      "canada-went\n",
      "okstaff\n",
      "-fitness/spa/concerts\n",
      "disappointed-booked\n",
      "fantaboulouse\n",
      "'re-modelled\n",
      "effic\n",
      "mindfr\n",
      "weree\n",
      "roomabo\n",
      "brunilda\n",
      "awh\n",
      "service-a+\n",
      "wonderful-pricey\n",
      "museum.sta\n",
      "14th-17th\n",
      "educat\n",
      "üíó\n",
      "villiard\n",
      "percect\n",
      "cancellabl\n",
      "game/g\n",
      "restu\n",
      "aboce\n",
      "microwave/refrige\n",
      "'prestige\n",
      "balue\n",
      "ahow\n",
      "re-furbished\n",
      "emenities\n",
      "roomn\n",
      "wynn/\n",
      "ulitmate\n",
      "opera-centric\n",
      "paris..\n",
      "planetree\n",
      "non-casino\n",
      "awrsome\n",
      "didn¬¥t\n",
      "personal/\n",
      "disappoiinting\n",
      "absolutlty\n",
      "evironment\n",
      "dind\n",
      "park-n-fly\n",
      "femaile\n",
      "15/nigh\n",
      "positives.pri\n",
      "eenvironment\n",
      "americannia\n",
      "counts..\n",
      "dolores.i\n",
      "hotel..probably\n",
      "re-booked\n",
      "crappiest\n",
      "inspi\n",
      "belvadere\n",
      "10/night\n",
      "/i\n",
      "fordont\n",
      "hotel/bars/games/peo\n",
      "whete\n",
      ".something\n",
      "sttentio\n",
      "un-impressive\n",
      "discovery.last\n",
      "expectations/standard\n",
      "union.square\n",
      "-decent\n",
      "exciting.bett\n",
      "3-aug.\n",
      "Ôªøt\n",
      "whol\n",
      "business-personal\n",
      "fabulouse\n",
      "tropic-average-cana\n",
      "christm\n",
      "mid-wint\n",
      "'eh\n",
      "yerg\n",
      "holiday/gnydm\n",
      "rt91\n",
      "paral\n",
      "a+a+a+\n",
      "service/maids\n",
      "alaram\n",
      "smoke-freegreat\n",
      "Èõ¢Èñã‰∫Üla\n",
      "foir\n",
      "staff/comfortable\n",
      "nephe\n",
      "hubsy\n",
      "youk-new\n",
      "farmborough\n",
      "visitiing\n",
      "location.l\n",
      "rooms.especially\n",
      "malfuncti\n",
      "bustlin\n",
      "lexing\n",
      "hoetel\n",
      "thompson-\n",
      "everyting\n",
      "apparthotel\n",
      "g-nug\n",
      "coool\n",
      "manhanttan\n",
      "neighbourh\n",
      "suffici\n",
      "employees/poor\n",
      "egyptol\n",
      "night/appalled\n",
      "o'k\n",
      "bellagio=service\n",
      "abreha\n",
      "accomm\n",
      ".hope\n",
      "arrangemen\n",
      "bars/restaurants\n",
      "flamingoing\n",
      "exselent\n",
      "unique-trendy-chic\n",
      "surounding\n",
      "paytables\n",
      "ja'nay\n",
      "positi\n",
      "beautifuli\n",
      "flaslight\n",
      "hospitality4\n",
      "ok-looking\n",
      "470/day\n",
      "down..\n",
      "statisfactory\n",
      "locationth\n",
      ".did\n",
      "disaterous\n",
      "..watch\n",
      "okayish\n",
      "expectations~~~~\n",
      "mediorcre\n",
      "trip/nyc\n",
      "day/nigh\n",
      "hamiltongreat\n",
      "naphia\n",
      "gloria/lisa\n",
      "perfrect\n",
      "day-one\n",
      "whatch\n",
      "1.the\n",
      "goodband\n",
      "..las\n",
      "3.5-4stars\n",
      "location-blocks\n",
      "positivesthe\n",
      "returni\n",
      "itravel2000\n",
      "grewt\n",
      "25/night\n",
      "locatrion\n",
      "staff-close\n",
      "manhattan/time\n",
      "longes\n",
      "hyatt/chicago\n",
      "great/interesting\n",
      "mohameed\n",
      "kabirnia\n",
      "remeber\n",
      "mayf\n",
      "üëéüëéüëé\n",
      "hotel/mot\n",
      "nights..\n",
      "sometim\n",
      "gorgeous-p\n",
      "amazing.i\n",
      "gabrie\n",
      ".great\n",
      "consitter\n",
      "researc\n",
      "visitd\n",
      "experience-bed\n",
      "unrelaxing\n",
      "disrepect\n",
      "honeymoom\n",
      "yester-year\n",
      "'upstairs\n",
      "marriott-\n",
      "dirty..no\n",
      "tamjpar\n",
      "crowd..not\n",
      "stratf\n",
      "consequen\n",
      ".no\n",
      "wee-note\n",
      "accommodating-great\n",
      "accomodat\n",
      "'g\n",
      "granddaugh\n",
      "disappointinh\n",
      "statrt\n",
      "DGDGDGDGDG+\n",
      "staff-good\n",
      "mind-blow\n",
      "loved‚òÜ‚òÜthe\n",
      "n'ho\n",
      ".better\n",
      "chicago-views\n",
      "beautifulhotel\n",
      "effiecency\n",
      "üè®\n",
      "before-definitely\n",
      "low-lit\n",
      "ilussion\n",
      "neaby\n",
      "hilton/ramada\n",
      "unique-\n",
      "üòÄüòÄüòÄ‚ù§Ô∏è\n",
      "achieveme\n",
      "-las\n",
      "despe\n",
      "surprizing\n",
      "modific\n",
      ",sucks\n",
      "staff..\n",
      "off-th\n",
      "made..\n",
      "DGDGDG.DGDG\n",
      "2king\n",
      "77jack\n",
      "amazinggggggg\n",
      "Á¥†Êô¥„Çâ„Åó„ÅÑ„Éõ„ÉÜ„É´ÔºÅÔºÅÔºÅ\n",
      "choppercon2015\n",
      "weekeng\n",
      "inn/manhattan\n",
      "checkout..\n",
      "access/wonderful\n",
      "s‚Ä¶never\n",
      "humong\n",
      "mr.zoil\n",
      "value/location\n",
      "diappointing\n",
      "yaah\n",
      "egreat\n",
      "hipste\n",
      "cordi\n",
      "2.8let\n",
      "value/retro\n",
      "disappoinging\n",
      "hermela\n",
      "trip-short\n",
      "299/ni\n",
      "year..checked\n",
      "class..great\n",
      "-comfort\n",
      "mike.m\n",
      "staff/perfect\n",
      "smalles\n",
      "proswe\n",
      "jessenia\n",
      "difficul\n",
      "lifefamily\n",
      "repea\n",
      "carpetting\n",
      "fasioned\n",
      "hendolyn\n",
      "10th-14th\n",
      "cancelled/no\n",
      "luxold\n",
      "50'sth\n",
      "s-l\n",
      "grandteens\n",
      "charasmatic\n",
      "bicl\n",
      "disocunt\n",
      "'tan\n",
      "engagem\n",
      "poncy..\n",
      "appreciat\n",
      "perect\n",
      "april-2016\n",
      "prosp\n",
      "limpe\n",
      "handic\n",
      "15t\n",
      "ÏûàÎäî\n",
      "stretc\n",
      "hotel/nice\n",
      "proerty\n",
      "21-35yr\n",
      "atmosphere.r\n",
      "palace-your\n",
      "summertim\n",
      "o.f.u.=o\n",
      "frequest\n",
      "'paris\n",
      "gem-\n",
      "proab\n",
      "clean/safe/affordable\n",
      "great.staff\n",
      "lincy\n",
      "inn-chicago\n",
      "d-16\n",
      "undercleaned\n",
      "purifie\n",
      "refurbising\n",
      "incredilbe\n",
      "bornday\n",
      "beautifal\n",
      "bay..\n",
      "family/friend\n",
      "park-and-sleep\n",
      "worldmarks\n",
      "impeccacable\n",
      "spaci\n",
      "..superb\n",
      "earthüòò\n",
      "jonus\n",
      "actuall\n",
      "spons\n",
      "recemend\n",
      "hotelgrea\n",
      "rock¬®n\n",
      "eventfu\n",
      "ntsasa\n",
      "getatay\n",
      "1day\n",
      "hotel-our\n",
      "vllage\n",
      "13-march\n",
      "libr\n",
      "w44t\n",
      "north-eas\n",
      "6nt\n",
      "towers-which\n",
      "unknow\n",
      "e-ma\n",
      "adulting\n",
      "stayexce\n",
      "week=less\n",
      "eco-friend\n",
      "competitio\n",
      "througho\n",
      "fulfi\n",
      "over-the\n",
      "diggs-\n",
      "upgrase\n",
      "price0o\n",
      "'las\n",
      "modern/clean/great\n",
      "'reso\n",
      "617616332marriott\n",
      "possi\n",
      "15th-22nd\n",
      "froma\n",
      "bedroc\n",
      "purpos\n",
      "again.lov\n",
      "threadba\n",
      "parj\n",
      "well..\n",
      "assessible\n",
      "steve-o-kay\n",
      "pac/may\n",
      "rollercoaste\n",
      "do..\n",
      "not-really-union\n",
      "sister-sister\n",
      "thumbn\n",
      "manhattan/new\n",
      "wonderfil\n",
      "klean\n",
      "trip/location/hotel\n",
      "room/pleasa\n",
      "chilin\n",
      "mamha\n",
      "drawb\n",
      "a++++\n",
      "st.giles\n",
      "15-apr\n",
      "18/day\n",
      "parc55-\n",
      "4-stars\n",
      "friendship/bucket\n",
      "amaaazingly\n",
      "tamela\n",
      "‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è\n",
      "classif\n",
      "nodig\n",
      "days/\n",
      "*¬®¬®*\n",
      "expectin\n",
      "accomodations-modern\n",
      "20days\n",
      "diesel/modern\n",
      "good/real\n",
      "best.hotel.ever\n",
      "nicce\n",
      "desastrous\n",
      "travelcon\n",
      "astoniushingly\n",
      "occation\n",
      "flamingolasvegas\n",
      "hanbee\n",
      "riff-raft\n",
      "miscom\n",
      "families/staff\n",
      "timesh\n",
      ".would\n",
      "configuratio\n",
      "positione\n",
      "ferr\n",
      "casino-resort\n",
      "expeckt\n",
      "epicüèô\n",
      "pool-\n",
      "familydad\n",
      "32for\n",
      "absolutel\n",
      "service/brand\n",
      "recommnding\n",
      "16yo\n",
      "opionion\n",
      "stays/2\n",
      "rooseve\n",
      "..look\n",
      "clatterbuck/sizemore\n",
      "self-\n",
      "roomd\n",
      "decepti\n",
      "stayüçç\n",
      "aixa\n",
      "60/day\n",
      "rasca\n",
      "homew\n",
      "allision\n",
      "wee-\n",
      "8:46pm\n",
      "visits/stay\n",
      "tgink\n",
      "üòûüòûüòûüòûüòû\n",
      "iillnois\n",
      "24th-31st\n",
      "3inarowvegas2018\n",
      "service/nightmare\n",
      "verrrrrrrrrrrrrry\n",
      "uptodate\n",
      "firmlogix\n",
      "pros-very\n",
      "super-hotel\n",
      "problems..\n",
      "reuschleins\n",
      "stopove\n",
      "bestfriend\n",
      "wellinghton\n",
      "location.gr\n",
      "'hip\n",
      "ph9\n",
      "celebrationthanks\n",
      "2-queen-beds\n",
      "kainoa ªs\n",
      ".cool\n",
      "psyc\n",
      "alluri\n",
      "pool/lazy\n",
      "indig\n",
      ".do\n",
      "hoilday\n",
      "330/night\n",
      "wed-sat\n",
      "l√®\n",
      "hotel//great\n",
      "expectaci√≥n\n",
      "stranz\n",
      "knickerbocjer\n",
      "like/love\n",
      "georgeous\n",
      "fran-tastic\n",
      "marajuana\n",
      "bacherlorletteeee\n",
      "mom/daughter\n",
      "vgk\n",
      "sailea\n",
      "pennsaylvania\n",
      "lane-\n",
      "daphne-ny\n",
      "fathe\n",
      "me.i\n",
      "french-styled\n",
      "gues\n",
      "downtown/magn\n",
      "9/18ÔΩû9/21„Éá„É©„ÉÉ„ÇØ„Çπ„ÇØ„Ç§„Éº„É≥„ÄÅÔºìÈöé„ÅÆÈÉ®Â±ã„Äé„Ç≥„Éü„É•„Éã„Ç±„Éº„Ç∑„Éß„É≥\n",
      "7h\n",
      "ractism\n",
      "pesonnel\n",
      "fun-\n",
      "activi\n",
      "kategory\n",
      "choces\n",
      "experience-super\n",
      "waldort\n",
      ".cramped\n",
      "uoda\n",
      "avioid\n",
      "groundbreak\n",
      "power/water\n",
      "apparentl\n",
      "convetion\n",
      "..now\n",
      "pennsylv\n",
      "chicago-all\n",
      "unpersonalized\n",
      "identity-not\n",
      "curbsid\n",
      "11howard.an\n",
      "cost-\n",
      "locationnot\n",
      "clean.selling\n",
      "travellor\n",
      "location-nice\n",
      ".owners\n",
      "acoomodation\n",
      "nooth\n",
      "clapt\n",
      "good-h\n",
      "staff.eas\n",
      "cassinos\n",
      "üé≥\n",
      "endbooked\n",
      "friendly/calm\n",
      "else-nice\n",
      "ballys\n",
      "..it\n",
      "omgosh\n",
      "mon-wed\n",
      "cargil\n",
      "nonsmo\n",
      "job..\n",
      "salreview\n",
      "d.j\n",
      "venecien\n",
      "exoensive\n",
      "hgi35\n",
      ".always\n",
      "shelbur\n",
      "absolutley\n",
      "prety\n",
      "goodthey\n",
      "sportsbook.best\n",
      "amanities\n",
      "dtay\n",
      "nhappy\n",
      "standerd\n",
      "locattion\n",
      "3-nig\n",
      "bar/lobby\n",
      "expieriance\n",
      "patty4131\n",
      "privatel\n",
      "creme-nyc\n",
      "bar49\n",
      "..fashion\n",
      "amazzinnnggg\n",
      "ok-n\n",
      "from12/20/\n",
      "neighborhoood\n",
      "licatiin\n",
      "tldr-\n",
      "thst\n",
      "uchica\n",
      "restaurant..no\n",
      "teip\n",
      "room..but..\n",
      "fifte\n",
      "meh..\n",
      "room1718\n",
      "messy/noisy\n",
      "park/ny\n",
      "ninet\n",
      "ever.the\n",
      "employeesbest\n",
      "hotelstaff\n",
      "em808\n",
      "nycüéÑ\n",
      "bad/worst\n",
      "bathroom/terrible\n",
      "nicer/bett\n",
      "splunk\n",
      "bull-pen\n",
      "infrastr\n",
      "farmont\n",
      "times.great\n",
      "gambler187\n",
      "cosmopolit\n",
      "away-from-the-strip\n",
      "‚≠êÔ∏è\n",
      "layover-\n",
      "mid-manhattan\n",
      "two-nigh\n",
      "rio-hidden\n",
      "service/management\n",
      "hollywod\n",
      "grandhotel\n",
      "gottschild\n",
      "frenc\n",
      "helppful\n",
      "nice-just\n",
      "-lots\n",
      "outside.looks\n",
      "perfect.it\n",
      "unbeat\n",
      "oais\n",
      "price-great\n",
      "service.eve\n",
      "bestüòâüòâüòâ\n",
      "-gaming\n",
      "conceniently\n",
      "-watch\n",
      ".thi\n",
      "non-friendly\n",
      "DGDG/DGDGDGDG\n",
      "mindblowin\n",
      "bargain-priced\n",
      "glitziness\n",
      "830am\n",
      "stay-no\n",
      "i'n\n",
      "extemely\n",
      "hotelwe\n",
      "entertainment/hotel\n",
      "guest/ga\n",
      "‚ù§Ô∏èüèô\n",
      "veryg\n",
      "spotsbook\n",
      "pricing-location\n",
      "noizy\n",
      "DG/DG/DGDGDGDG\n",
      "maddess\n",
      "hagered\n",
      "carlo-\n",
      "else-\n",
      "paris-last\n",
      "maggianos\n",
      ".ideal\n",
      "waterb\n",
      "overrall\n",
      "belliagio\n",
      "march8\n",
      "impersonable\n",
      "decent-showing\n",
      "melchezedek\n",
      "sub-st\n",
      "room-cant\n",
      "deferrred\n",
      "day/2\n",
      "proker\n",
      "affortable\n",
      "birthday/retirement\n",
      "DG/DGDG/DGDG-DG/DGDG/DGDG\n",
      "seriousne\n",
      "sxaffolding\n",
      "14,2015-au\n",
      "rightsp\n",
      "daughter-in\n",
      "kindes\n",
      "breakfasts/designer\n",
      "forgiv\n",
      "intertaining\n",
      "anybody-when\n",
      "\\ndo\n",
      "club-new\n",
      "service-yes\n",
      "remolde\n",
      "agaun\n",
      "longsstay\n",
      "location/noise\n",
      "sucked1\n",
      "delightfu\n",
      "playgrou\n",
      "signture\n",
      "muhibul\n",
      "ccomfortable\n",
      "perviously\n",
      "pick-me-up\n",
      "never-\n",
      "centi\n",
      "thievi\n",
      "location..construction\n",
      "augu\n",
      "suoer\n",
      "dissapoitment\n",
      "feb/marc\n",
      "perffect\n",
      "atmosphers\n",
      "ÿß\n",
      "location:5/5bathroom:2/3l\n",
      "looooved\n",
      "behav\n",
      "triop\n",
      "inabi\n",
      "pricing/\n",
      "options..\n",
      "furnitur\n",
      "commu\n",
      "different-\n",
      "5-stars\n",
      "excpetional\n",
      "walls..good\n",
      "resort/location\n",
      "beacen\n",
      "badboyroy\n",
      "heating/a/c\n",
      "october.we\n",
      "all-aro\n",
      "business-doubletree\n",
      "vood\n",
      "widl\n",
      "g-\n",
      "hotel/simple\n",
      "tuly\n",
      "'nightmare\n",
      "nyclovely\n",
      "-t\n",
      "function.i\n",
      "valdenia\n",
      "nerve-w\n",
      "ohhhhhhh\n",
      "31-year-o\n",
      "februay\n",
      "sight-see\n",
      "'resourc\n",
      "****must\n",
      "athleti\n",
      "one-elevator\n",
      "experience.only\n",
      "agreei\n",
      "ocernight\n",
      "mogadish\n",
      "disrikt\n",
      "centee\n",
      "riugh\n",
      "outreagously\n",
      "exprience\n",
      ".ugh\n",
      "volca\n",
      "premiumsuite\n",
      "place/seniors\n",
      "splurge/great\n",
      "choice/good\n",
      "accomodatable\n",
      "dottee\n",
      "valeu\n",
      "satisfyi\n",
      "tise\n",
      "nooit\n",
      "suite-provided\n",
      "prfect\n",
      "tastefull\n",
      "va-cay\n",
      "ahhhh-mazing\n",
      "oct-nov\n",
      "input..\n",
      "cleaneasy\n",
      "450/nig\n",
      "generously-sized\n",
      "booki\n",
      "*fraud\n",
      "04/06/l6\n",
      ".üíö\n",
      "managments\n",
      "wedding/las\n",
      "coatsjc\n",
      "expexted\n",
      "patio-selin\n",
      "–ø—Ä–µ–∫—Ä–∞—Å–Ω–æ–µ\n",
      "beatris\n",
      "experimce\n",
      "tocentral\n",
      "approximat\n",
      "2hour\n",
      "swimmi\n",
      "d'citt\n",
      "astmoshere\n",
      "weekenf\n",
      "choices/room\n",
      "hotel/venue\n",
      "returnimg\n",
      "plcae\n",
      "comfertable\n",
      "elysee-a\n",
      "allways\n",
      "fr=om\n",
      "feindly\n",
      "tommylama\n",
      "trendy/hip\n",
      "alright-\n",
      "vegas+vey\n",
      "well-updated\n",
      "üëéüëé\n",
      "everythhing\n",
      "timespent\n",
      "package/suite\n",
      "nivce\n",
      "customer-oriente\n",
      "machine=\n",
      "tripepi\n",
      "sls-the\n",
      "ventil\n",
      "hotel.staff\n",
      "architecture/facilities\n",
      "aqua-tastic\n",
      "colleen‚Äîtoo\n",
      "surpirse\n",
      "10looks\n",
      "goodbut\n",
      "riverfr\n",
      "layover-home\n",
      "clean/not\n",
      "DGDG-DGDGDGDGDGDG\n",
      "fairly-priced\n",
      "okarina\n",
      "business/girls\n",
      "aesome\n",
      "time-sh\n",
      "-\\nfantastic\n",
      "whirpool\n",
      "mehhhhhhh\n",
      "fee..\n",
      "whem\n",
      "r√≥w\n",
      "july15\n",
      "shame..\n",
      "pluming\n",
      "package-best\n",
      "decent-\n",
      "reciptionist\n",
      "excellente\n",
      "ecelletn\n",
      "¬£77pn\n",
      "manhattan-\n",
      "sunk-\n",
      "weekend/goddaughters\n",
      "luggagebo\n",
      "stay.staf\n",
      "relaxiation\n",
      "strip..it\n",
      "aquarium-good\n",
      "here-smelly\n",
      "but.\n",
      "here.okay\n",
      "june27\n",
      "montgom\n",
      "deservin\n",
      "gem/great\n",
      "hotel/surrounds/location/pool\n",
      "location/staff/value\n",
      "'ritz\n",
      "carlto\n",
      "grand-looking\n",
      "service/ex\n",
      "cenert\n",
      "cartw\n",
      "good/ok\n",
      "more/\n",
      "scen\n",
      "stith-moore\n",
      "gfny\n",
      "10nights\n",
      "luxurios\n",
      "2-2bedroom\n",
      "beddi\n",
      "truley\n",
      "staff/location/amenities\n",
      "flaminghetto\n",
      "/wedding/\n",
      "hotel-like\n",
      "executiv\n",
      "someti\n",
      "sls=sophistication\n",
      "ft.as\n",
      "..close\n",
      "cassars\n",
      "hotel-and\n",
      "450/night+\n",
      "manharttan\n",
      ".fr\n",
      "location/a\n",
      "parkk\n",
      "miedico\n",
      ".until\n",
      "*several\n",
      "location.however\n",
      "husbond\n",
      "service/dogs\n",
      "location‚Ä¶.bad\n",
      "faciliities\n",
      "bargane\n",
      "locationy\n",
      "precedi\n",
      "june2014\n",
      "metrop\n",
      "excellent++++\n",
      "tru-ly\n",
      "wver\n",
      "location..i\n",
      "b/rm\n",
      "starslocation\n",
      "uploa\n",
      "bar/lou\n",
      "+modern\n",
      "busy/poor\n",
      "veryt\n",
      "love.\n",
      "agasyan\n",
      "perfectgreat\n",
      "welcome/check-in\n",
      "colc\n",
      "iagg\n",
      "half-decent\n",
      "comfortus\n",
      "westagat\n",
      "ÿ¥Ÿäÿ°\n",
      "promen\n",
      "advantag\n",
      "frasico\n",
      "addre\n",
      "downüòä\n",
      "prevoius\n",
      "overclouded\n",
      "travelz\n",
      "location-restaurants\n",
      "location..very\n",
      "place.it\n",
      "byoisp\n",
      "~checking\n",
      "9mos\n",
      "fairfi\n",
      "typi\n",
      "-loop\n",
      "endu\n",
      "staff=not\n",
      "time.room\n",
      "charges-\n",
      "hotel.wo\n",
      "non-typical\n",
      "wooooooow\n",
      "coffee/cookie\n",
      "400/nig\n",
      "beait\n",
      "comfrotable\n",
      "usd/\n",
      "unsurprisingl\n",
      "so.phone\n",
      "interconne\n",
      "faulted..\n",
      "scre\n",
      "on-trend\n",
      "good.it\n",
      "overwelming\n",
      "-front\n",
      "disn\n",
      "unforgettabl\n",
      "themom\n",
      "room-not\n",
      "nights..really\n",
      "..unless\n",
      "quallity/price\n",
      "loovely\n",
      "two-n\n",
      "aeverything\n",
      "hotels/pools\n",
      "stay/visit\n",
      "almot\n",
      "fitness-oriented\n",
      "friendliness/helpfulness\n",
      "downto\n",
      "disappinting\n",
      "/qua\n",
      "especiall\n",
      "ewwww\n",
      "place.our\n",
      "class‚Ä¶beautiful\n",
      "vgas\n",
      "price.y\n",
      "sorprendente\n",
      "hollywood-january\n",
      "trafalga\n",
      "lower-than-strip\n",
      "pierre/taj\n",
      "synposium\n",
      "1-2minutes\n",
      "rageous\n",
      "bbest\n",
      "resort-poor\n",
      "professionell\n",
      "harlem..no\n",
      "codnitioner\n",
      "casears\n",
      "usual.m\n",
      "complementar\n",
      "resort-5\n",
      "superb.very\n",
      "groups/family\n",
      "loungey\n",
      "staffwe\n",
      "5yr\n",
      "aria-\n",
      "credit=no\n",
      "vdarra\n",
      "‚ù§nyny\n",
      "environmeny\n",
      "bestüí´üí´üí´üí´\n",
      "prosori\n",
      "lvrnr\n",
      "acces\n",
      "pretent\n",
      "complainin\n",
      "ways.very\n",
      "setting-\n",
      "ipoemena\n",
      "hill/fin\n",
      "adultswe\n",
      "DG/DG\n",
      "plae\n",
      "hotel/cas\n",
      "discov\n",
      "poor-medium\n",
      "begore\n",
      "catrena\n",
      "..sho\n",
      "manhatta\n",
      "prefa\n",
      "retro-vegas\n",
      ".gracious\n",
      "mercedes-great\n",
      "mid-siz\n",
      "evrey\n",
      "luxuery\n",
      "yofo\n",
      "caesars-\n",
      "'hookup\n",
      "worthwhi\n",
      "-unfriendly\n",
      "lobbyÔºåtufayelÔºåis\n",
      "suite‚ù§\n",
      "clean-tired\n",
      "luxourious\n",
      "overwelmed\n",
      "sportsbok\n",
      "lemeridi\n",
      "29-au\n",
      ".chicago\n",
      "gap..\n",
      "treasurable\n",
      "11:30a.m.\n",
      "maintance\n",
      "tuppa\n",
      "/ok\n",
      "happenings-times\n",
      "feb2016\n",
      "higly\n",
      "bwat\n",
      "noice\n",
      "decen\n",
      "parisian-style\n",
      "DGDGDGDGDGDGDG\n",
      "comfot\n",
      "patrickj\n",
      "spur-of-moment\n",
      "theme/\n",
      "okay..\n",
      "thing‚Ä¶\n",
      "imperi\n",
      "we'had\n",
      "night/day\n",
      ",awesome\n",
      "aaaaaa+++\n",
      "1:00a.m\n",
      "it'a\n",
      "1night/day\n",
      "oldschool\n",
      "okfor\n",
      "apprecia\n",
      "choies\n",
      "aware-not\n",
      "m.a.d\n",
      "hotel-transportation\n",
      "*stayed\n",
      "staff.very\n",
      "downtown.the\n",
      "post-superbowl\n",
      "does-\n",
      "mis-\n",
      "servino\n",
      "secondstay\n",
      "dropp\n",
      "issiez\n",
      "spazios\n",
      "overaged\n",
      "'responding\n",
      "DG-DGDG-DGDG\n",
      "recoma\n",
      "babalonia\n",
      "manahattan\n",
      "üò•\n",
      ".stops\n",
      "first/last\n",
      "part-\n",
      "10-stars\n",
      "the-is\n",
      "dec/jan\n",
      "musarat\n",
      "holiday..\n",
      "intercontine\n",
      "grils\n",
      "glamorus\n",
      "backst\n",
      "efective\n",
      ".who\n",
      "centraliz\n",
      "view/location\n",
      "place-midtown\n",
      "drinki\n",
      "southp\n",
      "place/nice\n",
      "partic\n",
      "indhira\n",
      "maintanance\n",
      "ah-maaaaazing\n",
      "imprompt\n",
      "hostes\n",
      "reort\n",
      "'bet\n",
      "ilanded\n",
      "furnit\n",
      "hotel.l\n",
      "*quiet\n",
      "full-\n",
      "nearly-botique\n",
      "restaurent\n",
      "loooooove\n",
      "indifferenc\n",
      "bargain-if\n",
      "ventu\n",
      "clean.non\n",
      "asian/mo\n",
      "slipp\n",
      "drien\n",
      "engagement-\n",
      "traveli\n",
      "good.e\n",
      "square-right\n",
      "location/view/service\n",
      "'icks\n",
      "c24\n",
      "'top\n",
      "yummie\n",
      "usd/night\n",
      "spaceish\n",
      "poor/fair\n",
      "smill\n",
      "'dump\n",
      "embar\n",
      "bar/restaura\n",
      "mexic\n",
      "eeh\n",
      "morning/a\n",
      "hospitali\n",
      "ifar\n",
      "veryshuttle\n",
      "4d3n\n",
      "annyoed\n",
      "hotelstay\n",
      "propoerty\n",
      "plaza-great\n",
      "'found\n",
      "wtaff\n",
      "287/5000just\n",
      "go-mini\n",
      "impossi\n",
      "remodel.great\n",
      "abhishe\n",
      "staff.it\n",
      ".over\n",
      "extremelly\n",
      "kddn\n",
      "-it\n",
      "convention-goers\n",
      "pricng\n",
      "DG/DGDG-DGDG/DG\n",
      "ceasars\n",
      "always.not\n",
      "area/lobby\n",
      "super-efficient\n",
      "noise.i\n",
      "handli\n",
      "see-\n",
      "pools/lazy\n",
      "flamgo\n",
      "disaapoint\n",
      "werent\n",
      "nonchalan\n",
      "bestttt\n",
      "Í≥µÌï≠Ïóê\n",
      "hotel/service\n",
      ".needs\n",
      "elegn\n",
      "samf\n",
      "nyc/manhattan\n",
      "steingalleryit\n",
      "garbag\n",
      "location-not\n",
      "bustl\n",
      "w/large\n",
      "gorgeo\n",
      "palace-9/2016\n",
      "weekend/bachelor\n",
      "rooms/tickets\n",
      "vave\n",
      "circut\n",
      "friendy\n",
      "unbelieva\n",
      "27i\n",
      "raddisson\n",
      "sept14-18\n",
      "excelentire\n",
      "waldof\n",
      "room/excellent\n",
      "primely\n",
      "wholefoo\n",
      "chicagothe\n",
      "gate/downtow\n",
      "goodone\n",
      "switch-false\n",
      "girls-getaway\n",
      "location-below\n",
      "sohoreasonabl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contr\n",
      "fect\n",
      "gramble\n",
      "friendlyness\n",
      "service-friendly\n",
      "wowee\n",
      "thieve\n",
      "guesth\n",
      "rules‚Äîgreat\n",
      "1year\n",
      ".now\n",
      "rokenbut\n",
      "decsent\n",
      "ckreddy\n",
      "good.somenot\n",
      "offhan\n",
      "jaidens\n",
      "fushion\n",
      "pre-summer\n",
      "wellness-themed\n",
      "'average\n",
      "regresare\n",
      "three-nig\n",
      ".housekeeping\n",
      "defin\n",
      "fashinoned\n",
      "..water\n",
      "associa\n",
      "gooo\n",
      "pppft\n",
      "staff.courteous\n",
      "self-par\n",
      "consultan\n",
      "44dollars/day\n",
      "utensi\n",
      "feneral\n",
      "immillorable\n",
      "amnish\n",
      "h**l\n",
      "rennovate\n",
      "decod\n",
      "non-negotia\n",
      "bite-\n",
      "wpnderful\n",
      "good..but\n",
      "un-effin\n",
      "tcrwp\n",
      "purpo\n",
      "matinihe\n",
      "turndo\n",
      "springhil\n",
      "2017intimate\n",
      "birthday/girlfriend\n",
      "flastscree\n",
      "aboit\n",
      "convienant\n",
      "grandchampi\n",
      "wuailty\n",
      "paking\n",
      "signt\n",
      "goodlack\n",
      "beatyfull\n",
      "liiiiittle\n",
      "headi\n",
      "egdes\n",
      "25..used\n",
      "place-quiet\n",
      "planni\n",
      "business/vacatio\n",
      "favorabl\n",
      "rabecca\n",
      "d-\n",
      "custmer\n",
      "jamika\n",
      "impossib\n",
      "noise/breakfast\n",
      "proslocation\n",
      "bestwestern\n",
      "greattime\n",
      "spur-of-the-mome\n",
      "acually\n",
      "adequte\n",
      "pennsylvani\n",
      "equa\n",
      "hotels-chicago\n",
      "apolog\n",
      "departme\n",
      "vegas-plenty\n",
      "shops/restaurants\n",
      "..pity\n",
      "bassicly\n",
      "shampoo/conditioner\n",
      "afforda\n",
      "imporvement\n",
      "construction+bugs=\n",
      "blen\n",
      "momdadandtwokids\n",
      "overratted\n",
      ".assigned\n",
      "well-come\n",
      "beautifil\n",
      "'one\n",
      "entranc\n",
      "assoctiation\n",
      "apologi\n",
      "mirac\n",
      "awdsomeness\n",
      "horrormovie\n",
      "DG.DGDG/DG\n",
      "econolodges\n",
      "eife\n",
      "tahitia\n",
      "unfri\n",
      "charnita\n",
      "tower-amazing\n",
      "katastrofi\n",
      "hotel/travel\n",
      "checked-out\n",
      "25hr\n",
      "consideri\n",
      "1st-\n",
      "artesi\n",
      "exsquiste\n",
      "incredibl\n",
      "service‚Ä¶unresolve\n",
      "2nig\n",
      "smoky-beware\n",
      "five-nigh\n",
      "restin\n",
      "neat-o\n",
      "funtional\n",
      "anyth\n",
      "reciev\n",
      "1-check\n",
      "location/indigo\n",
      "-flamin\n",
      "charges/noisy\n",
      "respite.clean.elegant\n",
      "stop-by\n",
      "employess\n",
      "decor/rooms\n",
      "ph50\n",
      "s.francisco\n",
      "bed/pillow\n",
      "toplocation\n",
      "clean2\n",
      ".wine\n",
      "disappointed-1st\n",
      "hork\n",
      "veaga\n",
      "okgreat\n",
      "pseudo-mini-bar\n",
      "torali\n",
      "conference/show\n",
      "buchana\n",
      "unhelpful/rude\n",
      "hotel-will\n",
      "utmo\n",
      "¬°the\n",
      "unbeknowns\n",
      "historian/athlete/artist\n",
      "issue-\n",
      "scoure\n",
      "eeehhhh\n",
      "why..\n",
      "joying\n",
      "minneap\n",
      "quick-trip\n",
      "-old\n",
      "tardis-like\n",
      "birthway\n",
      "stayfrom\n",
      "third-\n",
      "terriffic\n",
      "knockerboc\n",
      "*bally\n",
      "fantastice\n",
      "functionali\n",
      "stadturlaub\n",
      "location/needs\n",
      "courtya\n",
      "low-\n",
      "atmosphere.milena\n",
      "itlian\n",
      "DG:DGDG-DG\n",
      "walk-\n",
      "goooood\n",
      "optiona\n",
      "playgo\n",
      "0ver\n",
      "food/resteraunt\n",
      "square-broadway\n",
      "here.t\n",
      "ttropicana\n",
      "inconfortable\n",
      "labou\n",
      "=\\\n",
      "enchanting-a\n",
      "profile.av\n",
      "greatrooms\n",
      "sharons\n",
      "liiterally\n",
      "'what\n",
      "5-nights\n",
      "euorpean\n",
      "dreamforcd\n",
      "quentiessential\n",
      "sectio\n",
      "eateries..\n",
      "41th\n",
      "accomodations.and\n",
      "77usd\n",
      "internet/resort\n",
      "mgm+vegas\n",
      "vavavoom\n",
      "exelelent\n",
      "suwanna\n",
      "somew\n",
      "spazmatics\n",
      "squeakin\n",
      "booooo\n",
      ".comfortable\n",
      "flamingo/vegas\n",
      "stay/location/\n",
      "mid-class\n",
      "bar/roofto\n",
      "_room\n",
      "depe\n",
      "clueles\n",
      "francisco..\n",
      "evvvver\n",
      "henderson/las\n",
      "service/charges\n",
      "..food\n",
      "joeseph\n",
      "yorkm\n",
      "microwa\n",
      "bagagge\n",
      "k√≠nd\n",
      "subway.short\n",
      "5th/36\n",
      "district/battery\n",
      "cleanstunningno\n",
      "value..good\n",
      "intrusi\n",
      ".golden\n",
      "amenitiesth\n",
      "desk.the\n",
      "amnot\n",
      "thril\n",
      "affordabilit\n",
      "w37\n",
      "expee\n",
      "striesand\n",
      "chnge\n",
      "excellenet\n",
      "bugs-dont\n",
      "dreadi\n",
      "exhibitio\n",
      ".unless\n",
      "get-to-gethers\n",
      "recommmended\n",
      "preference-\n",
      "elagance\n",
      "yasmi\n",
      "'fantastic\n",
      "realizat\n",
      "seapo\n",
      "needd\n",
      "sratosphere\n",
      "commentmohammed/dolly\n",
      "afdordable\n",
      "doubletrees\n",
      "batht\n",
      "◊ê◊û◊ô◊™◊ô\n",
      "dlair\n",
      "DG/DGDGDGDG\n",
      "bittire\n",
      "'quirky\n",
      "anavercey\n",
      "amsterda\n",
      "finge\n",
      "immitation\n",
      "hotel/loction/service\n",
      "sightseei\n",
      "straig\n",
      "in-h\n",
      "francsco\n",
      "30yr\n",
      "wllmvieira\n",
      "travelli\n",
      "pugstooknyc\n",
      "inside..\n",
      "vegasever\n",
      "celebtations\n",
      "over-hyped\n",
      "loveeeeeeee\n",
      "price/clean\n",
      "/horrible\n",
      "humu\n",
      "fastatic\n",
      "ra-\n",
      "service/survey\n",
      "sherts\n",
      "eve..\n",
      "blinds/\n",
      "room1712\n",
      "staff/bathroom\n",
      "neig\n",
      "casino-the\n",
      "can..beware\n",
      "standard.i\n",
      "22-yr-old\n",
      "ratingn\n",
      "faux-parisian\n",
      "mehh..\n",
      "quadrup\n",
      "upstai\n",
      "expeirience\n",
      "freebe\n",
      "tprmick\n",
      "high-rolle\n",
      "//we\n",
      "maluma\n",
      "contemporary.it\n",
      "exemplif\n",
      "shagonai\n",
      "question‚Ä¶my\n",
      "vegas.it\n",
      "conexpo\n",
      "perfecte\n",
      "anywere\n",
      "outprice\n",
      "disstance\n",
      "non-smoki\n",
      "rooftop93\n",
      "pinneapple\n",
      "+DG\n",
      "electroni\n",
      "450/night\n",
      "homewoo\n",
      "barrett124\n",
      "bedla\n",
      "lourdis\n",
      "outstanidng\n",
      "lesol\n",
      "bell-a-gio\n",
      "defo\n",
      "location-stay\n",
      "'can\n",
      "good.dwfermu\n",
      "location/lovely\n",
      "4queens\n",
      "service-with-a-smile\n",
      "accommodat\n",
      "prepai\n",
      "glassbuild\n",
      "location.this\n",
      "inexpensive-\n",
      "unique/fun\n",
      "hotel.from\n",
      "run.rooms\n",
      "spendin\n",
      "goodish\n",
      "**warning**\n",
      "birthday.m\n",
      "babyyyyy\n",
      "4-queens\n",
      "advant\n",
      "hesitant/no\n",
      "1100/night\n",
      "tabel\n",
      "'view\n",
      "claustropho\n",
      "8year\n",
      "walk-thru\n",
      "staycay\n",
      "reccome\n",
      "crutche\n",
      "i-\n",
      "tremondous\n",
      "-resolved\n",
      "smiple\n",
      "before..i\n",
      "hotel..accommodation..personnel\n",
      "hell-evator\n",
      "generaly-\n",
      "specif\n",
      "traveling-highly\n",
      "disclosure-\n",
      "wrig\n",
      "qchs\n",
      "setup-\n",
      "non-homey\n",
      "pricel\n",
      "downh\n",
      "friendlyh\n",
      "w/excellent\n",
      "ducke\n",
      "dec2017\n",
      "—Ç–∞–∫\n",
      "dapril\n",
      "vispring\n",
      "usuall\n",
      "venido\n",
      "milleniu\n",
      "super-convenient\n",
      "mid-octob\n",
      "staff/breakfast\n",
      "sq/chinatown\n",
      "ofall..\n",
      "wow-times\n",
      "–±–µ–∑\n",
      "steall\n",
      "mr.trump\n",
      "fanatastic\n",
      "newfoundlan\n",
      "emerg\n",
      "outstanding..panoramic\n",
      "mjlive\n",
      "princ\n",
      "dichev\n",
      "stay.breakfast\n",
      "double/d\n",
      "positio\n",
      "becareful\n",
      "hampton-35th\n",
      "terrible/mean\n",
      "etcp\n",
      "jan.26th\n",
      "blindin\n",
      "couldl\n",
      "downgra\n",
      "tourname\n",
      "christines\n",
      "simila\n",
      "spa-tacular\n",
      "impersonab\n",
      "mandalaybay\n",
      "will.return\n",
      "surprisi\n",
      "village/soho\n",
      "defenity\n",
      "lastmin\n",
      "regretable\n",
      "thesecond\n",
      "mandator\n",
      "liitle\n",
      "three-w\n",
      "favori\n",
      "5-6pm\n",
      "pre-pai\n",
      "30thanniversary\n",
      "olpiwod\n",
      "vacatiion\n",
      "vacataion\n",
      "-cl\n",
      "belnor\n",
      "disppointment\n",
      "baby..\n",
      "birthday/experiencd\n",
      "DGDGDGDGDG\n",
      "atmosp\n",
      "perfect.very\n",
      "lugages\n",
      "again.staff\n",
      "clean.my\n",
      "squeek\n",
      "concigere\n",
      "know:1\n",
      "mckorm\n",
      "‚ùÑ\n",
      "hotel-overall\n",
      "nights‚Ä¶\n",
      "cean\n",
      "luxurio\n",
      "reccom\n",
      "dae/rci\n",
      "satterly\n",
      "..might\n",
      "frustrati\n",
      "casino/lobby\n",
      "milfo\n",
      "incrediable\n",
      "grandvirew\n",
      "hotels/cas\n",
      "prefeeable\n",
      "feeing\n",
      "mirageüëç\n",
      "durati\n",
      "sqare\n",
      "diffic\n",
      "engagment\n",
      "/the\n",
      "vacation-did\n",
      "20years\n",
      "irresis\n",
      "knock..whos\n",
      "featur\n",
      ".ok\n",
      "anazing\n",
      "mentioned..as\n",
      "tioms\n",
      "filty\n",
      "famiiy\n",
      "feel/work\n",
      "square/bro\n",
      "check-in..\n",
      "fabuloius\n",
      "tsq\n",
      "familystay\n",
      "tatt\n",
      "convenient-\n",
      "shagwana\n",
      "weekend-j\n",
      "109f\n",
      "hidd\n",
      "staff.needs\n",
      "m-th\n",
      "was‚Ä¶.well\n",
      "lobby/c\n",
      "horrbile\n",
      "expacted\n",
      "uhhhh-may-zing\n",
      "soundproofe\n",
      "-stayed\n",
      "mayby\n",
      "longq\n",
      "-disap\n",
      "csaesars\n",
      "check-outi\n",
      "thursday-monday\n",
      "service/no\n",
      "‚Ä™holiday\n",
      "ukksa\n",
      "medite\n",
      "conventio\n",
      "min.to\n",
      "pool.\n",
      "location.will\n",
      "ultra-luxurious\n",
      ".job\n",
      "suppos\n",
      "gem..\n",
      "kalachand\n",
      "monarail\n",
      "accountabilty\n",
      "recommend.the\n",
      "noist\n",
      "inciden\n",
      "DG/DGDG/DGDG-DG\n",
      "distu\n",
      "show~\n",
      "sell-by\n",
      "hights\n",
      "fullfilling\n",
      "2017-sf\n",
      "..which\n",
      "visiter\n",
      "12th,13\n",
      "financi\n",
      "extravagan\n",
      "bsbvegas\n",
      "afew\n",
      "frankp\n",
      "shareame\n",
      "soooooooo\n",
      "ateriffic\n",
      "avoid-\n",
      "disappointed/add\n",
      "equippe\n",
      "wedding\\honeymoon\n",
      "across-\n",
      "lexingo\n",
      "clean.pretty\n",
      "witc\n",
      "bay-cation\n",
      "uneve\n",
      "eficient\n",
      "parking+\n",
      "unscale\n",
      "at..\n",
      "meeting-\n",
      "charges-room\n",
      "ellegance\n",
      "encotr\n",
      "girl-getaway\n",
      "floor.we\n",
      "disguting\n",
      "lackluste\n",
      "linqs\n",
      "poolnot\n",
      "vanice\n",
      ".act\n",
      "grandk\n",
      "b/t\n",
      "scetchy\n",
      "location/below\n",
      "duscuss\n",
      "innsid\n",
      "outt\n",
      "nightsin\n",
      "wabc-\n",
      "introducti\n",
      "new/updated\n",
      "*this\n",
      "cool/hip\n",
      "booking/stay\n",
      "visit-\n",
      "january.love\n",
      "casiom\n",
      "leadershi\n",
      "central-location\n",
      "fi-di\n",
      "*if\n",
      "5/2017room\n",
      "Ïù¥ÏóêÏöî\n",
      "spa-like\n",
      "superi\n",
      "torelles\n",
      "iall\n",
      "diva-\n",
      "delighful\n",
      "'ba\n",
      "frnacisco\n",
      "pattys\n",
      "hotelcentral\n",
      "laalaa\n",
      ".unbelievable\n",
      "thelarge\n",
      "visit-parking\n",
      "more..\n",
      "vacayion\n",
      "DGDG:DG\n",
      "..parking\n",
      "harahs\n",
      "hilari\n",
      "2016we\n",
      "strip-quality\n",
      "cq-sf\n",
      "stran\n",
      "encoura\n",
      "experiences:1-initial\n",
      "spectabular\n",
      "bayone\n",
      "perha\n",
      "yuk.buy\n",
      "wynn/win\n",
      "francicso\n",
      "cardinal/cubs\n",
      "resortfriendly\n",
      "momcation\n",
      "hotel-small\n",
      "13yr\n",
      "nonsmoki\n",
      "in/outrooms\n",
      "disappointed‚Ä¶stay\n",
      "lovely.w\n",
      "times-\n",
      "hgi-\n",
      "lollapaloser\n",
      "reconition\n",
      "relo\n",
      "8th-13th\n",
      "mini-sf\n",
      "shooping/theatre\n",
      "overlo\n",
      "games/roulette\n",
      "beauti\n",
      "vegas-bally\n",
      "aufenthalt\n",
      "hesit\n",
      "excalibu\n",
      "eurohipsternycmess\n",
      "a-la-carte\n",
      "disappoiniting\n",
      "barhtub\n",
      "staffexcellant\n",
      "watch-out\n",
      "place.have\n",
      "wow-\n",
      "home-away-from-home\n",
      "croach\n",
      "service-less\n",
      "caino..\n",
      "affordable‚Äîan\n",
      "memberroom\n",
      "DGDG/DG/DG\n",
      "restauran\n",
      "francisxo\n",
      "winard\n",
      "sebbene\n",
      "comfortabloe\n",
      "nightno\n",
      "somwhere\n",
      "casino-hotel\n",
      "milfe\n",
      "essenc\n",
      "service.beds\n",
      "pre-christ\n",
      "overpri\n",
      "unwarrante\n",
      "fourse\n",
      "jlb\n",
      "location/quiet\n",
      "chicago/toronto\n",
      "lv.\n",
      "'hilton\n",
      "21days\n",
      "attantion\n",
      "staygr\n",
      "over-rate\n",
      "friendlyest\n",
      "rockinrio\n",
      "may29-june1\n",
      "dakine\n",
      "convention.the\n",
      "destinati\n",
      "location-viewsit\n",
      "h311\n",
      "room‚Äîbad\n",
      "locatio\n",
      "unsurpassed..\n",
      "for..\n",
      "debauc\n",
      "here.lovely\n",
      "isol\n",
      "best-very\n",
      "sat-tues\n",
      "/full\n",
      "restaurants/\n",
      "subtile\n",
      "*bed\n",
      "countl\n",
      "-easy\n",
      "conventions/business\n",
      "'holiday\n",
      "grill/lounge\n",
      "soapless\n",
      "nights/four\n",
      "greattttttt\n",
      "hispter\n",
      "‡∏õ‡∏≤‡∏£‡∏µ‡∏™\n",
      "deterant\n",
      "retro-hotel\n",
      "increadible\n",
      "hotel.rooms\n",
      "day/eve\n",
      "conference‚Äã\n",
      "city/business\n",
      "slue\n",
      "hilton/doubletree\n",
      "place‚ù§Ô∏è\n",
      "algonqu\n",
      "genui\n",
      "room~\n",
      "alwlays\n",
      "northbeach\n",
      "rock'n'roll\n",
      "staff.happy\n",
      "dinin\n",
      "valet/doormen\n",
      "w/ck\n",
      "stinch\n",
      "endswell\n",
      "loveddd\n",
      "baegas\n",
      "mclarron\n",
      "wow..\n",
      "Î∞©Î¨∏ÌïòÍ≥†\n",
      "gauranteed\n",
      "celebration/1st\n",
      "disappointin\n",
      "ploeasantly\n",
      "extensi\n",
      "pmace\n",
      "octuvious\n",
      "eleganza\n",
      "locationüçéüçéüçéüçé\n",
      "\\wonderful\n",
      "beddin\n",
      "uncount\n",
      "background/booking\n",
      "disconne\n",
      "larger-sized\n",
      "commod\n",
      "waaaa\n",
      "poor/room\n",
      "privacy/safety\n",
      "perfecf\n",
      "statue/ellis\n",
      "custoemr\n",
      "bayv\n",
      "hosel\n",
      "intervi\n",
      "jublie\n",
      "belved\n",
      "cromwel\n",
      "warmüòä\n",
      "istayed\n",
      "mights\n",
      "pros-for\n",
      "organiza\n",
      ".sucked\n",
      "'we\n",
      "millenniu\n",
      "super-hel\n",
      "decor-\n",
      "tunn\n",
      "egyptia\n",
      "welll\n",
      "-jubilee\n",
      "exhauste\n",
      "mskcc\n",
      "eygptian\n",
      "2008great\n",
      "pervizaj\n",
      "disppointed\n",
      "eighborhood\n",
      "1-br\n",
      "non-re\n",
      "experience.al\n",
      "totravel\n",
      "prooerty\n",
      "hotel373\n",
      "servicei\n",
      "location/free\n",
      "hotel/value/location\n",
      "excellecnt\n",
      ".these\n",
      "stay/awesome\n",
      "barten\n",
      "participa\n",
      "juuuust\n",
      "leisure-the\n",
      "chicago-excellent\n",
      "minimal/simple\n",
      "accomadation\n",
      "wecome\n",
      "26-30th\n",
      "üòÄ\n",
      "lication\n",
      "casino/re\n",
      "**pls\n",
      "describ\n",
      "impres\n",
      "grand-this\n",
      "showers.good\n",
      "dissapoint\n",
      "rooms/pool\n",
      "ifyou\n",
      "remodela\n",
      "DGDGDGDGDGDGDGDGDG\n",
      "'buts\n",
      "timesquar\n",
      "‚ù§Ô∏èüóΩüçé\n",
      "burgandy\n",
      "'under\n",
      "„Éë„Éº„ÇØ„Éè„Ç§„Ç¢„ÉÉ„Éà„Éñ„É©„É≥„Éâ„ÅåÂ§ßÂ•Ω„Åç„Å™„ÅÆ„Åß„ÄÅ„Éë„Éº„ÇØ„Éè„Ç§„Ç¢„ÉÉ„Éà„Åå\n",
      "vaule\n",
      "consistenc\n",
      "baddas\n",
      "presidi\n",
      "madness2018\n",
      "robot-like\n",
      "resort/parking\n",
      "troublefree\n",
      "excalibir\n",
      "conference/trade\n",
      "weddingmoon\n",
      "-here\n",
      "120/night\n",
      "pizzaz\n",
      "ultra-luxe\n",
      "trip..\n",
      "shower/bath\n",
      "jadarocks\n",
      "againüòä\n",
      "price-believe\n",
      "lobby/ba\n",
      "awwwwe\n",
      "fishrrman\n",
      "tenni\n",
      "creazy\n",
      "confortab\n",
      "ooom\n",
      "fare.ab\n",
      "derby/cinco\n",
      "aprtme\n",
      "immens\n",
      "yazm√≠n\n",
      "hotel-lousy\n",
      "9y/o\n",
      "loveeeeeee\n",
      "empha\n",
      "theho\n",
      "ecle\n",
      "horrible/unfriendly\n",
      "jackso\n",
      "hotel..location\n",
      "expeience\n",
      "fauc\n",
      "mccormic\n",
      "insf\n",
      "elvartors\n",
      "no-fril\n",
      "roxalinda\n",
      "rainshower\n",
      "45/day\n",
      "locationbig\n",
      "covenient\n",
      "possib\n",
      "treat-very\n",
      "mother/son\n",
      "off.club\n",
      "visoiting\n",
      "rendevous\n",
      "hadson\n",
      "desk/reservation\n",
      "happeist\n",
      "place-eh\n",
      "tinyer\n",
      "cinemacon\n",
      "elega\n",
      "cleanish\n",
      "maintanence\n",
      "libruary\n",
      "theheart\n",
      "staff/okay\n",
      "confirtable\n",
      "23yo\n",
      "non-gamlbing\n",
      "palozzo\n",
      "expret\n",
      "proce\n",
      "2-bedr\n",
      "blyss\n",
      "nit-picky\n",
      "shanekia\n",
      "tripüòú\n",
      "gambling-labor\n",
      "spa√ßious\n",
      "suprize\n",
      "centrral\n",
      "by-far\n",
      "myvegas\n",
      "bwdroom\n",
      "mearin\n",
      "ensureing\n",
      "positives-centrally\n",
      "viewss\n",
      "pleasura\n",
      "loac\n",
      "inhab\n",
      "misso\n",
      "..hate\n",
      "aria-amazing\n",
      "maintained.though\n",
      "growi\n",
      "cosmopo\n",
      "excallent\n",
      "buttttt\n",
      "birthay\n",
      "in-expensive\n",
      "DGDG/DG-DGDG\n",
      "magngificent\n",
      "side-not\n",
      "-do\n",
      "intersectio\n",
      "gorz\n",
      "bhg\n",
      "hollywodean\n",
      "perfeft\n",
      "airconditioni\n",
      "location.po\n",
      "chaot\n",
      "vehic\n",
      ".perhaps\n",
      "frustating\n",
      "northwes\n",
      "sonie\n",
      "grace-\n",
      "casino~\n",
      "hotel/roomthis\n",
      "yeck\n",
      ".exceeded\n",
      "conversat\n",
      "besid\n",
      "usally\n",
      "strip/friendly\n",
      "jessic\n",
      "discreto\n",
      "consid\n",
      "wonderful.much\n",
      "updated-good\n",
      "excerience\n",
      "t.e.r.r.i.b.l.e\n",
      "remeember\n",
      "aaa+\n",
      "completley\n",
      "airpo\n",
      "wheelchai\n",
      "neighborhhod\n",
      "tribeca-\n",
      "macna\n",
      "wowwww\n",
      "1.terrible\n",
      "freiendly\n",
      "festivies\n",
      "ownersh\n",
      "ok..\n",
      "nume\n",
      "marketing-but\n",
      "eidle\n",
      "mason/marina\n",
      "situa\n",
      "busie\n",
      "upsettin\n",
      "nyc/\n",
      "pressie\n",
      "manhattan-madison\n",
      "winterwonderland\n",
      "rrcr\n",
      "beautique\n",
      "usefu\n",
      "up-to-stan\n",
      "lyph\n",
      "hotel.price\n",
      "amoussa\n",
      "roomno\n",
      "whelming\n",
      "lovetion\n",
      "restra\n",
      "timehghhbuhbgfxtvjhvgfxf\n",
      "travago\n",
      "oliv\n",
      "fracisc\n",
      "hpvc\n",
      "brekkie\n",
      "midnigh\n",
      "effecient\n",
      "stanf\n",
      "adverage\n",
      "mascarading\n",
      "palazzo/venet\n",
      "way..\n",
      "tripb\n",
      "arrivale\n",
      "placre\n",
      "housekeepe\n",
      "deli/market\n",
      "frills-\n",
      "patrick/march\n",
      "eccletic\n",
      "almost..\n",
      "roll/\n",
      "spotbook\n",
      "summerline\n",
      "immeni\n",
      "aqusied\n",
      "helpful/friendly\n",
      "cheis\n",
      "disappointment-\n",
      "++\n",
      "mrsjkp3\n",
      "suites-quiet\n",
      "claen\n",
      "crowdless\n",
      "staff/managers\n",
      "close-walking\n",
      "mother/\n",
      "demandi\n",
      "loshiavo\n",
      "addic\n",
      "royalto\n",
      "hallw\n",
      "sohere\n",
      "gorgeous-\n",
      "vacat\n",
      "10minute\n",
      "hotel.when\n",
      "zoribel\n",
      "property,30\n",
      "-slow\n",
      "charakter\n",
      "piers/downton/far\n",
      "strret\n",
      "atmoshpe\n",
      "setrvice\n",
      "hyatt-\n",
      "1030pm\n",
      "DG/DGDG-\n",
      "havtu\n",
      "aaar\n",
      "elevtor\n",
      "drink..or\n",
      "zenshin‚Äî4\n",
      "fantastistic\n",
      "-scentsy\n",
      "flamingo-las\n",
      "pittsfie\n",
      "overcrow\n",
      "here**********\n",
      "resv\n",
      "smell/great\n",
      "armeana\n",
      "m-club\n",
      "brandnew\n",
      "wawep\n",
      "candlew\n",
      "comfortable‚Äîgr\n",
      ".com\n",
      "boulevar\n",
      "francisck\n",
      "'nice\n",
      "staycationing\n",
      "DGDGüèàüëêüèº\n",
      "anderer\n",
      "location-loca\n",
      "rooms-super\n",
      "bleisure\n",
      "detecto\n",
      "terren\n",
      "fun/shopping\n",
      "dowm\n",
      "unfriend\n",
      "comfortablycramped\n",
      "enoyed\n",
      "marb\n",
      "hoooo\n",
      "bad‚Ä¶‚Ä¶not\n",
      "nights.nice\n",
      "nicely-appointed\n",
      "sherato\n",
      "thuroughly\n",
      "over-charged\n",
      "wondeferful\n",
      "casino/great\n",
      "smallnes\n",
      "i‚ù§Ô∏èrow\n",
      "unipersonal\n",
      "coudl\n",
      "amazing‚òÜ‚òÜ\n",
      "'check\n",
      "opport\n",
      "widnows\n",
      "minuites\n",
      ".looking\n",
      "immacula\n",
      "vintag\n",
      "-i\n",
      "*great\n",
      "hakkone\n",
      "facility..\n",
      "blue-lin\n",
      "manatthan\n",
      "uncomfortabl\n",
      "..literally\n",
      "hiyel\n",
      "fan-bloody-tastic\n",
      "excellent-nearby\n",
      "almostüòä\n",
      "atlea\n",
      "38us/night\n",
      "much..\n",
      "october16\n",
      "nyc..pricey\n",
      "no-glitz\n",
      "sequ\n",
      "working/playing\n",
      "smank\n",
      "previsously\n",
      "alaround\n",
      "beachclub\n",
      "~a\n",
      "desrination\n",
      "retutn\n",
      "washr\n",
      "whinging\n",
      "june9-12\n",
      "atvhyatt\n",
      "expre\n",
      "good.provide\n",
      "singleys\n",
      "exetc\n",
      "swanky-euro-nyc\n",
      "ca.trip\n",
      "wedding/honey\n",
      "beekman..great\n",
      "laquinta-chicago\n",
      "shoppping\n",
      "unquestionab\n",
      "membersh\n",
      "upse\n",
      "hhonour\n",
      "23/night\n",
      "avalue\n",
      "disclaimer-\n",
      "rat-pack\n",
      "recommendfri\n",
      "delig\n",
      "surprise.sm\n",
      "pros-great\n",
      "santuary\n",
      "on-stri\n",
      "rreview\n",
      "negativel\n",
      "problem.but\n",
      "you-\n",
      "rock-sum\n",
      "..shame\n",
      "hotel-no\n",
      "-family\n",
      "park-new\n",
      "sudio\n",
      "conveniently-loc\n",
      "goregous\n",
      "years..\n",
      "royality\n",
      "detail/\n",
      "first-ti\n",
      "unhospitality\n",
      "23st\n",
      "re-furb\n",
      "inappropritaely\n",
      "everyo\n",
      "mela-excellent\n",
      "snoby\n",
      "advertize\n",
      "delibera\n",
      "pyrami\n",
      "coulpe\n",
      "averrage\n",
      "ovrall\n",
      "volc\n",
      "lisure\n",
      "‚ÄºÔ∏è\n",
      "◊§◊ô◊†◊ï◊ß\n",
      "vagues\n",
      "everything.staff\n",
      "flamingo/sad\n",
      "fr5ancisco\n",
      "stips\n",
      "arrogante\n",
      "june/\n",
      "vodoo\n",
      "modern-ish\n",
      "cerebration\n",
      "love:1\n",
      "faci\n",
      "row‚Ä¶\n",
      "feldhei\n",
      "positives-good\n",
      "improvement‚Ä¶\n",
      "pros+location+complimentary\n",
      "needs-filling\n",
      "ashame\n",
      "a-maze-ing\n",
      "novotels\n",
      "1900-era\n",
      "avtion\n",
      "vsiited\n",
      "bathrooms/casino\n",
      "tfrye\n",
      "worset\n",
      ".too\n",
      "hotel-immac\n",
      "capicity\n",
      "wifi-\n",
      "question.m\n",
      "offic\n",
      "-attention\n",
      "centerl\n",
      "design-modern\n",
      "chutzpay\n",
      "gorgoeous\n",
      "movi\n",
      "upst\n",
      "cslh\n",
      "'mini\n",
      "slow/poor\n",
      "Îàâoptions\n",
      "rivere\n",
      "refurnishment\n",
      "5:00pm\n",
      "-start\n",
      "univiting\n",
      "4-9th\n",
      "üëçüëåüòòüòó\n",
      "afrashteh\n",
      "mike/michael\n",
      "delightful..\n",
      "checking-in\n",
      "hesi\n",
      "expecta\n",
      "location-reasonable\n",
      "conevention\n",
      "4-ro\n",
      "honeymoon.hotel\n",
      "decentl\n",
      "carge\n",
      "shh‚Ä¶do\n",
      "liket\n",
      "rate-highly\n",
      "volupt√©\n",
      "aug.14-19th\n",
      "stay-we\n",
      "up..\n",
      "advertisement/rooms\n",
      "cuzzins\n",
      "approximatley12\n",
      "bookall\n",
      ".cle\n",
      "favouite\n",
      "accomodating/great\n",
      "fee-grea\n",
      "wow-weeeee\n",
      "location¬°\n",
      "attencion\n",
      "lovation\n",
      "location..need\n",
      "there.the\n",
      "dreamtrips\n",
      "blackjack-say\n",
      "hdve\n",
      "fraid-no-ghost\n",
      "plaza-\n",
      "baaaaaaccck\n",
      "flamingon\n",
      "niceridiculous\n",
      "superdoc\n",
      "pretentio\n",
      "claust\n",
      "top‚òπÔ∏è\n",
      "cleanelyness\n",
      "postivies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "casino..nice\n",
      "location/view-great\n",
      "fitzger\n",
      "hotel/terrible\n",
      "claasic\n",
      "satistaction\n",
      "w/suzie\n",
      "..rooms\n",
      "good‚Ä¶.but\n",
      "fro0m\n",
      "small.st\n",
      "3nig\n",
      "kids/teens\n",
      "outrageou\n",
      "recommendat\n",
      "vibe.bad\n",
      "scutigera\n",
      "service/acco\n",
      "chicago..\n",
      "pirce\n",
      "rat-a-tat-\n",
      "lcati\n",
      "..1st\n",
      "hahahaha\n",
      "2.very\n",
      "pallazo\n",
      "'another\n",
      "experince\n",
      "voluntar\n",
      "detailtc\n",
      "fab.u.lous\n",
      "switch-\n",
      "DG:DGDG.\n",
      "lux-\n",
      "robbbed\n",
      "highl\n",
      "gorgeouse\n",
      "ÊÉ≥ÂÉè„Çà„ÇäËâØ„Åã„Å£„Åü\n",
      "iimmaculate\n",
      "is..\n",
      "concierge/valet\n",
      "hotel-decor\n",
      "lovelly\n",
      "getaway/concert\n",
      "cons‚óèwa\n",
      "+nice\n",
      "personalit\n",
      "agwin\n",
      "*booking\n",
      "looking.i\n",
      "saying..\n",
      "surpi\n",
      "hospitality/\n",
      "samall\n",
      "amazing.the\n",
      "skyjump\n",
      "noisy/weird\n",
      "hostel/hotel\n",
      "non-demanding\n",
      "transportatio\n",
      "ashp\n",
      "vervice\n",
      "upkept\n",
      "franciscio\n",
      "palmsplace\n",
      "'port\n",
      "1030am\n",
      "value-great\n",
      ".never\n",
      "specia\n",
      "say..cle\n",
      "onderful\n",
      "smell/\n",
      "absen\n",
      "dfh\n",
      "2016.w\n",
      "non-tradi\n",
      "sallyann\n",
      "1-robert\n",
      "hobest\n",
      "friendly/accommodating/great\n",
      "midtown-bryant\n",
      "logie49\n",
      "jsut\n",
      "needin\n",
      "seasons-\n",
      "non-boutique\n",
      "revelat\n",
      "12:30pm-1\n",
      "non-cas\n",
      "muffl\n",
      "rocklei\n",
      "bush/front\n",
      "luxor-ious\n",
      ".to\n",
      "awesomeness..\n",
      "ketia\n",
      "disaray\n",
      "goodn\n",
      "hotel..nice\n",
      "favoritve\n",
      "six-five-oh-oh-oh\n",
      "gilleys\n",
      "oppor\n",
      "jewl\n",
      "reliab\n",
      "micro-room\n",
      "smoki\n",
      "brakfast\n",
      "aivan\n",
      "..carpet\n",
      "thestrip\n",
      "biwl\n",
      "library-themed\n",
      "vegaschristmas\n",
      ".fully\n",
      "centrally-l\n",
      "exceptionnal\n",
      "mystif\n",
      "staied\n",
      "exchang\n",
      "increa\n",
      "swuare\n",
      "spectactular\n",
      "reasonalble\n",
      "lipstic\n",
      "lousey\n",
      "club-beautiful\n",
      "strip‚Ä¶\n",
      "passionateless\n",
      "specta\n",
      "mannnn\n",
      "6hours\n",
      "conservetory\n",
      "simple.rooms\n",
      "rennaisance\n",
      ".check\n",
      "expereence\n",
      "deterio\n",
      "yesssss\n",
      "hotel-average\n",
      ".cher\n",
      "imploted\n",
      "pineappl\n",
      "pennsylva\n",
      "fairmontsf\n",
      "hip-ish\n",
      "renunion\n",
      "j.parker\n",
      "b-d\n",
      "spooktackular\n",
      "compl\n",
      "go-to-place\n",
      "occurred:1.\n",
      "230/ni\n",
      "row/\n",
      "chi-tow\n",
      "'add-ons\n",
      "vegasall\n",
      "distanc\n",
      "worldw\n",
      "funüòä\n",
      "650sq\n",
      "12000km\n",
      "ismetra\n",
      "affraid\n",
      "üî•üòÉüëèüèª\n",
      "bathroom/room\n",
      "zorrex\n",
      "zlinc\n",
      "nickeled-an\n",
      "gfreat\n",
      "ehh..\n",
      "-pool\n",
      "proporties\n",
      "signifcant\n",
      "reasonab\n",
      "2x/year\n",
      "spaciest\n",
      "good+bad=average\n",
      "hopef\n",
      "—Å–ø–æ–∫–æ–π–Ω–æ–π\n",
      "airconditioning-\n",
      "contemprary\n",
      "jacpot\n",
      "3-bed\n",
      "optiono\n",
      "3-s\n",
      "flamigo\n",
      "shern\n",
      "staycation/relaxation\n",
      "hotel-do\n",
      "/right\n",
      "televi\n",
      "shortfallings\n",
      "caesar's/nobu\n",
      "check-in/check-out\n",
      "travelor\n",
      "geed\n",
      "location..great\n",
      "ÊØéÂõûÊ•Ω„Åó„ÅÑÊóÖË°å„Åß„Åô„ÄÇ\n",
      "nov.8-12\n",
      "grandn\n",
      "hostel-like\n",
      "funlocation\n",
      "surpsi\n",
      ":40am\n",
      "value.our\n",
      "sstay\n",
      "jos√®\n",
      "kalliam\n",
      "nastayyyy\n",
      "recome\n",
      "maebe\n",
      "conferences/conventions\n",
      "amazinc\n",
      "challenge..noise\n",
      ".or\n",
      "hentze\n",
      "kidslov\n",
      "circus-circus\n",
      "staff/good\n",
      "hotel..excellent\n",
      "monthl\n",
      "üëèüëèüëè\n",
      "dirtest\n",
      "recommend+++\n",
      "realatives\n",
      "in.nice\n",
      "youbstay\n",
      "enormous‚Ä¶..\n",
      "smokele\n",
      "1-the\n",
      "trip~\n",
      "relaxing-gives\n",
      "hilton*\n",
      "presbyterian-columbia\n",
      "logustucs\n",
      "spesial\n",
      "readyness\n",
      "cinveniently\n",
      "dimei\n",
      "service/average\n",
      "vegas-tastic\n",
      "uglybaby\n",
      "◊ë◊®◊û◊î\n",
      "rooms.ex\n",
      "medern\n",
      "vaue\n",
      "retrun\n",
      "gerdie\n",
      "üòÑ\n",
      "hotel-really\n",
      "hotel..unfortunatel\n",
      "hexx\n",
      "subway/b\n",
      "tech-y\n",
      "moden\n",
      "Á´ãÂú∞„ÅØËâØ„ÅÑ„Åå„Çµ„Éº„Éì„Çπ„ÅØÊúüÂæÖ„Åß„Åç„Å™„ÅÑ\n",
      "stapl\n",
      "garosi\n",
      "tripcation\n",
      "witne\n",
      "price.very\n",
      "ny,1st\n",
      "street/car\n",
      "-away\n",
      "effiel\n",
      "physicia\n",
      "hadüí∏üí∞üíµ\n",
      "jacuz\n",
      "stay/good\n",
      "ÏïÑÏ£º\n",
      "trip-lower\n",
      "kimptons\n",
      "magnificent-\n",
      "experiece\n",
      "-third\n",
      "offstrip\n",
      "struggleing\n",
      "6t\n",
      "ruction\n",
      "luxiorious\n",
      "boutique-\n",
      "4/5location\n",
      "rooms..great\n",
      "somthing\n",
      "tilex\n",
      "fixing/upgrading/cleaning\n",
      "mileno\n",
      "croud\n",
      "room-fantasti\n",
      "overexpensive\n",
      "transiti\n",
      "wyhnd\n",
      "a*hotel\n",
      "manjo\n",
      "'facilityfe\n",
      "hearin\n",
      ".arrived\n",
      "else.strategical\n",
      ".terribly\n",
      "dontstayhere\n",
      "epectations\n",
      "fros\n",
      "professional.has\n",
      "retir\n",
      "hostel/\n",
      "caraca\n",
      "starish\n",
      "havestayed\n",
      "feedbak\n",
      "üçéüçéüçé\n",
      "competi\n",
      "ceaseres\n",
      "stay4\n",
      "gahd\n",
      "ricar\n",
      "perfect.th\n",
      "row-tastic\n",
      "umbre\n",
      "'quite\n",
      "stationÂè™Êúâ2ÂàÜÈêòËÖ≥Á®ã\n",
      "exeptionally\n",
      "phenomal\n",
      "shweet\n",
      "conr\n",
      "squate\n",
      "aurgust\n",
      "enogh\n",
      "mnnnnnn\n",
      "usuable\n",
      "avacation\n",
      "someho\n",
      "margari\n",
      "lobby/conc\n",
      "undesireable\n",
      "smelly.noth\n",
      "spankin\n",
      "interior/e\n",
      "strip..quite\n",
      "daighter\n",
      "mother..daughter\n",
      "-pleasant\n",
      "all-in-\n",
      "abando\n",
      "activit\n",
      "mon-s\n",
      "one-nig\n",
      "enhoyed\n",
      "travelodge-\n",
      "bargai\n",
      "sband\n",
      "marie/\n",
      "ÏÑúÎπÑÏä§Î•º\n",
      "wipe-able\n",
      "feel-goo\n",
      "22nd-may\n",
      ".sheets\n",
      "satasfied\n",
      "rehab.it\n",
      "service/noisy\n",
      "mother-in-la\n",
      "appropria\n",
      "non-gambler\n",
      "goodquiet\n",
      "imeplatium\n",
      "dopeeee\n",
      "re-don\n",
      "undifferent\n",
      ".besides\n",
      "plus-friendly\n",
      "fransico\n",
      "get-tog\n",
      ".2nd\n",
      "difgicult\n",
      "bellagi\n",
      "weddin\n",
      "DG-DG-DGDGDGDG\n",
      "weekend-outstanding\n",
      "itgentle\n",
      "workred\n",
      "helpful.great\n",
      "few-days\n",
      "size.e\n",
      "unbeleavable\n",
      "redu\n",
      "bachlorette\n",
      "dedicat\n",
      ".employees\n",
      "chicago-geat\n",
      "new-new\n",
      "somany\n",
      "denyed\n",
      "surronding\n",
      "fanci\n",
      "hotel..tremendous\n",
      "mmclu\n",
      "casino/sort\n",
      "/location\n",
      "good.very\n",
      "aces-a\n",
      "tupacvoice\n",
      "/motel\n",
      "sloleil\n",
      "carten-fujikin\n",
      "typicall\n",
      "scam..\n",
      "greyline\n",
      "compet\n",
      "ambianc\n",
      "oksy\n",
      "separ\n",
      "DGDGDGDG..\n",
      "art-themed\n",
      "older-style\n",
      "adlt\n",
      "beware-\n",
      "hampon\n",
      "but..what\n",
      "„Éã„É•„Éº„Ç¢„Éº„ÇØ„Åã„Çâ„ÅÆpath„ÅÆÈßÖwtc„Åã„ÇâËá≥Ëøë„ÄÅÂú∞‰∏ãÈâÑ\n",
      "hotel-top\n",
      "undi\n",
      "stay-still\n",
      "terribleeeeeeee\n",
      "night/4\n",
      "layout..alwa\n",
      "sulverton\n",
      "tirp\n",
      "strup\n",
      "perfectttt\n",
      "'sofitel\n",
      "13-17th\n",
      "freamont\n",
      "8:30p\n",
      "coudnt\n",
      "distur\n",
      "reviewe\n",
      "ovreall\n",
      "alrigh\n",
      "reprive\n",
      "aiight\n",
      "light-filled\n",
      "cusomer\n",
      "isssue\n",
      "14yr\n",
      "cost-wis\n",
      "8camera\n",
      "motel-that\n",
      "pied-a-terre\n",
      "couldn¬¥t\n",
      "salepersons\n",
      "shaby\n",
      "authori\n",
      "chicago-illinois\n",
      "sedond\n",
      "üëçüëç\n",
      "extremel\n",
      "'bra\n",
      "terrable\n",
      "priceta\n",
      "cnannoc\n",
      "lobby/e\n",
      "üòÄüòÄüòÄ\n",
      "hinever\n",
      "conference/relaxing\n",
      "illrepair\n",
      "inter-delightful\n",
      "nively\n",
      "trip.terrible\n",
      "post-sfmoma\n",
      "over-pri\n",
      "minuse\n",
      "daughte\n",
      "suitabl\n",
      "'best\n",
      "roofbar\n",
      "gemm\n",
      "accesabel\n",
      "apot\n",
      "surrey-\n",
      "booking*******\n",
      "beaultiful\n",
      "hoipe\n",
      "ph03\n",
      "ink48\n",
      "unhampton\n",
      "lcean\n",
      "sode\n",
      "pulle\n",
      "fab..u\n",
      "dark.don\n",
      "wedding/honeymoon/vacation\n",
      "views/do\n",
      "gjerlow\n",
      "2017.p\n",
      "3-nigh\n",
      "disap\n",
      "disastrousl\n",
      "clean.wi\n",
      "viisit\n",
      "casino/hotel/resort\n",
      "platinum/\n",
      "barthroom\n",
      "raem\n",
      "favnychotel\n",
      "room-lot\n",
      "bedcover\n",
      "vacagtion\n",
      "comfymaid\n",
      "jan.29-\n",
      "here.ther\n",
      "w/chain\n",
      "exept\n",
      "ave/milli\n",
      "holguy\n",
      "ashelel\n",
      "autho\n",
      "awesomehad\n",
      "insulatio\n",
      "5p.m\n",
      "manhattan/5th\n",
      "marlito10\n",
      "freque\n",
      "hospitle\n",
      "far..\n",
      "customer-centric\n",
      "giraffe******\n",
      ",to\n",
      "loooong\n",
      "12mn\n",
      "amazeing\n",
      ".typical\n",
      "me-oh\n",
      "cosr\n",
      "celebration/girls\n",
      "sporrts\n",
      "rattl\n",
      "tribeca-best\n",
      "valantines\n",
      "kinfu\n",
      "friendly/accommodating\n",
      "standatd\n",
      "memb\n",
      "patetic\n",
      "kasherika\n",
      "addtional\n",
      "getawaybarrett\n",
      "good-i\n",
      "fiugred\n",
      "great.quiet\n",
      "suite+\n",
      "toppie\n",
      "standards.dirty\n",
      "wihin\n",
      "weekdnd\n",
      "placelots\n",
      "hisory\n",
      "staff.super\n",
      "stayr\n",
      "place*\n",
      "vomi\n",
      "nylo\n",
      "great..good\n",
      "thng\n",
      "chicago/the\n",
      "'facility\n",
      "wefound\n",
      "bookingsystem\n",
      "chucago\n",
      "apartment/suite\n",
      "complic\n",
      "goodcheck\n",
      "metropolita\n",
      "ayptical\n",
      "sharte\n",
      "suitab\n",
      "service-bill\n",
      "thinki\n",
      "ohop\n",
      "coupleseeing\n",
      "appreaciate\n",
      "park/wr\n",
      "bettr\n",
      "exerci\n",
      "opinion.m\n",
      "cordinate\n",
      "over-pay\n",
      "well-sized\n",
      "security/f\n",
      "girltrip\n",
      "sheraton-\n",
      "brillance\n",
      "discription\n",
      "timele\n",
      "re-book\n",
      "aesthet\n",
      "honey-versary\n",
      "vegas..\n",
      ".anyw\n",
      "realcing\n",
      "chigaco\n",
      "accomidaition\n",
      "well-locat\n",
      "amoungst\n",
      "delivers-again\n",
      "oct.we\n",
      "nwfw\n",
      "nycsoho\n",
      "braodway\n",
      "embarcaderro\n",
      "towm\n",
      "witth\n",
      "bargarin\n",
      "dormitori\n",
      "actvity\n",
      "b-day\n",
      "microrooms\n",
      "check-in/out\n",
      "were2\n",
      "hip-great\n",
      "abouat\n",
      "celebrations/ga\n",
      "chiago\n",
      "beautil\n",
      "construction/renovations\n",
      "hotel/casino/restaurants\n",
      "squ\n",
      "facilities-\n",
      "DG/\n",
      "upcharged\n",
      "essentia\n",
      "riu-nyc\n",
      "conventioon\n",
      "efficientcy\n",
      "working/no\n",
      "deactiviating\n",
      "amazing.it\n",
      "pocket-size\n",
      "touhgth\n",
      "komali\n",
      "staffo\n",
      "inpanema\n",
      "location-wal\n",
      "frendl\n",
      "mildewy\n",
      "popula\n",
      "care/respond\n",
      "hearbreak\n",
      "embarcadaro\n",
      "12th-\n",
      "mitigat\n",
      "acommodation\n",
      "vlivel\n",
      "estadia\n",
      "overpricedb\n",
      "tranq\n",
      "otstanding\n",
      "surger\n",
      "csibb\n",
      "5star\n",
      "steppi\n",
      ".hip\n",
      "food/drinks\n",
      "honeymoon.wou\n",
      ".lo\n",
      "above/beyond\n",
      "airconditioner\n",
      "‚òò\n",
      "cearsars\n",
      "elegamnt\n",
      "carpetin\n",
      "place\\nfront\n",
      "annivsersay\n",
      "differenc\n",
      "'butler\n",
      "familyvacation\n",
      "oct15\n",
      "ntge\n",
      "gillys\n",
      "service/respo\n",
      "palace/total\n",
      "embarkadero\n",
      "10/19/2018cont\n",
      "cromwell.to\n",
      "üçª\n",
      "..sle\n",
      "neibors\n",
      "DGDGDGDGDG-\n",
      "nycwe\n",
      "accid\n",
      "woundnt\n",
      "hugo-a-go-go\n",
      "you'really\n",
      "bisited\n",
      "vistin\n",
      "o'hare-march\n",
      "ciy\n",
      "cancune\n",
      "bunkbed\n",
      "all-aorund\n",
      "progre\n",
      "routlette\n",
      "getw\n",
      "autum\n",
      "2018-10-06arrived\n",
      "ryalyn\n",
      "decent-size\n",
      "convinc\n",
      "fetty\n",
      "lowpool\n",
      "nice..bed\n",
      "timesha\n",
      "yorker-\n",
      "great.had\n",
      "***wrote\n",
      "osegjnposdngsen\n",
      "invisi\n",
      "plumme\n",
      "securty\n",
      "resto/bar\n",
      "westminst\n",
      ".then\n",
      "disatisfied\n",
      "mutilple\n",
      "nov.5-8\n",
      "reviews..\n",
      "wrigl\n",
      "location-awesome\n",
      "mullen-davey\n",
      "good.check\n",
      "10years\n",
      "visit..alwa\n",
      "whithout\n",
      "sophis\n",
      "convient\n",
      "bday..we\n",
      "bschoo\n",
      "fewwe\n",
      "charming.g\n",
      "questionabe\n",
      "room/corridor\n",
      "DG-DGDG-DGDG/DG-DGDG-DGDG\n",
      "'wharf\n",
      "ulaf\n",
      "surroundi\n",
      "longw\n",
      "'really\n",
      "crazytown\n",
      "breathtaki\n",
      "half-updated\n",
      "saety\n",
      "dump~\n",
      "'value\n",
      "reasonable-\n",
      "personality-filled\n",
      "vaslues\n",
      "efficient/smart\n",
      "location.c\n",
      "xoxoxoxoxoxoxo\n",
      "juanie\n",
      "celebrateing\n",
      "cassand\n",
      "disapeared\n",
      "pre-luggage\n",
      "location/pleasant\n",
      "trip-great\n",
      "DGDG/DGDG-DGDG/DG\n",
      "chairs-\n",
      "renovated/great\n",
      "stret\n",
      "garden-\n",
      "haappy\n",
      "mky\n",
      "fairmont‚ù§Ô∏è\n",
      "afrequent\n",
      "personnell\n",
      "shoquan\n",
      "renovtion\n",
      "abys\n",
      "holiday/\n",
      "500rooms\n",
      "neighborhod\n",
      "careworn.no\n",
      "rooms-comfy\n",
      "cashie\n",
      "thorughl\n",
      "illustrio\n",
      "comftorable\n",
      "parceldelivery\n",
      "pallazio\n",
      "/daughter\n",
      "outstandig\n",
      ",real\n",
      "yrma\n",
      "bathroomsc\n",
      "beaux-ar\n",
      "place..in\n",
      "evely\n",
      "ctiy\n",
      "remin\n",
      "michelango\n",
      "vegas/flamingo\n",
      "honeysuckl\n",
      "location/safe\n",
      "2-night\n",
      "ourselve\n",
      "alrounder\n",
      "halls/r\n",
      "nomans\n",
      "pilgrimag\n",
      "cc*\n",
      "diasspointed\n",
      "a+\n",
      "conveinently\n",
      "waldorfastoria\n",
      "sixe\n",
      "livelyness\n",
      "casino..al\n",
      "/cas\n",
      "familiy\n",
      "facelif\n",
      "mzkdavis34\n",
      "platium\n",
      "viberoom\n",
      "price.awesome\n",
      "choices/difficult\n",
      "underserviced\n",
      "hotel-lincoln\n",
      "bazinga\n",
      "realiably\n",
      "hotel-rooms\n",
      "inchecking\n",
      "bellago\n",
      "'motel\n",
      "4+star\n",
      ".perfect\n",
      "comfortabel\n",
      "park/sleep/fly\n",
      "valuevalue\n",
      "attentio\n",
      "preium\n",
      "burdle\n",
      ".donatello\n",
      "m'y\n",
      "thorughly\n",
      "mashavakure\n",
      "cheerful-ish\n",
      "ok..but\n",
      "check-in/out-\n",
      "staff/secur\n",
      "keyshiia\n",
      "disappointmen\n",
      "close-ish\n",
      "golf.started\n",
      "6:35am\n",
      "elagent\n",
      "helpful.but\n",
      "locationlocated\n",
      "bookings.com.and\n",
      "bed/showe\n",
      "besy\n",
      "old-cold-needs\n",
      "nickle-and-dimed\n",
      "benef\n",
      "prorerty\n",
      "chemica\n",
      "ÏàòÌïòÎ¨ºÏùÑ\n",
      "2417room\n",
      "customere\n",
      "'old-school\n",
      "-please\n",
      "continu\n",
      "therio\n",
      "10/11.we\n",
      "oversig\n",
      "harrahs~~awsome\n",
      "dependi\n",
      "air-condition\n",
      "colloseum\n",
      "kimberle\n",
      "phrc\n",
      "nhts\n",
      "ibupro\n",
      "holdem\n",
      "experiences-good\n",
      "unpre\n",
      "pickwock\n",
      "boliver\n",
      "assu\n",
      "room-a/c\n",
      "hokiday\n",
      "sewery\n",
      "7av\n",
      "czarshopper\n",
      "improvemen\n",
      "avgerage\n",
      "staffeveryone\n",
      "inprove\n",
      "/small\n",
      "sibli\n",
      "ok/mediocre\n",
      "out..\n",
      "charleys\n",
      "york'er\n",
      "room=amazingfood=amazi\n",
      "~~~\n",
      "lessgreat\n",
      "room/strip\n",
      "lovedd\n",
      "houshun\n",
      "allway\n",
      "bringley\n",
      "pulse-beat\n",
      "-downtown\n",
      "Í∞ÄÍ≤©ÎåÄÎπÑ\n",
      "partyweek\n",
      "oct-2015\n",
      "zzzs\n",
      "one-b\n",
      "loucation\n",
      "beautifully-designed\n",
      "funest\n",
      "amazingüëå\n",
      "gaby.i\n",
      "aaca\n",
      "couryar\n",
      "safisfied\n",
      "entertainment/hospitalit\n",
      "days..\n",
      "hotel-poor\n",
      "impeccable\\natten\n",
      "3d2n\n",
      "gold/platinum\n",
      "accompanie\n",
      "-our\n",
      "wardorf\n",
      "didmy\n",
      "room-service\n",
      "maginificient\n",
      "coorporate\n",
      "lovely.hotel\n",
      "dated-great\n",
      "ac/\n",
      "city-time\n",
      "orientat\n",
      "initia\n",
      "hotel31\n",
      "worry-free\n",
      "unparal\n",
      "tume\n",
      "mardegan\n",
      "mehret\n",
      "togethe\n",
      "househeeping\n",
      "elara/hilton\n",
      "'hostel\n",
      "greer563\n",
      "llooks\n",
      "relaxful\n",
      "eisenho\n",
      "swtay\n",
      "l.l\n",
      "flamingo..great\n",
      "bakc\n",
      "comfy/great\n",
      "remommended\n",
      "elecance\n",
      "now-husband\n",
      "wonderful/\n",
      "dec.10\n",
      "son/first\n",
      "meeting-getaway\n",
      "..without\n",
      "phenome\n",
      "childr\n",
      "yorktiny\n",
      "ofmy\n",
      "principa\n",
      "aircond\n",
      "coffee/tea\n",
      "dec-3\n",
      "headeache\n",
      "modern/tast\n",
      "creepy-\n",
      "ÿ¨ÿØÿßŸã\n",
      "engrs\n",
      "asquerosamente\n",
      "suckspool\n",
      "qualty\n",
      "aria.i\n",
      "un-believeable\n",
      "marchmadness\n",
      "amst\n",
      "micro-ro\n",
      "costs.they\n",
      "'first\n",
      "secur\n",
      "facny\n",
      "mainenance\n",
      "11nig\n",
      "hotle\n",
      "prices.has\n",
      "here.first\n",
      "titanik\n",
      "get-to\n",
      ".smoke\n",
      "balze\n",
      "every-\n",
      "nightstay\n",
      "checkout..charged\n",
      "offe\n",
      ".my\n",
      "scince\n",
      "good‚Äî-but\n",
      "augh\n",
      "inmejo\n",
      "advianc\n",
      "throug\n",
      "hotel/decent\n",
      "strategico\n",
      "sounde\n",
      "**save\n",
      "greates\n",
      "revovations\n",
      "starit\n",
      "carnagie\n",
      "famingo\n",
      "nightsthe\n",
      "supermar\n",
      "celebartion\n",
      "frendly\n",
      "antzy\n",
      "s-f\n",
      "winnard\n",
      "service-dated\n",
      "remore\n",
      "DGDG/DG-DGDG/DG\n",
      "altho\n",
      "1wtc\n",
      "limita\n",
      "w-\n",
      "refurbishedmen\n",
      "murtough\n",
      "relati\n",
      "babeee\n",
      "here=67\n",
      "zishan\n",
      "ago..now\n",
      "stayvacations\n",
      "un-rivall\n",
      "empire3016\n",
      "re-post\n",
      "w/shuttle\n",
      "house‚Ä¶\n",
      "luxiourous\n",
      "well-presented\n",
      "sean16\n",
      "disappointd\n",
      "relazing\n",
      "..nice\n",
      "clienta\n",
      "DG/DGDG-DG/\n",
      "helpful/courteous\n",
      "o-k\n",
      "iraquois\n",
      "curtious\n",
      "attens\n",
      "22august\n",
      "greratest\n",
      "rossevelt\n",
      "honolu\n",
      "surprsiing\n",
      "eyemask\n",
      "looks-\n",
      "cannibas\n",
      "arrrived\n",
      "decenber\n",
      "recommend.wis\n",
      "andez\n",
      "chicago/midway\n",
      "j.a\n",
      "ubicaci√≥n\n",
      "gotel\n",
      "anti-trum\n",
      "2015.excel\n",
      "lesoli\n",
      "..lots\n",
      "locationüòÄ\n",
      "padin\n",
      "transformatio\n",
      ",got\n",
      "hughe\n",
      "secind\n",
      "hotel.very\n",
      "redeco\n",
      "location.i\n",
      "employees/service\n",
      "*as\n",
      "madeli\n",
      "location.we\n",
      "excellence..\n",
      "celin\n",
      "bride+\n",
      "hotelnew\n",
      "piratey\n",
      "excellent..\n",
      "disappointed.t\n",
      "location/modern\n",
      "4-letter\n",
      "stay-stay\n",
      "23r\n",
      "appreciation/recognition\n",
      "bistr\n",
      "capric\n",
      "vages\n",
      "disappointmeny\n",
      "hiccu\n",
      "mcdonal\n",
      "functional.arri\n",
      "determ\n",
      "bad-\n",
      "DGDG/DGDG/DGDG-DGDG/DG\n",
      "striphouse\n",
      "aprilfool\n",
      "every.single.thin\n",
      "afffordable\n",
      "respress\n",
      "locationour\n",
      "reaks\n",
      "thower\n",
      "weekend-done\n",
      "other-wordly\n",
      "awkard\n",
      "extracharges\n",
      "chris‚Äîindividual\n",
      "..luxurious\n",
      "updating.but\n",
      "asth\n",
      "nolit\n",
      "humidify\n",
      "way.from\n",
      "hadn\n",
      "hardwo\n",
      "fourl\n",
      "amazzing\n",
      "maker/f\n",
      "friendly+\n",
      "prosperious\n",
      "strippe\n",
      "sporstbook\n",
      "DGDGDGDG-DGDG\n",
      "outsatnding\n",
      "..eleven\n",
      "gracelan\n",
      ".loud\n",
      "verynicerooms\n",
      "kristyf\n",
      "nymay\n",
      "dorm-like\n",
      "flat-sc\n",
      "wolco\n",
      "impovement\n",
      "dfinetely\n",
      "arrang\n",
      "wow..wow\n",
      "incredicble\n",
      "top-rate\n",
      "in/ch\n",
      "name-\n",
      "vidmantas\n",
      "hotelsare\n",
      "location..gla\n",
      "bedro\n",
      "amazing/fant\n",
      "honneymoon\n",
      "views-friendly\n",
      "royc\n",
      "hattahs\n",
      "average/very\n",
      "zakeyma\n",
      "age-wise\n",
      "casion\n",
      "paradi\n",
      "heat-air\n",
      "uuuuugh\n",
      "aaamazing\n",
      "mr.m\n",
      "disuad\n",
      "new-y\n",
      "-p\n",
      "meatpack\n",
      "eco-chic\n",
      "stay/\n",
      "classie\n",
      "hollywood/nov\n",
      "dog-friendly\n",
      "-staff\n",
      "wayroom\n",
      "overwo\n",
      "‚Ä¶..ever\n",
      "excitin\n",
      "definetl\n",
      "maddress\n",
      "convention/reunion\n",
      "wellin\n",
      "day‚ù§Ô∏è\n",
      "york.it\n",
      "squareÎ°ú\n",
      "grandclub\n",
      "fabrestaurants\n",
      "charecter\n",
      "nyno\n",
      "'unusual\n",
      "maintnance\n",
      "'cest\n",
      "..not..\n",
      "pricr\n",
      "avant-gard\n",
      "5th-floo\n",
      "chingon\n",
      "'very\n",
      "boulevard-we\n",
      "time..v\n",
      "plymout\n",
      "wee-view\n",
      "visitor-\n",
      "hchatha\n",
      "erikak\n",
      "tops-great\n",
      "location-several\n",
      "monar\n",
      "rollaw\n",
      "chelsea/nomad\n",
      "dojainese\n",
      "meeeeeh\n",
      "w35th\n",
      "lagre\n",
      "lcoation\n",
      "york-times\n",
      "-DG\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mikes7starreview\n",
      "bcak\n",
      "ÿ≥ÿπŸäÿØŸá\n",
      "manhattan-clo\n",
      "marrines\n",
      "DGDG/DGDG-DG/DGDGDG\n",
      "holiday.the\n",
      "same..\n",
      "associ\n",
      "siggie\n",
      "serevice\n",
      "hotel.love\n",
      "impressions/bates\n",
      "hilton-elara\n",
      "in-processing\n",
      "wake-ups\n",
      "agetaway\n",
      "ideally-situated\n",
      "fieldtrip\n",
      "enviornme\n",
      "ilovethelinq\n",
      "bakmah\n",
      "~i\n",
      "airdawgs\n",
      "comnfortable\n",
      "yessss\n",
      "presidentia\n",
      "lovely..\n",
      "be/\n",
      "home-from-home\n",
      "exem\n",
      "langhams\n",
      "hlodversson\n",
      "15usd/day\n",
      "people-watching\n",
      "bay/midtown\n",
      "'fish-market\n",
      "+exceptionnal\n",
      "snobish\n",
      "bacchanel\n",
      "regency-mccormick\n",
      "astoun\n",
      "saga-\n",
      "chinatow\n",
      "eclec\n",
      "gamb\n",
      "swif\n",
      "ordinar\n",
      "imptoimprov\n",
      "spacous\n",
      "location‚ò∫‚ò∫\n",
      "franchelly\n",
      "serivce/exp\n",
      "rhadames\n",
      "bath/shower\n",
      "renaiss\n",
      "unfairmont\n",
      "hono\n",
      "vegas/harrah\n",
      "overni\n",
      "acceptabl\n",
      "plaza..\n",
      "high-\n",
      "comfty\n",
      "rosd/sewer\n",
      "boutigue\n",
      "..lo\n",
      "comign\n",
      "improvents\n",
      "shellbourne\n",
      "veldig\n",
      ".impe\n",
      "inn/homewood\n",
      "discou\n",
      "days/3\n",
      "ago-not\n",
      "g-rate\n",
      "goood\n",
      "visitting\n",
      "vegas.on\n",
      "belnord\n",
      "medicre\n",
      "too-small\n",
      "15-19th\n",
      "stay.the\n",
      "soho-area\n",
      "Ï†ÄÎ†¥Ìïú\n",
      "elegand\n",
      "time..great\n",
      "‚ú®‚ú®‚ú®\n",
      "hyginene\n",
      "emily808\n",
      "decnt\n",
      "blackight\n",
      "palazzo-perfect\n",
      "holidaysüéÑ\n",
      "long-weekend\n",
      "staff‚Ä¶paper\n",
      "stripl\n",
      "weekstaff\n",
      "proseco\n",
      "experin\n",
      "rooms/d\n",
      "travelgogirl\n",
      "purcha\n",
      "ubicaci\n",
      "builted\n",
      "..basic\n",
      "georgeus\n",
      "kudels\n",
      "intersestin\n",
      "aple\n",
      "floor/lounge\n",
      "cool/classic\n",
      "'upscale\n",
      "a****\n",
      "son-in\n",
      "roxyy\n",
      "mabye\n",
      "roomawesom\n",
      "non-smokin\n",
      "seriva\n",
      "october.room\n",
      "remarkab\n",
      "*before*\n",
      "room.with\n",
      "hagenmaier\n",
      "refillab\n",
      "amazinggg\n",
      "tahati\n",
      "play..\n",
      "3night\n",
      "arsey\n",
      "berkshir\n",
      "love.posh\n",
      "cutrrntly\n",
      "hotel-extremely\n",
      "hererooms\n",
      "quietnroom\n",
      "happil\n",
      "vegas17\n",
      "koreat\n",
      "toilettries\n",
      "jabig\n",
      "briti\n",
      "accomadatio\n",
      "p/night\n",
      "'worst\n",
      "kimpon\n",
      "nuce\n",
      "hotel/little\n",
      "roosvelt\n",
      ".what\n",
      "simplysexy\n",
      "hen/pauline\n",
      "accomindations\n",
      "outstanding1\n",
      "ny'er\n",
      "acouple\n",
      "whatev\n",
      "location/nasty\n",
      "casino-cheap\n",
      "critisi\n",
      "want/need\n",
      "expactat\n",
      "huntingt\n",
      "unusabl\n",
      "platnum\n",
      "expectated\n",
      "well\\nsituated\n",
      "allegia\n",
      "09th\n",
      "beggining\n",
      "linclon\n",
      "foste\n",
      "great..love\n",
      "wwas\n",
      "cathedralb\n",
      "kids,11\n",
      "gwtaway\n",
      "for.ever\n",
      "soortsbook\n",
      "paren\n",
      "year/\n",
      "espacially\n",
      "gamble-\n",
      "friendlin\n",
      "wildcatfan44\n",
      "surperb\n",
      "traveler.i\n",
      "..massages\n",
      "mugged-\n",
      "breakings\n",
      "anywher\n",
      "eary-so\n",
      "trendy..\n",
      "business/extended\n",
      "invredible\n",
      "trip/stay\n",
      "down-town\n",
      "seedin\n",
      "29ho\n",
      "hygi√´ne\n",
      "manatten\n",
      "lanettera\n",
      "days.bee\n",
      "shoesize\n",
      "accommedations\n",
      "extrodanary\n",
      "chate\n",
      "‚ù§Ô∏èüòç\n",
      "warw\n",
      "exceleent\n",
      "copons\n",
      "flaminga\n",
      "tournamen\n",
      "nmlb\n",
      "vegas-class\n",
      "..but\n",
      "lifeti\n",
      "mutiple\n",
      "cannab\n",
      "hell..my\n",
      "nice..great\n",
      "coporate\n",
      "unwel\n",
      "pulito\n",
      "siuite\n",
      "ovah-rated\n",
      "changed..is\n",
      "**great\n",
      "refe\n",
      "goodpool\n",
      "vmworld\n",
      "plus-\n",
      "beware:1.\n",
      "zoheb\n",
      "hotel-fancy\n",
      "friendlystaff\n",
      "middle-tie\n",
      "hhoners\n",
      "mid-septembe\n",
      "11t\n",
      "preparat\n",
      "downr\n",
      "hhon\n",
      "hi-chicago\n",
      "biologica\n",
      "inforgettable\n",
      "wedding/christmas\n",
      "anniversary/visit\n",
      "location-in\n",
      "'room\n",
      "shoebox-size\n",
      "tripüéÇ\n",
      "-kudos\n",
      "amaaazing\n",
      "satisfiedinmichigan\n",
      "quiet..\n",
      "location/size/customer\n",
      "schedu\n",
      "speading\n",
      "raudel\n",
      "chowdhuny\n",
      "hotel.we\n",
      "window-sill\n",
      "eur/night\n",
      "client/colleague\n",
      "loevly\n",
      "olders\n",
      "fit//nice\n",
      "grand‚Äé\n",
      "gotte\n",
      "bffl\n",
      ".shame\n",
      "boutique-style\n",
      ".fast\n",
      "termin\n",
      "24-hours-service\n",
      "grumble-\n",
      "11:30pm\n",
      "byop\n",
      "room/pool\n",
      "hotel..including\n",
      "thewitt\n",
      "ever..m\n",
      "people..\n",
      "signature-mgm\n",
      "certifi\n",
      "-no\n",
      "nortth\n",
      "staffexcel\n",
      "eleazel\n",
      "way..but\n",
      "restraun\n",
      "tameika\n",
      "identit\n",
      "seccond\n",
      "zalo\n",
      "sadlyhad\n",
      "_new\n",
      "amenities-pl\n",
      "attractioncs\n",
      "photograp\n",
      "elements-gift\n",
      "vegas/bellagio\n",
      "relationsi\n",
      "transpa\n",
      "classic-\n",
      "children/parking\n",
      "august/septem\n",
      "bums.near\n",
      "a5night\n",
      ".both\n",
      "accide\n",
      "'maybe\n",
      "//www.tripadvisor.com/userreview-g45963-\n",
      "coautho\n",
      "muych\n",
      "airport/unlv\n",
      "avaiable\n",
      "expeensiv\n",
      "wednesday-\n",
      "pre-dinner\n",
      "buisiness\n",
      "mahattan\n",
      "desperae\n",
      "couples/adult\n",
      "-fitness\n",
      "-us\n",
      "üíì\n",
      "jan.2016\n",
      "junki\n",
      "service/poor\n",
      "atmo\n",
      "b-place\n",
      "-cardio/fitness\n",
      "titlelessness\n",
      "rooms-walkway\n",
      "super-bowl\n",
      "citytrip\n",
      "shops..\n",
      ".cl\n",
      "hotel‚Ä¶‚Ä¶\n",
      "mid-night\n",
      "positined\n",
      "thwas\n",
      "her3\n",
      "old-much\n",
      "fabuous\n",
      "jubliee\n",
      "◊ú◊ó◊ì◊®◊ô◊ù\n",
      "emoney\n",
      "service„ÄÇgood\n",
      "outrageo\n",
      ".stay\n",
      "bart/muni\n",
      "w/exemplary\n",
      "june/j\n",
      "proffestional\n",
      "downtown/west\n",
      "karnail924\n",
      "weekdn\n",
      "'standard\n",
      "knowledgabl\n",
      "goodlots\n",
      "nights.it\n",
      "beipei\n",
      "disorganizati\n",
      "nyc‚ùóÔ∏è\n",
      "semi-suite\n",
      "preferr\n",
      "muham\n",
      "vity\n",
      "gamers/wsop\n",
      "mcco\n",
      "enrou\n",
      ",hopefully\n",
      "parkingfree\n",
      "sparsley\n",
      ".overall\n",
      "placw\n",
      "enjoyd\n",
      "size/functionality\n",
      ".trust\n",
      "super-comfortable\n",
      "quality/price-\n",
      "wizzle\n",
      "square-art\n",
      "rjl\n",
      "acomidations\n",
      "nycc20\n",
      "perfactly\n",
      "'overbook\n",
      "non-vegas-like\n",
      "qualidade\n",
      "jeanelle\n",
      "anerversary\n",
      "ddddated\n",
      "accettable\n",
      "chihora\n",
      "incr\n",
      "reasonabl\n",
      "moneyg\n",
      "consextr\n",
      "jetblu\n",
      "delovely\n",
      "stayef\n",
      "excedllent\n",
      "recommede\n",
      "bezerkus\n",
      "39t\n",
      "convention-related\n",
      "tri-s\n",
      "shomeone\n",
      "subway-two\n",
      "mayb\n",
      "nevad\n",
      "shaquon\n",
      "panorami\n",
      "bluegre\n",
      "culi\n",
      "double-paid\n",
      "duton\n",
      "ever.graet\n",
      "characteri\n",
      "china-town\n",
      "pillow-gate\n",
      "dissappointed\n",
      "600/night\n",
      "stay..good\n",
      "floorin\n",
      "week..was\n",
      "service‚Ä¶stunning\n",
      "üòÅüòÅüòÅ\n",
      "casions\n",
      "time..even\n",
      "gariana\n",
      "hilton-las\n",
      "excellent-\n",
      "casino.lov\n",
      "cockroac\n",
      "plaza-friendly\n",
      "non-memorable\n",
      "shopp\n",
      "carziness\n",
      "bar-amazing\n",
      "cxfusion\n",
      "ggod\n",
      "everyth\n",
      "missleading\n",
      "midle\n",
      "6oth\n",
      "cathywe\n",
      "conceige\n",
      "go2\n",
      "fabulad\n",
      "roachville\n",
      "absoulutely\n",
      "DG/DGDG-DG/DGDG/DGDG\n",
      "cornell/columbia\n",
      "nyrr\n",
      "frustr\n",
      "probaly\n",
      "fronza\n",
      "inhere\n",
      "vlv\n",
      "fault-\n",
      "sept2016\n",
      "brurnham\n",
      "charshe728\n",
      "kejanah\n",
      "m.m\n",
      "lounge-samir\n",
      "glanc\n",
      "distrik\n",
      "casino..\n",
      "faaaancy\n",
      "strip.free\n",
      "eveyth\n",
      "hotel__centrally\n",
      "honeymoon-nyc\n",
      "***atrocious***\n",
      "salubri\n",
      "austr\n",
      "sssshhhh\n",
      "arragont\n",
      "reques\n",
      "upgarde\n",
      "39/night\n",
      "inn/midtown\n",
      "historical..\n",
      "staff-very\n",
      "tashari\n",
      "w/fri\n",
      "coffeemak\n",
      "inconvienced\n",
      "sheets-one\n",
      "intercontinen\n",
      "bed/breaklfast\n",
      "specatular\n",
      "bellagio..\n",
      "birtday\n",
      "stuc\n",
      "kind.servic\n",
      "manhattan-c\n",
      "DGDG.DG..\n",
      "exeperince\n",
      "antici\n",
      "dosnt\n",
      "srevices\n",
      "reviewgate\n",
      "cjob\n",
      "carlton-the\n",
      "***this\n",
      "flowerstre\n",
      "closerecomm\n",
      "inattenti\n",
      "too-hip\n",
      "-far\n",
      "town-rangers\n",
      "monday-fri\n",
      "imerial\n",
      "sleep..\n",
      "barrosfamily\n",
      "forewarned-\n",
      "location..mins\n",
      "almost-new\n",
      "business/holiday\n",
      "mid-cost\n",
      "inn-manhattan\n",
      "corrid\n",
      "‚Ä≠stayed\n",
      "Èõ¢Â∏Ç‰∏≠ÂøÉpowell\n",
      "prices-quality\n",
      "hotel/airfare\n",
      "peterpow\n",
      "reviewif\n",
      "expriance\n",
      "chna\n",
      "gym/swimming\n",
      "20-ies\n",
      "vaycay\n",
      "grossma\n",
      "own..\n",
      "possiby\n",
      "misplac\n",
      "construction/communication/service\n",
      "adorei\n",
      "omni-chicago\n",
      "horren\n",
      "cons-\n",
      "theeeee\n",
      "like-i\n",
      "travellng\n",
      "girl/baseball\n",
      "dark/dated\n",
      "ubicad\n",
      "flight/hot\n",
      "thurs-s\n",
      "cowor\n",
      "serviceselena\n",
      "tarnishe\n",
      "stars//-will\n",
      "theplaza\n",
      "hugeeeee\n",
      "here..great\n",
      "convien\n",
      "requeste\n",
      "property/resort/location\n",
      "roxs\n",
      "deffernt\n",
      "nuggest\n",
      "turis\n",
      "eaglerider\n",
      "gunny65\n",
      "andpleasure\n",
      "location‚Ä¶..\n",
      "floddy\n",
      "tt-lv\n",
      "-located\n",
      "locl\n",
      "hotel-s\n",
      "5-da\n",
      "1.buffet\n",
      "hollywood-\n",
      "üë∞üèª\n",
      "desigin\n",
      "burni\n",
      "pefrect\n",
      "appoin\n",
      "return-2-ny\n",
      "renewal-family\n",
      "vancou\n",
      "location..a\n",
      "evenin\n",
      "blaydes\n",
      "buildin\n",
      "allowin\n",
      "ungoing\n",
      "renevation\n",
      "..huge\n",
      "amenitie\n",
      "spart\n",
      "flami\n",
      "extraorddinary\n",
      "straff\n",
      "valet/do\n",
      "value/city\n",
      "dirtyüóë\n",
      "collecti\n",
      "appropriat\n",
      "first-c\n",
      "üòçüòçüòõ\n",
      "luxor-cares\n",
      "construc\n",
      "location..renovated\n",
      "loved-\n",
      "space‚Ä¶\n",
      "noisynot\n",
      "serbice\n",
      "lkchari\n",
      "conveinantly\n",
      "one-year-ol\n",
      "europen-style\n",
      "news..\n",
      "softbal\n",
      "thoghtful\n",
      "spaciou\n",
      "todmann\n",
      "fourseasons\n",
      "vegas/ar\n",
      "engrazia\n",
      "hotel‚Äã\n",
      "hospitalit\n",
      "greart\n",
      "frequenc\n",
      "backstree\n",
      "chuwdaury\n",
      "sub-quality\n",
      "inhave\n",
      "staffclean\n",
      "reasonablty\n",
      "square+v\n",
      "here.i\n",
      "time.staff\n",
      "nice..clean\n",
      "kids/teenagers\n",
      "fedexed\n",
      "hotellet\n",
      "hgis\n",
      "location/brand\n",
      "catfished\n",
      "support/service\n",
      "prefection\n",
      "recomendo\n",
      "circus-\n",
      "walkabl\n",
      "pre-book\n",
      "imenza\n",
      "accepte\n",
      "parklane\n",
      "marathon-weekend\n",
      "stay1\n",
      "dism\n",
      "rtiz-carlton\n",
      "location..please\n",
      "kabuki-japantown\n",
      "weedend\n",
      "definelly\n",
      "socrat\n",
      "food/casino\n",
      "great..\n",
      "diabled\n",
      "returnag\n",
      "onsit\n",
      "cleangood\n",
      "reservated\n",
      "bachanal\n",
      "'grande\n",
      "visitors.me\n",
      "lijes\n",
      "results‚Ä¶several\n",
      "poorly-maintained\n",
      "'bait\n",
      "lowel\n",
      "nights..ha\n",
      "holdays\n",
      "in-sho\n",
      "'exclusive\n",
      "opportu\n",
      "renaissance/\n",
      ".beware\n",
      "xcape\n",
      "meadtow\n",
      "excellently-situated\n",
      "nitpicks\n",
      "family/frien\n",
      "days/nights\n",
      "vegas‚Ä¶\n",
      "malandr\n",
      "khiara\n",
      "stay..double\n",
      "matties\n",
      "vallue\n",
      "3-start\n",
      "iroquois-a\n",
      "elevatore\n",
      "charm/modern\n",
      "47w\n",
      "hotel-level\n",
      "conve\n",
      "ÂæàÊñ∞\n",
      "effortle\n",
      "ripp-off\n",
      "week-hilton\n",
      "i15\n",
      "room-\n",
      "opening_gre\n",
      "vety\n",
      "surprise-\n",
      "hilly/upper\n",
      "=strip\n",
      "poorroom\n",
      "phamous\n",
      "onebar\n",
      "shuttle-visibly\n",
      "arazm\n",
      "◊û◊ú◊ï◊ü\n",
      "seaport-nyc\n",
      "iguret\n",
      "whonderful\n",
      "+*+=++++++s√∫per\n",
      "32-floor\n",
      "sverage\n",
      "500usd\n",
      "lokasyon\n",
      "vacation/birthday\n",
      "whoda\n",
      "-suites-las-vegas-airport-\n",
      "underwelmed\n",
      "property.great\n",
      "emorys\n",
      "saisfaction\n",
      "celabrating\n",
      "wnfr\n",
      "marthon\n",
      "vacation.caesars\n",
      "stayedsin\n",
      "location-comfy\n",
      "alexg3bml\n",
      "okcleanliness\n",
      "location‚Äî\n",
      "location-but\n",
      "bggffbjuyfgdfh\n",
      "problem-fixed-asap.friendl\n",
      "angels/glenmore\n",
      "plus-standa\n",
      "evening/late\n",
      "nyc-hilton\n",
      "veryn\n",
      "location/good\n",
      "commitm\n",
      "excelence\n",
      "-absolutely\n",
      "offerin\n",
      "confo\n",
      "washingto\n",
      "10/5ellis\n",
      "up/\n",
      "eldor\n",
      "matil\n",
      "impo\n",
      "DGDG-DGDG/DG/DGDGDGDG\n",
      "new.room\n",
      "centu\n",
      "weeked\n",
      "stayig\n",
      "market/valencia\n",
      "site..\n",
      "baysal\n",
      "casinois\n",
      "scinta\n",
      "facicities\n",
      "priced..but\n",
      "hotel.is.amazing\n",
      "process/contact\n",
      "locationfabulous\n",
      "location-subway\n",
      "locatet\n",
      "more..but\n",
      "bro-trip\n",
      "plazza\n",
      "surprisely\n",
      "dalano\n",
      "hollywood-great\n",
      "kotyuk\n",
      "good..was\n",
      "innacurate\n",
      "pre-warned\n",
      "meservice\n",
      "wow-factor\n",
      "touck\n",
      "bellogio\n",
      "anniversary.the\n",
      "u√±forgettable\n",
      "locationÔºå\n",
      "vip+\n",
      "unmaintaine\n",
      "vanill\n",
      "personabl\n",
      "mile/navy\n",
      "casars\n",
      "hiÃálton\n",
      "nicemodern\n",
      "time.multi\n",
      "pod5\n",
      "staff/centrally\n",
      "‚òÜ\n",
      "'but\n",
      "'roxy\n",
      "spaceship-esque\n",
      "napw\n",
      "-l\n",
      "run/\n",
      "indiff\n",
      "forgetaboutit\n",
      "touch-\n",
      "location/exceptional\n",
      "birthday..\n",
      "undesirabl\n",
      "beustiful\n",
      "pocke\n",
      "day.h\n",
      "..awe\n",
      "ÏúÑÏπòÍ∞Ä\n",
      "6thwatch\n",
      "sincit\n",
      "skydiva1966\n",
      "üòÅ\n",
      "voodooed\n",
      "curtesy\n",
      "line-great\n",
      "royalton-\n",
      "stars-\n",
      "2015.t\n",
      "prosthis\n",
      "mapl\n",
      "zaines\n",
      ".above\n",
      "bestgate\n",
      "piecefull\n",
      "44/day\n",
      "'opt\n",
      "horse-themed\n",
      "fitzpatric\n",
      "wazuzu\n",
      "insatisfation\n",
      "bar/res\n",
      "servicd\n",
      "hotel..amazi\n",
      "hiply\n",
      "buchannan\n",
      ".avoid\n",
      "apreciate\n",
      "sencind\n",
      "-best\n",
      "bulidings\n",
      "/city\n",
      "displeas\n",
      "gatew\n",
      "ballga\n",
      "4yr\n",
      "waffl\n",
      "sun-t\n",
      "shudd\n",
      "enginee\n",
      "johnath\n",
      "valub\n",
      "april-29th\n",
      "ecomda\n",
      "'reserve\n",
      "space-\n",
      "encoun\n",
      "nights.hotel\n",
      "disappointed.they\n",
      "trudgin\n",
      "rebuildin\n",
      "smellly\n",
      ".give\n",
      "inn-\n",
      "locarion\n",
      "warrm\n",
      "nugget/rush\n",
      "mattresse\n",
      "emotio\n",
      "falli\n",
      "stayu\n",
      "aspen-style\n",
      "12.30pm\n",
      "eleva\n",
      "earbed\n",
      "passibl\n",
      "blueman\n",
      "clean.great\n",
      "cleanest..ac\n",
      "center-n\n",
      "poolnice\n",
      "linq..compact\n",
      "vcacation\n",
      "..stay\n",
      "waldorf-asto\n",
      "googlein\n",
      "wounder\n",
      "points-\n",
      "unadvert\n",
      "readi\n",
      "need/want\n",
      "reasturants\n",
      "‚Äãtldr\n",
      "may30-june\n",
      "probl\n",
      "great.room\n",
      "near-best\n",
      "..bravo\n",
      "/doubletree\n",
      "hospi\n",
      "4ni\n",
      "remote-c\n",
      "pool-side\n",
      "ovetnighter\n",
      "midtwn\n",
      "pleasureüëç\n",
      "omega-vegas\n",
      "sissyb\n",
      "breathtaking-\n",
      "143clean\n",
      "vonholman\n",
      "pod39\n",
      "hotle/casino\n",
      "hotel/location/staff\n",
      "vrbo\n",
      "anneversary\n",
      "unprepar\n",
      "multi-da\n",
      "uodate\n",
      "sleeping..\n",
      "brautiful\n",
      "non-pretentious\n",
      "swishotel\n",
      "back-alley\n",
      "cqh\n",
      "contempora\n",
      "spectcular\n",
      "holloywood\n",
      "yobot\n",
      "vacaton\n",
      "martiniq\n",
      "-6pm\n",
      "espre\n",
      "-sweet\n",
      "everythinng\n",
      "gril\n",
      "accomation\n",
      "finall\n",
      "importan\n",
      "stratophere\n",
      "upgrate\n",
      "manhaten\n",
      "room/bathroom\n",
      "‚ù§Ô∏èwe\n",
      "balc\n",
      "re-fur\n",
      "perfirmance\n",
      "truey\n",
      "decior\n",
      "pro/con\n",
      "accomodation/good\n",
      "DGDG/DGDG/-DG\n",
      "hotel-room\n",
      "swissote\n",
      "restaurant/bar\n",
      "staff.clean\n",
      "rooms-great\n",
      "otion\n",
      "lackluster/dated\n",
      "squars\n",
      "further-\n",
      "medvedtskaya\n",
      "stay~\n",
      "275./night\n",
      "üëçüëèüèª\n",
      "lhw\n",
      "avacad\n",
      "lcoatio\n",
      "*wonderful\n",
      "burnha\n",
      "clubqu\n",
      "alittle\n",
      "DGDGDGDGDG.\n",
      "medium-low\n",
      "family.w\n",
      "comoda\n",
      "serviceabl\n",
      "break..\n",
      "abismal\n",
      "chocol\n",
      "hoteel\n",
      "indicatin\n",
      "accomodations/\n",
      "hummmmm\n",
      "h.i\n",
      "waaay\n",
      "2015travel\n",
      "outstand\n",
      "surprizes\n",
      "lionell\n",
      "hotel-sized\n",
      "hotel.customers\n",
      "cuttig\n",
      "lovarion\n",
      "ph2072015\n",
      "agent/industry\n",
      "davines\n",
      "roomsche\n",
      "disrespec\n",
      "clean/spacious/gr\n",
      "mueseum/memorial\n",
      "good.we\n",
      "thursday-h\n",
      "bar/music\n",
      "hotels/\n",
      "suclu\n",
      "wspo\n",
      "great/not\n",
      "passt\n",
      "tc15\n",
      "inn-side\n",
      "byov\n",
      "trup\n",
      "fairfiel\n",
      "gentelness\n",
      "days.ve\n",
      "iannacone\n",
      "anyversary\n",
      "heavie\n",
      "qualiyy\n",
      "quiet..perfectly\n",
      "frien\n",
      "conceptvery\n",
      "teview\n",
      "place.small\n",
      "misf\n",
      "'wowed\n",
      "eco-friendl\n",
      "ebill\n",
      "1suit\n",
      "narsa\n",
      "location/trendy\n",
      "üòç\n",
      "courtyard/magnificent\n",
      "rip-o\n",
      "wrok\n",
      "employee/staff\n",
      "you\\nwo\n",
      "macy's/time\n",
      "32/day\n",
      "bellho\n",
      "2015we\n",
      "gardens-\n",
      "luxorvacatio\n",
      "styke\n",
      "price/benefit\n",
      "clasical\n",
      "clean.would\n",
      "incovenien\n",
      "prett\n",
      "bachelorette/bachelor\n",
      "hotel.have\n",
      "lounge/ba\n",
      "topoftheworld\n",
      "-room\n",
      "neo-\n",
      "staff-nice\n",
      "did't\n",
      "greatg\n",
      "lifts/elevators\n",
      "luxor-a\n",
      "spraye\n",
      "6night\n",
      ".highly\n",
      "starwoods\n",
      "mousecapade\n",
      "perfect..\n",
      "complimentart\n",
      "deligh\n",
      "clean.staff\n",
      "intermin\n",
      "service..some\n",
      "chek-in\n",
      "freee\n",
      "deterrant\n",
      "planne\n",
      "/friend\n",
      "unannoucned\n",
      "+-\n",
      "money..but\n",
      "coffee/t\n",
      "manhattan/ti\n",
      "built/renovated\n",
      "annoyanc\n",
      "service=\n",
      "rooms.fun\n",
      "here-period\n",
      "10:30p\n",
      "meal.wow\n",
      "intert\n",
      ".rip\n",
      "ammenities\n",
      "ovely\n",
      "mid-westerners\n",
      "saje\n",
      "beuatiful\n",
      ".again\n",
      "-deluxe\n",
      "checki\n",
      "bellisimo\n",
      "septfmber2016\n",
      "drinks.at\n",
      "luxing\n",
      ".reques\n",
      "atmosphear\n",
      "ratin\n",
      "üòÉ\n",
      "freestandi\n",
      "neeedd\n",
      "recommendi\n",
      "itfm\n",
      "microtek\n",
      "accolti\n",
      "8/ellis\n",
      "thin..\n",
      "siites\n",
      "hyatt-fiasco\n",
      "no-mo\n",
      "manager-irina\n",
      "6-da\n",
      "rooms/old\n",
      "property-a\n",
      "steali\n",
      "javis\n",
      "housekeepi\n",
      "hotel‚Äîwith\n",
      "functio\n",
      "ivrecently\n",
      "esperience\n",
      "favourate\n",
      "colleage\n",
      "nice..updated..clean\n",
      "district\\midtown\n",
      "again..great\n",
      "stay-cati\n",
      "friendly.long\n",
      "location/funky\n",
      "expereinced\n",
      "bsuy\n",
      "casin\n",
      "privacy‚Ä¶\n",
      "availble\n",
      "hotel.row\n",
      "w/extras\n",
      "attrac\n",
      ".super\n",
      "newyork=fun=row\n",
      "south..get\n",
      "downill\n",
      "city..per\n",
      "business/convention\n",
      "district-seap\n",
      "weekend-\n",
      "disappointed.terrible\n",
      "location/clean\n",
      ".loca\n",
      "architectu\n",
      "business/shopping\n",
      "hourendous\n",
      "friend..\n",
      "child-free\n",
      "mlmeyer\n",
      "connection-\n",
      "thursdahy\n",
      "destination-\n",
      "respons\n",
      "grandkid\n",
      "wasent\n",
      "conferenceh\n",
      "runed\n",
      "lanet\n",
      "well-staff\n",
      "venitian\n",
      "pros.pools\n",
      "Ìò∏ÌÖîÏùÄ\n",
      "pchotel\n",
      "sparklin\n",
      "julyvery\n",
      "rustl\n",
      "pre-op\n",
      "beginni\n",
      "location.\n",
      "belevedere\n",
      "—Å–Ω–∞\n",
      "airw\n",
      "resverd\n",
      "shape..\n",
      "march-madness\n",
      "televis\n",
      "slots3\n",
      "thrm\n",
      "ridivulo\n",
      "beverag\n",
      "amment\n",
      "bellagios\n",
      "ÈÇÑ‰∏çÈåØ\n",
      "-*\n",
      "price.f\n",
      "beds=sore\n",
      "properti\n",
      "located/newly\n",
      "neighbourhoo\n",
      "bally-hoo\n",
      "elabor\n",
      "stay..ver\n",
      "hhono\n",
      "promesses\n",
      "dejligt\n",
      "hotel-overpriced\n",
      "ever-smell\n",
      "staayed\n",
      "first‚Äî\n",
      "tenderlion\n",
      "inn-north\n",
      "clean/nice\n",
      "stayv\n",
      "off-t\n",
      "hotel/dining\n",
      "'happening\n",
      "accomodation=large\n",
      "chicagp\n",
      "view/warm\n",
      "visut\n",
      "goodw\n",
      "hamta\n",
      "nobu.gr\n",
      "sfgiants\n",
      "DG+++++\n",
      "atroc\n",
      "winga\n",
      "concierg\n",
      "guestho\n",
      "waldrof\n",
      "alwasy\n",
      "i‚ù§hy36\n",
      "feacal\n",
      "crafte\n",
      "tgiving\n",
      "vegas-9/2015\n",
      "unless/until\n",
      "dingey\n",
      "greatritz\n",
      "artwor\n",
      "houskee\n",
      "alkurdi\n",
      "repeat/regular\n",
      "3:45am\n",
      "misunderst\n",
      "sumerize\n",
      "spectaculous\n",
      "comffy\n",
      "unhyatt\n",
      "nicknam\n",
      "experiemce\n",
      "late/ea\n",
      "venetian/\n",
      ".excelle\n",
      "fantas\n",
      "hotel‚Ä¶fi\n",
      "roomsdamp\n",
      "fromsc\n",
      "abstv\n",
      "sarvie\n",
      "strip-howev\n",
      "omfortable\n",
      "ipane\n",
      "well-t\n",
      "amenaties\n",
      "view-amazing\n",
      "regardles\n",
      "location-mediocre\n",
      "geattimes\n",
      "bedroom/3\n",
      "understaf\n",
      "dissaponte\n",
      "-keven\n",
      "wauw\n",
      "fantsastic\n",
      "Ë¶™Âàá„Å´‰∫àÁ¥Ñ„Åó„Å¶„Åè„Çå„Åæ„Åó„Åü„ÄÇ\n",
      "DGDG/DG/DGDG-DGDG/DGDG/DGDG\n",
      "price-to-quality\n",
      "fffth\n",
      "locationin\n",
      "bave\n",
      "location-staff-room\n",
      "himss18\n",
      "loct\n",
      "stay/vis\n",
      "agefurnitur\n",
      "wowww\n",
      "occaision\n",
      ".excellent\n",
      "jovanne\n",
      "impressed/wo\n",
      "conveniebt\n",
      "suite/\n",
      "property/hotel/casino\n",
      "buiness\n",
      "behal\n",
      "califor\n",
      "theater-goer\n",
      "hotel-terrible\n",
      "property/wonderful\n",
      "kickass\n",
      "furniced\n",
      "constantl\n",
      "touch‚òπ\n",
      "tea/bar\n",
      "marijuana-like\n",
      "ipan\n",
      "why‚Ä¶\n",
      "avergage\n",
      "disaster-\n",
      "nenetian\n",
      "multi-billio\n",
      ".still\n",
      "staff-all-ve\n",
      "bed/breakfast\n",
      "hundsamely\n",
      "palace/hotel\n",
      "be.the\n",
      "-direct\n",
      "again.clean\n",
      "5night\n",
      "goodexample\n",
      "hakkasan\n",
      "refurbed\n",
      "baaaaack\n",
      "friend/bda\n",
      "mloney\n",
      "continuousl\n",
      "neighboorhood\n",
      "soundproofin\n",
      "holloween\n",
      "limitat\n",
      "lisa/sportsbook\n",
      "music/da\n",
      "perfectly-locat\n",
      "neighbhoorhood\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atentive\n",
      "hiphospitality\n",
      "fromjapan\n",
      "editi\n",
      "geweldig\n",
      "satified\n",
      "help.we\n",
      "accessibity\n",
      "slummy\n",
      "nice.nice\n",
      "vegal\n",
      "vegasstill\n",
      "seapor\n",
      "room/hotel\n",
      "fastiletion\n",
      "'once\n",
      "la-nyc\n",
      "2nd-9th\n",
      "desk/\n",
      "gooood\n",
      ".with\n",
      "wellcomy\n",
      "connecti\n",
      ".every\n",
      "words-\n",
      "califlyer\n",
      "sohogrand\n",
      "knicke\n",
      "ex-ce-llent\n",
      "‚òÜ‚òÜ\n",
      "vegas‚Ä¶..\n",
      "recepction\n",
      "3yrs\n",
      "perfectgood\n",
      "hect\n",
      "homegreat\n",
      "soend\n",
      "layouut\n",
      "maximun\n",
      "hilton/ha\n",
      "devlearn\n",
      "beslt\n",
      "service.ruined\n",
      ".walk\n",
      "◊î◊û◊ô◊ß◊ï◊ù\n",
      "excellent/awesome\n",
      "noticiable\n",
      "personnaly\n",
      "saticfied\n",
      "below-le\n",
      "lomitola\n",
      "delano-\n",
      "a2y\n",
      "walls/unclean\n",
      "yauri\n",
      "vesgas\n",
      "hvac/food\n",
      "showerhea\n",
      "germ-a-phobe\n",
      "redort\n",
      "amaz\n",
      "arty/boutique\n",
      "dodnt\n",
      "bathroom-too\n",
      "islamd\n",
      "modern/amazing\n",
      "justs\n",
      "..apparent\n",
      "nights.had\n",
      "dissapoi\n",
      "avenue/mag\n",
      "y/o\n",
      "vegas-style\n",
      "seatt\n",
      "comfyist\n",
      "keilan\n",
      "maintence\n",
      "cooles\n",
      "cruisenan\n",
      "kimberlicious\n",
      "modern-v\n",
      "situati\n",
      "i‚ù§ny\n",
      "ecolodge\n",
      "w.o\n",
      "intedibly\n",
      "spoll\n",
      "mgm=ymca\n",
      "hotel..good\n",
      "DGDGDGDG-DGDG/DGDG~\n",
      "elevador\n",
      "jeneaha\n",
      "midtown/hell\n",
      "soperfect‚Ñ¢\n",
      "argonautthis\n",
      "spectular\n",
      "rassisson\n",
      "muhamma\n",
      "chees\n",
      "location-away\n",
      "somehwat\n",
      "onenightstaycation\n",
      "hotel-convenient\n",
      "napa/sonoma/sanfrancisco\n",
      "engagin\n",
      "locationjr\n",
      "**DG**\n",
      "bmcm\n",
      "located.price\n",
      "hotw\n",
      "hoppy71\n",
      "confidentl\n",
      "a*\n",
      "bepo\n",
      "doormanaa\n",
      "now-favorite\n",
      "reception/front\n",
      "ovrt\n",
      "stripview\n",
      "resort-best\n",
      "o0n\n",
      "swissy\n",
      "mandalayslayed\n",
      "emporer\n",
      "i-90/94\n",
      "ŸÅŸÜÿØŸÇ\n",
      "pelot\n",
      "service/rooms\n",
      "nicve\n",
      "pillowtop\n",
      "floorclea\n",
      "exhaus\n",
      "anypla\n",
      "extermely\n",
      "amenities/level\n",
      "kellams\n",
      ".watch\n",
      "hotel..less\n",
      "ny-ny\n",
      "slots-olde\n",
      "dreamtrip\n",
      "..int\n",
      "embarcader\n",
      "-oct\n",
      "unatt\n",
      "room647overlook\n",
      "jenell\n",
      "magnifacent\n",
      "exqusite\n",
      "'use\n",
      "pros*acknowledgment\n",
      "tbbmd\n",
      "enough-\n",
      "janeay\n",
      "lavona\n",
      "critiqu\n",
      "festivit\n",
      "bit/a\n",
      "located-good\n",
      "fineral\n",
      "witho\n",
      "overnighter\n",
      "on4-1-\n",
      "clean-nice\n",
      "streetview\n",
      "nighthotel\n",
      "membershi\n",
      "challengi\n",
      "waaaaay\n",
      "terriifc\n",
      "food/se\n",
      "overall.very\n",
      "..left\n",
      "ufc217\n",
      "father-sons\n",
      "novtel\n",
      "informat\n",
      "amme\n",
      "nycwff\n",
      "nights.2\n",
      "DG/DG/DGDG\n",
      "crow√±e\n",
      "ever.bi\n",
      "poolplayers\n",
      "staff/hotel\n",
      "strongl\n",
      "*great*\n",
      "–∫–æ—Ä–æ—Ç–∫–∏–π\n",
      "inyb\n",
      "it..th\n",
      "recomme\n",
      "fab48\n",
      "graciou\n",
      "january.p\n",
      "onelive\n",
      "godfrey.w\n",
      "nostalg\n",
      "service/people\n",
      "facillities\n",
      "suite-great\n",
      "vacation-majestic\n",
      "artsy-feel\n",
      "2-qu\n",
      "ac/heat\n",
      "scenary\n",
      "events/etc\n",
      "check-in/housekeepng\n",
      "locatgion\n",
      "michiga\n",
      "blks\n",
      "euro-style\n",
      "0915hrs\n",
      "raddest\n",
      "stylish/modern\n",
      "disrepai\n",
      "locationan\n",
      "proport\n",
      "personaliz\n",
      "rockation\n",
      "convenieint\n",
      "smaaaaal\n",
      "romanc\n",
      "officia\n",
      "advertising-this\n",
      "betw\n",
      "stewar\n",
      "fairmonf\n",
      "palazzo.the\n",
      "DG‚òÜ\n",
      "ashleys\n",
      "..my\n",
      "5yo\n",
      "hygene\n",
      "desapointin\n",
      "stripclose\n",
      "diedra\n",
      "thanksgiviving\n",
      "positives-well\n",
      "'hands\n",
      "cigere\n",
      "..home\n",
      "octobe\n",
      "unprofess\n",
      "melbo\n",
      "room.everyt\n",
      "overprices\n",
      "douchy\n",
      "overpricedpool\n",
      "comfort=complacent\n",
      "w42\n",
      ".remodeled\n",
      "into..\n",
      "lescota\n",
      "all.my\n",
      "üò°üò°\n",
      "-rooms\n",
      "'marriott\n",
      "attention-hotel\n",
      "compaints\n",
      "bedgood\n",
      "vegas2018\n",
      "tresure\n",
      "freemontstreet\n",
      "boutique-h√¥tel\n",
      "quiet-only\n",
      "ok..bed\n",
      "ataj\n",
      "here.big\n",
      "breakfeast\n",
      "busband\n",
      "chinatown/financial\n",
      "christmac\n",
      "out..d\n",
      "guyspretty\n",
      "suite/room\n",
      "chior\n",
      "not-so-quiet\n",
      "businesstrip\n",
      "pre-digital\n",
      "say‚Ä¶\n",
      "2.there\n",
      "i-spa\n",
      "mamuca\n",
      "nysbf\n",
      "somevwork\n",
      "front-des\n",
      "4seasons\n",
      "..dont\n",
      "gyde\n",
      "casino/convention\n",
      "noisy/off-character\n",
      "unev\n",
      "aerie-like\n",
      "non-refurbished\n",
      "baseb\n",
      "eh..\n",
      "swim-loving\n",
      "family/teen\n",
      "nobhill\n",
      "ces2\n",
      "kleinfelds\n",
      "arch-ingly\n",
      "Âè≤‰∏äÊúÄ‰Ωé„ÅÆ„Éõ„ÉÜ„É´„Åß„Åó„Åü„ÄÇ\n",
      "sabree\n",
      "vaky\n",
      "begin-\n",
      "buzzli\n",
      "hotel-good\n",
      "19-26th\n",
      "internatio\n",
      "generlly\n",
      "43r\n",
      "tyred\n",
      "surprisewonderful\n",
      "interior-\n",
      "7/1/18room\n",
      "cost2\n",
      "417keven\n",
      "competiti\n",
      "awsy\n",
      "slickis\n",
      "one.night\n",
      "member/owner\n",
      "hotel/rooms/location\n",
      "sonice\n",
      "increditable\n",
      "hotel/hos\n",
      "feelings..\n",
      "ceris\n",
      "location/classy\n",
      "james-roofdeck\n",
      "ÏÉàÎ≤ΩÏóê\n",
      "clogg\n",
      "omfg\n",
      "old/expensive\n",
      "lasvegas_oct\n",
      ".one\n",
      "balacony\n",
      "fhj\n",
      "hotel..live\n",
      "100deposit\n",
      "non-casion\n",
      "conforta\n",
      "tooftop\n",
      "thirtynineth\n",
      "birthdayweek\n",
      "carlevale\n",
      "depos\n",
      "resott\n",
      "location/fun/vibe\n",
      "customer/absent\n",
      "not-over-the-top\n",
      "voutique\n",
      "wouldnstay\n",
      ".beautiful\n",
      "feesüëéüèª\n",
      "yikes-\n",
      "nycstay\n",
      "brekfast\n",
      "birhday\n",
      "yyyyyaasss\n",
      "dunge\n",
      "..because\n",
      "harah\n",
      "legget\n",
      "qsen\n",
      "maangement\n",
      "1130am\n",
      "check-\n",
      "..this\n",
      "money..\n",
      "gratitu\n",
      "traux\n",
      "-fight\n",
      "yoursel\n",
      "vakay\n",
      "swanky/upscale\n",
      "extorcinate\n",
      "j-lo\n",
      "magnifice\n",
      "mr.clean\n",
      "wooow\n",
      "triphound\n",
      "club/hotel\n",
      "masq\n",
      "nightttt\n",
      "marylyn\n",
      "low-hassle\n",
      "lost-found\n",
      "terrrible\n",
      "ballys.the\n",
      "servive\n",
      "..got\n",
      "excuisite\n",
      "hoorayyyy\n",
      "portf\n",
      "abberation\n",
      "must-do\n",
      "overcrowde\n",
      "hollyhood\n",
      "21sf\n",
      "avenuei\n",
      "unbeliveable\n",
      "sorta-hidden\n",
      "martar\n",
      "manag\n",
      "appearan\n",
      "day-\n",
      "weddingstayobtaining\n",
      "refin\n",
      "chrysle\n",
      "noising\n",
      "central.you\n",
      "less-than-positi\n",
      "birthday/cubs\n",
      "time/great\n",
      "chillcation\n",
      "smallno\n",
      "ways..\n",
      "herehote\n",
      "üé±\n",
      "transportat\n",
      "fiolla\n",
      "'drilling\n",
      "stayre\n",
      "wireles\n",
      "staff-really\n",
      "manager/loud\n",
      "impression‚Ä¶\n",
      "timegreat\n",
      "expected-\n",
      "classüôåüèª\n",
      "javitz\n",
      "mid-r\n",
      "location..old\n",
      "cessars\n",
      "me-well\n",
      "acension\n",
      "roundabou\n",
      "pleease\n",
      "servicw\n",
      "visit.sunday\n",
      "undewhelmed\n",
      "cleanloca\n",
      "outpos\n",
      "relva\n",
      "westgat\n",
      "swindeled\n",
      "‚ù£‚ù£‚ù£\n",
      "*just\n",
      "central..lots\n",
      "sofisticated\n",
      "starsfull\n",
      "ralfs\n",
      "downtown/tribeca\n",
      "stayes\n",
      "comfurtable\n",
      "adviso\n",
      "refurbi\n",
      "biggish\n",
      "ciity\n",
      "anoth\n",
      "place.everybody\n",
      ".forget\n",
      "-poor\n",
      "disappoinying\n",
      "ralp\n",
      "wrigleyvill\n",
      "nascac\n",
      "pizzaz-\n",
      "qulity\n",
      "cozzy\n",
      "stay.it\n",
      "well-before\n",
      "staff.cle\n",
      "hilton/union\n",
      "nfr/first\n",
      "hotelth\n",
      "hotelgood\n",
      "'go\n",
      "laura-ann\n",
      "builinding\n",
      "getawayüòÑüòÑ\n",
      "memember\n",
      ".sometimes\n",
      "exagge\n",
      "spacious.e\n",
      "neithe\n",
      "ritz-c\n",
      "wyndom\n",
      "=perfect\n",
      "vecation\n",
      "modern=equiped\n",
      "kadeney\n",
      "6:45pm\n",
      "obviousl\n",
      "smyler\n",
      "acomadating\n",
      "grifters/people\n",
      "management/staff\n",
      "üçî\n",
      "locationll\n",
      "thompso\n",
      "ergotherapeute\n",
      "aperence\n",
      "mrs.leon\n",
      "openion\n",
      "judgmen\n",
      "views-\n",
      "furature\n",
      "prsonal\n",
      "washin\n",
      "zepplin\n",
      "uncommunicatiev\n",
      "belonings\n",
      "adaptes\n",
      "renamed/remodeled\n",
      "staff/employees\n",
      "reasonaable\n",
      "workers..do\n",
      "aroumd\n",
      "rooms.good\n",
      "breakfadt\n",
      "discoverv\n",
      "regristration\n",
      "wondful\n",
      "upgr\n",
      "hotelvery\n",
      "riomg\n",
      "nytsh\n",
      "cesears\n",
      "horrile\n",
      "soon..\n",
      "after-service\n",
      "yay‚Äîno\n",
      "jahaida\n",
      "spot/good\n",
      "notwith\n",
      "sixtysohojustok\n",
      "expectati\n",
      "musty-just\n",
      "gc-\n",
      "out-and-about\n",
      "sights/sou\n",
      "'petite\n",
      "gym/wifi/breakfast\n",
      "minuses=just\n",
      "nights.the\n",
      "coolist\n",
      "back.mrs\n",
      "times-square\n",
      "themse\n",
      "confessi\n",
      "spectualr\n",
      "grounds/furnishing\n",
      "gramsey\n",
      "sun-\n",
      "üöï\n",
      "hapoyb\n",
      "adertised\n",
      "price/\n",
      "trabro\n",
      "salespeo\n",
      "double-booked\n",
      "super..a\n",
      "stars..\n",
      "wi-\n",
      "curb-side\n",
      "honeymoon‚ù§Ô∏è\n",
      "-52n\n",
      "clean..the\n",
      "aniversary‚ù§Ô∏è‚ù§Ô∏è‚ù§Ô∏è\n",
      "so-ho\n",
      "tolleen\n",
      "DG/DGDG-DG/DGDG-DGDGDGDG\n",
      "meh-would\n",
      "impressedisent\n",
      "seei\n",
      "hotelduper\n",
      "attemp\n",
      "dothe\n",
      "misconceiving\n",
      "presido\n",
      "popul\n",
      "13th-18th\n",
      "fom/it\n",
      "location-very\n",
      "wbwc\n",
      "bset\n",
      "emabssy\n",
      "fashio\n",
      "venetta\n",
      "wond\n",
      "hivery\n",
      "achanging\n",
      "concienient\n",
      "/cooling\n",
      "hotel-type\n",
      "unautherized\n",
      "hotel-las\n",
      "hotel..especially\n",
      "vonevntion\n",
      "toilet-\n",
      "outw\n",
      "lobby/atrium\n",
      "bessb\n",
      "cool/funky\n",
      "aproblem\n",
      "time.hotel\n",
      "cesarspalace\n",
      "hugo-\n",
      "hotel/wonderful\n",
      "2018reserved\n",
      "usq\n",
      "goodx\n",
      "good/some\n",
      "awesome99\n",
      "n-e-v-e-r\n",
      "summaris\n",
      "place.with\n",
      "bad-not\n",
      "30-floor\n",
      "hotel‚ù§Ô∏è\n",
      "time/party\n",
      "sls-\n",
      "summariz\n",
      ".others\n",
      "griendly\n",
      "bettee\n",
      "purp\n",
      "comy\n",
      "+free\n",
      "moderat\n",
      "paims\n",
      "birfday\n",
      "redb\n",
      "non-smoking/no-casino\n",
      "ÎèåÏïÑÎã§ÎÖÄÎèÑ\n",
      "beds-cant\n",
      "unsatisf\n",
      "anniversa\n",
      "paddie\n",
      "nightl\n",
      "back.from\n",
      "valtentines\n",
      "conviniece\n",
      "non-renovated\n",
      "didint\n",
      "bi-modal\n",
      "newly-re\n",
      "personal/leisure\n",
      "traveloc\n",
      "6month\n",
      "memorabl\n",
      "momstay\n",
      "maint\n",
      "-for\n",
      "vagab\n",
      "deteriated\n",
      "suprebook\n",
      "rooms.p\n",
      ".attraction\n",
      "+.big\n",
      "again..\n",
      "miscommunition\n",
      "excelebt\n",
      "refund..\n",
      "locoation\n",
      "complimen\n",
      "firegramma\n",
      "besr\n",
      "service/4\n",
      "hotel/pet\n",
      "shelter-i\n",
      ".might\n",
      "jayzz1992\n",
      "location/wonderful\n",
      "renocation\n",
      "experinence\n",
      "pre-nye\n",
      "pretentiousn\n",
      "nught\n",
      "pricey.good\n",
      "quaint-well\n",
      "relaxe\n",
      "furthe\n",
      "symposium-conference\n",
      "ok.excel\n",
      "conveniencecons\n",
      "top-\n",
      "decent-some\n",
      "unsati\n",
      "e.s\n",
      "double-h\n",
      "-top\n",
      "hotel/staff\n",
      "view/lincoln\n",
      "nayeli\n",
      "quartes\n",
      "locaction\n",
      "clean..and\n",
      "happene\n",
      "urin\n",
      "francisco-\n",
      "marvelle\n",
      "epitomy\n",
      "..fastest\n",
      "ammazing\n",
      "technolog\n",
      "over-designed\n",
      "famili\n",
      "stripstaff\n",
      "rooms\\nhuman\n",
      "woth\n",
      "feel..but\n",
      "goldennugget\n",
      "dis-astor\n",
      "exceri\n",
      "cha'ching\n",
      "tho~\n",
      "sumir\n",
      "-price\n",
      "fairmont/accorhotels\n",
      "trump-worthy\n",
      "cleanleness\n",
      "knowledgab\n",
      "nugget-las\n",
      ".decided\n",
      "stuffgreat\n",
      "location/spacious\n",
      "negati\n",
      "subjectiv\n",
      "policie\n",
      "that.i\n",
      "ariaaaaaa\n",
      "easi\n",
      "facin\n",
      "pre-review\n",
      "old\\nsons\n",
      "-check\n",
      "/unwelcoming\n",
      "wfron\n",
      "oh-so-delicious\n",
      "shabb\n",
      ",we\n",
      "intercontin\n",
      "anniversay/christmas\n",
      "staywalking\n",
      "thingsthe\n",
      "contentntal\n",
      "newyorkian\n",
      "neverhyatt\n",
      "francisco-walk\n",
      "frineds\n",
      "wallstre\n",
      "host-\n",
      "physi\n",
      "awesomefood\n",
      "r.n\n",
      "food/drin\n",
      "spent4\n",
      "bibliophi\n",
      "notlih\n",
      "mybest\n",
      "disclosu\n",
      "„ÅØÂøÖË¶ã\n",
      "sprucin\n",
      "blindboys\n",
      ".1.oo\n",
      "intercontental\n",
      ".in\n",
      "like:1.\n",
      "departur\n",
      "supercity\n",
      "britn\n",
      "prpoerty\n",
      "resplandant\n",
      "apology.avoid\n",
      "req\n",
      "gerat\n",
      "helpf\n",
      "'little\n",
      "trrp\n",
      "westlodge\n",
      "properpty\n",
      "fkamingo\n",
      "hogo\n",
      "location.clean\n",
      "flig\n",
      "despair..\n",
      "qualtiy\n",
      "boutique-st\n",
      "japenese\n",
      "minimilist\n",
      "19my\n",
      "descri\n",
      "samoia\n",
      "caesarsstyle\n",
      "disgr\n",
      "service/room/location\n",
      "awesomesauce\n",
      "smills\n",
      "city/ramada\n",
      "arrrival\n",
      "okay.the\n",
      "antiquate\n",
      "locatedd\n",
      "hotel-service\n",
      "nightlite\n",
      "older-sty\n",
      "harrarah\n",
      "mirage-average\n",
      "tmat\n",
      ".cant\n",
      "runaroud\n",
      "tcob\n",
      "◊ñ◊ï◊í◊ô◊™\n",
      "price-beware\n",
      "budget-contrained\n",
      "semi-last\n",
      "rooms..\n",
      "locatotion\n",
      "i¬¥d\n",
      "non-las-vegas\n",
      "isvery\n",
      "all-sui\n",
      "belford..\n",
      "misreprese\n",
      "up-town\n",
      "runned\n",
      "hubby-unit\n",
      "cleanness/aw\n",
      "stay-quie\n",
      "nights.to\n",
      "service-with\n",
      "ü§ë\n",
      "flashcoin.io\n",
      "w-a\n",
      "‚ûï\n",
      "üò©üî´\n",
      "loewes\n",
      "location-bad\n",
      "tourist/\n",
      "flimingo\n",
      "holleyood\n",
      "multi-centre\n",
      "yasss\n",
      "compell\n",
      "marqis\n",
      "citigold\n",
      "topmarks\n",
      "pool=\n",
      "realit\n",
      "orbtiz\n",
      "decorat\n",
      "renommended\n",
      "f.a.b.u.l.o.u.s\n",
      "infras\n",
      "skypool\n",
      "strip.good\n",
      "hoote\n",
      "usded\n",
      "distrance\n",
      "linqed\n",
      "deliciou\n",
      "dreamf\n",
      "practic\n",
      "descr\n",
      "fundementally\n",
      "hotel/nightlife\n",
      "canthink\n",
      "miorage\n",
      "w/hyatt\n",
      "straordinario\n",
      "unexpectantly\n",
      "lauxeriouse\n",
      "one-nighter\n",
      "un-marriott\n",
      "superbook.eas\n",
      "uodated\n",
      "hospotality\n",
      "short-staffed\n",
      "bathrooms-\n",
      "sord\n",
      "jeffer\n",
      "resturant\n",
      "excellency‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è\n",
      "theatre-goer\n",
      "weren¬¥t\n",
      "locatiin\n",
      "interncontinental\n",
      "squeekiest\n",
      "removations\n",
      "stay-over\n",
      "bag-\n",
      "everyw\n",
      "gemof\n",
      "nates\n",
      "100years\n",
      "-at\n",
      "12:30pm\n",
      "pit-st\n",
      "vegasl\n",
      "districe\n",
      "seigels\n",
      "monrail\n",
      "atrio\n",
      "royals/mets\n",
      ".actually\n",
      "'ghetto\n",
      ".hotel\n",
      "service/atmosphere\n",
      "shell/\n",
      "city-\n",
      "ulgy\n",
      "hgvacationclub\n",
      "traveld\n",
      "‚ô•Ô∏èof\n",
      "maddenin\n",
      "overpacked\n",
      "hotel/buffet/comps\n",
      "'old\n",
      "recommanded\n",
      "teen/tweens\n",
      "hiltontimeshare\n",
      "expensi\n",
      "statemen\n",
      "no-no-no\n",
      "..brillian\n",
      "findi\n",
      "people/building\n",
      "outst\n",
      "travelodg\n",
      "impoli\n",
      "super-clean\n",
      "üòï\n",
      "reun\n",
      "spacey.a\n",
      "surprise/\n",
      "service+\n",
      "..re\n",
      "promi\n",
      ".budget\n",
      "nylo-unexpected\n",
      "complaicent\n",
      "thorou\n",
      "cahos\n",
      "casin√≤\n",
      "earthfriendly\n",
      "'the\n",
      "unimpres\n",
      "schedul\n",
      "wantt\n",
      "ËâØ„Åã„Å£„Åü„Å®„Åì„ÇçÔºöÈ´òÁ¥öÊÑü„ÅÇ„Åµ„Çå„Çã„Éõ„ÉÜ„É´ÂÜÖË£Ö„ÅÆË£ÖÈ£æ„ÅåÁ¥†Êïµ„Åß„Åó„Åü„ÄÇ„Å®„Å´„Åã„Åè‰Ωï\n",
      "dauntin\n",
      "unexpectedl\n",
      "wante\n",
      "wrap-a\n",
      "fantastic.excellen\n",
      "licoln\n",
      "chicago-sout\n",
      "beforeroom\n",
      "tahite\n",
      "observan\n",
      "magice\n",
      "jyou\n",
      "üëéüèæ\n",
      "perectly\n",
      "hotel..what\n",
      "spaciuos\n",
      "nyc-times\n",
      "plesaure\n",
      "chawal\n",
      "'cool\n",
      "silvertn\n",
      "facililties\n",
      "terrific/facility\n",
      "town/bo\n",
      "complimenta\n",
      "murrray\n",
      "staffh\n",
      "industr\n",
      "customer-\n",
      "2015.the\n",
      "asalway\n",
      "doubltetree\n",
      "gdaughters\n",
      "hiltonh\n",
      "strip..room\n",
      "struggl\n",
      "2adults\n",
      "¬£DGDGDGDG\n",
      "experience/reliable\n",
      "upgradede\n",
      "non-techie\n",
      "toddlerrific\n",
      "nokka\n",
      "arrival/chec\n",
      "‚ú≥Ô∏è‚ú≥Ô∏è‚ú≥Ô∏è‚ú≥Ô∏è‚ú≥Ô∏è\n",
      "silverton/bass\n",
      "personality-chic\n",
      "‚Ä¢.hotel\n",
      "nastalgic\n",
      "renovation..\n",
      "edisson\n",
      "staydream\n",
      "üòÅüëç\n",
      "comfortable-\n",
      "sights/subway\n",
      "startmy\n",
      "'row\n",
      "confy\n",
      "hospitality..wonderful\n",
      "ny.if\n",
      "spriti\n",
      "better.the\n",
      "aspec\n",
      "desp\n",
      "donna-\n",
      "nightsp\n",
      "good-room\n",
      "e-gypped\n",
      "6-c\n",
      "c.s\n",
      "quaters\n",
      "'clean\n",
      "unpleasure\n",
      "awful-\n",
      "carlo/\n",
      "weddinf\n",
      "didsapointm\n",
      "spa.djanel\n",
      "celebrati\n",
      "energet\n",
      "tkd\n",
      "blu-high\n",
      "tendernob\n",
      "lovley\n",
      "mileston\n",
      "neighb\n",
      "üç∏\n",
      "effeciency\n",
      "stuffyÔºåand\n",
      "show/retail\n",
      "elevators¬°\n",
      "occupan\n",
      "shabby-shabby\n",
      "comfortabele\n",
      "additiona\n",
      "benjaminfun\n",
      "lisseth\n",
      "twice-\n",
      "fuvk**g\n",
      "hotel/great\n",
      "professional/hel\n",
      "poola\n",
      "place.been\n",
      "brightl\n",
      "illinoi\n",
      "dissatisfactory\n",
      "joy-traveller\n",
      "inculde\n",
      "bedd\n",
      "w/ba\n",
      "impersona\n",
      "basebal\n",
      "overhau\n",
      "nyc/redux\n",
      "ritz-level\n",
      "hiostorical\n",
      "7ave\n",
      "urgh\n",
      "reccommended\n",
      "wowzle\n",
      "room/super\n",
      "6:40am\n",
      "'in\n",
      "3+great\n",
      "awhile-\n",
      "satitsfied\n",
      "veges\n",
      "-overcharged\n",
      "wahied\n",
      "people-dumb\n",
      "romorous\n",
      "exroom\n",
      "misfort\n",
      "lasvegas.com\n",
      "review1.0\n",
      "nyki\n",
      "shopping/din\n",
      "w/family\n",
      "hamilto\n",
      "hicago\n",
      "anniversary/concert\n",
      "accessibi\n",
      "4rd\n",
      "godfr\n",
      "room-helpful\n",
      "ÔøΩÔøΩ\n",
      "strengh\n",
      "unlcean\n",
      "hamptonvegas\n",
      "dcenteal\n",
      "exculibur\n",
      "bathto\n",
      "vacaa\n",
      "casuno\n",
      "„Ç∞„É©„É≥„Éâ„Çµ„Éº„ÇØ„É´„ÉÑ„Ç¢„Éº„ÅÆÂâçÊ≥ä„Å´\n",
      "hometow\n",
      "like-a\n",
      "con:1\n",
      "helllo\n",
      "*writing\n",
      "slippersshower\n",
      "marijua\n",
      "awesome..mostly\n",
      "funkyhotel\n",
      "hotel/high\n",
      "wonderware\n",
      "better‚Ä¶\n",
      "conditioner/foul\n",
      "-ti\n",
      "wwalking\n",
      "room-nicely\n",
      "vegasny\n",
      "funfunfun\n",
      "baggae\n",
      "hill/midtown\n",
      "ultraconvenient\n",
      "pleaseant\n",
      "tourist-ville\n",
      "atmospherer\n",
      "sub-level\n",
      "changed-great\n",
      "..rocks\n",
      "hotel.it\n",
      "property/location/quality\n",
      "station/madison\n",
      "unsleepable\n",
      "approfittatori\n",
      "paqioua\n",
      "sorryüíÅüèæ‚Äç‚ôÄÔ∏è\n",
      "unwi\n",
      "kkimpton\n",
      "insulti\n",
      "view.s\n",
      "start.oh\n",
      "lewci\n",
      "acous\n",
      "away-would\n",
      ".of\n",
      "veaw\n",
      "rediculues\n",
      "three-nigh\n",
      "espr\n",
      "reallyif\n",
      "participat\n",
      "milenorth\n",
      "goldlen\n",
      "casino-\n",
      "babsfromchicago\n",
      "roosevent\n",
      "value/noisy\n",
      ".ever\n",
      "value-driven\n",
      "firts\n",
      "paaashawwwhh\n",
      "times‚Äã\n",
      "street‚Ä¶great\n",
      "-daugh\n",
      "fabulous.great\n",
      "man-oh\n",
      "hotel*\n",
      "located/\n",
      "convenient-great\n",
      "mice/rodents\n",
      "nyc-chelsea\n",
      "expence\n",
      "friendly.room\n",
      "vacatoon\n",
      "pro's-\n",
      "tv/projec\n",
      "training/vacation\n",
      "laborday\n",
      "26k\n",
      "25-29th\n",
      "sanctuary.serv\n",
      "critique-pro\n",
      "experience.every\n",
      "fams\n",
      "‚Äãnotch\n",
      "management-\n",
      "stevend\n",
      "fremon\n",
      "pressu\n",
      "gondolie\n",
      "17/day\n",
      "hostory\n",
      "wanti\n",
      "regardin\n",
      "facilit\n",
      "hip-\n",
      "localitation\n",
      "goodcentral\n",
      "hamptom\n",
      "mid-st\n",
      "piranio\n",
      "chicgo\n",
      "hotel-almost\n",
      "domenic11\n",
      "non-premium\n",
      "celecbration\n",
      "amazinf\n",
      "shape-\n",
      "loking\n",
      "..terrible\n",
      "aransa\n",
      "you'v\n",
      "location..every\n",
      "feel-poorservice\n",
      "supercalifradalisticespialadocious\n",
      "grreat\n",
      "-very\n",
      "misrepresente\n",
      "+++++++++\n",
      ".well\n",
      "ad-ons\n",
      "commin\n",
      "girl-friends\n",
      "„ÅåÂ¶•ÂΩì„Åã„Å™\n",
      "roomvery\n",
      "2017stay\n",
      "48le\n",
      "underwhelmed‚Äîlikely\n",
      "combinat\n",
      "restur\n",
      "facilities/\n",
      "festiv\n",
      "flimago\n",
      ".beds\n",
      "'wynner\n",
      "downtown/loop\n",
      "paris-\n",
      "elopment\n",
      "reccomendable\n",
      "palazzo/venetia\n",
      "-35th\n",
      "repres\n",
      "extra-ordinarily\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hamton\n",
      "congra\n",
      "ÓÇë\n",
      "casino/nice\n",
      "overcha\n",
      "misfotune\n",
      "comrfortable\n",
      "arpine\n",
      "gezennia\n",
      "owm\n",
      "properly.fro\n",
      "amaizing\n",
      "coctail\n",
      "view„Å´4Ê≥ä„Åó„Åæ„Åó„Åü„ÄÇÈÉ®Â±ã„ÅØ\n",
      "hungout\n",
      "staff‚ù§Ô∏è\n",
      "mmmmh\n",
      "quirkly\n",
      "yuc\n",
      "DGDG/DG\n",
      "views-spacious\n",
      "lttle\n",
      "kyriakedes\n",
      "chicag\n",
      "not-so\n",
      "diastorous\n",
      "comforfable\n",
      "visit/work\n",
      "hotel\\n\n",
      "room.close\n",
      "dissappointingly\n",
      "wynn/e\n",
      "day.rooms\n",
      "great/\n",
      "resort.dirty\n",
      "'ohana\n",
      "right-size\n",
      "'treasure\n",
      "intru\n",
      "conference/\n",
      "son√≥\n",
      "bo-peep\n",
      "euh\n",
      "b/f\n",
      "our5th\n",
      "this..i\n",
      "super.fanta\n",
      "crowded-looking\n",
      "approximatel\n",
      "view-front\n",
      "matranos\n",
      ".mazing\n",
      "vasat-\n",
      "notch-5\n",
      "kimenyi\n",
      "sheriton\n",
      "wedding.p\n",
      "poor/bland\n",
      "hotet\n",
      "say.the\n",
      "denverpro\n",
      "top-notched\n",
      "hotwi\n",
      "apoint\n",
      "bally's-better\n",
      "refereshmen\n",
      "show..i\n",
      "35st\n",
      "hell'so\n",
      "condo/studio\n",
      "location-shower\n",
      "paul/pittsburgh\n",
      "DGDG/DGDG/DGDG-\n",
      "tastin\n",
      "mabager\n",
      "ipsy\n",
      "brllliant\n",
      "room-good\n",
      "satifsaction\n",
      "veterenarian\n",
      "nights.first\n",
      "embarke\n",
      "sheynin\n",
      "afay\n",
      "wynners\n",
      "decor.friendly\n",
      "hotel-upgrades\n",
      "uncleand\n",
      "s.point\n",
      "amazing‚Äîfig-s\n",
      "mccirm\n",
      "*long\n",
      "dollianne\n",
      "lokation\n",
      "veas\n",
      "pleasnat\n",
      "citty\n",
      "nerver\n",
      "lobby/bar/loun\n",
      "fooor\n",
      "hummm\n",
      "7th-9th\n",
      "extrodinary\n",
      "halloween-esque\n",
      "bentl\n",
      "vibe=perfection\n",
      "wter\n",
      "5years\n",
      "njoyed\n",
      "cozy-mod\n",
      "hotel/watch\n",
      "vegas.very\n",
      "conclusi\n",
      "home‚Ä¶central\n",
      "pre-holida\n",
      "ËâØÂ•ΩÁöÑ‰ΩèÂÆøÁ∂ìÈ©ó\n",
      "rabbiting\n",
      "belclaire\n",
      "in\\out\n",
      "boasterous\n",
      "aria-las\n",
      "DG/DGDG-DGDG/DGDG\n",
      "coret\n",
      "fundamen\n",
      "horray\n",
      "expens\n",
      "landmark-\n",
      "drawers-no\n",
      "convention-mccormick\n",
      "rooms.dealt\n",
      "rront\n",
      "gofrey\n",
      "1-5xx\n",
      "‚Ä¶you\n",
      "surpirised\n",
      "gests\n",
      "shiningly\n",
      "–º–µ—Å—Ç–æ\n",
      "nobb\n",
      "work.the\n",
      "make-you-pay\n",
      "perfect-one\n",
      "grandaugher\n",
      "üîùüîùüîù\n",
      "hotel-pleasant\n",
      "-co\n",
      "weekend/24th\n",
      "everything-room\n",
      "bacteria/\n",
      "enor\n",
      "50yd\n",
      "falmingo/margaritaville\n",
      "stylisch\n",
      "strip-great\n",
      "thanksg\n",
      "ritz-carltons\n",
      "drinks/h'dourves\n",
      "altern\n",
      "okthis\n",
      "shedlin\n",
      "hotel+leisure=complete\n",
      "bloo\n",
      "renevated\n",
      "quality/price\n",
      "unfortunately..\n",
      "de-lightful\n",
      "considerab\n",
      "2-n\n",
      "..amazing\n",
      "were.everything\n",
      "loun\n",
      "writting\n",
      "palazzo/v\n",
      "sofitels\n",
      "broadway/shopping\n",
      "well..i\n",
      "pyramiddle\n",
      "pre-birthday\n",
      "trisp\n",
      "iprefer\n",
      "gennero\n",
      "vegas..your\n",
      "Îàámodern\n",
      "hazah\n",
      "soft-spo\n",
      "pillow-y\n",
      "lovelovelove\n",
      "2bdrm\n",
      "wallkin\n",
      "suuuuuper\n",
      "victim-\n",
      "treatmenttreatment\n",
      "continuou\n",
      "service‚ùó\n",
      "staffwhen\n",
      "recons\n",
      ".for\n",
      "attentative\n",
      "everyoneour\n",
      "point.this\n",
      "wiwi\n",
      "refreshe\n",
      "'affordable\n",
      "york/\n",
      "gambl\n",
      "w/view\n",
      "sleezy\n",
      "vagman\n",
      "new-ish\n",
      "slower-than-molasses\n",
      "0.5m\n",
      "privil\n",
      "excur\n",
      "*****breathtaking\n",
      "staff.pathetic\n",
      "itsel\n",
      "stylers\n",
      "complimentry\n",
      "'down\n",
      "sept'17\n",
      "'daily\n",
      "'spe\n",
      "first-this\n",
      "ohhhhh\n",
      "yesr\n",
      "extra-ordinar\n",
      "saticefied\n",
      "square.great\n",
      "sssshh\n",
      "for11\n",
      "excellent..we\n",
      "nightspr\n",
      "nyc‚Äìan\n",
      "havc\n",
      "exclesior\n",
      "ÏπúÏ†àÌï¥Ïöî\n",
      "quuen\n",
      "unfriendly/unhelpful\n",
      "6-night\n",
      "discusting\n",
      "winnng\n",
      "homewonderful\n",
      "resort/casino\n",
      "improveme\n",
      "Á´ãÂú∞„ÅÆËâØ„ÅÑ„Éõ„ÉÜ„É´„ÄÅÈÉ®Â±ã„ÇÇÂ∫É„ÅèÂø´ÈÅ©\n",
      "recommand\n",
      "here.rooms\n",
      "begin..a\n",
      "volleybal\n",
      "4star\n",
      "sentimen\n",
      "room-had\n",
      "ups-\n",
      "confirmatio\n",
      "teturn\n",
      "asthetic\n",
      "archer-ific\n",
      "fun-n-games\n",
      "caesars.pomp\n",
      "4nigths\n",
      ".award\n",
      "one-wee\n",
      "stay***\n",
      ".star\n",
      "werebig\n",
      "everythig\n",
      "casinosilver\n",
      "concierge-\n",
      "extravag\n",
      "unsupervis\n",
      "average-ish\n",
      "staffthe\n",
      "/noyes\n",
      "measrure\n",
      "c950\n",
      "souffrant\n",
      "well-loc\n",
      "podplaydeal\n",
      "hallowe\n",
      "airmiles\n",
      "ŸàŸáÿ∞ÿß\n",
      "augutus\n",
      "coby95\n",
      "polocies\n",
      "year.i\n",
      "sleeing\n",
      "luxuary\n",
      "brothe\n",
      "run-do\n",
      "nightmar\n",
      "bathroom/shower\n",
      "dlano\n",
      "kdg\n",
      "stay-catio\n",
      "sociable/rooms\n",
      "loongggggg\n",
      "servce\n",
      "t-moble\n",
      "evety\n",
      "unpoli\n",
      "perfe\n",
      "hol√Æday\n",
      "eeeeeh\n",
      "interdrone\n",
      "terrific-\n",
      "high-rollers\n",
      "place-close\n",
      "sopt\n",
      "mohamm\n",
      "uggh\n",
      "birthiversary\n",
      "21at\n",
      "location-near\n",
      "spicial\n",
      "multigun\n",
      "temperat\n",
      "staff.we\n",
      "complime\n",
      "afriandi\n",
      "-fantastic\n",
      "topdeck\n",
      "stayc\n",
      "gno\n",
      "elegan\n",
      "skysuites\n",
      "wcnq\n",
      ".caesars\n",
      "excaliburs\n",
      "base..\n",
      "nixe\n",
      "michaelangel\n",
      "surprise/workout\n",
      "stay-nice\n",
      "perience\n",
      "lodgings-\n",
      "‚Äãwe\n",
      "expereinece\n",
      "poir\n",
      "beautuful\n",
      "-the\n",
      "provi\n",
      "paigow\n",
      "shopping/exp\n",
      "acommodations\n",
      "owesome\n",
      "ketterng\n",
      "investiment\n",
      "energyzing\n",
      "amazinggggg\n",
      "jonie\n",
      "overblown-\n",
      "pricepoi\n",
      "modernisin\n",
      "unlimi\n",
      "graduat\n",
      ".sho\n",
      "crimbo\n",
      "in.location\n",
      "-a\n",
      "travelong\n",
      "here-finally\n",
      "complim\n",
      "astorias\n",
      "moham\n",
      "mohammad/dolly\n",
      "..handy\n",
      "-small\n",
      "ususlly\n",
      "sky-\n",
      "homy\n",
      "economy/location\n",
      "**we\n",
      "properly.one\n",
      "pictures/unaccommadating\n",
      "histori\n",
      "unforgotable\n",
      "'free\n",
      "+excellent\n",
      "interent\n",
      "pessimismo\n",
      "miscommunicatio\n",
      "1must\n",
      "..and\n",
      "showere\n",
      "awfs\n",
      "\\ncan\n",
      "wednes\n",
      "inconsistencie\n",
      "atmosphere-not\n",
      "butmold\n",
      "'white\n",
      "professiona\n",
      "nycüíÉüèª\n",
      "frinedly\n",
      ".stop\n",
      "/friendl\n",
      "headache-inducing\n",
      "scandi\n",
      "algonqui\n",
      "good.found\n",
      "deal.location\n",
      "placemore\n",
      "gorgous\n",
      "pillowseverythi\n",
      "dissatisf\n",
      "refelction\n",
      "visa/\n",
      "**wonderful\n",
      "*ch\n",
      "funtimes\n",
      "small/tight\n",
      "amozon.co\n",
      "‚ù§Ô∏èfabulous\n",
      "execuhve\n",
      "gambling.no\n",
      "visitied\n",
      "unhap\n",
      "bestfriends\n",
      "majical\n",
      "juldagar\n",
      "423usd\n",
      "locationwise\n",
      "markete\n",
      "hnyus\n",
      "woowed\n",
      "venic\n",
      "üéÇ\n",
      "unpolite\n",
      "approache\n",
      "rodalyn\n",
      "frint\n",
      "inexistant\n",
      "tensi\n",
      "tourny\n",
      "hygenic\n",
      "diffirent\n",
      "yesterday27/1\n",
      "mould/stains\n",
      "aniversery\n",
      "arr/dep\n",
      "service.on\n",
      "5th-10th\n",
      "sat-sat\n",
      "manthattan\n",
      "toweps\n",
      "rude.had\n",
      "einf\n",
      "linq/highroller\n",
      "additionnal\n",
      ".slig\n",
      "dyla\n",
      "excellent/outstanding\n",
      "vdar\n",
      "westwing\n",
      "friendlily\n",
      "thoug\n",
      "niberhood\n",
      "majesti\n",
      "improvi\n",
      "appreance\n",
      "'backside\n",
      "accommodation..nothing\n",
      "greatmeal\n",
      "-we\n",
      "mini-staycation\n",
      "ll-vegas\n",
      "tsq-\n",
      "\\n\n",
      "off-but-near-the-strip\n",
      "ostent\n",
      "above-par\n",
      "travelers/\n",
      "ttlv\n",
      "place-very\n",
      "outdoo\n",
      "restaut\n",
      "clean..easy..fun\n",
      "lounge/bar\n",
      "stimmt\n",
      "usaually\n",
      "past-\n",
      "horrible..you\n",
      "stay++\n",
      "hols\n",
      "roofdeck\n",
      "casino-y\n",
      "frea\n",
      "üëè\n",
      "2-roo\n",
      "economy/good\n",
      "anyhwhere\n",
      "a*****\n",
      "grandv\n",
      "xannot\n",
      "vegas-if\n",
      "hesitatingly\n",
      "apprehenisve\n",
      "‚úåüèΩÔ∏è\n",
      "'okay\n",
      "'hotel\n",
      "wacation\n",
      "peelingredroom\n",
      "redbur\n",
      "b.my\n",
      "sun-wed\n",
      "memorab\n",
      "itll\n",
      "meeting/conference\n",
      "conferency\n",
      "incompatant\n",
      "annaul\n",
      "ill-kept\n",
      "decompensating\n",
      "accomadition\n",
      "301.sa\n",
      "chinatown..\n",
      "awesome..\n",
      "square/centra\n",
      "chicago.w\n",
      "bed-that\n",
      "sightin\n",
      "work/fun\n",
      "tues-t\n",
      "hospitality-based\n",
      "intercontial\n",
      "qunita\n",
      "recenitly\n",
      "asthet\n",
      "pefection\n",
      "dissapoinment\n",
      "'stuff\n",
      "anerica\n",
      "immacu\n",
      "location.many\n",
      "could't\n",
      "leisur\n",
      "peoce\n",
      "timeshare..timeshare..timeshare..timeshare\n",
      "respo\n",
      "'si\n",
      "park-ish\n",
      "locationÔºåpoor\n",
      ".upgraded\n",
      "check-in.there\n",
      "weastgate\n",
      "happends\n",
      "deliv\n",
      "jh54\n",
      "extrav\n",
      "gracie713\n",
      "-until\n",
      "yes..i\n",
      "manhatto\n",
      "littlr\n",
      "üëåüëç\n",
      "overwhelmin\n",
      "uxurious\n",
      "unexpectable\n",
      "'almost\n",
      "lolla\n",
      "restera\n",
      "walma\n",
      "backl\n",
      "michelobs\n",
      "pickwic\n",
      "jmhs\n",
      "henr\n",
      "sweet-spot-on-th\n",
      "thestr\n",
      "internationall\n",
      "elbow-room\n",
      "architectually\n",
      "alofts\n",
      "gimm\n",
      "fogotten\n",
      "fees/ridiculously\n",
      "hotel..huge\n",
      "staff..but\n",
      "surpris\n",
      "californ\n",
      "vacatin\n",
      "michelange\n",
      "suitcas\n",
      "birthday/easter\n",
      ".good\n",
      "regar\n",
      "ownership/not\n",
      "hotel/exceptional\n",
      "timeüíö\n",
      "wonderfual\n",
      "hostess/greeter\n",
      "maryannea\n",
      "eati\n",
      "affini\n",
      "patchy..\n",
      "alright/fine\n",
      "plua\n",
      "definatley\n",
      "traveiing\n",
      "location-rooms\n",
      "shabby/very\n",
      "pentho\n",
      "unfortuante\n",
      "sshhhh\n",
      "time/place\n",
      "weretreated\n",
      "stay-as\n",
      "ponteri\n",
      "hotel-it\n",
      "post-stay\n",
      "value-small\n",
      "neiborhood\n",
      "lateva\n",
      "choice.very\n",
      "anfd\n",
      "locaation\n",
      "near'ish\n",
      "conditio\n",
      "racebook\n",
      "stuite\n",
      "price/comfort\n",
      "express..\n",
      "may.i\n",
      "la-quinta\n",
      "decepcion\n",
      "..yawn\n",
      "tripguy\n",
      "roac\n",
      "desing\n",
      "weighi\n",
      "nickled\n",
      "-you\n",
      "deserv\n",
      "noalit\n",
      "execelkent\n",
      "travler\n",
      "budget/\n",
      "Î≤àÌôîÍ∞ÄÎùºÏÑú\n",
      "DG/DG/DGDG-\n",
      "bfast\n",
      "greatlocation\n",
      "reunion/wedding\n",
      "misbeha\n",
      "chicago-the\n",
      "well-ru\n",
      "wondefful\n",
      "52n\n",
      "thanksgiveng\n",
      "stay-valentine\n",
      "comprehensi\n",
      "bare-bone\n",
      "experiance\n",
      "privilaged\n",
      "shower/tub\n",
      "cleanfree\n",
      "supeeeeeer\n",
      "awayüëçüèæ\n",
      ",DGDGDGDG\n",
      "anenities\n",
      "unfort\n",
      "aafnyc\n",
      "party/c\n",
      "wonderful/great\n",
      "pennsylvan\n",
      "hotel..when\n",
      "seaons\n",
      "2015i\n",
      "vene\n",
      "hostess/wa\n",
      "charnise\n",
      ".bellagio\n",
      "ample-sized\n",
      "*ver\n",
      "kitan\n",
      "pube\n",
      "**lengthy\n",
      "glamping\n",
      "actvities\n",
      "expedia.easy\n",
      "recove\n",
      "appauling\n",
      "whiskyfest\n",
      "visit-april\n",
      "vewgas\n",
      "california-las\n",
      "invitatiom\n",
      "thorougly\n",
      "tggat\n",
      "carreful\n",
      "wlaking\n",
      "mediam\n",
      "birthday-trip\n",
      "expla\n",
      "helpfulvery\n",
      "anaversery\n",
      "sple\n",
      "plaza-it\n",
      "veru\n",
      "strai\n",
      "excape\n",
      "reseveration\n",
      "hugo/nicole\n",
      "exq\n",
      "thecromwell\n",
      "recoomended\n",
      "vasayo\n",
      "dristrict\n",
      "owt\n",
      "hotel.frie\n",
      "experience-a\n",
      "7star\n",
      "stunn\n",
      "DG/DG**\n",
      "8mins\n",
      "***adequate\n",
      "-trump\n",
      "omn\n",
      "room110\n",
      "„Çπ„Çø„Ç§„É™„ÉÉ„Ç∑„É•„Åß„Éó„É≠„Éï„Çß„ÉÉ„Ç∑„Éß„Éä„É´„Å™„Éõ„ÉÜ„É´\n",
      "confusio/issues\n",
      "Êàë\n",
      "someting\n",
      "restaurants/cafes\n",
      "sceptica\n",
      "omini\n",
      "unfreindl\n",
      "fitzpatricks=\n",
      "dirctly\n",
      "yoiu\n",
      "staff-hotel\n",
      "7nt\n",
      "√†/c\n",
      "followin\n",
      "‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ\n",
      "-location-sm\n",
      "comapred\n",
      "desk-\n",
      "memories..\n",
      "sun-weds\n",
      "tidy.exc\n",
      "staff/great\n",
      "rubb\n",
      "haidy\n",
      "5:30am\n",
      "thatnever\n",
      "hithis\n",
      "helpful.restaurant\n",
      "switch-a-roooooom\n",
      "excellent.wish\n",
      "ÿ¨ÿØÿß\n",
      "time-share\n",
      "condot\n",
      "mini-vaca\n",
      "traverler\n",
      "exemplery\n",
      "stready\n",
      "hotel..amazing\n",
      "DG..\n",
      "entert\n",
      "handf\n",
      "perso\n",
      "service/condi\n",
      "h-o-r-r-i-b-l-e\n",
      "operat\n",
      "midler..perfect\n",
      "proporty\n",
      "excellenttimes\n",
      ".roaches\n",
      ".so\n",
      "cbrookes\n",
      "resort/\n",
      "guard..\n",
      "budwiser\n",
      "vegass\n",
      "sinag\n",
      "wow-thanks\n",
      "also-ver\n",
      "welcomeüòÄ\n",
      "end..\n",
      "room/bad\n",
      "even-midtown\n",
      "500/night\n",
      "day-cation\n",
      "atmosphe\n",
      "reasinable\n",
      "compliants\n",
      "nopu\n",
      "intim\n",
      ".best\n",
      "'basic\n",
      "pre-p\n",
      "g/f\n",
      "boutiquestyle\n",
      "expreience\n",
      "inconvience\n",
      "-boutique\n",
      "fraude\n",
      "prothis\n",
      "√†t\n",
      "2*overly\n",
      "scourin\n",
      "railwa\n",
      "noudelman\n",
      "hurti\n",
      "forwa\n",
      "profit-drive\n",
      "albei\n",
      "backlane\n",
      ".e\n",
      "exoectations\n",
      "on-l\n",
      "exceptionel\n",
      "communa\n",
      "flamingo-\n",
      "locayion\n",
      "idowntown\n",
      "6ave\n",
      "hat..the\n",
      "raphae\n",
      "apeal\n",
      "talelas\n",
      "mccaran\n",
      "hubicaci√≥n\n",
      "balanc\n",
      "mrs.hyman\n",
      "ihave\n",
      "decafe\n",
      "sreedhar\n",
      "madness/\n",
      "placeconvenien\n",
      "costs..\n",
      "unpleasentness\n",
      "nightma\n",
      "signatur\n",
      "funzi\n",
      "issueonce\n",
      "evertything\n",
      "families/young\n",
      "poshed\n",
      "professionals/w\n",
      "lovcation\n",
      "legas\n",
      "stayepinnaple\n",
      "contru\n",
      "adara\n",
      "rese\n",
      "evenit\n",
      "schnazzy\n",
      "youi\n",
      "larison\n",
      "grandure\n",
      "restarant\n",
      "starwo\n",
      "netherl\n",
      "endle\n",
      "gezzz\n",
      "athlet\n",
      "clean.f\n",
      "ballly\n",
      "incomple\n",
      "dreamey\n",
      "unprofessiona\n",
      "rollator\n",
      "esthe\n",
      "agreeabl\n",
      "mymum\n",
      "cathyoharney\n",
      "'neighborhood\n",
      "rejuvinated\n",
      "club-going\n",
      "staff.th\n",
      "reception/staff\n",
      "comfar\n",
      "strip/walking\n",
      "ewwwwwwwwwwww\n",
      "playgoround\n",
      "ah-mazing\n",
      "christamas\n",
      "d+\n",
      "expecred\n",
      "hotel..no\n",
      "service/concierge\n",
      "yankees/braves\n",
      "caesears\n",
      "hiltonhhonors\n",
      "mjor\n",
      "iroqouis\n",
      "thu-\n",
      "timinique\n",
      "id√©ale\n",
      "berkshire-location\n",
      "'famil\n",
      "timothay\n",
      ".ha\n",
      "certainl\n",
      "'young\n",
      "fridendliness\n",
      "lnot\n",
      "manhatt\n",
      "thought/had\n",
      "wiew\n",
      "offers-\n",
      "justif\n",
      "6nights\n",
      "refrigerato\n",
      "verrrrrrryy\n",
      "plaace\n",
      "work-cation\n",
      "lower-\n",
      "hotel..same\n",
      "ruiner\n",
      "eleswh\n",
      "roger/nyc\n",
      "nothng\n",
      "radalicious\n",
      "midtown/grand\n",
      "dissaponting\n",
      "elsew\n",
      "frontdesk\n",
      "sept,23rd,2016\n",
      "highe\n",
      "constuction\n",
      "wedding-may\n",
      "strip.room\n",
      "forum-unbelievable\n",
      "querky\n",
      "city-dwelle\n",
      "desatisfied\n",
      "-families\n",
      "blv\n",
      "dissap\n",
      "samll\n",
      "confetence\n",
      "delapelated\n",
      "sistersinny\n",
      "15mins\n",
      "autisti\n",
      "goodre\n",
      "alt+right\n",
      "wharf-\n",
      "location-beautiful\n",
      "family/birthday\n",
      "adjustabl\n",
      "hotel-highly\n",
      "whaf\n",
      "freesmoke\n",
      "rcbp\n",
      "staff.go\n",
      "ammeneties\n",
      "inexpe\n",
      "danc\n",
      "hiilton\n",
      "geor\n",
      "whirlpo\n",
      "location*3\n",
      "satter.n\n",
      "ok..it\n",
      "w/f\n",
      "wriggleyville\n",
      "beautiful/service\n",
      "180ish\n",
      "non-high\n",
      "stayüòÅ\n",
      "breakwe\n",
      "fairmonts\n",
      "beautycon\n",
      "accomandating\n",
      "frindly\n",
      "quiet/\n",
      "DG-\n",
      "well-l\n",
      "reluc\n",
      ".locations\n",
      "orice\n",
      "drrive\n",
      "housekeeping..\n",
      "book-lov\n",
      "hotel.deluxe\n",
      "time.\n",
      "unacceptable..\n",
      "please.asap\n",
      "narchmadness\n",
      "downtown-\n",
      "erither\n",
      "rude.c\n",
      "intook\n",
      "marketinggene\n",
      "experience.v\n",
      "wit-\n",
      "'arena\n",
      "alguma\n",
      "hervorragend\n",
      "24,2017we\n",
      "englishm\n",
      "luxurious/peaceful\n",
      "/beds\n",
      "novemb\n",
      "magnifiicent\n",
      "everytine\n",
      "separat\n",
      "accountabi\n",
      "financialdistrict\n",
      "modern-classical\n",
      "18-19th\n",
      "owner-gone\n",
      "place.very\n",
      "enjoing\n",
      "location.its\n",
      "ü¶íü¶íü¶í\n",
      "novot\n",
      "rittweger\n",
      "frisco~\n",
      "cosmpolitan\n",
      "ideales\n",
      "farimont\n",
      "incid\n",
      "20-23r\n",
      "perection\n",
      "manhattan-ho\n",
      "concierge/tim\n",
      "un.real\n",
      "attaction\n",
      "pillybear\n",
      "infamou\n",
      "excesive\n",
      "unmatche\n",
      "fevorit\n",
      "thatv\n",
      "üíñ\n",
      "bearkoda\n",
      "l‚ù§ve\n",
      "4th-9th\n",
      "DGDG/DG-DGDG/DGDG\n",
      "locationa\n",
      "adaqute\n",
      "locationwe\n",
      "inoraseed\n",
      "plase\n",
      "8yrs\n",
      "times..\n",
      "price..but\n",
      "pre-thanksgiving\n",
      "casablancacasablanca\n",
      "comfortable.i\n",
      "dieg\n",
      "bad.we\n",
      "soakin\n",
      "plannin\n",
      "amazoing\n",
      "refridgerator\n",
      "affiana\n",
      "impressed-\n",
      "ahort\n",
      "helpful\\nstaff\n",
      "un-maintained\n",
      "price~\n",
      "gautry\n",
      "midtown/ch\n",
      "birthdaytrip\n",
      "heraldsqr\n",
      "conveniengly\n",
      "phonemanal\n",
      "that:1\n",
      "dissaster\n",
      "breathta\n",
      "emphas\n",
      "-centrally\n",
      "long-delaye\n",
      "hyatt-e.\n",
      "construction-\n",
      "forcimprovement\n",
      "feb25-28\n",
      "disapprecommending\n",
      "once-great\n",
      "chic..\n",
      "misscue\n",
      "üéÑvacation\n",
      "hotel-casin\n",
      "room-including\n",
      "pre-holiday\n",
      "ttrails\n",
      "debenedetto\n",
      "favrorites\n",
      "2ave\n",
      "amenites\n",
      "president.for\n",
      "dayday\n",
      "atat\n",
      "updated..\n",
      "confress\n",
      "it¬¥s\n",
      "-chicago\n",
      "chowdury\n",
      "locationyou\n",
      "manhattam\n",
      "'bes\n",
      "dec25\n",
      "th√®me\n",
      "heregreat\n",
      "irrita\n",
      "nasti\n",
      "aprox\n",
      "phonomonal\n",
      "amou\n",
      "priv\n",
      "nyc-great\n",
      "absolouty\n",
      "omni-\n",
      "rockef\n",
      "free/\n",
      "beautifuly\n",
      "re-invest\n",
      "..by\n",
      "old/worn\n",
      "splend\n",
      "stay..coming\n",
      "noisey\n",
      "'all\n",
      "triip\n",
      "◊í◊®◊ï◊¢◊î\n",
      "satisfield\n",
      "tripadv\n",
      "marrio\n",
      "indiffer\n",
      "dive-\n",
      "mugzy\n",
      "hidid\n",
      "stafff\n",
      "here.onl\n",
      "canyon-ov\n",
      "gold/\n",
      "proble\n",
      "üéä\n",
      "affordable..\n",
      "opportunities/\n",
      "dishonesr\n",
      "happytrip\n",
      "enth\n",
      "reviw\n",
      "noise/conditions\n",
      "beautiful/no\n",
      "disclos\n",
      "baugues\n",
      "daughter‚Äî-her\n",
      "assor\n",
      "dining/poor\n",
      "3-night-stay\n",
      "founta\n",
      "accumadations\n",
      "stayagain\n",
      "handil\n",
      "venerab\n",
      "DGDGDGDG-DGDGDGDG\n",
      "it-magnificent\n",
      "forei\n",
      "jewe\n",
      "servicebecau\n",
      "aspects..\n",
      "wedding/vacay\n",
      "definatle\n",
      "delightlful\n",
      "concerige\n",
      "phillies/white\n",
      "winter-\n",
      "sefani\n",
      "stayl\n",
      "expedit\n",
      "birthyday\n",
      "keuri\n",
      "disapoitment\n",
      "schillo\n",
      "rennovated\n",
      "midranged\n",
      "fant√°stic\n",
      "sky-view\n",
      "hoildays\n",
      "heral\n",
      "bars/nightlif\n",
      "overrrun\n",
      "**warning\n",
      "friendley\n",
      "bowerty\n",
      "hotem\n",
      "midrown\n",
      "pleasntly\n",
      "valentines/annivers\n",
      "adeguate\n",
      "17t\n",
      "loooking\n",
      "despirate\n",
      "friendliness/\n",
      "icemaker\n",
      "complaints.hotel\n",
      "cost/prize\n",
      "december-january\n",
      "where/how\n",
      "buttwo\n",
      "accommoadations\n",
      "location/disappointing\n",
      "eligant\n",
      "loacat\n",
      "okcentral\n",
      "free/decent\n",
      "sopover\n",
      "venitia\n",
      "reba/b\n",
      "property/perfect\n",
      "\\new\n",
      "diffently\n",
      "alxways\n",
      "crombomb\n",
      "dtvegas\n",
      "jefferso\n",
      "service/faulty\n",
      "wwko\n",
      "luxorcheck\n",
      "friendly.listened\n",
      "days/4\n",
      "bconnected\n",
      "cloae\n",
      "hollywooood\n",
      "surpasse\n",
      "prici\n",
      "torise\n",
      "fishersmans\n",
      "alwyas\n",
      "communiciation\n",
      "accmodations\n",
      "oudated\n",
      "death..\n",
      "ggreat\n",
      "good.all\n",
      "partyi\n",
      "free-\n",
      "eduropean\n",
      "accomadtion\n",
      "treat.this\n",
      "outrageus\n",
      "‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è\n",
      "backup/dirty\n",
      "-erin\n",
      "park/northside\n",
      "do.great\n",
      "birkeshire\n",
      "serivc\n",
      "nicole-\n",
      "square.recept\n",
      "homeüòÄ\n",
      "kiddi\n",
      "wres\n",
      "gurlzzz\n",
      "-bedbug\n",
      "neighborhoud\n",
      "hitrl\n",
      "odourous\n",
      "helpfull\n",
      "goldspike\n",
      "party/dinner\n",
      "averge\n",
      "intero\n",
      "towb\n",
      "rooms/s\n",
      "yabu-designed\n",
      "hlloween\n",
      "steay\n",
      "falmingos\n",
      "üòÄüò¨\n",
      "manhatton\n",
      "hotel/perfect\n",
      "taken-care\n",
      "achitecture\n",
      "omg-so\n",
      "pre-emi\n",
      "room-making\n",
      "ok.please\n",
      "cheap2\n",
      "davetwa\n",
      "destination*\n",
      "yeasmin\n",
      "unfortanle\n",
      "outstandi\n",
      "exh\n",
      "appreci\n",
      "casino/ho\n",
      "vegas..horibble\n",
      "5k+\n",
      "noisi\n",
      "w/professional\n",
      "qualific\n",
      "albiet\n",
      "unaccommodating\n",
      "DGDG++\n",
      "desk/customer\n",
      "quietes\n",
      "arround\n",
      "here.frien\n",
      "strip/great\n",
      "layoover\n",
      "expan\n",
      "madnesss\n",
      "rwo\n",
      "-spring\n",
      "feont\n",
      "magn\n",
      "hijust\n",
      "perfecttt\n",
      "reccommend\n",
      "quaulity\n",
      "absoluley\n",
      "beiing\n",
      ".amaz\n",
      "warra\n",
      "'tourist\n",
      "bow~\n",
      "provided/across\n",
      "DG/DG-DG/DG/DGDG\n",
      "rooms-convenient\n",
      "definit\n",
      "appollonia\n",
      "thoughtfult\n",
      "babe99\n",
      "15yo\n",
      "framto\n",
      "unclea\n",
      "kohne\n",
      "oshea\n",
      "action-adjacent\n",
      "masterp\n",
      "conveniant\n",
      "=not\n",
      "valenty\n",
      "caesarspalace\n",
      "comment‚Ä¶‚Ä¶the\n",
      "good..not\n",
      "hotel/ca\n",
      "anxio\n",
      "rooms/\n",
      "we.ve\n",
      "-style\n",
      "hollywood/easy\n",
      "square-\n",
      "getaway/birthday\n",
      "¬°recomiendo\n",
      "firstimer\n",
      "onelocation\n",
      "lakesho\n",
      "unim\n",
      "reseort\n",
      "honeymoon-trip\n",
      "**just\n",
      "wgcr\n",
      "alert*\n",
      "memeori\n",
      "beggi\n",
      "3pm..\n",
      "searchi\n",
      "anniversary/shopping/relaxing\n",
      "gsls\n",
      "registrati\n",
      "roomspric\n",
      "*most\n",
      "that¬¥s\n",
      "schmendy\n",
      "half-business\n",
      "pilfere\n",
      "besidee\n",
      "mansfiel\n",
      "timliness\n",
      "loveble\n",
      "greatjohnathon\n",
      "in.really\n",
      "madmax\n",
      "newyor\n",
      "check-in/reception\n",
      "retro-'60s\n",
      "day/ni\n",
      "probaby\n",
      "liecens\n",
      "ph_april_2016\n",
      "deceiv\n",
      "well-ap\n",
      "inconsist\n",
      "mizuya\n",
      "celebration-granddaughters\n",
      "disappointedl\n",
      "location/resteraunt\n",
      "loooooved\n",
      "goodgood\n",
      "llttle\n",
      "chuwdury\n",
      "wear-and-tear\n",
      "speechles\n",
      "criss/love/luxor\n",
      "executive/club\n",
      "workou\n",
      "busstatio\n",
      "experience-great\n",
      "uptow\n",
      "ameris\n",
      "highligh\n",
      "fees/poor\n",
      "graduati\n",
      "02/24/18che\n",
      "eperfect\n",
      "compromis\n",
      "differe\n",
      "good.the\n",
      "unbeliable\n",
      "hotelairey\n",
      "secong\n",
      "republi\n",
      "personalis\n",
      "e-m\n",
      "in.new\n",
      "stay-wonderful\n",
      "stay~~great\n",
      "holtels\n",
      "couple-to-three\n",
      "off-st\n",
      "ofcourse\n",
      "suuuuuuuuper\n",
      "top..room\n",
      "overstatin\n",
      "eeek\n",
      "1bd\n",
      "fee/little\n",
      "mislead-under\n",
      "anyhere\n",
      "seluxe\n",
      "37sq\n",
      "local-\n",
      "good-enough\n",
      "wafer-thin\n",
      "„Ç¢„ÇØ„Çª„ÇπËâØ„ÅÑ„Éû„É≥„Éè„ÉÉ„Çø„É≥ÈáëËûçË°ó„ÅÆ„Éõ„ÉÜ„É´\n",
      "hotel/it\n",
      "staff/beautiful\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tut..\n",
      "palace-enec\n",
      "perfectamundo\n",
      "floati\n",
      "encha\n",
      "visit-love\n",
      "bachannal\n",
      "conference/girls\n",
      "surpried\n",
      "cloce\n",
      "fabuloys\n",
      "ocea\n",
      "gpoing\n",
      "vegas..bar\n",
      "with/from\n",
      "lollapalo\n",
      "haytt\n",
      "¬°¬°¬°¬°\n",
      "summarybryant\n",
      "1-when\n",
      "boutique-y\n",
      "-shame\n",
      "enj\n",
      "sep.20\n",
      "automa\n",
      "trip/adventure\n",
      "unconsc\n",
      "well.our\n",
      "additioanl\n",
      "catego\n",
      "international~very\n",
      "renuwing\n",
      "bad.bathroom\n",
      "casino.every\n",
      "go-to-hotels\n",
      "weekendin\n",
      "enjoyable.me\n",
      "affor\n",
      "suckometer\n",
      "100/night\n",
      "anybo\n",
      "ludl\n",
      "'cosy\n",
      "walkers/runners\n",
      "dissapeared\n",
      "loungeüç∑üç∫üç∏üôè\n",
      "neighborehood\n",
      "convininent\n",
      "staff.i\n",
      "swefish\n",
      "4days/3n\n",
      "idyatt\n",
      "small-minded\n",
      "euthanasi\n",
      "aviod\n",
      "mrsm1504\n",
      "definetely\n",
      "area.qu\n",
      "loungi\n",
      "31-sep\n",
      "15th-20thapril\n",
      "crown..\n",
      "dauther\n",
      "value/basic\n",
      "nyny\n",
      "position.f\n",
      "vistiting\n",
      "mgm/strip\n",
      "orleans-\n",
      "spruci\n",
      "sunday/monday\n",
      "reception/check\n",
      "sherry-\n",
      "party..\n",
      "scruem\n",
      "intercontienta\n",
      "impresses-\n",
      "extra-special\n",
      "fridgeb\n",
      "5/3/16for\n",
      "semi-boutique\n",
      "1block\n",
      "travalled\n",
      "unprofisional\n",
      "mlife\n",
      "in/che\n",
      "house.think\n",
      "enthusists\n",
      "staycation=reset\n",
      "asela\n",
      "god-send\n",
      "comfortable..delicious\n",
      "conventry\n",
      "„Åì„Å°„Çâ„ÅÆÂè£„Ç≥„Éü„Åß„ÅØÂ£∞„ÅåËÅû„Åì„Åà„Çã„ÄÅÂ§ñ„ÅÆÈü≥„Åå„ÅÜ„Çã„Åï„ÅÑ„ÄÅ„ÉÅ„Çß„ÉÉ„ÇØ„Ç§„É≥„Å´‰∏¶„Å∂Á≠â„Éû„Ç§\n",
      "overwhel\n",
      "stafd\n",
      "alloca\n",
      "üè©\n",
      "expande\n",
      "sofab\n",
      "sanfranci\n",
      "familty\n",
      "nythe\n",
      "teacozy\n",
      "tobui\n",
      "dayuse.com\n",
      "surprise/i\n",
      "restraurant\n",
      "4year\n",
      "sq/ft\n",
      "solieh\n",
      "cente\n",
      "not-so-special\n",
      "-rude\n",
      "decept\n",
      "decieve\n",
      "touch..\n",
      "non-chalant\n",
      "sunke\n",
      "balcany\n",
      "accomp\n",
      "brysn\n",
      "jetl\n",
      "to-to\n",
      "traff\n",
      "hotel.super\n",
      "whaaaat\n",
      "hotelbuilding\n",
      "belveder\n",
      "trip-one\n",
      "ceasres\n",
      "hotel-friendly\n",
      "nice.heat\n",
      "front-\n",
      "iplace\n",
      "-throw\n",
      "hotlanta3\n",
      "awesomeÔºÅ\n",
      "chicagoüòÄ\n",
      "non-remodeled\n",
      "desappointing\n",
      "wellness-minded\n",
      "creme/as\n",
      "undistinct\n",
      "enmployees\n",
      "phsept\n",
      "soho/tribeca/chinatown\n",
      "excellnt\n",
      "Î¨¥Î£åÎùºÍ≥†\n",
      "4br/4ba\n",
      "behrmanns\n",
      "jamesis\n",
      "efficency\n",
      "luxuri\n",
      "centre/sh\n",
      "ecpect\n",
      "relax/fun\n",
      "ambia\n",
      "strip-that\n",
      "6-like\n",
      "wonderul\n",
      "plus+\n",
      "gourme\n",
      "diffrent\n",
      "new/modern\n",
      "disguisting\n",
      "hoteltes\n",
      "exhausted-mom\n",
      "whhaaat\n",
      "üòÇ\n",
      "modrian\n",
      "flaminto\n",
      "18t\n",
      "consistenty\n",
      "mindblower\n",
      "street-quiet-resp\n",
      "graduatioin\n",
      "monac\n",
      "crasars\n",
      "perspec\n",
      "okay..rooms\n",
      "hitzville\n",
      "recommedatiion\n",
      "club/owners\n",
      "n¬∫\n",
      "'mm\n",
      "-predatory\n",
      "vegasth\n",
      "in.awful\n",
      "unpr\n",
      "crowded.th\n",
      "possition\n",
      "bridesmai\n",
      "location.helpfu\n",
      "ranki\n",
      "-tipping\n",
      "nice-looking\n",
      "week-\n",
      "days-\n",
      "value-european\n",
      "it.wynn\n",
      "decembe\n",
      "nigjt\n",
      "wosrt\n",
      "pricleline.com\n",
      "dtlv/\n",
      "reaaly\n",
      "27due\n",
      "visitare\n",
      "iconic..\n",
      "bowling/visit\n",
      "century21\n",
      "contemporar\n",
      "19-22n\n",
      "special..service\n",
      "victi\n",
      "definint\n",
      "DGDGDGDG.DG\n",
      "ex-nyc\n",
      "rexation\n",
      "billing/\n",
      "to.improve\n",
      "'fa\n",
      "non-questionable\n",
      "again-partial\n",
      "superb.jeann\n",
      "soho.the\n",
      "lobby/casin\n",
      "babulas\n",
      "drif\n",
      "wronge\n",
      "/stunning\n",
      "toalet\n",
      "mangificent\n",
      "candlewoo\n",
      "experence\n",
      "sleeps..\n",
      "hotel-awesome\n",
      "'madness\n",
      "anadulterated\n",
      "/decent\n",
      "mini-b\n",
      "-shark\n",
      "nyc..very\n",
      "loveky\n",
      "gusy\n",
      "shop-worn\n",
      "couple/business\n",
      "excellent..clean..professional\n",
      "lloking\n",
      "casilio\n",
      "sparkiling\n",
      "palced\n",
      "jumpi\n",
      "mancation\n",
      "chose/accept\n",
      "overall.rooms\n",
      "hotel.t\n",
      "proshotel\n",
      "tucke\n",
      "neice\n",
      "unaccetable\n",
      "unpleasa\n",
      "teadiness\n",
      "furnishe\n",
      "cabbed\n",
      "eervice\n",
      "cutting-ed\n",
      "four..2\n",
      "annoying/pushy\n",
      "regret..\n",
      "updated.gr\n",
      "fi/di\n",
      "helpul\n",
      "non-smoke\n",
      "flipflop\n",
      "wekng\n",
      "m'lud\n",
      "liliputians\n",
      "relaize\n",
      "pretentiou\n",
      "business.eve\n",
      "25yr\n",
      "unflamingo\n",
      "sosorry\n",
      "vegas..took\n",
      "ariahhhhhhh\n",
      "vivaaaaaaa\n",
      "durinbg\n",
      "-not\n",
      "april2007\n",
      "catasrophically\n",
      "smiles-\n",
      "constan\n",
      "peoplemy\n",
      "flatiro\n",
      "fanciness\n",
      "service/ambiance\n",
      "bithd\n",
      "-amy\n",
      "beware1\n",
      "enough.gorgeous\n",
      "conferen\n",
      "alegiant\n",
      "p.what\n",
      "imper\n",
      "mum/daughter\n",
      "iocation\n",
      "overvooked\n",
      "hotwir\n",
      "ÿßŸÑŸÅŸÜÿØŸÇ\n",
      "DG-DG-DGDGDGDG.\n",
      "21st/22n\n",
      "DGDGDG-DGDG\n",
      "goodÔºå\n",
      "‚Äãthis\n",
      "denetha\n",
      "myvega\n",
      "sofit\n",
      "empowere\n",
      "accosti\n",
      "midieval\n",
      "mehhh\n",
      "ceasers\n",
      "idea/conce\n",
      "nose-p\n",
      "grand-daughters\n",
      "convenient-clean-\n",
      "imporession\n",
      "horrendou\n",
      "givig\n",
      "exellency\n",
      "appeali\n",
      "10ish\n",
      "resteraunt\n",
      "hotel\\nlas\n",
      "outstandng\n",
      "inexpensi\n",
      "tritt-shenk\n",
      "site-seeing\n",
      "masqu\n",
      "sillversmith\n",
      "timessqu\n",
      "disppointing\n",
      "boutique-s\n",
      "two-bath\n",
      "stay.upgraded\n",
      "pricyy\n",
      "shmootique\n",
      "tehir\n",
      "not-to-expensive\n",
      "mini-va\n",
      "overall.newly\n",
      "monday-frid\n",
      "alrig\n",
      "..another\n",
      "evid\n",
      "heeah\n",
      "alternatieve\n",
      "trinnie60\n",
      "ostentatiou\n",
      "lollapollooza.great\n",
      "nughts\n",
      "madne\n",
      "unbelie\n",
      "suggeste\n",
      "subw\n",
      "ghiardelli\n",
      "good-location\n",
      "upperwestside\n",
      "feekings\n",
      "afternoo\n",
      "DG/DG-DG\n",
      "belongi\n",
      "s'agit\n",
      "..wish\n",
      "5plus\n",
      "handeling\n",
      "guiragossian\n",
      "metapacking\n",
      "rio-suites\n",
      "staff/borderline\n",
      "leadership-\n",
      "sscam\n",
      "q.t\n",
      "iamrock\n",
      "event/banquet/\n",
      "flaunty\n",
      "reccmmend\n",
      "elde\n",
      "exoected\n",
      "man-up\n",
      "weekend.small\n",
      "waitressess\n",
      "noc30-dec7\n",
      "hotels.went\n",
      "seconf\n",
      "taylorsweet16\n",
      "'te\n",
      "comfirt\n",
      ".park\n",
      "favroite\n",
      "ansd\n",
      "refrig\n",
      "ironin\n",
      "inng\n",
      "unhospitable\n",
      "thermostat/heater\n",
      "ubicated\n",
      ".they\n",
      "defintely\n",
      "palace-vegas\n",
      "reason-\n",
      "quietish\n",
      "*travel\n",
      "wynnfabulous\n",
      "50t\n",
      "w/my\n",
      "hotela\n",
      "homiest\n",
      "searsucker\n",
      "go-er\n",
      "fix-ups\n",
      "interner\n",
      "helloi\n",
      "exerc\n",
      "5-er\n",
      "service..when\n",
      "furnis\n",
      "~*~*~*~\n",
      "hortible\n",
      "bway\n",
      "overse\n",
      "whiteha\n",
      "rrue\n",
      "effo\n",
      "sratch\n",
      "eleveat\n",
      ".rooftop\n",
      "charge/urban\n",
      "hotel-elara\n",
      "venitian/palazzo\n",
      "hotel‚Ä¶.back\n",
      "hilton'a\n",
      "..gr\n",
      ".check.lobb\n",
      "noise/\n",
      "gansev\n",
      "night.the\n",
      "breakfast/ho\n",
      "sofitel/accor\n",
      "surprsingly\n",
      "adequ\n",
      "suana\n",
      "enjo6yment\n",
      "time-share/resort\n",
      "helpfulconsierge\n",
      "dieing\n",
      "indiferent\n",
      "location+service+quality+service=happy\n",
      "hipst\n",
      "preauthorazation\n",
      "reaspn\n",
      "clean.good\n",
      "concerty\n",
      "atyp\n",
      "business/vacation\n",
      "york-most\n",
      "structur\n",
      "pyramid-elevators\n",
      "stay.th\n",
      "pointsgreat\n",
      "alwaystryin2bcool\n",
      "depr\n",
      "individua\n",
      "10t\n",
      "üôÑ\n",
      "detailed-oriented\n",
      "ÌîΩÏóÖÏù¥\n",
      "confid\n",
      "beautiful..\n",
      "turist\n",
      "impresive\n",
      "4:30p\n",
      "midtownhotel\n",
      "graduation/family\n",
      "in-and-out\n",
      "central-\n",
      "riendly\n",
      "emplo\n",
      "librari\n",
      "unattract\n",
      "'weekend\n",
      "innumerab\n",
      "cromwell-very\n",
      "recentl\n",
      "zzmacmac\n",
      "eceptional\n",
      "fall/winte\n",
      "beds/linens\n",
      "3-nightstay\n",
      "housekeepin\n",
      "goodlocking\n",
      "convention/conference\n",
      "42.95/night\n",
      "oct.8th\n",
      "hotel,80\n",
      "ƒálass\n",
      "Áú†„Çâ„Å™„ÅÑÁî∫\n",
      "clogge\n",
      "excee\n",
      "visiti\n",
      "deffinitely\n",
      "pricves\n",
      "alrightneed\n",
      "lpm166\n",
      "weekt\n",
      "recommed\n",
      "greatway\n",
      "repleni\n",
      "29-dec.\n",
      "daughter-hol\n",
      "yoik\n",
      "casino-las\n",
      "all-suite\n",
      "reccomend\n",
      "warwi\n",
      "sceney\n",
      "amaazzzinnnggg\n",
      "firlst\n",
      "burnh\n",
      "boutique~\n",
      "friendly/hel\n",
      "refleck\n",
      "holidaze\n",
      "gat-away\n",
      "acommodating\n",
      "interacte\n",
      "awhil\n",
      "surou\n",
      "vtop\n",
      "compinentary\n",
      "athmosphere\n",
      "coffee/breakfast\n",
      "muea\n",
      "reviewi\n",
      "everuthing\n",
      "expext\n",
      "DG/DGDG/DG\n",
      "restraurants\n",
      "food/dr\n",
      "excellent-a\n",
      "desdtination\n",
      "bespok\n",
      "inn/tribeca\n",
      "renovsted\n",
      "shampoo+conditioner\n",
      "approxima\n",
      "service..beds\n",
      "weekn\n",
      "skyscaper\n",
      "√©lys√©es\n",
      "casino/relaxed\n",
      "loacati\n",
      "goodoh\n",
      "invasion/hotel\n",
      "roof/poker\n",
      "enama\n",
      "breakfastroom\n",
      "csueb\n",
      "nobu-\n",
      "sir/madammy\n",
      "categ\n",
      "gr√©√¢t\n",
      "crowded-not\n",
      "bar/restauran\n",
      "let-diwn\n",
      "years/anniversary\n",
      "sexcellent\n",
      "..awful\n",
      "proceudres\n",
      "way.suites\n",
      "arrival/check\n",
      "pootlr\n",
      "hooterific\n",
      "poor.foo\n",
      "starrooms\n",
      "kushkin\n",
      "cleanask\n",
      "birthday~\n",
      "offere\n",
      "roomsunfortunately\n",
      "pointscentralfu\n",
      "facelift/renovation\n",
      "thoro\n",
      "pro-the\n",
      "all-loc\n",
      "13t\n",
      "faacotry\n",
      "proerties\n",
      "manhhattan\n",
      "incre\n",
      "b-e-a-u-t-i-f-u-l\n",
      "amaaaaaazing\n",
      "venetion\n",
      "ecommended\n",
      "multi-cuisine\n",
      "lobby/conference\n",
      "wkend-thanks\n",
      "halpfull\n",
      "locaito\n",
      "is-\n",
      "delightfull\n",
      "situat\n",
      "room/great\n",
      "workcation\n",
      "stay-need\n",
      "stayimg\n",
      "easyto\n",
      "place-stayed\n",
      "grast\n",
      "well-organizedvery\n",
      "central.supe\n",
      "smalle\n",
      "zoffrino\n",
      "maching\n",
      "proprty\n",
      "flamingo-hilton\n",
      "cosmopol\n",
      "ahhhhhmazing\n",
      "resteruant\n",
      "caguindagan\n",
      "yutkovsky\n",
      "stravaganza\n",
      "chelsea-\n",
      "proximaty\n",
      "lifet\n",
      "place.so\n",
      "washed/r\n",
      "flith\n",
      "nice/affordable\n",
      "keikei\n",
      "lunch..\n",
      "50and\n",
      "well-appo\n",
      "positives:1.\n",
      "russell-thompson\n",
      "delicio\n",
      "specialis\n",
      "fieindly\n",
      "devini\n",
      "presum\n",
      "nice-\n",
      "somewhere/anywhere\n",
      "desk/employee\n",
      ".giant\n",
      "quinnta\n",
      "custoner\n",
      "hotel/apt\n",
      "..plenty\n",
      "mini-fridges\n",
      "variat\n",
      "storet\n",
      "exprecince\n",
      "carnigie\n",
      "drity\n",
      "divatude\n",
      "compre\n",
      "trip-enjoyed\n",
      "until.i\n",
      "hostel-style\n",
      "up.make\n",
      "pyramid1\n",
      "nightclu\n",
      "luxor-theres\n",
      "so-so-staff\n",
      "quiete\n",
      "outsstanding\n",
      "vfm\n",
      "restfull\n",
      "frig-coffee\n",
      "charginig\n",
      "ummmmm\n",
      "gexceptional\n",
      "üòäüëå\n",
      "in-in\n",
      "all.1\n",
      "hotel.iÃá\n",
      "compliaints\n",
      "slayin\n",
      "exte\n",
      "spaaaaaace\n",
      "fragrance-free\n",
      "1jan2017\n",
      "goodp\n",
      "carpete\n",
      "-sm\n",
      "exciteing\n",
      "..everything\n",
      "marketing.tiny\n",
      "wake-\n",
      "rooms‚Ä¶\n",
      "thisbwas\n",
      "vegas-stay\n",
      "rooms-recommended\n",
      "sneeky\n",
      "positives-great\n",
      "vacatition\n",
      "ÔΩéÔΩâÔΩÉÔΩÖ\n",
      "long-distan\n",
      "üò¨üçïüòç\n",
      ".the\n",
      "for4\n",
      ".made\n",
      "hostle\n",
      "comfortsble\n",
      "1.b\n",
      "fabulauos\n",
      "pooor\n",
      "with-out\n",
      "iove\n",
      "middleof\n",
      "bellcapsmoke\n",
      "plaza-lv\n",
      "pre-anniversary\n",
      ".business\n",
      "leav\n",
      "kwana\n",
      "theydidn\n",
      "üòÖ\n",
      "quivk\n",
      "undeliverables\n",
      "overflowi\n",
      "textbo\n",
      "room‚Äîworst\n",
      "underwhelme\n",
      "location/no\n",
      ".thanks\n",
      "inconvenieces\n",
      "smalllllll\n",
      "lixury\n",
      "stayhad\n",
      "lvms\n",
      "enjoyablable\n",
      "cuple\n",
      "delive\n",
      "stay.ooms\n",
      "hotel.the\n",
      ".ac\n",
      "nostalgia-filled\n",
      "sendayen\n",
      "non-tryst-dr\n",
      "day/anniversary\n",
      "bears/packers\n",
      "you‚Ä¶\n",
      "minimalistic-type\n",
      "city/\n",
      "wow-what\n",
      "except..\n",
      "nowotel\n",
      "beaco\n",
      "fly..but\n",
      "lakeview.1\n",
      "special-check\n",
      "earpl\n",
      "a-mazing\n",
      "cesures\n",
      "misadvertized\n",
      "proo\n",
      "‚ú®‚ú®‚ú®‚ú®\n",
      "DGDG-DG.\n",
      "stay‚Äîagain\n",
      "altoug\n",
      "observati\n",
      "valenine\n",
      "leftov\n",
      "stratfo\n",
      "concierge/management\n",
      "vacation/nationwide\n",
      "hotel/decor\n",
      "espect\n",
      "service.room\n",
      "stay..but\n",
      "sanal\n",
      "aldrist\n",
      "linq101\n",
      "buckt\n",
      "srijith\n",
      "feeling/uncomf\n",
      "mr.mohammad\n",
      "oxyge\n",
      "week..\n",
      "registr\n",
      "recogn\n",
      "charges..\n",
      "place-\n",
      "convenient/clean/friendly\n",
      "electri\n",
      "-free\n",
      "old-wor\n",
      "in-ho\n",
      "paycation\n",
      "tribeco\n",
      "reburbished\n",
      "room/rough\n",
      "transi\n",
      "25/charge\n",
      "workdmark\n",
      "vacation/black\n",
      "down-hill\n",
      "nyc/times\n",
      "machapo\n",
      "homei\n",
      "for5\n",
      "vegas.stay\n",
      "hofell\n",
      "location/bang\n",
      "wowza\n",
      "engli\n",
      "plazzo\n",
      "70/day\n",
      "adjustme\n",
      "in-suite\n",
      "hihotel\n",
      "worste\n",
      "unive\n",
      "hotel/excellent\n",
      "baaad\n",
      "poolsid\n",
      "worstüòë\n",
      "differente\n",
      "definently\n",
      "personall\n",
      "cool-kid\n",
      "district/time\n",
      "adjournin\n",
      "speend\n",
      "49/night\n",
      "spontaneo\n",
      "claubush\n",
      "servicenot\n",
      "-needs\n",
      "basic+\n",
      "imme\n",
      "ti3\n",
      "place-midway\n",
      "theplace\n",
      "◊î◊í◊¢◊™◊ô\n",
      "7-night\n",
      "usel\n",
      "mentio\n",
      "rooms/services\n",
      "newyourk\n",
      "conversati\n",
      "26/16-jan\n",
      "25.t\n",
      "queenofhearts\n",
      "adjacen\n",
      "shower/downtown\n",
      "secure/safe\n",
      "niether\n",
      "15rh\n",
      "food.good\n",
      "was't\n",
      "changed-\n",
      "travelere\n",
      "-director\n",
      "afortable\n",
      "good„ÄÇthe\n",
      "frind\n",
      "terribl\n",
      "location..and\n",
      "sdokgj\n",
      "–Ω–æ—á–∏\n",
      "atmosphere.the\n",
      "beware-lots\n",
      "hide-a-way\n",
      "thought..\n",
      "-wonderful\n",
      "baltimo\n",
      "localation\n",
      "w/attentive\n",
      "advance..i\n",
      "reuni\n",
      "2bd\n",
      "april.l\n",
      "discove\n",
      "sept.21,2015a\n",
      "regencynewyork\n",
      "bevies\n",
      "troples\n",
      "mediocer\n",
      "snoo\n",
      "cheapes\n",
      "hitchcoc\n",
      "discribe\n",
      "not-to-be\n",
      "elegence\n",
      "blahhhhhhhh\n",
      "agaib\n",
      "excdllent\n",
      "decoration/\n",
      "verymuch\n",
      "retropilot\n",
      "unrivale\n",
      "vacuume\n",
      "staffqu\n",
      "safe/\n",
      "harrras\n",
      "customers/mlife\n",
      "classy-\n",
      "prefac\n",
      "unimpresive\n",
      "DGDG.DGDG.DG\n",
      "paris/cea\n",
      "evw\n",
      "don¬¥t\n",
      "boce\n",
      "hotel..rooms\n",
      "average/poor\n",
      "holywoo\n",
      "w/in\n",
      "beatufiul\n",
      "graitude\n",
      "staff-knowledgeable\n",
      "mopaloozax\n",
      "hotel-only\n",
      "place..if\n",
      "buildi\n",
      "-rooftop\n",
      "room-we\n",
      "vegaa\n",
      "love-this-hotel\n",
      "relaxingtwo\n",
      "hotelgreat\n",
      "active/\n",
      "stay.2\n",
      "weelend\n",
      "aldcroft\n",
      "overn\n",
      "senra\n",
      "expeted\n",
      "strategicall\n",
      ".large\n",
      "vacation/business\n",
      "makeove\n",
      "room/noisy\n",
      "plesan\n",
      "inconsideration\n",
      "improvememt\n",
      "phenomina\n",
      "w/mini-fridges\n",
      "location/birthday\n",
      "*worst\n",
      "outlo\n",
      "perfectÔºÅÔºÅ\n",
      "teen-club\n",
      "tomlas\n",
      "great.so\n",
      "win~\n",
      "we'v\n",
      "trivago\n",
      "rip-\n",
      "typic\n",
      "location.due\n",
      "wondertime\n",
      "michangelo\n",
      "grwat\n",
      "wppi\n",
      "flaimingo\n",
      "..upgraded\n",
      "wundervoll\n",
      "check-in/e\n",
      "lyk\n",
      "roomsgreat\n",
      "march/18\n",
      "stay/spacious\n",
      "mbss\n",
      "discree\n",
      "overqll\n",
      "ghave\n",
      ".keep\n",
      "12th-16th\n",
      "comforatbale\n",
      "imaginaion\n",
      "demagnetized\n",
      "comfortabke\n",
      "prossmack\n",
      "maxw\n",
      ".when\n",
      "valet/bellhop\n",
      "supportiv\n",
      "novote\n",
      "attention/customer\n",
      "christmaseiland\n",
      "roommat\n",
      "üòü\n",
      "luxurius\n",
      "helpful.i\n",
      "way‚ù§Ô∏è\n",
      "aliante\n",
      "quibbl\n",
      "manhattan‚Ä¶\n",
      "wood-paneled\n",
      "maggianos..acr\n",
      "anymote\n",
      "'self\n",
      "organizin\n",
      "island-\n",
      "ces-business\n",
      "mices\n",
      "forbky\n",
      "6:30am\n",
      "strand-\n",
      "ü§Æ\n",
      "self-closing\n",
      "architectur\n",
      "hotel-hot\n",
      "pot/mary\n",
      "sevrice\n",
      "100lb\n",
      "stay-cat\n",
      "awesoome\n",
      "trip/destination\n",
      "commo\n",
      "foodcourt\n",
      "location-some\n",
      "infoth\n",
      "personab\n",
      "alth\n",
      "s'allume\n",
      "rooms.it\n",
      "attrezzata\n",
      "wasnice\n",
      "up.location\n",
      "june.hotel\n",
      "softel\n",
      "cleaning.friend\n",
      "wedding/birthday\n",
      "location.con\n",
      "bell/\n",
      "low-keyed\n",
      "comentaries\n",
      "-DGDG/DGDG/DGDG\n",
      "momories\n",
      "razamataz\n",
      "veguas\n",
      "city/u\n",
      "bachelorett\n",
      "wowser\n",
      "/night\n",
      "hotel..only\n",
      "supris\n",
      "special/\n",
      "3-4vti\n",
      "touri\n",
      "unh-tis\n",
      "things~\n",
      "hotel.abi\n",
      "poshes\n",
      "complaints..\n",
      "rauco\n",
      "eithe\n",
      "hotel-dont\n",
      "techka-licious\n",
      "striv\n",
      "1/19/2015.pros\n",
      "mid-change\n",
      "helful\n",
      "hotel/location\n",
      "mb/delano\n",
      "magicial\n",
      "reaso\n",
      "place/no\n",
      "hotelli\n",
      "pro¬¥s\n",
      "c√±osed\n",
      "adminit\n",
      "elsewere\n",
      "prcice\n",
      "trip/vacation\n",
      "everyrhing\n",
      "getaway-flamingo\n",
      "location-family\n",
      "/check-out\n",
      "laughli\n",
      "factory..\n",
      "piace\n",
      "small/quiet\n",
      "cleaning-\n",
      "mahoosive\n",
      "boutique-feeling\n",
      "ŸÑÿßŸÜ\n",
      "tigerjam\n",
      "one‚≠êÔ∏èüåü\n",
      "concerni\n",
      "placewas\n",
      "debac\n",
      "hooa\n",
      "room.big\n",
      "ÂçÅÊï∞Âπ¥„Å∂„Çä„Å´„É©„Çπ„Éô„Ç¨„Çπ„ÇíË®™Âïè„Åó„Åæ„Åó„ÅüÂâçÂõû„ÅØ„ÉÄ„Ç¶„É≥„Çø„Ç¶„É≥„Å´ÊªûÂú®„Åó\n",
      "clear..the\n",
      "25t\n",
      "colleag\n",
      "chan'tele\n",
      "great.spa\n",
      "canada/alaska\n",
      "exected\n",
      "pubilic\n",
      "deal-\n",
      "fresh-feeling\n",
      "'park\n",
      "DG-DG-DG\n",
      "sudderth\n",
      "amentit\n",
      "conditionerf\n",
      "bunk-bed\n",
      "friendlist\n",
      ",a\n",
      "room/\n",
      "25th-29th\n",
      "deal-breaker\n",
      "fsvouritr\n",
      "ÔªøÔªøi\n",
      "-licious\n",
      "thewi\n",
      "atvwestgate\n",
      "location/expensive\n",
      "square/midtown\n",
      "3days/2nights\n",
      "followe\n",
      "skandinavian\n",
      ".fro\n",
      "clean..\n",
      "quintess\n",
      "clearn\n",
      "becau\n",
      "'dressed\n",
      "awesme\n",
      "triathalon\n",
      "specifical\n",
      "us-\n",
      "infrastructur\n",
      "weddi\n",
      "riverwal\n",
      "second-guess\n",
      "pretencious\n",
      "exl\n",
      "-again\n",
      "300dollars\n",
      "'disappointed\n",
      "keven/breakfast\n",
      "datec\n",
      "locatioj\n",
      "üòê\n",
      "western-hawthorne\n",
      "ooch\n",
      "ambigious\n",
      "beds/pillows\n",
      "overvthe\n",
      "hotel-quiet\n",
      "colaborative\n",
      "algonq\n",
      "ultra-mode\n",
      "acomodat\n",
      "bybergs\n",
      "surprie\n",
      "stay-cations\n",
      "bad1\n",
      "citize\n",
      "preche\n",
      "exclu\n",
      "head..\n",
      "wihout\n",
      "remarka\n",
      "satisfac\n",
      "huuuugggeee\n",
      "hotel‚Ä¶\n",
      "satisfacotry\n",
      "econom\n",
      "tradit\n",
      "husdand\n",
      "print18\n",
      "incom\n",
      "tenderl\n",
      "maryl\n",
      "super-comfy\n",
      "olae\n",
      "jones-\n",
      "expetience\n",
      "5-10..as\n",
      "12:00pm\n",
      "hmmmmmm\n",
      "knowin\n",
      "..poor\n",
      "boutqiue\n",
      "room/linen\n",
      "sevice\n",
      "gettaway..\n",
      "positiion\n",
      "versey\n",
      "y'all\n",
      "celebation\n",
      "fragr\n",
      "fun-in-the-sun\n",
      "praisers\n",
      "locstion.clean\n",
      "wonderfulyl\n",
      "location_good\n",
      "angent\n",
      "middl\n",
      "unlimite\n",
      "wanna-be\n",
      "business=school\n",
      "rooms.outstandi\n",
      "previo\n",
      "standarts\n",
      "amazing.we\n",
      "cheical\n",
      "venentian\n",
      "value~great\n",
      "24th/6th\n",
      "boutique-like\n",
      "disaste\n",
      "onmi\n",
      "cearars\n",
      "vegas/summerlin\n",
      "shannigans\n",
      "hwd\n",
      "service/good\n",
      "easytobook.com\n",
      "wesin\n",
      "strolle\n",
      "21st-27th\n",
      "shantele\n",
      "ehhh\n",
      "cleaniliness\n",
      "airport-quality\n",
      "old/noisy\n",
      "spotl\n",
      "unle\n",
      "price/service\n",
      "luxary\n",
      "wowwwwww\n",
      "designsy\n",
      "iÃáts\n",
      "oocation\n",
      "frigob\n",
      "recommend.wait\n",
      "w/exceptional\n",
      "seegs\n",
      "nothandicappedfriendly\n",
      "flydrive\n",
      "trip/50th\n",
      "29-sept.\n",
      "javegas\n",
      "21sept\n",
      "ritx\n",
      "babymo\n",
      "aditiona\n",
      "'sin\n",
      "inconsiste\n",
      "mkae\n",
      "DGDG-DGDG-DGDG-DGDG\n",
      ".giada\n",
      "t'he\n",
      "resort-not\n",
      "'pain\n",
      "foodhall\n",
      "pros+\n",
      "rituelle\n",
      "burlilngame\n",
      "abov\n",
      "kitsh\n",
      "yorktastic\n",
      "good.if\n",
      "57street\n",
      "adaquate\n",
      "replac\n",
      "lovelythe\n",
      "quickie.booked\n",
      "collea\n",
      "house-chicago-solo\n",
      "conciege\n",
      "ncguy\n",
      "wherecthis\n",
      "cons‚Ä¢\n",
      "16-23red\n",
      "receptiondecent\n",
      "3.5stars\n",
      "favourit\n",
      "one-n\n",
      "unforgeable\n",
      "ropey\n",
      "enviornment\n",
      "sylvi\n",
      "vegaswh\n",
      "non-waivable\n",
      "ridiculou\n",
      "surpricingly\n",
      "world-\n",
      "pee-ewww\n",
      "manhattan..bang\n",
      "weclcom\n",
      "location/sold\n",
      ".port\n",
      "globalis\n",
      "endroit\n",
      "book-westgate\n",
      "locationfriendly\n",
      "archiecture\n",
      "transfe\n",
      "-_-\n",
      "mngt\n",
      "halways\n",
      "massag\n",
      "**amazi\n",
      "grill/ba\n",
      "imploye\n",
      "alsways\n",
      "money.go\n",
      "comfy-\n",
      "featu\n",
      "-rebecca\n",
      "agai\n",
      "re-name\n",
      "biz/pleasure\n",
      "13th-\n",
      "compelle\n",
      "unpac\n",
      "price\\n\n",
      "summerli\n",
      "wories\n",
      "tryps\n",
      "tari-\n",
      "cigarett\n",
      "room/cleanliness\n",
      "wynner\n",
      "th-\n",
      "incredbile\n",
      "glh\n",
      "bellagio-\n",
      "DGDGDGDG/DGDG\n",
      "spendi\n",
      "gourgeous\n",
      "atro\n",
      "place/location\n",
      "middale\n",
      "sreputation\n",
      "dirtywould\n",
      "adve\n",
      "wondeefuk\n",
      "labware\n",
      "greatbut\n",
      "rivin\n",
      "quiet-great\n",
      "mohhammed\n",
      "security-bad\n",
      "Âú∞ÈªûÂæàÊñπ‰æøÔºålobby\n",
      "stabdar\n",
      "w-o-w\n",
      "8/26locatio\n",
      "marriott-quality\n",
      "xma\n",
      "well-appointe\n",
      "hotel-business\n",
      "1star\n",
      "bahahahahaha\n",
      "staycationp\n",
      "\\nincredible\n",
      "woundn\n",
      "check-the\n",
      "every-time\n",
      "gungormezer\n",
      "chicago/great\n",
      "location-convenient\n",
      "suites/area\n",
      "frayi\n",
      "not..\n",
      "nights/6\n",
      "significan\n",
      "shoppin\n",
      "unapolog\n",
      "apessos\n",
      "20/night\n",
      "un-renovated\n",
      "diamon\n",
      "sized-roo\n",
      "frienndl\n",
      "stay..fabulous\n",
      "accommodaton\n",
      "seuffert\n",
      "bizar\n",
      "whart\n",
      "byself\n",
      "wuiet\n",
      "vacatio\n",
      "answ\n",
      "non-\n",
      "letisha\n",
      "asst.management\n",
      "mkde\n",
      "value.i\n",
      "bedview\n",
      "babyy\n",
      "rooms/property\n",
      "'majestic\n",
      "floor/no\n",
      "m828\n",
      ".although\n",
      "surpirsed\n",
      "excellend\n",
      "accomdations\n",
      "donno\n",
      "rescent\n",
      "tropicana.the\n",
      "nnext\n",
      "6yo\n",
      "kcups\n",
      "mpeccable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visized\n",
      "nyc.h\n",
      "room/hotel/casino\n",
      "freshenin\n",
      "casino/\n",
      "sleets\n",
      "pros-close\n",
      "trumptastic\n",
      "vacaci√≥n\n",
      "boutiqui\n",
      "espressomachine\n",
      "dorm-type\n",
      "spa/club\n",
      "nyc-style\n",
      "stayüòé\n",
      "locaed\n",
      "„É©„Çπ„Éô„Ç¨„Çπ„ÅÆÊ≠¥Âè≤„ÇíÊÑü„Åò„Åï„Åõ„Çã\n",
      "ah..\n",
      "decis\n",
      "suuuper\n",
      "hotel..given\n",
      "american*\n",
      "over-bearing\n",
      "disapionted\n",
      "myselfholida\n",
      "gerva\n",
      "yprk\n",
      "cnguyenswallow\n",
      "raynauds\n",
      "bed-strip\n",
      "prime-town\n",
      "neeede\n",
      "pool/beach\n",
      "spanking-clean\n",
      "silverto\n",
      "cozy/compact\n",
      "elar\n",
      "2yo\n",
      "it-we\n",
      "desm\n",
      "place..been\n",
      "check-in/check-\n",
      "fufill\n",
      "***the\n",
      "sphynx/sunrise\n",
      "pizze\n",
      "luncheoned\n",
      "Í∑∏Î¶¨Í≥†\n",
      "cleanthere\n",
      "expected.easy\n",
      "minicay\n",
      "ew.i\n",
      "location/rooms\n",
      "mengeling\n",
      "great.th\n",
      "convenitent\n",
      "issu\n",
      "aussies..south\n",
      "26juice\n",
      "customer-unfriendly\n",
      "all-a\n",
      "..walkabl\n",
      "stay-thought\n",
      "dimmy\n",
      "Á¥†Êô¥„Çâ„Åó„ÅÑ„Éõ„ÉÜ„É´\n",
      "high-stre\n",
      "familiness\n",
      "superbingo\n",
      "lkna\n",
      "enterta\n",
      "toilet/shower\n",
      "vacation.nightmare\n",
      "somebo\n",
      "it'ts\n",
      "udated\n",
      "nostolgic\n",
      "yajaira\n",
      "comfortabl\n",
      "resevationist\n",
      "locationc\n",
      "tepravel\n",
      "jacqueia\n",
      "cofee\n",
      "jloc\n",
      "stay/zero\n",
      "concept-\n",
      "housekeeping=\n",
      "3-star.pros\n",
      "satayed\n",
      "buliding\n",
      "rooms-very\n",
      "location/inconsistent\n",
      "clim\n",
      "modene\n",
      "louge\n",
      "resort~conveniently\n",
      "limnice\n",
      "replaceme\n",
      "harbor/statue\n",
      "part3\n",
      "high-roller\n",
      "under-serviced\n",
      "appart\n",
      "place‚Äîstaff\n",
      "n'roll\n",
      "place..\n",
      "convineant\n",
      "uber/ly\n",
      "importantl\n",
      "staff/bad\n",
      "experential\n",
      ".really\n",
      "beds-beautiful\n",
      "honeymoonüòç\n",
      "'budget\n",
      "promotion/\n",
      "downttown\n",
      "complexcasino\n",
      "sleep.for\n",
      "reminde\n",
      "definitiliy\n",
      "enjoya\n",
      "midw\n",
      "by-gone\n",
      "maurad\n",
      "ssshhhhhhhhh\n",
      "up.i\n",
      "rootop\n",
      "radiaaon\n",
      "appre\n",
      "hotel.buffet\n",
      "stay‚Äînot\n",
      "location/too\n",
      "lifetime..\n",
      "otherwi\n",
      "hersheys\n",
      "abom\n",
      "*spacious*\n",
      "ü§¨\n",
      "overnig\n",
      "desapointed\n",
      "thtat\n",
      "welcoming..\n",
      "buddi\n",
      "lounge/eating\n",
      "horrib\n",
      "anymore..\n",
      "okay.not\n",
      "english/deutsch\n",
      "4-bubble\n",
      "ajoining\n",
      "msrk\n",
      "benef√≠cio\n",
      "upgrades/i\n",
      "location..close\n",
      "pack-expo\n",
      "misrepresen\n",
      "crininal\n",
      "ok..do\n",
      "flawed..\n",
      "200usd\n",
      "grandvuew\n",
      "room.where\n",
      "beds.\n",
      "mysel\n",
      "location/staff/cleanliness\n",
      "-feb.5,2018\n",
      "woudl\n",
      "slum-lord\n",
      "smaller..\n",
      "hotel..gambling\n",
      "ace-inspired\n",
      "exceptional-\n",
      "thebaccarat\n",
      "clarabel\n",
      "5*room\n",
      "mtsh\n",
      "/sl\n",
      "seemle\n",
      "chippe\n",
      "superfriendly\n",
      "word..wow\n",
      "stune\n",
      "zone-like\n",
      "sightseein\n",
      "stripit\n",
      "uber/lyft\n",
      "terryfic\n",
      "rushy\n",
      "possibl\n",
      "refr\n",
      "property-japanese\n",
      "offerd\n",
      "disapponted\n",
      "rivernor\n",
      "exvellent\n",
      "skepti\n",
      "safe.personable\n",
      "'c\n",
      "-self\n",
      "hotel|accommodation\n",
      "starboxin\n",
      "upkee\n",
      ".co\n",
      "constructio\n",
      "isolat\n",
      "is.wh\n",
      "sh-sh-sh-shopping\n",
      "cookwar\n",
      "powerlifti\n",
      "nice.rea\n",
      "nyc-trip\n",
      "refl\n",
      "tail-en\n",
      "learne\n",
      "fromidaho\n",
      "warned-why\n",
      "occu\n",
      "timeshare/hotel\n",
      "towar\n",
      "nicely-placed\n",
      "..other\n",
      "sherry-netherlands\n",
      "gallagers\n",
      "ugghh\n",
      "kid-free\n",
      "previou\n",
      "confirt\n",
      "terrible/over\n",
      "overlooki\n",
      "pre-arri\n",
      "buffett/heating\n",
      "points..\n",
      "efucation\n",
      "screwe\n",
      "kids.the\n",
      "vegas.c\n",
      "usual.gordon\n",
      "thomp\n",
      "-ask\n",
      "surpringsly\n",
      "alw\n",
      "diasappointed\n",
      "perfek\n",
      "sensorarily\n",
      "york-uni\n",
      "spectacular-\n",
      "lifts/int\n",
      "nations-\n",
      "location+service+room\n",
      "comfort..\n",
      "astay\n",
      "marketi\n",
      "mixed_bag\n",
      "wsop.stayed\n",
      "shuttle-\n",
      "nights.gre\n",
      "unfriendl\n",
      "mntourists\n",
      "g√©r√¢t\n",
      "hotel~particularly\n",
      "appraisel\n",
      "quarthers\n",
      "appoiloved\n",
      "must-\n",
      "niggl\n",
      "favorate\n",
      "pampe\n",
      "excellent.i\n",
      "hilton-financial\n",
      "peggys\n",
      "vegasstays\n",
      "impecc\n",
      "cost/noisey\n",
      "taopicana\n",
      "serive\n",
      "encore-excellent\n",
      "terrble\n",
      "ohhh..fremont\n",
      "it-if\n",
      "gutic\n",
      "complitary\n",
      "DGDGDGDG/DGDGDGDG\n",
      "laq\n",
      "imag\n",
      "wynnencore\n",
      "retreat-\n",
      "asht\n",
      "convienie\n",
      "generou\n",
      "bartend\n",
      "sqf\n",
      "tyrp\n",
      "amtrax\n",
      "70ties‚Ä¶\n",
      "üçéüçéüçéüçégreat\n",
      "daddy/daughter\n",
      "unsurprisi\n",
      "hellooo\n",
      "narci\n",
      "kimb\n",
      "emphasiz\n",
      "neic\n",
      "top-notc\n",
      "cablecar\n",
      "hhmmm\n",
      "anna=\n",
      "elebators\n",
      "shut-eye\n",
      "roomüëéüèΩ\n",
      "upity\n",
      "1.they\n",
      "dsappointing\n",
      "'welcomed\n",
      "consec\n",
      "elegeant\n",
      "man-üíûüíû-tan\n",
      "exaggerati\n",
      "location-all\n",
      "turni\n",
      "glitc\n",
      "fslv\n",
      "tightttt\n",
      "often.this\n",
      "weolcom\n",
      "location/affordable\n",
      "fidi\n",
      "friendly-great\n",
      "slots//\n",
      "infrequ\n",
      "novembe\n",
      "syat\n",
      "row-\n",
      "getu\n",
      "for.ex\n",
      "d'citta\n",
      "comfortable-location-accommodating\n",
      "gambling-great\n",
      "forsure\n",
      "poin\n",
      "chair..\n",
      "recommendingthe\n",
      "perfect-the\n",
      "cosmopoli\n",
      "srorng\n",
      "dhoes\n",
      "accompdations\n",
      "dwe\n",
      "cheapy\n",
      "torrelle\n",
      "blt/\n",
      "expeirence\n",
      "roofmy\n",
      "pefectly\n",
      "vibe.roo\n",
      "inexpen\n",
      "chicagoa\n",
      "Í∑∏Í±∏\n",
      "-if\n",
      "often.wi\n",
      "experienci\n",
      "citybreak\n",
      "place‚Ä¶but\n",
      "tgere\n",
      "corenr\n",
      "neibothood\n",
      "cytheria\n",
      "lounge-like\n",
      "staff-small\n",
      "easte\n",
      "bacheloret\n",
      "greaty\n",
      "vegas-one\n",
      ",nyc\n",
      "inpresive\n",
      "location/view\n",
      "fantastic/excellent\n",
      "york..pretty\n",
      "improvem\n",
      "elevators-\n",
      "snowstorn\n",
      "excellent/expensive\n",
      "allwe\n",
      "royals/cubs\n",
      "legen-waitforit-dary\n",
      "silve\n",
      "aggravati\n",
      "persoma\n",
      "exxcellant\n",
      "ventetian\n",
      "march.quic\n",
      "quir\n",
      "pre-servi\n",
      "non-destination\n",
      "valuje\n",
      "conceierge\n",
      "dirty/old\n",
      "conditioner/heater\n",
      "107lounge\n",
      "tuscanny\n",
      "housekeeping..laziness\n",
      "cadabri\n",
      "4-sta\n",
      "earne\n",
      "however..ask\n",
      "chancello\n",
      "location+rooftop\n",
      "kouser\n",
      "arghhh\n",
      "DG/DGDG/DGDG-DG/\n",
      "l.v\n",
      "plactically\n",
      "kzk\n",
      ".gambling\n",
      "christkindl\n",
      "rencent\n",
      "imrovements\n",
      "nobutastic\n",
      "reviewgreat\n",
      "hubb\n",
      "cronic\n",
      "on-strip\n",
      "‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è\n",
      "transferre\n",
      ".courteous\n",
      "belleclair\n",
      "rowtyc\n",
      "resonable\n",
      "excelenthotel\n",
      "oh-so-crowded\n",
      "isagenix\n",
      "am4\n",
      "unbelievab\n",
      "rundo\n",
      "decent.the\n",
      "comtemporary\n",
      "unhygeinic\n",
      "hilton55\n",
      "outweight\n",
      ".pure\n",
      "disaster..waited\n",
      "benihanas\n",
      "attractions/\n",
      "friday-sunday\n",
      "dogfest\n",
      "4blocks\n",
      "/bartender\n",
      "visti\n",
      "reput\n",
      "imppressed\n",
      "oppos\n",
      "r3508\n",
      ".meh\n",
      "melb\n",
      "hasslefree\n",
      "water-line\n",
      "priced-\n",
      "matt.rosaria\n",
      "*no\n",
      "organizaton\n",
      "-does\n",
      "smely\n",
      "terrificfront\n",
      "unple\n",
      "largebagno\n",
      "delamo\n",
      "off-the-beaten\n",
      "unexpec\n",
      "ceilin\n",
      "venettian\n",
      "accross-the-board\n",
      "excellentvery\n",
      "fr*ckin\n",
      "edisom\n",
      "italian-themed\n",
      "tropicant\n",
      "cl54\n",
      "event-g\n",
      "successconnect\n",
      "price/friendly\n",
      "wowfrom\n",
      "longer..\n",
      "povided\n",
      "üíóüíó\n",
      "soeil\n",
      "10.9.17was\n",
      "daniel-valet\n",
      "aboveandbeyond\n",
      "stayn\n",
      "room19010\n",
      "evaluation/rating\n",
      "grandmothe\n",
      "hipster-cool\n",
      "checked-i\n",
      "verrrrrrrrrryyyyyy\n",
      ".jackie\n",
      "stadiu\n",
      "jebs\n",
      "skline\n",
      "good-excellent\n",
      "carlton/san\n",
      "travek\n",
      "atvtvis\n",
      "instagrammers\n",
      "smokyi\n",
      "aftrr\n",
      "2-bedrooms\n",
      "travel/meeetings\n",
      "building.luxury\n",
      "august/sta\n",
      "mistified\n",
      "the.venetian\n",
      "DGüåü\n",
      "lexinton\n",
      "president/my\n",
      "bucket-list\n",
      "loacti\n",
      "replen\n",
      "accomodations/bar\n",
      "herefor\n",
      "roomya\n",
      "..w\n",
      "facecloth\n",
      "check-in/\n",
      "hubbies\n",
      "appearin\n",
      "bowery-hotel\n",
      "downown\n",
      "expecatations\n",
      "knowledanl\n",
      "nicel\n",
      "stay-mixed\n",
      "sanfrantastic\n",
      "outweig\n",
      "aladdi\n",
      "one-bed\n",
      "darnita\n",
      "a..\n",
      "value/servic\n",
      "sleep/\n",
      "disorganiz\n",
      "satisfact\n",
      "platinu\n",
      "~marriott\n",
      "dee-lectabaly\n",
      "wiped-away\n",
      "geart\n",
      "starti\n",
      "absolutly\n",
      "venue/hotel\n",
      "tables/staff\n",
      "minuite\n",
      "underconstruction\n",
      "51happybornmonth\n",
      "explo\n",
      "flamingoed\n",
      "autonomus\n",
      "ridicu\n",
      "trip/mini\n",
      "presentation=free\n",
      "wall-sized\n",
      "decedance\n",
      "location-across\n",
      "flamingo-new\n",
      "exteri\n",
      "cotiga\n",
      "five-stars\n",
      "disappointing..\n",
      "mimute\n",
      "unexexpected\n",
      "coxy\n",
      "scrappiest\n",
      "*noise\n",
      "inefffective\n",
      "ourse\n",
      "gougy\n",
      "masquerad\n",
      "pro'sgreat\n",
      "meetings/conventions\n",
      "2nd.april\n",
      "touchs\n",
      "helpful..\n",
      "under-whelming\n",
      "upmar\n",
      "ewwwwwww\n",
      "price/mid\n",
      "cacsino\n",
      "bell-person\n",
      "sunbathi\n",
      "winter-t\n",
      "work..\n",
      "relationsand\n",
      "removation\n",
      "highlig\n",
      "oldiest\n",
      "bbait\n",
      "diversit\n",
      "supervi\n",
      "childreb\n",
      "essentiall\n",
      "best‚Äî\n",
      "writt\n",
      "convenie\n",
      "ddiva\n",
      "horroble\n",
      "artw\n",
      "exposu\n",
      "time-square\n",
      "hotel.located\n",
      "expectations..willing\n",
      "disapoi\n",
      "18de\n",
      "pre-arrival\n",
      "friendlty\n",
      "montecarl\n",
      "locaiton\n",
      "combinati\n",
      "hotel.greete\n",
      "3-night\n",
      "troub\n",
      ".pros\n",
      "‚ù§Ô∏èperfect\n",
      "staycatiion\n",
      "properties/terrific\n",
      "lovated\n",
      "ac2\n",
      "old..\n",
      "bathromm\n",
      "aneminties\n",
      "roomsvery\n",
      "scce\n",
      "renevotation\n",
      "exhus\n",
      "reduce-reuse-\n",
      "stratosph\n",
      "restaurant/br\n",
      "mangment\n",
      "„Éªnovotel\n",
      "exeprience\n",
      "pre-tee\n",
      "rude/disinterested\n",
      "laocation\n",
      "stya\n",
      "desti\n",
      "baqck\n",
      "hotel..ok\n",
      "nteresting\n",
      "talboto\n",
      "disaster.just\n",
      "constrction\n",
      "apremium\n",
      "bicyc\n",
      "christmas/n\n",
      ".wit\n",
      "un-vegas\n",
      "location.big\n",
      "technol\n",
      "tripthe\n",
      "swan-fabulous\n",
      "cdc1196\n",
      "e64st\n",
      "lucky..\n",
      "nicecor\n",
      "hotelexperiance\n",
      "comfy/classy\n",
      "city-times\n",
      "gosh..\n",
      "haddicap\n",
      "district/loop\n",
      "-weekend\n",
      "jovene\n",
      "business/holidays\n",
      "spain.nice\n",
      "buffet-\n",
      "chicago/downt\n",
      "perfection..another\n",
      "location.stay\n",
      "presentati\n",
      "w/sitting\n",
      "businsess\n",
      "hotel/food\n",
      "spot.hotel\n",
      "8-15th\n",
      "hotel.had\n",
      "inadeqate\n",
      "caasino\n",
      "ittt\n",
      "vdaraaaaaahhhhhhh\n",
      "unfinis\n",
      "cheching\n",
      "ugh-\n",
      "e-folio\n",
      "whistl\n",
      "ciaiowe\n",
      "nobelden\n",
      "zeppe\n",
      "out/in\n",
      "amazzzzzing\n",
      "nice/\n",
      "addore\n",
      "lamees\n",
      "michig\n",
      "trael\n",
      "commuti\n",
      "worthwhile-\n",
      "ahain\n",
      "fitzg\n",
      "property/poorly\n",
      "dadüòÉ\n",
      "louisvuitton\n",
      "extraordinar\n",
      "located/friendly\n",
      "missingdirty\n",
      "suppo\n",
      "ptice\n",
      "thsna\n",
      "deficie\n",
      "sohotel\n",
      "encore/wynn\n",
      "veyr\n",
      "hide-away\n",
      "efficient,32\n",
      "palace/augustus\n",
      "neidaly\n",
      "aria~looking\n",
      "name.this\n",
      "ny.vi\n",
      "ny-e\n",
      "uncarded\n",
      "unprententious\n",
      "21rs\n",
      "descrived\n",
      "family/kids\n",
      "apr/6-9\n",
      "gansvoort\n",
      "there.1\n",
      "inclusiv\n",
      "ok/good\n",
      "cqsf\n",
      "hotelde\n",
      "unbelievingly\n",
      "smancy\n",
      "mlbworld\n",
      "serbi\n",
      "here.man\n",
      "tower.\n",
      "wekcome\n",
      "3th\n",
      "recently.s\n",
      "'pod\n",
      "üòéüòéüòéüòáüòáüòáüòçüòçüòç\n",
      "true-gem\n",
      "views..a\n",
      "pyrimid\n",
      "beautfil\n",
      "european-styl\n",
      "w.o.w\n",
      "staff.coul\n",
      "overviewi\n",
      "amazingbed\n",
      "definaltly\n",
      "baaaaaaaack\n",
      "good/fri\n",
      "vegaslocation\n",
      "thanksroom\n",
      "dblcityview\n",
      "pyramids-\n",
      "decidin\n",
      "salison\n",
      "institutional-looking\n",
      "non-gamers\n",
      "service/gaming/food/sh\n",
      "amazing..beyond\n",
      "friendlt\n",
      "amenti\n",
      "wynn-classy\n",
      "mancheste\n",
      "gatekeepe\n",
      "old/dirty\n",
      "seevers\n",
      "not-too\n",
      "‚ù§Ô∏èfor\n",
      "marriottt\n",
      "average-poor\n",
      "embasey\n",
      "soooooo\n",
      "ihad\n",
      "floor-men\n",
      "stadf\n",
      "f.u.b.a.r.ed\n",
      "/lowlights\n",
      "hiton\n",
      "newly-rennovated\n",
      "refurbishin\n",
      "pre-a\n",
      "wedding/honeymoon\n",
      "everything-if\n",
      "48l\n",
      "deadzone\n",
      "cozy-industrial\n",
      "manyhattan\n",
      "espec\n",
      "fan/air\n",
      "manhattan-seaport\n",
      "viewgrea\n",
      "-exp\n",
      "event-excellent\n",
      "room-small\n",
      "dysfu\n",
      "weere\n",
      "vdissapoints\n",
      "tinest\n",
      "exeperience\n",
      "mid-centre\n",
      "furnishin\n",
      "'thompson\n",
      "hotel/club\n",
      "rightwelcome\n",
      "outgoi\n",
      "choice/amazing\n",
      "boutique-get\n",
      "cityhotel\n",
      "laqu\n",
      "price/location\n",
      "misfortun\n",
      "madnes\n",
      "lvttcg\n",
      "hudson-\n",
      "vixit\n",
      "lociation/value\n",
      "hgv-las\n",
      "ballys/paris\n",
      "plce\n",
      "surelythe\n",
      "beautiful1\n",
      "'apartment\n",
      "mism\n",
      "phoen\n",
      "atmospher\n",
      "yes-yes-yes\n",
      "20yrs\n",
      "accomodatin\n",
      "=only=\n",
      "enjoyrd\n",
      "june6-june11\n",
      "DGDGDGDG/DGDG/DGDG~\n",
      "cicago\n",
      "techinical\n",
      "fabuloso\n",
      "ezperienxe\n",
      "cosmop\n",
      "indif\n",
      "smilinginvegas\n",
      "kimpt\n",
      "installin\n",
      "azing\n",
      "aapex/sema\n",
      "tslbott\n",
      "moderniz\n",
      ".chic\n",
      "highlly\n",
      "sohoo\n",
      "wonderful-extr\n",
      "nice.keurig\n",
      "mr.acheampong\n",
      "familby\n",
      "bar..\n",
      "trouvent\n",
      "brillia\n",
      "fixtures/finishing\n",
      "decaden\n",
      "in.ver\n",
      "go/stay\n",
      "facilitiers/\n",
      "aobisc\n",
      "money-loud\n",
      "g-host\n",
      "unex\n",
      "nights/5days\n",
      "suite..only\n",
      "hote/\n",
      "well-accommodated\n",
      "clai\n",
      "necessa\n",
      "amentites\n",
      "staff.smooth\n",
      "shopping/dining\n",
      "depen\n",
      "dimini\n",
      "amazballs\n",
      "oppertunities\n",
      "tofeal\n",
      "smaaaaall\n",
      "waslooking\n",
      "vuluptuous\n",
      "upfated\n",
      "big-big\n",
      "customer..\n",
      "imaginat\n",
      "armena\n",
      "amenit\n",
      "generaly\n",
      "clean.close\n",
      "fodd\n",
      "5-stay\n",
      "trip2017\n",
      "cool.just\n",
      "view.\n",
      "mr.hamilton\n",
      "—Å—Ä–æ–∫\n",
      "architechture\n",
      "sucky\n",
      "contemporay\n",
      "grandour\n",
      "‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è\n",
      "hotel.alt\n",
      "discar\n",
      "stresser\n",
      "giod\n",
      "madalay\n",
      "imperial~\n",
      "~20minute\n",
      "stay-friendly\n",
      "bugs.book\n",
      "aria/\n",
      "DGDG-DGDG.\n",
      "mornig\n",
      "propertyi\n",
      "guesrs\n",
      "wron\n",
      "treaure\n",
      "discrep\n",
      ".ch\n",
      "succe\n",
      "communicat\n",
      "outr\n",
      "45years\n",
      "-che\n",
      "ofers\n",
      "floor-\n",
      "vacation*\n",
      "gaming-area\n",
      "downf\n",
      "minusses\n",
      "footp\n",
      "service/receptio\n",
      "gothe\n",
      "extrem\n",
      "tast\n",
      "location/bad\n",
      "westn\n",
      "4qs\n",
      "kalapsa\n",
      "inad\n",
      "theref\n",
      "lexingtom\n",
      "nicenostalgic\n",
      "-exceed\n",
      "mamara\n",
      "achiev\n",
      "rooms/bathrooms\n",
      "avoid/\n",
      "u40s\n",
      "bavettee\n",
      "crapsmaster\n",
      "nice-lookin\n",
      "grab-n-go\n",
      "sservice\n",
      "witn\n",
      "oow\n",
      "lynq\n",
      "refurishment\n",
      "notifi\n",
      "robbiie\n",
      "york.h\n",
      "publi\n",
      "wasn¬¥t\n",
      "nights.our\n",
      "accommo\n",
      "arquitetural\n",
      "comfortable3\n",
      "unfortunetly\n",
      "premiu\n",
      "somewhe\n",
      "bellagi-no\n",
      ".wow\n",
      "summerl\n",
      "johnf\n",
      "families/people\n",
      "me-\n",
      "intens\n",
      "boulevard/strip\n",
      "awsommmm\n",
      "all-too\n",
      "forev\n",
      "happy/\n",
      "aith\n",
      "spok\n",
      "^_¬∞\n",
      "condo/hotel\n",
      "overhaul.wouldnt\n",
      "whiteh\n",
      "aggabee\n",
      "remarkabl\n",
      "bucketlist\n",
      "roomawesome\n",
      "attribut\n",
      "equipme\n",
      "reorg\n",
      "g.o.a.t\n",
      "spaceous\n",
      "chatacter\n",
      "awey\n",
      "casino/hote\n",
      "wayüíé\n",
      "locationsurrounded\n",
      "room/b\n",
      "wedding/holiday\n",
      "checkin-\n",
      "socc\n",
      "english-themed\n",
      "tub/\n",
      "perfect-util\n",
      "good-clean\n",
      "trendy-\n",
      "\\nsecurity\n",
      "in-l\n",
      "chargeme\n",
      "lock-\n",
      "annoyin\n",
      "tabl\n",
      "flamino\n",
      "hightligh\n",
      "place-conveni\n",
      "pre-cruis\n",
      "2-night-stay\n",
      "runwa\n",
      "time/retail\n",
      "svetaclos\n",
      "enchantedcame\n",
      "tidie\n",
      "overhe\n",
      "boutique-feel\n",
      "electr\n",
      "'urban\n",
      "westloop\n",
      "no-frill\n",
      "mother/daughter-trip\n",
      "6400th\n",
      "elevatorscheck\n",
      "stay-the\n",
      "at/in\n",
      "dowag\n",
      "vacy\n",
      "infes\n",
      "tenderloim\n",
      "convenient..can\n",
      "deecent\n",
      "weekend/birthday\n",
      "eddieson\n",
      "vbest\n",
      "wynnderful\n",
      "custumor\n",
      "chcag\n",
      "chelsea-manhattan\n",
      "pleased..\n",
      "hotel-tonigh\n",
      "infree\n",
      "casinonice\n",
      "eveeer\n",
      "ammenity\n",
      "8n\n",
      "houskeeping\n",
      "harrased\n",
      "brillinat\n",
      "pleanst\n",
      "ÏÇ¨\n",
      "fisherm\n",
      "abdualla\n",
      "charact\n",
      "cosmopolitan/las\n",
      "janauary\n",
      "m√©dium\n",
      "silvert\n",
      "'jw\n",
      "cromwll\n",
      ".old\n",
      "2pm/worse\n",
      "industrial-chic\n",
      "clean.b\n",
      "closley\n",
      "decievin\n",
      "-it-\n",
      "elagant\n",
      "munozhubbard\n",
      "quiet.very\n",
      "tomor\n",
      "underpar\n",
      "foreig\n",
      "facility-incredible\n",
      "service.you\n",
      "accomdatio\n",
      "fair+\n",
      "indigo/great\n",
      "museum-goers\n",
      "hesita\n",
      "reinforc\n",
      "square.\n",
      "fustrating\n",
      "confference\n",
      "fransis\n",
      "roomates\n",
      "everytim\n",
      "familyho\n",
      "unfrendly\n",
      "nov-26th\n",
      "pre-quake\n",
      "vday\n",
      "..great\n",
      "bacherlorette\n",
      "centrl\n",
      "husand\n",
      "worr\n",
      "boogy\n",
      "parkmgm\n",
      ",resta\n",
      "uninviti\n",
      "wanted/\n",
      "quet\n",
      "friendly+dog\n",
      "friendly/clean\n",
      "full/see\n",
      "nypalace\n",
      "convenientl\n",
      "m-li\n",
      "christol\n",
      "location/pool\n",
      "high-touch\n",
      "homewod\n",
      "strawbe\n",
      "clean..restaurants\n",
      "doorknob-\n",
      "raos\n",
      "octives\n",
      "location-sandra\n",
      "..dire\n",
      "regenc\n",
      "golf/gambling\n",
      "1p.m\n",
      "costl\n",
      "addr\n",
      "htel\n",
      "depre\n",
      "firslty\n",
      "chi-city\n",
      "158/night\n",
      "acquir\n",
      "top-not\n",
      ".mixed\n",
      "hitel\n",
      "exccellent\n",
      "bar/hotel\n",
      "overcharg\n",
      "cityvisit\n",
      ".fantastic\n",
      "rhow\n",
      "enjoyme\n",
      "well-kno\n",
      "tenament\n",
      "'you\n",
      "ink4\n",
      "anniversarymoon\n",
      "decor..i\n",
      "4.5hrs\n",
      "nascarüèÅ\n",
      "nightmare..\n",
      "weaknesse\n",
      "althoug\n",
      "exprctations\n",
      "blingy\n",
      "'restaurant\n",
      "stay‚Äîeach\n",
      "..bellagio\n",
      "murdies\n",
      "rarel\n",
      "horible\n",
      "mar16\n",
      "hoetl\n",
      "non-partiers\n",
      "we'r\n",
      "gramery\n",
      "advanture\n",
      "value/small\n",
      "15-18t\n",
      "DGDG:DGDG\n",
      "zzzzzzzzzz\n",
      "14th-1\n",
      "abun\n",
      "fillmo\n",
      "cypr\n",
      "isscc\n",
      "ŸÜÿ∏ŸäŸÅ\n",
      "great..no\n",
      "accommodation.\n",
      "relaxing..\n",
      "apprehens\n",
      "awewome\n",
      "washington-jef\n",
      "location-location-location\n",
      "location/clean/nice\n",
      "kipsbay\n",
      "nongaming\n",
      "inser\n",
      "doormen/conci√´rges\n",
      "good/great\n",
      "beach/pool\n",
      "expetien\n",
      "interuped\n",
      "location-under\n",
      "ga-ross\n",
      "mom/\n",
      "experieince\n",
      "great.we\n",
      "emaile\n",
      "crisis‚Äîgreat\n",
      "hands-down\n",
      "su-premium\n",
      "restaraunts\n",
      "conveni\n",
      "..should\n",
      "york/eastside\n",
      "aussiesinvegas\n",
      "constr\n",
      "dvino\n",
      "from.home\n",
      "locationit\n",
      "fistly\n",
      "furni\n",
      "fun‚Ä¶lost\n",
      "bay-\n",
      "tipperlulu\n",
      "shamefull\n",
      "beautiful-looking\n",
      "modern.e\n",
      "ma-hoo-sive\n",
      "talle\n",
      "arm-les\n",
      "goldm\n",
      "conseires\n",
      "friendly.i\n",
      "8t\n",
      "'undesirables\n",
      "bugsey\n",
      "post-bachelors\n",
      "dealertainers\n",
      "stay..constantly\n",
      "resurant\n",
      "upseting\n",
      "..nothing\n",
      "cleanes\n",
      "hotel/condominium\n",
      "landma\n",
      "benefi\n",
      "bar/e\n",
      "trip-1st\n",
      "dayed\n",
      "ameritana\n",
      "DG/DGDG-DGDG\n",
      "hotel..a\n",
      "slepping\n",
      "bed‚ÄºÔ∏è\n",
      "houtique\n",
      "seringe\n",
      "childre\n",
      "freezin\n",
      "peac\n",
      "signifucantly\n",
      "lobby/common\n",
      "gettnig\n",
      "down/staff\n",
      "kitc\n",
      "clean-\n",
      "pampar\n",
      "2nit\n",
      "godrey\n",
      "bell-hop\n",
      "wintrust\n",
      "value-highly\n",
      "roomheated\n",
      "top-of\n",
      "destress\n",
      "apartme\n",
      "reaxing\n",
      "documen\n",
      "'broadw\n",
      "‰æøÂà©„Å™Á´ãÂú∞„Åß„Åô„ÄÇjfk„Åã„Çâ„ÅØ\n",
      "herenot\n",
      "miste\n",
      "satyed\n",
      "eye-ca\n",
      ".low\n",
      "eastsi\n",
      "chillaxing\n",
      "sloved\n",
      "anniversary/mother\n",
      "wotked\n",
      "DGDG/DG-DGDG/DG/DGDGDGDG\n",
      "hotelonly\n",
      "location/location\n",
      "costelli\n",
      "quarters/world\n",
      "maste\n",
      "üíê\n",
      "toget\n",
      "coast/orleans\n",
      "hotel.for\n",
      "stay-rooms\n",
      "run-\n",
      "apprehe\n",
      "jewlel\n",
      "c/p\n",
      "drivi\n",
      "meraviglioso\n",
      "locatedit\n",
      "average/adequate\n",
      "pyrmid\n",
      "holidayy\n",
      "hiked-out\n",
      "reservatio\n",
      "geek-friendly\n",
      "fromt\n",
      "bedroom/shower\n",
      "ŸÖŸàŸÇÿπ\n",
      "aspects-very\n",
      "hoprocket\n",
      "*DGDGDG\n",
      "leagu\n",
      "althou\n",
      "400+/night\n",
      "buffetnot\n",
      "realt\n",
      "here.love\n",
      "stratosp\n",
      "nightmare/pool\n",
      "..otherwise\n",
      "superbloom\n",
      "dark/non\n",
      "iverhy\n",
      "vegas..woohoo\n",
      "spinale\n",
      "elevator..\n",
      "ago.t\n",
      "rooms/service\n",
      "eviden\n",
      "first-cla\n",
      "festival-balcony\n",
      "htsq\n",
      "7night\n",
      "üëåüèΩ\n",
      "pre-renovati\n",
      "pear-as\n",
      "esuites\n",
      "absoloutely\n",
      "wwwest\n",
      "staria\n",
      "constructino\n",
      "..g\n",
      "milwauke\n",
      "chammika\n",
      "photogr\n",
      "düòéwntown\n",
      "pocketboo\n",
      "room/concept\n",
      "expericene\n",
      "staff.loved\n",
      "beutifull\n",
      "dowto\n",
      "signiture\n",
      "home-\n",
      "dj7212018\n",
      "auomatic\n",
      "substa\n",
      ".magnific\n",
      "longer6\n",
      "marvelo\n",
      "away-\n",
      "utte\n",
      "vefas\n",
      "prebooking\n",
      "1brm\n",
      "irre\n",
      "satisfi\n",
      "restri\n",
      "20lb\n",
      "jublilee\n",
      "fiftynyc\n",
      "genncomm\n",
      "worlds..\n",
      "stay.but\n",
      "manegment\n",
      "tlc/updating\n",
      "mini-family\n",
      "sleepman\n",
      "stiled\n",
      "trip..not\n",
      "multi-generation\n",
      "strong-armed\n",
      "usd9+\n",
      "casesars\n",
      "ph/lv\n",
      "memeorable\n",
      "giest\n",
      "fridgepoor\n",
      "vegas-large\n",
      "unenjoyable\n",
      "plaxd\n",
      "location.ju\n",
      "3pcredit\n",
      "waldorf-ast\n",
      "hamiltimes\n",
      "0.5miles\n",
      "king.\n",
      "hotal/\n",
      "casino-very\n",
      "aloof/\n",
      "people-friendly\n",
      "itchi\n",
      "refurbishi\n",
      "inbetwee\n",
      "mirage-\n",
      "amaxing\n",
      "terrible/look\n",
      "lroce\n",
      "disappointed-better\n",
      "hotel..beware\n",
      "accou\n",
      "amazing..\n",
      "checke\n",
      "brainier\n",
      "-slightly\n",
      "schmurfday\n",
      "vikie\n",
      "unpl\n",
      "roomsfilthy\n",
      "3weeks\n",
      "ricidulous\n",
      "daylight-except\n",
      "snding\n",
      "w/access\n",
      "wynn-encore\n",
      "soho/nomad\n",
      "appreciatio\n",
      "fwi\n",
      "hospitality..nice\n",
      "shhtory\n",
      "friesdly\n",
      "monday-th\n",
      "durig\n",
      "collusiu\n",
      "online-bait\n",
      "trlp\n",
      "casino.wish\n",
      "paris-esque\n",
      "bad/not\n",
      "moneu\n",
      "janito\n",
      "conformatable\n",
      "phonomenal\n",
      "nerlie\n",
      "hamilt\n",
      "excelent\n",
      "immedi\n",
      "sanfrancisico\n",
      "francisco/union\n",
      "lexingto\n",
      "gansvoo\n",
      "housekeepimg\n",
      "warthol\n",
      "bar/rest\n",
      "25yrs\n",
      "aaa++\n",
      "ireally\n",
      "trailf\n",
      "everything..was\n",
      "room‚Ä¶\n",
      "-but\n",
      "conspro\n",
      "disagre\n",
      "colleague/friend\n",
      "retrea\n",
      "pleasantstayed\n",
      "..italian\n",
      "hotel+delicious\n",
      "disableds\n",
      "fly/c\n",
      "hugo-business\n",
      "newly-renovated\n",
      "empolyees\n",
      "/wonderful\n",
      "t1m3\n",
      "vegas-caesars\n",
      "musuems\n",
      "typicalvegas\n",
      "btwn\n",
      "traditi\n",
      "starked\n",
      "walkwa\n",
      "Ïù∏ÌÑ∞ÎÑ∑Ïóê\n",
      "10-jan16\n",
      "overnight-\n",
      "balxpny\n",
      "cesarme\n",
      "hisorical\n",
      "monji\n",
      "serviceroom\n",
      "posizione\n",
      "givestr\n",
      "jijji\n",
      "benjam\n",
      "castle-themed\n",
      "expensivw\n",
      "exac\n",
      "over-smoked\n",
      "serviceab\n",
      "mean..\n",
      "2-eff\n",
      "-flore\n",
      "value/fantastic\n",
      "epthimy\n",
      "üåüüåüüåüüåüüåü\n",
      "alex1985\n",
      "dupar\n",
      "location-mixed\n",
      "ever*\n",
      "wirele\n",
      "semi-hidden\n",
      "nongrata\n",
      "br/2\n",
      "coffe\n",
      "everat\n",
      "-quality\n",
      "luxury-\n",
      "dealers/pit\n",
      "enjoed\n",
      "nearly¬£1400\n",
      "august2015\n",
      "marlto\n",
      "smoking/non\n",
      "bhigroog\n",
      "rudiest\n",
      "beds-stayed\n",
      "lunche\n",
      "erics\n",
      "thoroughl\n",
      "amazing..a\n",
      "26t\n",
      "grandish\n",
      "family11\n",
      "undeci\n",
      "shuttlebus\n",
      "nickerbo\n",
      "buffet.food\n",
      "shawdy\n",
      "centrally-placed\n",
      "nicly\n",
      "expierience\n",
      "exelent\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worst/best\n",
      "w/tiny\n",
      "‚Ç¨DG\n",
      "sutisfied\n",
      "room+friendly\n",
      "hotel/price/location\n",
      "standardness\n",
      "casablana\n",
      "ejbt123\n",
      "trumpste\n",
      "coveninet\n",
      "wounderfull\n",
      "most-friendly\n",
      "prison-chic\n",
      "vnea\n",
      "fun/parking\n",
      "bleh\n",
      "new/renovated\n",
      "vegaaaas\n",
      "back.mike\n",
      "pre-t\n",
      "thompson/parks\n",
      "233/ni\n",
      "dsigwing\n",
      "resturants\n",
      "exci\n",
      "sellina\n",
      "shopping/theatre\n",
      "loby\n",
      "approxi\n",
      "sidetrip\n",
      "fransc\n",
      "closecto\n",
      "hotel/hostel\n",
      "amuse/lobby\n",
      "glitsy\n",
      "17h30\n",
      "personnel/\n",
      "what/how\n",
      "convention/pleasure\n",
      "cat-friendly\n",
      "annhal\n",
      "wear/a\n",
      "endin\n",
      "snowey\n",
      "casino-basically\n",
      "opposit\n",
      "fruit-infused\n",
      "employees..the\n",
      "vest-pocket\n",
      "kids..\n",
      "vlue\n",
      "escellent\n",
      "locstion\n",
      "expectef\n",
      "hotel/resort\n",
      "oct.2nd-oct.\n",
      "teamlam\n",
      "w/1\n",
      "waaaaaayy\n",
      "billagio\n",
      "property.pros\n",
      "'red-eye\n",
      "wooowwww\n",
      "ameritania..an\n",
      "hotel-makes\n",
      "once-gran\n",
      "stay.started\n",
      "services/civility\n",
      "night-room\n",
      "adjac\n",
      "surpises\n",
      "rush/di\n",
      "boutiqu\n",
      "pleaseantly\n",
      "aweseome\n",
      "karioki\n",
      "wanderi\n",
      "dewhawn\n",
      "jozh\n",
      "uswill\n",
      "most-good\n",
      "check-in/check\n",
      "tutts\n",
      "conditon\n",
      "start/end\n",
      "noicse\n",
      "faboules\n",
      "flutt\n",
      "hilto\n",
      "stayng\n",
      "hyattthis\n",
      "housekee\n",
      "inconsi\n",
      "asian-insp\n",
      "-arrival\n",
      "◊ï◊ê\n",
      "out-of-the-ordinary\n",
      "supershuttl\n",
      "trip2016\n",
      "movememt\n",
      "liliputi\n",
      "alrea\n",
      "great/unique\n",
      "evertyhing\n",
      "amazaballs\n",
      "stop-\n",
      "linco\n",
      "DGDGDG\n",
      "loceation\n",
      "lobby/restaurant\n",
      "59/f\n",
      "andclean\n",
      "requesti\n",
      "garbagge\n",
      "guets\n",
      "loctaion\n",
      "casino/our\n",
      "urg\n",
      "hapiness\n",
      "15-22nd\n",
      "hawth\n",
      "fabul\n",
      "average-historic\n",
      "DGDG-DG-DGDG\n",
      "werkend\n",
      "‚Äãavoid\n",
      "convention/\n",
      "japantow\n",
      "..espec\n",
      "every1\n",
      "terriblw\n",
      "rentevated\n",
      "so..rooms\n",
      "on-sold\n",
      "downtowner\n",
      "b-\n",
      "klimpton\n",
      "staff2\n",
      "money.nice\n",
      "refurbshed\n",
      "ophisticated\n",
      "dissapointedüôÅ\n",
      "wrigle\n",
      "unfullfilled\n",
      "plumbing/unwanted\n",
      "tvisit\n",
      "guysweekendtrip\n",
      "comodities\n",
      "üôÇ\n",
      "de'ma\n",
      "deep-freeze\n",
      "maitr\n",
      "cabrilobjelic\n",
      "dinora\n",
      "redocorating\n",
      "location/quality/price\n",
      "service/hospitality\n",
      "outside..but\n",
      "uncommunicated\n",
      "squueze\n",
      "fammily\n",
      "salespitch\n",
      "rleaxing\n",
      "noviello\n",
      "scott/sportsbook\n",
      "48lex\n",
      "gay-pride\n",
      "staff/management\n",
      "hily\n",
      "üòÜüòÜüòÜ\n",
      "location/modern/clean\n",
      "ibmer\n",
      "looooove\n",
      "keeeeevin\n",
      "'boutiquey\n",
      "week-amazing\n",
      "30y\n",
      "brown/purple\n",
      "semi-hotel\n",
      "bhm\n",
      "comps/upgrades\n",
      "terriblle\n",
      "exterior/interior\n",
      "kitche\n",
      "gramercy/flatiron\n",
      "testin\n",
      "‚úçÔ∏è‚úçÔ∏è‚úçÔ∏è‚úçÔ∏è‚úçÔ∏è\n",
      "great‚Ä¢hotel\n",
      "cluel\n",
      "whalf\n",
      "c-c-c-construction\n",
      "back.ho\n",
      "afteenoon\n",
      "angelm\n",
      "fuctional\n",
      "cimfort\n",
      "unremodeled\n",
      "millenials\n",
      "re-experience\n",
      "nightlife/restaurant\n",
      "location/high\n",
      "vulnerabilit\n",
      "nice.team\n",
      "ipcpr\n",
      "attenda\n",
      ".history\n",
      "valde\n",
      "small-ish\n",
      "confusing/\n",
      "unconforable\n",
      "affordavle\n",
      "steip\n",
      "impos\n",
      "okay-\n",
      "monday-\n",
      "insu\n",
      "business/leasure\n",
      "lake-view\n",
      "higher-lower\n",
      "second-timer\n",
      "barcley\n",
      "knickerbocke\n",
      "greatl\n",
      "yomaries\n",
      "4-st\n",
      "cathphilstockport\n",
      "checki9ng\n",
      "journo\n",
      "summ\n",
      "administratiors\n",
      "magnficent\n",
      "location-horrible\n",
      "okei\n",
      "hubbys\n",
      "beautiful-very\n",
      "stacycation\n",
      "deals/unsafe\n",
      "wayer\n",
      "sf-\n",
      "ir√°\n",
      "uncleanly\n",
      "flucht\n",
      "overl\n",
      "be-big\n",
      "ponde\n",
      "alright..\n",
      "mega-expensive\n",
      "prosperfect\n",
      "roomsb\n",
      "terrificly\n",
      "expensif\n",
      "appointe\n",
      "owsum\n",
      "doubletreetimessquare\n",
      "fischerman\n",
      "demefrie\n",
      "jujjust\n",
      "cheata\n",
      "romantic/nice\n",
      "top-location\n",
      "tarika\n",
      "with..\n",
      "feelings-\n",
      "twelv\n",
      "repeate\n",
      "square/broadwa\n",
      "accomodationg\n",
      "manager/supervisor\n",
      "downtown..\n",
      "ammeni\n",
      "heritaget\n",
      "accommodations-non-accommodating\n",
      "suite-n\n",
      "grimaldi/kenny\n",
      "member-give\n",
      "demesa\n",
      "milleni\n",
      "chinatown/little\n",
      "unproffesional\n",
      "themarcelhotel\n",
      "aircon/heating\n",
      "aporeciated\n",
      "mommy/daddy\n",
      "matt-food/beverage\n",
      "unprofessionell\n",
      "-another\n",
      "changeble\n",
      "connol\n",
      "historu\n",
      "excalibur..dont\n",
      "estad√≠a\n",
      "chippi\n",
      "staff/shady\n",
      "eric-\n",
      "h√¥tellerie\n",
      "10/10front\n",
      "ciscolive\n",
      "friday-mond\n",
      "econo-lodge\n",
      "stripeverythi\n",
      "trendy/vibrant\n",
      "yoly\n",
      "freedo\n",
      "doury\n",
      "44t\n",
      "deal1\n",
      "strip/downtown\n",
      "p-ho\n",
      "ÊÇ™„ÅÑ\n",
      "totall\n",
      "location/friendly\n",
      "big/clean\n",
      "'experience\n",
      "i'am\n",
      "down-at-the-heels\n",
      "comfo\n",
      "inaceptable\n",
      "diamondmember\n",
      "^0th\n",
      "location/price/service/a\n",
      "alawys\n",
      "rooms\\nfriendly\n",
      "upper-west-side\n",
      "edison-art\n",
      "servicefeel\n",
      "thetrump\n",
      "absur\n",
      "requiri\n",
      "convince..\n",
      "stunnig\n",
      "paramoun\n",
      "palace..\n",
      "avererage\n",
      "covenience\n",
      "inste\n",
      "attem\n",
      "thry\n",
      "excellent‚Äã\n",
      "location.superb\n",
      "vaction\n",
      "explori\n",
      "hotelüòÄ\n",
      "forun\n",
      "midtown/penn\n",
      "contacte\n",
      "beds-\n",
      "nycthe\n",
      "hotel/timesha\n",
      "holiwood\n",
      "masquarade\n",
      "remoled\n",
      "excellentmay\n",
      "fromfinland\n",
      "18.aug\n",
      "bedrooms-\n",
      "well-maintai\n",
      "hotel-amenities\n",
      "butterrible\n",
      "3day\n",
      "renovations-\n",
      "find-\n",
      "lobby/location\n",
      "soundproo\n",
      "desk-luisa\n",
      "ballys.1s\n",
      "perfectio\n",
      "homeymoon\n",
      "samesame\n",
      "price-conscious\n",
      "jumpe\n",
      "üëçüëçüíó\n",
      "DG**\n",
      "casino/rooms/food\n",
      "great-\n",
      "pedestr\n",
      "clowns/thieves\n",
      "bad.a\n",
      "siuit\n",
      "astou\n",
      "nycstaff\n",
      "vaccation\n",
      "hawthor\n",
      "'doubletr\n",
      "feb-6th\n",
      "goodthe\n",
      "experienc\n",
      "much-deserved\n",
      "eccerntricities\n",
      "excellante\n",
      "chicagovisit\n",
      "y.o\n",
      "1.that\n",
      "holistay/\n",
      "free.they\n",
      "room/housekeeping\n",
      "bombin\n",
      "aaahhhhhhhhhh\n",
      "easy.workers\n",
      "w/teenage\n",
      "hobbit-sized\n",
      "unsatisfied/disappointed\n",
      "day.had\n",
      "disappointnig\n",
      "'bonkerz\n",
      "say..we\n",
      ".top\n",
      "ghos\n",
      "hotel..wonderful\n",
      "pplace\n",
      "absoulty\n",
      "double-check\n",
      "acckmodations\n",
      "comortable\n",
      "friday.o\n",
      "a-\n",
      "ever-the\n",
      "vegas-lots\n",
      "run-cation\n",
      "staffs..\n",
      "monry\n",
      "thenlocation\n",
      "vindict\n",
      "‚ô°caesars\n",
      "yana-best\n",
      "inlaw\n",
      "gramerc\n",
      "morrisse\n",
      "goodlocation\n",
      "reinv\n",
      "jers\n",
      "locationi\n",
      "bigten\n",
      "innrooms\n",
      "seneka\n",
      "awful..\n",
      "here.pros\n",
      "envoronment\n",
      "suede-covered\n",
      "pooooool\n",
      "5mins\n",
      "firepit\n",
      ".while\n",
      "sportdbook\n",
      "hutzpah\n",
      "beekma\n",
      "agustus\n",
      "restfu\n",
      "valueable\n",
      "but..wow..1st\n",
      "-worst\n",
      "grest\n",
      "availabl\n",
      "wow‚Ä¶\n",
      "neighborh\n",
      "sir/madambooking\n",
      "caesar'a\n",
      "spots..\n",
      "wekend\n",
      "ammentities\n",
      "disappontment\n",
      "relativ\n",
      "nadirah\n",
      "juliu\n",
      "dangerou\n",
      "bugsys\n",
      "registra\n",
      "beatutiful\n",
      "localiza√ß√£o\n",
      "kindnes\n",
      "üôÅ\n",
      "oppulence\n",
      "mediocre-\n",
      "***horrible***\n",
      "partt\n",
      "csrsars\n",
      "service*\n",
      "water/coffee\n",
      "confu\n",
      "botiue\n",
      "ritz-carl\n",
      "rest/stay\n",
      "9/21/2016..never\n",
      "lucury\n",
      "tables/\n",
      "brillian\n",
      "sept/oct\n",
      "sloooooooowest\n",
      "fantasticoooo\n",
      "removated\n",
      "packag\n",
      "childish/archa\n",
      "july/beginning\n",
      "daug\n",
      "experiences/vegas\n",
      "concerge/\n",
      "unbelinqable\n",
      "'hood\n",
      "ypperlig\n",
      "qway\n",
      "staygre\n",
      "Í≥†ÎßôÎã§Îäî\n",
      "over-valued\n",
      "giordanos\n",
      "parking/construction\n",
      "brekky\n",
      "average..smoky\n",
      "upscal\n",
      "occasio\n",
      "rooms/amenitie\n",
      "outdon\n",
      "ÊãâÊñØÁª¥Âä†ÊñØÂ§ßÈÅìÊ†∏ÂøÉÂú∞ÊÆµÁöÑÊûóÂÖãÈÖíÂ∫ólinq\n",
      "DG-DGDGDG\n",
      ".young\n",
      "..nearly\n",
      "reception-excellent\n",
      "meeeh\n",
      "thirdhand\n",
      "strategically-located\n",
      "cofortabel\n",
      "decei\n",
      "hotels.seclean\n",
      "solei\n",
      "thing..\n",
      "location/restaurant\n",
      "DG/DG/DGDG-DG/DGDG/DGDG\n",
      "service/cleaning\n",
      "lovatiln\n",
      "moxy-big\n",
      "mailfunctioned\n",
      "air-keeping\n",
      "strip‚ÄºÔ∏è\n",
      "prime1\n",
      "alack\n",
      "diegos\n",
      "unsolicite\n",
      "service..thanks\n",
      "inoubliables\n",
      "location.brand\n",
      "awayl\n",
      "planethollywood\n",
      "immacul\n",
      "thoughful\n",
      "superp\n",
      "philha\n",
      "spelinio\n",
      "chapero\n",
      "captian\n",
      "loft-like\n",
      "lasal\n",
      "10/day\n",
      "ha'nah\n",
      "beautiful-staff\n",
      "purch\n",
      "nighmare\n",
      "**d\n",
      "aniverary\n",
      "~not\n",
      "mid0town\n",
      "exca\n",
      "ny|manhattan\n",
      "small..internet\n",
      "gmail.com\n",
      "‚ù§Ô∏è\n",
      "exilerating\n",
      "well-design\n",
      "sister-in-\n",
      "aahh\n",
      "appropiate\n",
      "renovatin\n",
      "eybl\n",
      "palya\n",
      "thanks.the\n",
      "shopping/attraction\n",
      "stinkey\n",
      "bugsout\n",
      "intelleg\n",
      "priced-but\n",
      "knickerbo\n",
      "harraka\n",
      "-most\n",
      "shuttl\n",
      "re-model\n",
      "ourgirlscalitrip2016\n",
      "consierges\n",
      "roomsnot\n",
      "jan.02\n",
      "markandgloria\n",
      "bac322\n",
      "cuite\n",
      "unfavor\n",
      "22nd-24th\n",
      "primr\n",
      "month.hotel\n",
      "unpleas\n",
      "ecellent\n",
      "nancys\n",
      "'grand\n",
      "expectatipn\n",
      "romon\n",
      "loacted\n",
      "'li\n",
      "hotel-amazing\n",
      "busuiness\n",
      "value/nice\n",
      "stayand\n",
      "/paris\n",
      "rooms/service/food\n",
      "üêÄ\n",
      "nice.some\n",
      "5days\n",
      "goodlast\n",
      "maded\n",
      "mother/daugher\n",
      "wowmy\n",
      "centeraly\n",
      "crowdiest\n",
      "non-casi\n",
      "stay-nj\n",
      "outda\n",
      "akada\n",
      "secti\n",
      "7'th\n",
      "location/thin\n",
      "kbis\n",
      "sumpt\n",
      "ciyty\n",
      "'vintage\n",
      "marriott/starwood\n",
      "closer.get\n",
      "row-great\n",
      "cosmoplitan\n",
      "bouteeky\n",
      "'centric\n",
      "upgra\n",
      "sept.stay\n",
      "islan\n",
      "nice-craps\n",
      ".plenty\n",
      "weiry\n",
      "treasure-travel\n",
      "nonsmokin\n",
      "ikriem\n",
      "relexing\n",
      "feb.2015\n",
      "in/\n",
      "2018we\n",
      "pleazzzzz\n",
      "locacaton\n",
      "therw\n",
      "everence\n",
      "einfaches\n",
      "place/super\n",
      "circel\n",
      "make-\n",
      "experience.not\n",
      "anniersary\n",
      "ü§¢\n",
      "warwich\n",
      "microhotel\n",
      "cosiest\n",
      "disclosur\n",
      "accommodations/good\n",
      "12-14mar17\n",
      "beststaffev\n",
      "strip/fountains\n",
      "nyc.we\n",
      "bachlorerte\n",
      "wheelc\n",
      "confinient\n",
      "highway..close\n",
      "marrak\n",
      "milenial\n",
      "halls/\n",
      "cleancustomer\n",
      "de'marcus\n",
      "avrage\n",
      "educati\n",
      "heakth\n",
      "lobby/room\n",
      "brittiania\n",
      "adjoyi\n",
      "first-rat\n",
      "humormaking\n",
      "shicking\n",
      "elizab\n",
      "applian\n",
      "orienteds\n",
      "deliteful\n",
      "go-ers\n",
      "plunger.and\n",
      "card/slot\n",
      "citizencel\n",
      ".fun\n",
      "celebrity-\n",
      "gomad\n",
      "hospitabl\n",
      "stop-ov\n",
      "weinste\n",
      "faclities\n",
      "gererally\n",
      "nyc.centr\n",
      "accompan\n",
      "room/good\n",
      "post-cr\n",
      "broadway-perfect\n",
      "stay.park\n",
      "club/disco\n",
      "carees\n",
      "comfortable-nothing\n",
      "friendly/help\n",
      "hard-sell\n",
      "centre/female\n",
      "newyorker\n",
      "conformtable\n",
      "notificati\n",
      "seriously-\n",
      "ammenitie\n",
      "expectations..\n",
      "holday\n",
      "a-ok\n",
      "p.h\n",
      "..fro\n",
      "-primaril\n",
      "good.impres\n",
      "madisson\n",
      "modern/hip\n",
      "and\\npri\n",
      "pllace\n",
      "overite\n",
      "10:00pm\n",
      ".dirty\n",
      "alarmi\n",
      "brgr\n",
      "feath\n",
      "midrang\n",
      "alcatr\n",
      "busniess\n",
      "hispitality\n",
      "showc\n",
      "boulevarde\n",
      "location‚Äîwithin\n",
      "üè†\n",
      "impressio\n",
      "resort-very\n",
      "pros-nice\n",
      "service/attitude\n",
      "*home*\n",
      "horiffic\n",
      "parkvery\n",
      "firepl\n",
      "conferenceattendee\n",
      "petstay\n",
      "anniversa-date\n",
      "wheneve\n",
      "cheerf\n",
      "seasons-five\n",
      "cascity\n",
      "babymoon\n",
      "grand-my\n",
      "efffected\n",
      "apalled\n",
      "-spg\n",
      "rothenhaus\n",
      "serviceüëåüèº\n",
      "queuei\n",
      "innocenzi\n",
      "luv2travel\n",
      "timeshare/condo\n",
      "tripadvis\n",
      "times.ver\n",
      "terrible/inefficient\n",
      "Îß§Ïö∞\n",
      "rork\n",
      "clealiness\n",
      "disadvanta\n",
      "2+3+4th\n",
      "√∏ur\n",
      "experience/fantastic\n",
      "square/b\n",
      "oark\n",
      "kabuk\n",
      "greed/incompetence\n",
      "realiz\n",
      "location-den\n",
      "executice\n",
      "carlos..excellent\n",
      "strip-excellent\n",
      "descriminat\n",
      "location+\n",
      "location..\n",
      "Â§™Â∑ÆÁöÑÈÖíÂ∫ó\n",
      "jly\n",
      "woukdbt\n",
      "medwed-parker\n",
      "rooms/location\n",
      "hotel-was\n",
      "grand..\n",
      "highlite\n",
      "room-wish\n",
      "cany\n",
      "starwood/westin\n",
      "gambler39\n",
      "pot/unclean\n",
      "placethe\n",
      "nights.r\n",
      "nooooo..\n",
      "st.regis\n",
      "yohenn\n",
      "f-a-n-t-a-s-t-i-c\n",
      "doopy\n",
      "amsterd\n",
      "chearfull\n",
      "pre-cruise\n",
      "joelro\n",
      "nickel-and\n",
      "condo/suite\n",
      "christmas-nyc\n",
      "reiks\n",
      "hotel/tremendous\n",
      "district..\n",
      "pyramid..\n",
      "chicaco\n",
      "hamb\n",
      "harrah's.\n",
      "nylo-\n",
      "repear\n",
      "'wake\n",
      "f.hannemann\n",
      "ndw\n",
      "ommmm\n",
      "tribecc\n",
      "talbott-\n",
      "good-if-mixed\n",
      "hurri\n",
      "absoultey\n",
      "stay.rude\n",
      "woluld\n",
      "orlea\n",
      "roomm√∫ltiple\n",
      "basicbusiness\n",
      "i‚ù§Ô∏èny\n",
      "vegas-experience\n",
      "***first\n",
      "supr\n",
      "survice\n",
      "wow-every\n",
      "surprizingly\n",
      "vegasness\n",
      "unreasonabl\n",
      "check-inbooking\n",
      "organizatio\n",
      "fautless\n",
      "doesnot\n",
      "stying\n",
      "painfull\n",
      "nine-night\n",
      "rate..\n",
      "cherylewe\n",
      "hollwood\n",
      "prechristmas\n",
      "trip.hotel\n",
      "avles\n",
      "dinne\n",
      "rooms/food\n",
      "m_g_\n",
      "shazzfant\n",
      "brunch,11-4\n",
      "casinos-r\n",
      "celetration\n",
      "brand-spanking\n",
      "ambian\n",
      "DGDGDGDG/DGDGDG\n",
      "staffcame\n",
      "imrpoving\n",
      "unfor\n",
      "discrimin\n",
      "medriocre\n",
      ".acceptab\n",
      "good-some\n",
      "duhadaway\n",
      "check-in-\n",
      "primier\n",
      "proprerty\n",
      "bustly\n",
      "..please\n",
      "2db\n",
      "eldes\n",
      "woderful\n",
      "caitl\n",
      "firmdale\n",
      "pool/water\n",
      "infrastructu\n",
      "staff.this\n",
      "inissues\n",
      "cnveniences\n",
      "insectos\n",
      "resrort\n",
      "temperatu\n",
      "copmfortable\n",
      "oour\n",
      "hour..\n",
      "coackroach\n",
      "steared\n",
      "aerial-\n",
      "manathan\n",
      "ever-\n",
      "pet-friendly\n",
      "roomgreat\n",
      "in-transit\n",
      "renais\n",
      "ÔºíÔºêÔºëÔºòÂπ¥ÔºóÊúà„Å´‰πÖ„Åó„Å∂„Çä„ÅÆ„Éã„É•„Éº„É®„Éº„ÇØÊóÖË°å„Çí„Åó„ÅüÈöõ„ÄÅ\n",
      "sevice/hotel\n",
      "space-better\n",
      "logisti\n",
      "gton\n",
      "disappointed.very\n",
      "depressin\n",
      "a1if\n",
      "wondefu\n",
      "families/small\n",
      ".disappointing\n",
      "begin..\n",
      "vacationüòä\n",
      "rooms-good\n",
      "arcitecture\n",
      "hotel-very\n",
      "nyc.a\n",
      "obstructe\n",
      "baaaaaaaaaaaack\n",
      "palazzo/ventitian\n",
      "wonkas\n",
      "concierge/receptionist\n",
      "squashy\n",
      "starwoo\n",
      "friendliess\n",
      "concen\n",
      "honn√™te\n",
      "chowd\n",
      "comforte\n",
      "ugghhhhh\n",
      "-sense\n",
      "shhhowtime\n",
      "basics-\n",
      "jacu\n",
      "wellk\n",
      "trrrrrrbl-great\n",
      "midwe\n",
      "turkmenoglu\n",
      "firewo\n",
      "business/fami\n",
      "watee\n",
      "staynew\n",
      "40mins\n",
      "notgood\n",
      "waouh\n",
      "stay..\n",
      "customer-hands\n",
      "sound-proofing\n",
      "convienantly\n",
      "fashi\n",
      "luxury.close\n",
      "proprry\n",
      "non-updated\n",
      "sofa-bedvery\n",
      "center-strip\n",
      "nolannln\n",
      "locationthis\n",
      "goodni\n",
      "staff.complimenta\n",
      "stayied\n",
      "gaurantee\n",
      "comfortable/good\n",
      "trip/weeken\n",
      "luggag\n",
      "21us\n",
      "definantly\n",
      "staff|\n",
      "mainten\n",
      "happy-wo\n",
      "timing/leaky\n",
      "ibrocevic-a\n",
      "hrsf\n",
      "demodeled\n",
      "hanpton\n",
      "excitem\n",
      "october-\n",
      "7-11th\n",
      "styaing\n",
      "hidea\n",
      "roomgood\n",
      "subtr\n",
      "**please\n",
      "mass-service\n",
      "continures\n",
      "prostit\n",
      "non-vegas-y\n",
      "beddings\n",
      "omg..\n",
      "alre\n",
      "bargain-\n",
      "location.frien\n",
      "pullman-coac\n",
      "independ\n",
      "size-\n",
      "heat/air\n",
      "very/busy\n",
      "okok\n",
      "fans‚ù§Ô∏è\n",
      "lisagnome\n",
      "2-room\n",
      "5minute\n",
      "amazzzzzzzing\n",
      "beautif\n",
      "represen\n",
      "warning-they\n",
      "airfild\n",
      "restoratio\n",
      "hotel.internet\n",
      "disho\n",
      "high-ceilings\n",
      "trandy\n",
      "stay-girlfriends\n",
      "lvnv17\n",
      "hotel-lack\n",
      "ibie\n",
      "footba\n",
      "'see\n",
      "salv\n",
      "ÔºöÔºà\n",
      "considerin\n",
      "nice/upgraded\n",
      "tri-fecta\n",
      "coment\n",
      "mimimi\n",
      "newyearseve\n",
      "fanilies\n",
      "temporar\n",
      "repla\n",
      "bdy\n",
      "grandpar\n",
      "north/broadway\n",
      "managers/dealers\n",
      "maintaned\n",
      "giul\n",
      ".open\n",
      "19th/23rd\n",
      "sffd\n",
      "generator/v\n",
      "bungleows\n",
      "hyd\n",
      "wasn'r\n",
      "taylia\n",
      "seamles\n",
      "amaing\n",
      "points1\n",
      "withou\n",
      "eateries-\n",
      "casinolocation\n",
      "stay-very\n",
      "birthdayüòä\n",
      "ohnono\n",
      "servicr\n",
      "ü§ôüèº\n",
      "malaysi\n",
      "night-but\n",
      "24th-nyc\n",
      "33/day\n",
      "brigh\n",
      "stay/recommend\n",
      "visibl\n",
      "joey1134\n",
      "cartwri\n",
      "w40th\n",
      "DG/DG/DGDG/-\n",
      "activiti\n",
      "turn-up\n",
      "reservatons\n",
      "cumpl\n",
      "meetings/\n",
      "oppositie\n",
      "atmosfere\n",
      "surposed\n",
      "busin\n",
      "placeüåüüåüüåüüåüüåü\n",
      "good.security\n",
      "mixtur\n",
      "angelinos\n",
      "travalodge\n",
      "over-priced\n",
      "well-d\n",
      "villa.gr\n",
      "avoid..\n",
      "nicestay\n",
      "ganesvoort\n",
      "plently\n",
      "feel..\n",
      "moderm\n",
      "madeover\n",
      "collec\n",
      "staff/ser\n",
      "brookl\n",
      "hearld\n",
      "wothless\n",
      "hadnt\n",
      "estab\n",
      "areas/broken\n",
      "enterntainment\n",
      "relas\n",
      "price,5\n",
      "10night\n",
      "fafded\n",
      "mamagement\n",
      "employees/great\n",
      "‚öòüçÉ\\ni\n",
      "efficient-sized\n",
      "expectaions\n",
      "goodservice\n",
      "lindah\n",
      "tobtimes\n",
      "ontheav\n",
      "ti-\n",
      "plumbing/noise\n",
      "best..shows\n",
      "249/night\n",
      "jasmim\n",
      "jarrel\n",
      "entrence\n",
      "deliverin\n",
      "family-gramm\n",
      "50yrs\n",
      "excella\n",
      "refrige\n",
      "incons\n",
      "ms.christine\n",
      "hotel.first\n",
      "fair..\n",
      "tour‚Ä¶\n",
      "disappointements\n",
      "building/\n",
      "embacadero\n",
      "nights-\n",
      ".shuttle\n",
      "business/bring\n",
      "door‚Ä¶\n",
      "chicago/family\n",
      "helloooo\n",
      "gingerbrea\n",
      "tourist.hotel\n",
      "poolgirl\n",
      "beds.wi\n",
      "breakfast+free\n",
      "edgie40\n",
      "firshermans\n",
      "aforable\n",
      "..top\n",
      "traditio\n",
      "pyra-midd-le\n",
      "hotel/rotten\n",
      "crowdvery\n",
      "rooms-centrally\n",
      "veryspac\n",
      "casino/bland\n",
      "ŸÖŸÖÿ™\n",
      "w0w\n",
      "inticed\n",
      "mother/daught\n",
      "4-hours\n",
      "upstair\n",
      "-worn\n",
      "dissappointent\n",
      "p-e-r-f-e-c-t\n",
      "breekman\n",
      "-may\n",
      "grreeaatt\n",
      "greeti\n",
      "rcmh\n",
      "americania\n",
      "slipper/wet\n",
      "perspecti\n",
      "18th-22\n",
      "time-stayed\n",
      "hotelfirsttime.we\n",
      "archite\n",
      "fabulouslness\n",
      "üòçüíö\n",
      "refreshme\n",
      "accomoda\n",
      "peny\n",
      "yasamin\n",
      "a++\n",
      "amazing.new\n",
      "pro-mat\n",
      "valentines/anniversary\n",
      "v√°rios\n",
      "dodgiest\n",
      "surrou\n",
      "infe\n",
      "'uns\n",
      "ok‚Ä¶\n",
      "comfortab\n",
      "three-d\n",
      "indifferent..\n",
      "breakfast/room\n",
      "entreatments\n",
      "pool/aquapar\n",
      "and/friends\n",
      "specislist\n",
      "district/chinatown\n",
      "middelclass\n",
      "modernisati\n",
      "kind/\n",
      "¬¥ve\n",
      "staff/owner\n",
      "ny..in\n",
      "maravilhoso\n",
      "travele\n",
      "attent\n",
      "cappuc\n",
      "well-appointed/newly\n",
      "best.hotel.ever.\n",
      "earthüèÜ\n",
      "21stbirthday\n",
      "realstate\n",
      "enjoyabl\n",
      "118/si\n",
      "visit/\n",
      "migely/cusank\n",
      "xasino\n",
      "post-rennovation\n",
      "hotelfactory\n",
      "subwa\n",
      "defia\n",
      "virw\n",
      "27t\n",
      "firmont\n",
      "prentenion\n",
      "everywher\n",
      "troubl\n",
      "roomsize\n",
      "street/airport\n",
      "40t\n",
      "comstruction\n",
      "hopefull\n",
      "ultra-chic\n",
      "1st.class\n",
      "paris-in\n",
      "great.it\n",
      "comfortability\n",
      "busy..\n",
      "remodell\n",
      "ex-stream\n",
      "faceift\n",
      "at.lov\n",
      "genti\n",
      "so..fi\n",
      "lobby/receptio\n",
      "exell\n",
      "birthday-spectacular\n",
      "breakast\n",
      "//www.tripadvisor.com/userreview-g60763-\n",
      "incle\n",
      "modern..\n",
      "negatives-\n",
      "inidgo\n",
      "everythign\n",
      "eys\n",
      "nnew\n",
      "only-non\n",
      "standard-\n",
      "mischarged\n",
      "schmanzy\n",
      "coconugget\n",
      "iconicl\n",
      "zetta-redone\n",
      "hotel..perfect\n",
      "super-friendl\n",
      "450/nigh\n",
      "heven\n",
      "aniiversary\n",
      "service/outdate\n",
      "occasionall\n",
      "frankg\n",
      "tue-fri\n",
      "airconditi\n",
      "imposibl\n",
      ".see\n",
      "unavai\n",
      "recemmend\n",
      "comman\n",
      "s-l-o-w\n",
      "grrat\n",
      "thewit\n",
      "plac√©\n",
      "pr/customer\n",
      ".duck\n",
      "lv.got\n",
      "stay-for\n",
      "5we\n",
      "rockfella\n",
      "carsars\n",
      "desrve\n",
      "avoiding..\n",
      "funexcellent\n",
      "dirty/rude\n",
      "alsom\n",
      "forfive\n",
      "r+f\n",
      "square/javits\n",
      "pennysylva\n",
      "borukhov\n",
      "360vegas\n",
      "smoke/casino\n",
      "consistent/ok\n",
      "oldsport\n",
      "graleat\n",
      "mis-fire\n",
      "histry\n",
      "unbearabl\n",
      "tendy\n",
      "pictu\n",
      "habita\n",
      "westhouse-first\n",
      "suite-pool\n",
      "cub/cards\n",
      "hollywood/modern\n",
      "lower-floor\n",
      "seen-never\n",
      "midn\n",
      "70thbirthday\n",
      "gameswould\n",
      "sigh~\n",
      "transfare\n",
      "sabrena\n",
      "yesira\n",
      "deepstack\n",
      "twon\n",
      "this\\nhotel\n",
      "up..twice\n",
      "get-awayy\n",
      "elysi\n",
      "trip.the\n",
      "7:40am\n",
      "un-upgraded\n",
      "2013.e\n",
      "stay.arrival\n",
      "pre-checked\n",
      "DGDG/DGDG-\n",
      "pampere\n",
      "terace\n",
      "iber\n",
      "81/ni\n",
      "rigth\n",
      "first-e\n",
      "frigobar\n",
      "mandelay\n",
      "you¬¥d\n",
      "fastastic\n",
      "-breakfast\n",
      "hwad\n",
      "people/service\n",
      "pool.good\n",
      "70us\n",
      "daghter\n",
      "thnaksgiving\n",
      "first-timers\n",
      "eeeek\n",
      "lasve\n",
      ".pity\n",
      "-given\n",
      "stars/diamonds/dots\n",
      "pillo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conveninet\n",
      "concert.if\n",
      "weekend‚Äîwish\n",
      "pstory\n",
      "soho/tribeca\n",
      "accomodatons\n",
      "onvernight\n",
      "romms\n",
      "towere\n",
      "26apr\n",
      "dingy/dirty\n",
      "location-staff\n",
      "efficiency-style\n",
      "beautful\n",
      "perne\n",
      "luggage..sheets\n",
      "locatrd\n",
      "here***-\n",
      "view/great\n",
      "faciility\n",
      "starema\n",
      "rioom\n",
      "fees..\n",
      "gross-\n",
      "4-ni\n",
      "legen\n",
      "ipadembassy\n",
      "soho/c\n",
      "departi\n",
      "casab\n",
      "colaboration\n",
      "ny-stay\n",
      "locationshould\n",
      "desonest\n",
      "uninspi\n",
      "casino/hotel\n",
      "ratzker\n",
      "bell/lobby\n",
      "consci\n",
      "controve\n",
      "placeand\n",
      "determi\n",
      "condencending\n",
      "well-thought-\n",
      "experience..\n",
      "a+++++++++\n",
      "disab\n",
      "megabu\n",
      "üçæ\n",
      "clasd\n",
      "mysteri\n",
      "majorit\n",
      "bay/delano\n",
      "ehhhhhh\n",
      "located-\n",
      "immatu\n",
      "sister-in-l\n",
      "inviti\n",
      "/leisure\n",
      "aafew\n",
      "conference/work\n",
      "comferstbk\n",
      "t/t\n",
      "handr\n",
      "aroundcthe\n",
      "tripdate\n",
      "mandaly\n",
      "lakeshake\n",
      "singers5252\n",
      "thereif\n",
      "¬£¬£¬£\n",
      "ms.mckenzie\n",
      "miidtown\n",
      "annivarsery\n",
      "user-unfriendly\n",
      "flammingo\n",
      "haloween\n",
      "nightbreak\n",
      "dependab\n",
      "impolit\n",
      "newi\n",
      "rcommend\n",
      "'stand\n",
      "accomdati\n",
      "lesoleil\n",
      "be-close\n",
      "ameniti\n",
      "strengthwhen\n",
      "bavk\n",
      "king-si\n",
      "price-value\n",
      "ameritina\n",
      "pool/spa\n",
      "hotel/location/\n",
      "downtownhotel\n",
      "sokay\n",
      "michelang\n",
      "management/customer\n",
      "'winter\n",
      "..below\n",
      "cleane\n",
      "hotel/casi\n",
      "thisbhotel\n",
      "buisness/fun\n",
      "perple\n",
      "hotelphile\n",
      "fweekend\n",
      "workshop/owner\n",
      "outstanding-highly\n",
      "well-decor\n",
      "encoreüíï‚ù§Ô∏èüèÜ\n",
      "slslasvegas\n",
      "motiflots\n",
      "room/suite.it\n",
      "comfortable.beautifu\n",
      "con-s.\n",
      "oolala\n",
      "pricelin\n",
      "stay11\n",
      "alll\n",
      ".smoky\n",
      "high-line\n",
      "in-hous\n",
      "work.cl\n",
      "'premium\n",
      "unaccep\n",
      ",DG\n",
      "beabutiful\n",
      "ewwwww\n",
      "premiumdou\n",
      "sqaur\n",
      "unhe\n",
      "parking.and\n",
      "free..\n",
      "nycm\n",
      "beautiful‚Äî\n",
      "attr\n",
      "consisten\n",
      "reasons1\n",
      "websit\n",
      "parissienne-themed\n",
      "fsirmo\n",
      "◊ò◊ï◊ë\n",
      "tmts\n",
      "merveilleuses\n",
      "DGDG*DG\n",
      "üò†\n",
      "informin\n",
      "overpar*\n",
      "location.stayed\n",
      "sightseeing/theatre\n",
      "getawat\n",
      "place/tons\n",
      "bad~\n",
      "convieneint\n",
      "leaveüò±\n",
      "instae\n",
      "exerience\n",
      "york/che\n",
      "summervisit\n",
      "park..\n",
      "hostsgr\n",
      "borique\n",
      "cromwell-fabulous\n",
      "enteri\n",
      "hollywo\n",
      "geeting\n",
      "overr\n",
      "outsatanding\n",
      ".prices\n",
      "rounderful\n",
      "daygoo\n",
      "2015let\n",
      "grea\n",
      "spot..perfect\n",
      "district/times\n",
      "zen-like\n",
      "nightand\n",
      "unique/eclectic\n",
      "park-europea\n",
      "fourseason\n",
      "hotel/casin\n",
      "sweatboxofdoom\n",
      "resveration\n",
      "..perfect\n",
      "wed-sun\n",
      "undersatandabl\n",
      "spectacluar\n",
      "chicago-south/umc\n",
      "s√©jour\n",
      "celiacs\n",
      "xsmall\n",
      "location.good\n",
      "enoug\n",
      "manager-renata\n",
      "rpscottvb\n",
      "9-night\n",
      "businees\n",
      "wwellington\n",
      "fronk\n",
      "choice-\n",
      "aaaaa+++++\n",
      "◊†◊í◊ô◊©◊ï◊™\n",
      "sightseeing-\n",
      "..horrible\n",
      "lnternet\n",
      "super-fancy\n",
      "location/tower\n",
      "corfortable\n",
      ".friendly\n",
      "employee-customer\n",
      "chandree\n",
      "relaxing/\n",
      "beaware\n",
      "definetly\n",
      "stay.a\n",
      "1197p\n",
      "vegas/\n",
      "ambiance-\n",
      "scrol\n",
      "clean.pros\n",
      "cosmopolitain\n",
      "'windy\n",
      "stayvacation\n",
      "mediter\n",
      "üòõ\n",
      "oyste\n",
      "manadarin\n",
      "bait-and-switch\n",
      "glitch..kimpton\n",
      "hicups\n",
      "christkindel\n",
      "girlfiends\n",
      "mid-ra\n",
      "cheapshuttle\n",
      "necessitie\n",
      "dime-\n",
      "..biggest\n",
      "scratc\n",
      "unsensitive\n",
      "premides\n",
      "competition/family\n",
      "underwhelmin\n",
      "DG****\n",
      "outdated.\n",
      ".rosaria\n",
      "üá∫üá∏‚úàÔ∏è\n",
      "reguards\n",
      "cafe/bar\n",
      "leaki\n",
      "suite/tower\n",
      "old-\n",
      "grand‚Ä¶\n",
      "non-patron\n",
      "stations-\n",
      "westsgate\n",
      "girlfrie\n",
      "room-clean\n",
      "uncomf\n",
      ".blood\n",
      "10month\n",
      "gymnasti\n",
      "excelletnt\n",
      "excellanr\n",
      "place.easy\n",
      "views.i\n",
      "a..ma\n",
      "displ\n",
      "embarcad\n",
      "nyc-good\n",
      "nasscar\n",
      "disappointedüòì\n",
      "dsy\n",
      "nobod\n",
      "macarons\n",
      "cenrall\n",
      "faboulous\n",
      "weeke\n",
      "zabars\n",
      "Èõñ‰∏çÊòØÂú®vegas\n",
      "and-na\n",
      "pictures..\n",
      "roomsattentive\n",
      "waits/roaches\n",
      "inaccuaracies\n",
      "suite-excellent\n",
      "renovated.pros\n",
      "hotwl\n",
      "underdelivered\n",
      "greeeeeat\n",
      "november/decem\n",
      "‰ΩçÊñºthe\n",
      "location.hot\n",
      "^_^\n",
      "fineroom\n",
      "keenah\n",
      "costomer\n",
      "visit.the\n",
      "servuce\n",
      "s*+\n",
      "hotel-dirty\n",
      "intermitent\n",
      "lobby/casi\n",
      "elevetors\n",
      "recption\n",
      "midtown/theater\n",
      "roomsfriendl\n",
      "pichini\n",
      "forenelli\n",
      "eco-hotel\n",
      "scener\n",
      "enjoyab\n",
      "enough-very\n",
      "enormo\n",
      "service/hotel\n",
      "gemsto\n",
      "ventila\n",
      "odorle\n",
      "eaterie\n",
      "here..\n",
      "newwork\n",
      "syste\n",
      "mini-hyatt\n",
      "consc\n",
      "broulio\n",
      "ameniteis\n",
      "fehlt\n",
      "places-\n",
      "horrible/\n",
      "confort√°vel\n",
      "row..\n",
      "intermi\n",
      "prresidents\n",
      "DG/DG/DGDG-DG/DGDG\n",
      "stay*\n",
      "commercial-\n",
      "residences.alleged\n",
      "coustomer\n",
      "h.j\n",
      "room/convenient\n",
      "breatht\n",
      "headach\n",
      "location.a/c\n",
      "haunted.i\n",
      "exp√©ri\n",
      "captain-david\n",
      "price-bad\n",
      "unforgettab\n",
      "service/housekeepi\n",
      "york-\n",
      "cromwellll\n",
      "baaaack\n",
      "park/times\n",
      "ineffic\n",
      "invo\n",
      "ugraded\n",
      "convi\n",
      "mid-\n",
      "sean-bellman\n",
      "somewher\n",
      "xmass\n",
      "omenties\n",
      "superhost\n",
      "rocks/\n",
      "ambiance+rooms+staff+locati\n",
      "wyndham.com\n",
      "egypti\n",
      "food/gamble\n",
      "79t\n",
      "concert/sister\n",
      "handicaped\n",
      "location-central\n",
      "sring\n",
      "silverton/las\n",
      "end-\n",
      "super-place\n",
      "in.are\n",
      "hamption\n",
      "hotel/casino-\n",
      "vigin\n",
      "non-ada\n",
      "blacksto\n",
      "great/out\n",
      "questio\n",
      "‚ô°‚ô°‚ô°‚ô°\n",
      "introdu\n",
      "willios\n",
      "..first\n",
      "chinato\n",
      "interesti\n",
      "again.that\n",
      "vegas‚Äîthat\n",
      "noic\n",
      "book/bar\n",
      "reacurring\n",
      "oasi\n",
      "sacrafice\n",
      "issues..\n",
      "twenty-so\n",
      "*the\n",
      "outwe\n",
      "dumpsville\n",
      "5*star\n",
      "perh\n",
      "dstr\n",
      "ammenit\n",
      "hotelüò¢\n",
      "ineffa\n",
      "serviceex\n",
      "clean-good\n",
      "check-out/check\n",
      "~11pm\n",
      "half-\n",
      "service/staff\n",
      "w/flies\n",
      "headwrecker\n",
      "hogtel\n",
      "apparen\n",
      "iinfested\n",
      "deterioarted\n",
      "mis-steps\n",
      "..hotel\n",
      "especi\n",
      "sunco\n",
      "surveillance/\n",
      "wlking\n",
      "dreamthis\n",
      "marjandawn17\n",
      "staffsenka\n",
      "xall\n",
      "distrikt\n",
      "north/times\n",
      "drap\n",
      "amaa\n",
      "feb/march\n",
      "management/bad\n",
      "localtion\n",
      ".underrated\n",
      "fantasticl\n",
      "ayuzzzz\n",
      "thetown\n",
      "vauch\n",
      "spelli\n",
      "tyci\n",
      "days11\n",
      "undergr\n",
      "palace-like\n",
      "top-shelf\n",
      "nhotel\n",
      "-nyc\n",
      "100ish\n",
      "m-azing\n",
      "lasss\n",
      "thereyet\n",
      "secoond\n",
      "shabyc\n",
      "hotel-i\n",
      "g=\n",
      "june9-11\n",
      "..lower\n",
      "underrat\n",
      "42n\n",
      "-the-way\n",
      "tower..and\n",
      "non-cassino\n",
      "ecpecred\n",
      "annivers\n",
      "..an\n",
      "forthrigh\n",
      "girlfri\n",
      "sunh\n",
      "department-\n",
      "deposi\n",
      "off-lv\n",
      "roompr\n",
      "goodsrooms\n",
      "-staybridge\n",
      "rock-las\n",
      "great..although\n",
      "disappoointed\n",
      "untilyou\n",
      "ceej\n",
      "waooo\n",
      "bwith\n",
      "starb\n",
      "disappointes\n",
      "boyfr\n",
      "york/manhattan\n",
      "price/valu\n",
      "youkhann\n",
      "the.best.hotel.experience.ever\n",
      "quality/value\n",
      "anyone..\n",
      "2doublebedsdeluxe\n",
      "wholeheartedl\n",
      "necessaril\n",
      "stay-but\n",
      "stay-will\n",
      "hilton-quality\n",
      "familyl\n",
      "father/daughter\n",
      "tripadviser\n",
      "envit\n",
      "nongamblers\n",
      "service.p\n",
      "side.g\n",
      "stay.our\n",
      "locatd\n",
      "christmast\n",
      "budget-friendl\n",
      "dirty/\n",
      "check-in/room\n",
      "masrmh-outstanding\n",
      "fees/hidden\n",
      "broulie\n",
      "aberage\n",
      "schimolies..what\n",
      "yaaaas\n",
      "rocki\n",
      "parisüëç\n",
      "benja\n",
      "7/5/2room\n",
      ".üëå\n",
      "roombuffet\n",
      "üéâüéâüéâüéâüéâ\n",
      "schmidel\n",
      "no-sign\n",
      "for-sometimes\n",
      "nuggett\n",
      "girlfend\n",
      "miniscu\n",
      "fantasticplace\n",
      "tamya\n",
      ".just\n",
      "~it\n",
      "a/c-70\n",
      "innto\n",
      "maika'i\n",
      "ufc200\n",
      "veryyyy\n",
      "arrogent-\n",
      "rooms-easy\n",
      "quirkines\n",
      "descen\n",
      "-neighborhood\n",
      "1yr\n",
      "buffasin\n",
      "cloustraphobic\n",
      "disapoint\n",
      "v-klass\n",
      "onli\n",
      "value/quality\n",
      "elefsnt\n",
      "theath\n",
      "linenes\n",
      "mostlly\n",
      "shelt\n",
      "discoveri\n",
      "loungy\n",
      "elyse√©\n",
      "hotel-exceptional\n",
      "tldr\n",
      "decieded\n",
      "wabbly\n",
      "service/h\n",
      "remidied\n",
      "pennsyl\n",
      "penn-\n",
      "formthe\n",
      "poopoo\n",
      "unbelieveabably\n",
      "comfortale\n",
      ".used\n",
      "town/herald\n",
      "clearl\n",
      "timeshare..\n",
      "unionizaton\n",
      "8.25am\n",
      "newyorknewyork\n",
      "unproganized\n",
      "location-lacks\n",
      "unforge\n",
      "homewoods\n",
      "larget\n",
      "bad..the\n",
      "w44th\n",
      "authenticall\n",
      "food/bev\n",
      "penth\n",
      "girk\n",
      "hotel/restaurant/staff/bar\n",
      "13th20016\n",
      "inth\n",
      "safefty\n",
      "ipop\n",
      "deleno\n",
      "qurky\n",
      "4ish\n",
      ".yuck\n",
      "yrok\n",
      "outstnading\n",
      "\\york\n",
      "pros-location\n",
      "millienum\n",
      "roxys\n",
      "soundpro\n",
      "roomsthe\n",
      "chiselers\n",
      "recntly\n",
      "'lame\n",
      "roo\\nm\n",
      "parking/valet\n",
      "ptevious\n",
      "nonse\n",
      "empressive\n",
      "iÔ∏èt\n",
      "orcha\n",
      "7stars\n",
      "bentley-\n",
      "self-check\n",
      "value/cost\n",
      "thga\n",
      "recognit\n",
      "duckbutter\n",
      "deal/experience\n",
      "location-able\n",
      "DG:DG.\n",
      "vidits\n",
      "cousi\n",
      "excellent-highly\n",
      "exemplifi\n",
      "underlivers\n",
      "roomslots\n",
      "spectacular~\n",
      "efficiencyienc\n",
      "horribe\n",
      "service+clean\n",
      "conforts\n",
      "old/outdated\n",
      "chrichton\n",
      "absolutelt\n",
      "small.ba\n",
      "accompa\n",
      "rverything\n",
      "2015awesome\n",
      "pool..\n",
      "reequest\n",
      "8hour\n",
      "caoellupo\n",
      "experinec\n",
      "DG/DGDG/DGDGDG\n",
      "missthis\n",
      ".lights\n",
      "perfect-better\n",
      "nice.roo\n",
      "suite..\n",
      "presc\n",
      "50thanniversary\n",
      "promat\n",
      "tyreswhen\n",
      "refurbishme\n",
      "bastballl.football\n",
      "hsuites\n",
      "owner/manager\n",
      "lockated\n",
      "pre-che\n",
      "-so\n",
      "rverywhere\n",
      "location-decent\n",
      ".sexy\n",
      "lcation\n",
      "park/stay/fly\n",
      "mini-memorial\n",
      "delando\n",
      "a+a+a+a+\n",
      "homless\n",
      "librar\n",
      "simple.decor\n",
      "well-poised\n",
      "locatoon\n",
      "radission\n",
      "manhattten\n",
      "a1-\n",
      "remodeled.just\n",
      "need..\n",
      "reaslly\n",
      "astore1\n",
      "bellechaire\n",
      "character-\n",
      "jan.2017\n",
      "greenwic\n",
      "fantastic.modern\n",
      "ganesevoort\n",
      "boyfrie\n",
      "share/hotel\n",
      "golore\n",
      "accommodati\n",
      "recetionists\n",
      "doll/rockettes\n",
      "-fountain\n",
      "fancy/\n",
      "ouitsatnding\n",
      "fiod\n",
      "tiny-oh-my-\n",
      "hellton\n",
      "return-disappointing\n",
      "casino.room\n",
      "againn\n",
      "reconment\n",
      "custermer\n",
      "v.nice\n",
      "DGDGDG..\n",
      "warldof\n",
      "anivisary\n",
      "staff/car\n",
      "problem-free\n",
      "hotel-close\n",
      "citiviews\n",
      "nassof\n",
      "business/couples\n",
      "staycation/baecation\n",
      "triplocat\n",
      "pizaz\n",
      "heavi\n",
      "lobby/proper\n",
      "helpful28\n",
      "accomadations\n",
      "fairl\n",
      "recep√ßi√≥n\n",
      "street-simple\n",
      "bay-bee\n",
      "braned\n",
      "multi-night\n",
      "inkcred\n",
      "casino/service/food/drinks\n",
      "terrrace\n",
      "boutique-styled\n",
      "obviou\n",
      "interieur\n",
      "wedding/family\n",
      "terribleroom\n",
      "price-perf\n",
      "vegasbaby\n",
      "dbia\n",
      "kaffenberger\n",
      "bad-smel\n",
      "formerl\n",
      "constructi\n",
      "'list\n",
      "perfection/stellar\n",
      "relaxing-perfect\n",
      "thompson-mcknight\n",
      "ickly\n",
      "16-26t\n",
      "graat\n",
      "palazzio\n",
      "insidie\n",
      "biotech/automation\n",
      "horrah\n",
      "comfortable.if\n",
      "appointed-\n",
      "away..\n",
      "islolated\n",
      "cnonvenience\n",
      "talke\n",
      "to..\n",
      "diaappointing\n",
      "nickel-and-dimed\n",
      "paker\n",
      "ohmiland\n",
      "bar/club\n",
      "well-app\n",
      "mrandmrsvegas\n",
      "-terrific\n",
      "over-exaggerated\n",
      "infrastruct\n",
      "hilton..\n",
      "fifty-5\n",
      "DG/DGDG/DGDG-DG/DGDG\n",
      "pros*\n",
      "'conference\n",
      "gorgeous/\n",
      "auberge-perfect\n",
      "turn-\n",
      "nature-reclaims-buildi\n",
      "luxuruious\n",
      "good.room\n",
      "informativ\n",
      "surro\n",
      "32n\n",
      "neighborho\n",
      "cleanlieness\n",
      "crownp\n",
      "servicedrinks\n",
      "hallways-not\n",
      "hinden\n",
      "averae\n",
      "10:30am\n",
      "fantstic\n",
      "consta\n",
      "Â§ßË°óÔºå‰ΩÜÂú∞Èªû„ÄÅ‰∫§ÈÄöÂ∞öÁÆóÊñπ‰æøÔºåÊÄßÂÉπÊØîÈ´ò\n",
      "40-50s\n",
      "bustle-free\n",
      "spectaculer\n",
      "perfect~you\n",
      "wualitu\n",
      "michigann\n",
      "large-ish\n",
      "lucr\n",
      "drlotte\n",
      "excec\n",
      "clebration\n",
      "unloa\n",
      "waldorf=ast\n",
      "nautically-them\n",
      "wohoo\n",
      "faaantastic\n",
      "speciall\n",
      "disappointed..would\n",
      "revisite\n",
      "fireplac\n",
      "staff-incredibly\n",
      "designlady\n",
      "paradice\n",
      "spentb4\n",
      "stumb\n",
      "aliz\n",
      "tourdesk\n",
      "attit\n",
      "rooms-perf\n",
      "disapiinted\n",
      "woulnt\n",
      "1405september\n",
      "concep\n",
      "zuvorkommend\n",
      "boderline\n",
      "jetleg\n",
      "excus\n",
      "non-cheesy\n",
      "richmen\n",
      "glamsquad\n",
      "side/nyc\n",
      "rooms/su\n",
      "touble\n",
      "casabla\n",
      "gereat\n",
      "july4th\n",
      "Êµ∑Â§ñÊóÖË°å„ÇÇ„Éã„É•„Éº„É®„Éº„ÇØ„ÇÇÂàù„ÇÅ„Å¶„Åß„Åó„Åü„ÅåÈùûÂ∏∏„Å´Âø´ÈÅ©„Åã„Å§ÂÆâÂøÉ„Åó„Å¶ÈÅé„Åî„Åô\n",
      "heate\n",
      "bedbound\n",
      "park.hav\n",
      "disappoi\n",
      "over-promised\n",
      "innüò°\n",
      ".like\n",
      "time.beautiful\n",
      "yo'self\n",
      "-town\n",
      "price..it\n",
      "anniversary/marathon\n",
      "daggy\n",
      "'modern\n",
      "everythin\n",
      "servicev\n",
      "location/very\n",
      "eastsid\n",
      "Â∏Ç‰∏≠ÂøÉÂÆåÁæéÂú∞Èªû\n",
      "videoing\n",
      "traine\n",
      "ladys\n",
      "uniqe\n",
      "w/10\n",
      "daughers\n",
      "DGDG-\n",
      "claasy\n",
      "spemdid\n",
      "sleep/eat/drink\n",
      "tweenagers\n",
      "üòÆ\n",
      "jackhol\n",
      "huuggeeee\n",
      "fiflthy\n",
      "unlik\n",
      "facinating\n",
      "met/exceeded\n",
      "becare\n",
      "boulde\n",
      "superhotel\n",
      "wcw4l\n",
      "..gre\n",
      "'hampton\n",
      "ilove\n",
      "elogance\n",
      "room/cold\n",
      "gajary\n",
      "fub=n\n",
      "non-caring\n",
      "transition-\n",
      ".wo\n",
      "willbe\n",
      "magnnificent\n",
      "aliyana\n",
      "vegas.nice\n",
      "bargain*\n",
      "convocati\n",
      "x10000\n",
      "engagi\n",
      "arlo-soho\n",
      "skylofts\n",
      "location/easy\n",
      "ambassasor\n",
      "un'fortune'ate\n",
      "airportbreakfast\n",
      "decorati\n",
      "sucks.diamond\n",
      "'excellent\n",
      "loves2travel\n",
      "certianly\n",
      "goodnes\n",
      "june/2017\n",
      "location..helpful\n",
      "courtnell\n",
      "unco\n",
      "..inviti\n",
      "inpirati\n",
      "real-not\n",
      "rules/not\n",
      "here-great\n",
      "christmas/belated\n",
      "..eh\n",
      "thursday-sunday\n",
      "draf\n",
      "remdeled\n",
      "ragge\n",
      "co-work\n",
      "undistu\n",
      "imbarassing\n",
      "owners/read\n",
      "business/conference\n",
      "complaints-the\n",
      "someh\n",
      "sissotel\n",
      "detec\n",
      "antho\n",
      "dayroo\n",
      "manhattanarea\n",
      "birthda\n",
      "experience|\n",
      "thelocation\n",
      "'mo\n",
      "bachelor/ette\n",
      "magunson\n",
      "dreding\n",
      "personnel-\n",
      "disappointug\n",
      "amerita\n",
      "anniversary/rod\n",
      "stay-at\n",
      "everwhere..\n",
      "hilton-lik\n",
      "realyl\n",
      "dimeing\n",
      "renov\n",
      "arroga\n",
      "'average/\n",
      "hidded\n",
      "wacker/michigan\n",
      "cockrouches\n",
      "revew\n",
      "scamdalay\n",
      "5th-a\n",
      "resc\n",
      "excellent.location\n",
      "geogr\n",
      "placecame\n",
      "worderfull\n",
      "assumin\n",
      "resort‚ÄºÔ∏è\n",
      "bleedin\n",
      "annuall\n",
      "alcat\n",
      "ah-mah-zing\n",
      "evrything\n",
      "bellgio\n",
      "chcago\n",
      "scammers/\n",
      "accodo\n",
      "stinks.\n",
      "fantantastic\n",
      "guard/bouncer\n",
      "shame..i\n",
      "night.p\n",
      "cleanness/location\n",
      "2017e\n",
      "nebrask\n",
      "short-reservat\n",
      "original-\n",
      "stylish..small\n",
      "◊ó◊ï◊®◊£\n",
      "jet-lag\n",
      "catarac\n",
      "atenci√≥n/excellent\n",
      "8-9p\n",
      "one-\n",
      "bhateja\n",
      "disapointting\n",
      "recpt\n",
      "serice\n",
      "DGDGDG-DG\n",
      "city/business/confer\n",
      "acknowled\n",
      "business/please\n",
      "extrodinar\n",
      "5:30p\n",
      "location-two\n",
      "bumpiness\n",
      "staff.1\n",
      "consistentl\n",
      "incheck\n",
      ".michi\n",
      "it..stay\n",
      "short-changed\n",
      "costu\n",
      "hotel/caring\n",
      "üéÇüéâüéÅ\n",
      "wellness-mi\n",
      "spaciour\n",
      "samballate\n",
      "iroqu\n",
      "sharkfest\n",
      "westingc\n",
      "millini\n",
      "issues/decor\n",
      "superk76\n",
      "hooster\n",
      "cassaundra\n",
      "exhorbitance\n",
      "odor.the\n",
      "nycfou\n",
      "room-larg\n",
      "ciggs\n",
      "mini-vacation\n",
      "flowers..\n",
      "makover\n",
      "tediou\n",
      "casino-downtown\n",
      "baecation\n",
      "westgate-las\n",
      "thetime\n",
      "knowledga\n",
      "purposethe\n",
      "hotel.nice\n",
      "electricial\n",
      "xmas2016\n",
      "succesfull\n",
      "reque\n",
      "stratasphe\n",
      "amagingly\n",
      "cons..not\n",
      "flat-like\n",
      "recreati\n",
      "famuly\n",
      "revieeww\n",
      "downtown/civic\n",
      "restaurants..beautiful\n",
      "floorconcierge\n",
      "undesira\n",
      "resosrt\n",
      "star/\n",
      "cadger\n",
      "iuxor\n",
      "comfort-\n",
      "becom\n",
      "locale/hotel\n",
      "patrick5870\n",
      "again.t\n",
      ",sorry\n",
      "mid-blo\n",
      "motherdaughtertrip\n",
      "thispropert\n",
      "run/work\n",
      "identifi\n",
      "mccrossans\n",
      "paid.good\n",
      "pareeee\n",
      "prosnice\n",
      "hilton-portfolio\n",
      "bhise\n",
      "giacob\n",
      "starri\n",
      "snmmi\n",
      "DGDG/DGDG\n",
      "wonerfull\n",
      "mid-strip\n",
      "warmes\n",
      "cisnero\n",
      "signi\n",
      "staff.lovely\n",
      "awesome..jeff\n",
      "handlery\n",
      "amwedding\n",
      "/guest\n",
      "sohot\n",
      "pheon\n",
      "anlother\n",
      "winingtable\n",
      "margie2018\n",
      "locationüòÉ\n",
      "'wow\n",
      "rock/summer\n",
      "house-keeping\n",
      "terribel\n",
      "mccorminck\n",
      "experience/poor\n",
      "locat\n",
      "accus\n",
      "soecial\n",
      "w/e\n",
      "none.arr\n",
      "stay‚ù£\n",
      "days/ni\n",
      "comfortable..may\n",
      "spacoius\n",
      "for.had\n",
      "perfecion\n",
      "in/great\n",
      "tea-\n",
      "starck/schrager\n",
      "25/room\n",
      "tbis\n",
      "tainers\n",
      "cwell\n",
      "updating/touching\n",
      "stanford/kstate\n",
      "superh\n",
      "historiic\n",
      "bath/sho\n",
      "ÌïòÏö∞Ïä§ÌÇ§ÌïëÎèÑ\n",
      "others..\n",
      "artisitc\n",
      "conceigne\n",
      "newbe\n",
      "place.tiny\n",
      "casalanca\n",
      "mandley\n",
      "place.a\n",
      "bldg-ski\n",
      "effe\n",
      "spot.easy\n",
      "much-hailed\n",
      "i'l\n",
      "thanksgivivng\n",
      "helpful.opport\n",
      "here.and\n",
      "beyhive\n",
      "stmt\n",
      "convenience+comfort+luxury=londonhouse\n",
      "10mins\n",
      "opene\n",
      "wickedspoon\n",
      "weeks.day\n",
      "glamoro\n",
      "location/views\n",
      "emabasy\n",
      "firsr\n",
      "mix-ups\n",
      "c+/b-\n",
      "virually\n",
      "yolla\n",
      "atomosphere\n",
      "14/day\n",
      "equisite\n",
      "far.but\n",
      "sfaff\n",
      "manager-\n",
      "flashies\n",
      "againg\n",
      "remodle\n",
      "views..\n",
      "caseih\n",
      "athle\n",
      "room.fir\n",
      "luste\n",
      "yout\n",
      "horrrrible\n",
      "unremarker\n",
      "recommandable\n",
      "hotellocation\n",
      "baybridge\n",
      "performanc\n",
      "prosi\n",
      "suitc\n",
      "street/\n",
      "quarte\n",
      "again.there\n",
      "location/cute\n",
      "conveinience\n",
      "rooms-friendly\n",
      "scoo\n",
      "convienent\n",
      "under-stated\n",
      "netti\n",
      "tripad\n",
      "amassive\n",
      "mgm-variety\n",
      "-holiday\n",
      "fatigu√©\n",
      "alanhf\n",
      "beutiful\n",
      "avilable\n",
      "standard-less\n",
      "side‚Ä¶\n",
      "addtions\n",
      "‚ù§Ô∏ècaesars\n",
      "location-hotel\n",
      "comfortablel\n",
      "door/bell\n",
      "-cation\n",
      "estada\n",
      "gareenteed\n",
      "noised\n",
      "booking.c\n",
      "rubbishy\n",
      "swisaotel\n",
      "issues-\n",
      "perferct\n",
      ".stained\n",
      "atbthe\n",
      "excep\n",
      "-disgusting\n",
      "lelaxation\n",
      "resort//spa\n",
      "toddl\n",
      "romantic/\n",
      "+++very\n",
      "hotel/resor\n",
      "absolultey\n",
      "pasamos\n",
      "alright-but\n",
      "kendahl\n",
      "obvi\n",
      "groovey\n",
      "balcony.i\n",
      "new-fan\n",
      "timeshare/extended\n",
      "lisset\n",
      "w/great\n",
      "locationpricepool\n",
      ".bu\n",
      "place-not\n",
      "accomo\n",
      "2-5th\n",
      "prestidge\n",
      "super-excited\n",
      "49the\n",
      "fast.easy\n",
      "appaling\n",
      "skyscr\n",
      "hospitality-comfortable-clean\n",
      "all-suites\n",
      "unconfortable\n",
      "mon.-\n",
      "12/13-18t\n",
      "possibilit\n",
      "—Å—Ç—Ä–∏–ø–∞\n",
      "maitained\n",
      "nicenplace\n",
      "fablunous\n",
      "hussel\n",
      "wereclean\n",
      "bill's/barbary\n",
      "expec\n",
      "sohote\n",
      "a-ok.\n",
      "encountere\n",
      "birthday/business\n",
      "baltera\n",
      "service/meals\n",
      "worhty\n",
      "unsatisfac\n",
      "fran..\n",
      "stars.top\n",
      "acomadations\n",
      "excellent.the\n",
      "sonit\n",
      "quali\n",
      ".grea\n",
      "manhattan-really\n",
      "jorje\n",
      "overshad\n",
      "southloop\n",
      "checkin/\n",
      "zelos\n",
      "night-mare\n",
      "impanea\n",
      "niceservice\n",
      "errrrrr\n",
      "luxuru\n",
      "ssurprised\n",
      "location=\n",
      "perfect-\n",
      "nice/accommodatin\n",
      "disapo\n",
      "heinzer\n",
      "eleganc\n",
      "milit\n",
      "usual.great\n",
      "painstakin\n",
      "aroun\n",
      "bellecliare\n",
      "experincing\n",
      "disorganizein\n",
      "architecture-\n",
      "informatio\n",
      "pluged\n",
      "penthouse-\n",
      ".afford\n",
      "nachc\n",
      "hotelfantasti\n",
      "lke\n",
      "asto\n",
      "anniversarry\n",
      "room..super\n",
      "mid-town/theatre\n",
      "staffget\n",
      "recc\n",
      "closet-sized\n",
      "placesüòÅ\n",
      "reservation-\n",
      "hostin\n",
      "patc\n",
      "horriblescary\n",
      "aircon\n",
      "undersold..\n",
      "property-convenient\n",
      "veryclean\n",
      "spg.co\n",
      "/big\n",
      "hampton-\n",
      "dosappointed\n",
      "character/ame\n",
      "victo\n",
      "absoulutly\n",
      "..need\n",
      "hyatt.i\n",
      "strip-esque\n",
      "kdw1\n",
      "nloc\n",
      "reputaion\n",
      "good.buy\n",
      "skylounge\n",
      "nonsen\n",
      "trip-vegas\n",
      "extected\n",
      "average/kind\n",
      "namescon\n",
      "find/fairly\n",
      "cittty\n",
      "physici\n",
      "this‚Äã\n",
      "walkt\n",
      "fridge..no\n",
      "staff-great\n",
      "rooms.ceiling\n",
      "srvice\n",
      "5:00am\n",
      "disgustin\n",
      "nyc-\n",
      "husstle\n",
      "8nights\n",
      "delayno\n",
      "location/accomodating\n",
      "ashleen\n",
      "expierance\n",
      "yanelly\n",
      "excellent/efficient\n",
      "experinces\n",
      "theroof..\n",
      "2-bed\n",
      "bouev\n",
      "doubtfull\n",
      "bedroom/2\n",
      "kwahme\n",
      "simpatic\n",
      "asop\n",
      "hotel-chicago\n",
      "noit\n",
      "twentysomethi\n",
      "spartin\n",
      "number1\n",
      "dogfriendly\n",
      "..***********\n",
      "fantanstic\n",
      "lady-of-the-\n",
      "pad27\n",
      "stevewynn\n",
      "spont\n",
      "value/concept\n",
      "shittest\n",
      "wisdo\n",
      "story-\n",
      "decently-priced\n",
      "repairs/upkeep\n",
      "overspen\n",
      "good/excellent\n",
      "panash\n",
      "rollercon\n",
      "dad/daughter\n",
      "utah/grande\n",
      "baby-moon\n",
      "skyl\n",
      "getaway.roo\n",
      "security/not\n",
      "street/times\n",
      "outweights\n",
      "relax/p\n",
      "nooked\n",
      "garag\n",
      "tranquili\n",
      "mandari\n",
      "spontanously\n",
      "mid-apri\n",
      "glose\n",
      "tjhe\n",
      "DG:DGDG-\n",
      "buainess\n",
      "crouded\n",
      "tiredddecor\n",
      "hoteldid\n",
      "shout-o\n",
      "wondefrul\n",
      "alwayz\n",
      "hoten\n",
      "locationm\n",
      "relaxing/calm\n",
      "palazo\n",
      "repr\n",
      "tuckaway\n",
      "goddaughters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "designedge\n",
      "incredib\n",
      "gpod\n",
      "vegas-lite\n",
      "night.it\n",
      "shoppingbags\n",
      "pleasently\n",
      "shoould\n",
      "hotelro\n",
      "fleetwoo\n",
      "place-great\n",
      "chicagao\n",
      "love‚Ä¶\n",
      "harrah¬¥s\n",
      "pittcon\n",
      "roll-in\n",
      "resturaunts\n",
      "reunio\n",
      "DGDG/DGDG-DG\n",
      "rewords\n",
      "location/new\n",
      "locationproperty\n",
      "city-like\n",
      "rooms.comforta\n",
      "great.could\n",
      "smoth\n",
      "4-seasons\n",
      "avisor\n",
      "mid-stay\n",
      "lovecapetown\n",
      "'y\n",
      "4mbs\n",
      "outstadning\n",
      "grouptrip\n",
      "hospitality.we\n",
      "atrip\n",
      "destation\n",
      "once..\n",
      "providi\n",
      "traceyh\n",
      "hyatt-not\n",
      ".pick\n",
      "..again\n",
      "vegas2016\n",
      "accommations\n",
      "stron\n",
      "stay-ca-tion\n",
      "stay„ÄÇ4\n",
      "kathalin\n",
      "burthday\n",
      "facelift.not\n",
      "hospedamos\n",
      "star-\n",
      "vegas-the\n",
      "residentialneighborhood\n",
      "chance-find\n",
      "4c-\n",
      "business-stay\n",
      "madii\n",
      "kooza\n",
      "vieww\n",
      "clean/safe\n",
      "week.locate\n",
      "efforted\n",
      "property-best\n",
      "phlai\n",
      "seening\n",
      "aleays\n",
      "mindfrea\n",
      "love.y\n",
      "ridicolous\n",
      "sungl\n",
      "game.the\n",
      "visit/stay\n",
      "neighborhood-like\n",
      "frequ\n",
      "hotels-\n",
      "nyease\n",
      "great~\n",
      "1150pm\n",
      "district-amazin\n",
      "surveyrun\n",
      "assigne\n",
      "nghts\n",
      "34t\n",
      "DGDGDG.\n",
      "lakevie\n",
      "broadwaycon\n",
      "price/performanc\n",
      "serivce\n",
      "fianceee\n",
      "maximillious\n",
      "spectucular\n",
      "johnn\n",
      "placegreat\n",
      "traveliers\n",
      "price=expensive\n",
      "..construction\n",
      "sighseeing\n",
      "location.quee\n",
      "atmosphere.w\n",
      ".rude\n",
      "thoght\n",
      "families-w/\n",
      "mariju\n",
      "seaport-manhattan\n",
      "concentient\n",
      "weedi\n",
      "non-city\n",
      "fun-fun\n",
      "nolitan\n",
      "millineum\n",
      "corporat\n",
      "floorwas\n",
      "noiose\n",
      "||\n",
      "crotin\n",
      "constru\n",
      "broadway-very\n",
      "concert/cubbies\n",
      "vacumed/hidden\n",
      "mccormck\n",
      ".did't\n",
      "..eventually\n",
      "activies\n",
      "healt\n",
      "DGDGDGDG‚Ä¶\n",
      "alvethia\n",
      "uploded\n",
      "nonex\n",
      "two-oh-two\n",
      "DGDGDG+\n",
      "week.st\n",
      "service-tired\n",
      "fanatstic\n",
      "w37t\n",
      "tropicana.nice\n",
      "breakfa\n",
      "barefo\n",
      "upcharge\n",
      ".ahem\n",
      "bomb.com\n",
      "encomendas\n",
      "weekend..\n",
      "astoria-\n",
      "mid-wes\n",
      "stop/ca\n",
      "maintenance/housekeepi\n",
      "tinany\n",
      "tryptastic\n",
      "fountain-view\n",
      "definitl\n",
      "stay-gorgeous\n",
      "chicago..and\n",
      "stunningserv\n",
      "condo-like\n",
      "street-\n",
      "stink-\n",
      "penthou\n",
      "fair/not\n",
      "weekd\n",
      "ineffi\n",
      "600sq\n",
      "resturent\n",
      "helpi\n",
      "marina/wharf\n",
      "comfortables\n",
      "dissapoints\n",
      "bacholar\n",
      "redde\n",
      "connectin\n",
      "meowwwww\n",
      "town/little\n",
      "expereience\n",
      "cycy\n",
      "lincol\n",
      "bellec\n",
      "pros-hotel\n",
      "midt\n",
      "spre\n",
      "stay3d\n",
      "fridnly\n",
      "quickbe\n",
      "hotel/own\n",
      "wallking\n",
      "flimi\n",
      "rooms/decent\n",
      "mascaraing\n",
      "filfthy\n",
      "clucter\n",
      "getaway/reasonable\n",
      "mom/s\n",
      "hotell-great\n",
      "claustrophobia-inducing\n",
      "pleaseü§ë\n",
      "husba\n",
      "overprice\n",
      "goodth\n",
      "winter-recess\n",
      "3cs\n",
      "DGDG/DG/DGDG-DGDG/DG/DGDG\n",
      "openi\n",
      "brilli\n",
      "choice..\n",
      "distr\n",
      "veautif\n",
      "-wish\n",
      "do-over\n",
      "outrag\n",
      "notic\n",
      "experance\n",
      "sartie\n",
      "londonhous\n",
      ".minus\n",
      "faultl\n",
      "12t\n",
      "birthday/wedding\n",
      "misrepre\n",
      "unresp\n",
      "notifyi\n",
      "precisiona\n",
      "subu\n",
      "-apart\n",
      "tribecca\n",
      ".going\n",
      "'tired\n",
      "easie\n",
      "manageme\n",
      "reac\n",
      "ntly\n",
      "miss..\n",
      "mrket\n",
      "anyt\n",
      "prosgreat\n",
      "usatrip2017\n",
      "nigth\n",
      "bones-your\n",
      "itine\n",
      "roomsbathroom\n",
      "downsta\n",
      "syle\n",
      "h√¥te\n",
      "localizatiom\n",
      "hotel.check\n",
      "DG-DGDG-\n",
      "location‚Ä¶.at\n",
      "pricelined\n",
      "timesqu\n",
      "but..\n",
      "room/deal\n",
      "gambling..\n",
      "matress\n",
      "vacartion\n",
      "things-\n",
      "bachelo\n",
      "boutiquey\n",
      "drving\n",
      "emoji\n",
      "fees.\n",
      "location/hilton\n",
      "cleanlinees\n",
      "ponderi\n",
      "'bridge\n",
      "aftern\n",
      "8:00am\n",
      "this-poor\n",
      "dedrics\n",
      "volunt\n",
      "convector\n",
      "ismeta\n",
      "phoeniminal\n",
      "expensice\n",
      "alwas\n",
      "lollapollooza\n",
      "night.i\n",
      "30th-sept\n",
      "superbook-the\n",
      "oldy\n",
      "ü§µüèª\n",
      "famiies\n",
      "~DG\n",
      "youor\n",
      "fashionish\n",
      "hotelstayed\n",
      "nomad/chelsea\n",
      "price-\n",
      "onesel\n",
      "overbooks\n",
      "dissapointments\n",
      "***amazing\n",
      "holidayyyyyyy\n",
      "‚úà‚úà‚úà\n",
      "auberg\n",
      "reimburserd\n",
      "birthdayüéà\n",
      "..smoke\n",
      "getaroom.com\n",
      "spigne\n",
      "mccarra\n",
      "picki\n",
      "property.good\n",
      "busines/\n",
      "fabworried\n",
      "2018p\n",
      "spectacula\n",
      "migue\n",
      "-resort\n",
      "surprised.the\n",
      "'madhouse\n",
      "aveue\n",
      "xmas/birthday\n",
      "i'v\n",
      "donwtown\n",
      "hastle\n",
      "g..l\n",
      "wondereful\n",
      "attra\n",
      "04feb-\n",
      "nov.2017\n",
      "goldent\n",
      "feom\n",
      "miles/lincoln\n",
      "w/this\n",
      "52th\n",
      "pierris\n",
      "..best\n",
      "accommodation..\n",
      "port√©e\n",
      "üò≥\n",
      "reciep\n",
      "diid\n",
      "wee-notes\n",
      "softiel\n",
      "tsbn\n",
      "clran\n",
      "housekkee\n",
      "reasonnable\n",
      "jsully\n",
      "high-dollar\n",
      "È®íÈü≥„Å®‰∫∫Á®ÆÂ∑ÆÂà•Ôºànoisy\n",
      "pros-we\n",
      "eqyptian\n",
      "poor/non\n",
      "spg/starwo\n",
      "afforduxury\n",
      "glorif\n",
      "overv\n",
      "fast-\n",
      "reinvad\n",
      "mondria\n",
      "decoratio\n",
      "recomenda\n",
      "ccall\n",
      "seasons-reputation\n",
      "back-pl\n",
      "3:30pm\n",
      "frncisco\n",
      "service..but\n",
      "nightcap-\n",
      "wrea\n",
      "review-winnipeg\n",
      "neg*\n",
      "exexperience\n",
      "staff/customer\n",
      "hcny\n",
      "firstly..\n",
      "luxor-\n",
      "Íπ®ÎÅóÌïú\n",
      "grandd\n",
      "2014-great\n",
      "things/lots\n",
      "shamd\n",
      "luxor.would\n",
      "coughi\n",
      "cleanlines\n",
      "assig\n",
      "anti-new\n",
      "well-r\n",
      "treadmi\n",
      "property..value\n",
      "disgrace..\n",
      "plughs\n",
      "unporfes\n",
      "wthat\n",
      "gautlent\n",
      "preimier\n",
      "welcoming.this\n",
      "a-maz-ing\n",
      "bdangelo\n",
      "travelle\n",
      "jayki\n",
      "üòè\n",
      "stay-just\n",
      "disppoint\n",
      "storag\n",
      "horrifi\n",
      "hgvc/flamingo\n",
      "w/no\n",
      "panaramic\n",
      "experiencelocation\n",
      "therenovtion\n",
      "builin\n",
      "vt8800\n",
      "cassaq\n",
      "located.very\n",
      "overall.prosvalet\n",
      "guremmro\n",
      "swellegant\n",
      "13-16th\n",
      "kimp\n",
      "kindn\n",
      "experience.\n",
      "thisthis\n",
      "reboo\n",
      "enthusia\n",
      "hotel.excellent\n",
      "swanky-est\n",
      "livingsocia\n",
      "consiistently\n",
      "t.l.c\n",
      "ubication\n",
      "rotalty\n",
      "4days.it\n",
      "beautiful.good\n",
      "inn-like\n",
      "100/nig\n",
      "family/concert\n",
      "disclo\n",
      "popc\n",
      "post-christmas\n",
      "oshirohakase\n",
      "aquar\n",
      "valiree-good\n",
      "40yrs\n",
      "review.co\n",
      "trump-vegas\n",
      "ref.\n",
      "gentl\n",
      "restrurant\n",
      "location-affordable\n",
      "geteway\n",
      "babyminders\n",
      "'empire\n",
      "awfu\n",
      "tiime\n",
      "friday-sund\n",
      "soake\n",
      "holiday/weddin\n",
      "wiats\n",
      "squarei\n",
      "***updated\n",
      "memgers\n",
      "italy/chinatown\n",
      "augustu\n",
      "sour-\n",
      "unique/amazing\n",
      "apon\n",
      "pantalen\n",
      "keyontae\n",
      "consi\n",
      "xmas/new\n",
      "arrivalwe\n",
      "non-exis\n",
      "exttremely\n",
      "acatraz\n",
      "exclenet\n",
      "unremarkabl\n",
      "ideally-located\n",
      "outstading\n",
      "nosiest\n",
      "◊™◊®◊í◊ù◊û◊ú◊ï◊ü\n",
      "everythinf\n",
      "ex-city\n",
      "antiqu\n",
      "othewise\n",
      "4plus\n",
      "'smack\n",
      "right-in-the-center\n",
      "coinside\n",
      "hotel-rude\n",
      "kayebells\n",
      "anyti\n",
      "dec.2016\n",
      "conferences..\n",
      "tiffanys\n",
      "helpful2\n",
      "2-q\n",
      "unsurpasse\n",
      "trip-could\n",
      "upsca\n",
      "**spa\n",
      "comfortabily\n",
      "central-the\n",
      "birthday/anniverary\n",
      "christas\n",
      "belcny\n",
      "haxi\n",
      "all.space\n",
      "yeoseph\n",
      "slow.cle\n",
      "stop2017\n",
      "nahro\n",
      "trag\n",
      "brand-\n",
      "literall\n",
      "property.very\n",
      "lasvega\n",
      "sreception\n",
      ".as\n",
      "greatit\n",
      "property..except\n",
      "overlooke\n",
      "inspecte\n",
      "nights..terrific\n",
      "virjinia\n",
      "walforf\n",
      "personaliza\n",
      "downhi\n",
      "lanais\n",
      "respec\n",
      "'place\n",
      "witht\n",
      "confi\n",
      "conven\n",
      "clubquart\n",
      "aniversity\n",
      "„É™„Çæ„Éº„Éà„É´„Éº„É†„Å´ÂÆøÊ≥ä„Åó„Åæ„Åó„Åü„ÄÇÂè£„Ç≥„Éü„ÅØËã±Ë™û„ÅßÊõ∏„ÅÑ„Åü„ÅÆ„Åß‰∏ãË®ò„ÇíÂèÇÁÖß„Åè\n",
      "eccezionale\n",
      "cliford\n",
      "hauntedly\n",
      "business/pleasu\n",
      "price/locat\n",
      "stay/road\n",
      "aslee\n",
      "area/in\n",
      "„Äåo„Äç\n",
      "nights/3\n",
      "properity\n",
      "friemdly\n",
      "ecpectation\n",
      "propositi\n",
      "located/decorated\n",
      "nightshuge\n",
      "runr\n",
      "delores/john\n",
      "andvi\n",
      "accomedati\n",
      "21yrs\n",
      "inefficienct\n",
      "histroic\n",
      "p.o.s\n",
      "francess\n",
      "9to5explorer\n",
      "onseptemb\n",
      "compaired\n",
      "reall\n",
      "clean.cons\n",
      "jan1-6\n",
      "flip-flo\n",
      "impessed\n",
      "repub\n",
      "detial\n",
      "nights.bo\n",
      "ÂæÖÂú®ÈÄôË£èËøë20Â§©ÔºåÊØèÂ§©ÈÉΩÂ∞çÊñº‰ªñÂÄëÁöÑÊï¨Ê•≠ËàáÊ≠°Ê®ÇÁöÑÂ∑•‰ΩúÊ∞õÂúçÊÑüÂãï„ÄÇÈÄôÂú®‰∫ûÊ¥≤\n",
      "mini-snacks\n",
      "advise..\n",
      "butegas\n",
      "stateme\n",
      "awfuldirtysmellybed\n",
      "elera/\n",
      "sppedy\n",
      "servie\n",
      "daaaaahling\n",
      "wallpaper/pain\n",
      ".lucky\n",
      "breakfact\n",
      "propertyok\n",
      "belvede\n",
      "knickerbocker..\n",
      "unpla\n",
      "inconvienent\n",
      "location~stay\n",
      "Ìò∏ÌÖî\n",
      "bachelor/bachelorette\n",
      "pleascent\n",
      "best‚Ä¶\n",
      "trawally\n",
      "undergoin\n",
      "walk-a\n",
      "szx\n",
      "in/ups\n",
      "hidden/false\n",
      "yazmin\n",
      "/to\n",
      "vancouve\n",
      "location/ok\n",
      "staed\n",
      "room/mix\n",
      "saska\n",
      "service/change\n",
      "hanabee\n",
      "name-boutique\n",
      "becam\n",
      "roons\n",
      "conci\n",
      "my2nd\n",
      "miniatur\n",
      "famo\n",
      "dark-drab\n",
      "location/issues\n",
      "-updated\n",
      "≈°tay\n",
      "effecie\n",
      "first.good\n",
      "bacchannel\n",
      "mini-bar\n",
      "26-28th\n",
      "locationhot\n",
      "biaised\n",
      "extreamly\n",
      "cvent\n",
      "style-\n",
      "square.very\n",
      "holel-a\n",
      "pier2620\n",
      "walls+neighbors=very\n",
      "*detailed\n",
      "absol\n",
      "once-gr\n",
      "groupons\n",
      "vvvveeeegaaaassss\n",
      "thanksgiving/birthday\n",
      "'upcharges\n",
      "medieva\n",
      "cooked-to-ord\n",
      "201t6\n",
      "hotelwhat\n",
      "stau\n",
      "husb\n",
      "mini-city\n",
      "expensiv\n",
      "celebratiom\n",
      "birthday/\n",
      "holimoon\n",
      "38t\n",
      "footprin\n",
      "mid-sept\n",
      "proxi\n",
      "/workers\n",
      "10/10sta\n",
      "absoloute\n",
      "satisfied-will\n",
      "h.e\n",
      "faantastic\n",
      "judg\n",
      "unaccomodati\n",
      "non-smokng\n",
      "boardline\n",
      "stay..even\n",
      "locationnice\n",
      "w.38th-the\n",
      "smel\n",
      "airp\n",
      "..beautiful\n",
      "balimore/london/nj\n",
      "granduer\n",
      "pet/cat\n",
      "Í∞ÄÍ≤©Ïù¥\n",
      "classi\n",
      "misadvertising\n",
      "rubbush\n",
      "unconsumed\n",
      "'non-\n",
      "4point\n",
      "bar-if\n",
      "lisa-sportsbook\n",
      "clien\n",
      "hotel.gre\n",
      "locationlocation\n",
      "unin\n",
      "redbury\n",
      "overviewwhile\n",
      "affordable/old\n",
      "paahk\n",
      "lane-great\n",
      "excursionis\n",
      "categor\n",
      "superv\n",
      ",2nd\n",
      "lovy\n",
      "suuuuper\n",
      "atmosph\n",
      "muhibal\n",
      "girlfirend\n",
      ".from\n",
      "father-\n",
      "home-base\n",
      "probolem\n",
      "pros1-surrou\n",
      "view‚Äîs\n",
      "'run\n",
      "'sta\n",
      "joved\n",
      "üéâüéâ\n",
      "myve\n",
      "tent..but\n",
      "uppe\n",
      "time.wond\n",
      "birthd\n",
      "melaney\n",
      "appropr\n",
      "expectee\n",
      "everyb\n",
      "mini-v\n",
      "unparrelled\n",
      "fantadtic\n",
      "friendly/helpful\n",
      "renti\n",
      "greatplace\n",
      "picthers\n",
      "carrabis\n",
      "spacieuses\n",
      "noisysidewalks\n",
      "anywh\n",
      "up-to\n",
      "here..would\n",
      "summarize‚Ä¢\n",
      "york~\n",
      "sleepi\n",
      "stolen/missing\n",
      "renaissance-level\n",
      "29-october\n",
      "swog\n",
      "great-would\n",
      "üëçüèº\n",
      "..average\n",
      "timessquare\n",
      "backin\n",
      "swiss√¥tell\n",
      "smili\n",
      "sloooowwww\n",
      "dyl\n",
      "lengt\n",
      "s**t.\n",
      "cleaness\n",
      "hidson\n",
      "tuesday-saturday\n",
      "courtessy\n",
      "puddl\n",
      "leadin\n",
      "eart\n",
      "DG+DG\n",
      ".dis\n",
      "corner..\n",
      "dreamville\n",
      "remodele\n",
      "nois\n",
      "sketc\n",
      "peelin\n",
      "configurati\n",
      "thewellington\n",
      "questioni\n",
      "inn-chelsea\n",
      "luxuious\n",
      "bigges\n",
      "confortble\n",
      "solice\n",
      "staff-friendly\n",
      "wellingt\n",
      "favortie\n",
      "californi\n",
      "hoyel\n",
      "fianancial\n",
      "place-luxurious\n",
      "everlyn\n",
      "bartender-\n",
      "morganshot\n",
      "hotel.stayed\n",
      "hotel-clean\n",
      "mr.ran\n",
      "unusuall\n",
      "super-cool\n",
      "yummiest\n",
      "seriou\n",
      "harrahs\n",
      "accomodationfor\n",
      "5:45pm\n",
      "warminf\n",
      "4-30pm\n",
      "hybarger\n",
      "budget-conscious\n",
      "terasse\n",
      "smbience\n",
      "woti\n",
      "froli\n",
      "up-parasol\n",
      "theater-royal\n",
      "robins/delpostro\n",
      "waterss\n",
      "villasen\n",
      "700/nig\n",
      "disssggguuuusssssttt\n",
      "upfit\n",
      "hotel.everything\n",
      "cruisey\n",
      "hellothis\n",
      "birthday/first\n",
      "at~\n",
      "pulizia\n",
      "hassle-free\n",
      "figh\n",
      "casino/reso\n",
      "misleading-\n",
      "hopeful/\n",
      "30second\n",
      "days.checkin\n",
      "weekened\n",
      "goodnightsleep\n",
      "excha\n",
      "disappoin\n",
      "obstinant\n",
      "ttentive\n",
      "hotel-value\n",
      "absoulety\n",
      "nycl\n",
      "exercis\n",
      "whyndham\n",
      "15057i\n",
      "history-rich\n",
      "*watch\n",
      "last7\n",
      "mr./mrs\n",
      "jailene\n",
      "sportsb\n",
      "dreadf\n",
      "rooms..comfortable\n",
      "hotel1\n",
      "pembrok\n",
      "exclus\n",
      ".because\n",
      "great-super\n",
      "agoda\n",
      "afinia\n",
      "üò≠\n",
      "benea\n",
      "fitte\n",
      "up/excellent\n",
      "aroundreal\n",
      "doller\n",
      "s-p-a-c-\n",
      "/celebration\n",
      "it..we\n",
      "view/natural\n",
      "time..no\n",
      "vibe..happening\n",
      "..oterwise\n",
      "DG-DGDG-DGDGDGDG\n",
      "nyeve\n",
      "citiview\n",
      "11howard\n",
      "incidentials\n",
      "failur\n",
      "8nts\n",
      "baysi\n",
      "pleasureroom\n",
      "aaaaa+\n",
      "professional/\n",
      "in..17\n",
      "macdona\n",
      ".fu\n",
      "casabl\n",
      "awasome.exelent\n",
      "mesiocre\n",
      "room/s\n",
      "herefron\n",
      "famcy\n",
      "finish-property\n",
      "luidin\n",
      "silvesmith\n",
      "well-lo\n",
      "jasmineglueck\n",
      "aasked\n",
      "easil\n",
      "bally's.-\n",
      "exceptional-perfect\n",
      "3*hotel\n",
      "magnifiecent\n",
      "mid-budget\n",
      "blackj\n",
      "56ÈöéÔºàÂÆüÈöõ„Å´„ÅØ-10ÈöéÔºâ„ÅÆpanoramic\n",
      "abourt\n",
      "styy\n",
      "value..odd\n",
      "stay/make\n",
      "wedding/spring\n",
      "nickleback\n",
      "tired-looking\n",
      "carpeti\n",
      "glamor..\n",
      "thhis\n",
      "nigr\n",
      "'happy\n",
      "thete\n",
      "emergen\n",
      "unbealivable\n",
      "ti=\n",
      "well-situated\n",
      "update..\n",
      "accomations\n",
      "dayeverythi\n",
      "givne\n",
      "faishon\n",
      "understan\n",
      "decor/near\n",
      "ryan3311\n",
      "cornrll\n",
      "rpyal\n",
      "safety-conscious\n",
      "word-\n",
      "cosmoplolitan\n",
      "vanitian\n",
      "suites/rooms\n",
      "free/included\n",
      "'u\n",
      "pretenious\n",
      "sigthseeing\n",
      "value.the\n",
      "unacommadating\n",
      "gwyne\n",
      "cockta\n",
      "thanksgving\n",
      "rio/harrah\n",
      "affordfable\n",
      "four-n\n",
      "thurs-\n",
      "actaly\n",
      "ripo\n",
      "drawbac\n",
      "-will\n",
      "cozy..\n",
      "uchic\n",
      "great.other\n",
      "christmas-new\n",
      "paraody\n",
      ".ne\n",
      "break-excellent\n",
      "supberb\n",
      "terrible.the\n",
      "terific\n",
      "occasiona\n",
      "rght\n",
      "services..\n",
      "‚úîÔ∏è\n",
      "annoyi\n",
      "w/one\n",
      "resonably\n",
      "10yrs\n",
      "friendly-\n",
      "welcolming\n",
      "architectual\n",
      "buccannal\n",
      "shloush\n",
      "thic\n",
      "geli4849\n",
      "bag.first\n",
      "renw\n",
      "convinence\n",
      "amazing.staff\n",
      "horri\n",
      "shoc\n",
      "exorcted\n",
      "bandaid\n",
      "wassuper\n",
      "kept/great\n",
      "torned\n",
      "dosent\n",
      "reconmended\n",
      "ü§¶üèª‚Äç‚ôÄÔ∏è\n",
      "sixtysoho\n",
      "averagr\n",
      "350/night\n",
      "celerabration\n",
      "pubbing\n",
      "trol\n",
      "moderately-priced\n",
      "spacation\n",
      "'hidden\n",
      "gamilian\n",
      "succ\n",
      "hotellarge\n",
      "satg\n",
      "registrator\n",
      "touch-up\n",
      "clean.houseke\n",
      "exha\n",
      "numorous\n",
      "panar\n",
      "hostel*****\n",
      "bowwow\n",
      "spg-p\n",
      "‚ú®\n",
      "locationgre\n",
      "bacherlotte/bachelor\n",
      "cicumstances\n",
      "renovationhot\n",
      "recomendable\n",
      "viewssuper\n",
      "brestaurants\n",
      "..modern\n",
      "value-for-money\n",
      "possibil\n",
      "ienjoyable\n",
      "'cept\n",
      "terroble\n",
      "repair/remod\n",
      "wonderful~\n",
      "pboom\n",
      "beware-flamingos\n",
      "hrer\n",
      "perfection..wish\n",
      "opverpriced\n",
      "well-situated-\n",
      "inclus\n",
      "found/security\n",
      "posioning\n",
      "////////////////////////////////////////\n",
      ".often\n",
      "spg-brand\n",
      "ahhhhhhh\n",
      "üëéüèªüëéüèªüëéüèªüëéüèªüëéüèªüëéüèª\n",
      "bottl\n",
      "getaway..\n",
      "dusappointed\n",
      "'glamourest\n",
      "whirlwin\n",
      "'guest\n",
      "delici\n",
      "'big\n",
      "myvstay\n",
      "harrahs-las\n",
      "skyr\n",
      "side..the\n",
      "lobby/\n",
      "price.around\n",
      "knickerboker\n",
      "controll\n",
      "o'ha\n",
      "alert**\n",
      "durinh\n",
      "esmee\n",
      "adequate..ve\n",
      "techological\n",
      "lovliness\n",
      "albit\n",
      "10th-14\n",
      "friday/saturday\n",
      "ip/quad\n",
      "no-\n",
      "hsotel\n",
      "warwck\n",
      "accomad\n",
      "goodmany\n",
      "boutique-sized\n",
      "while.sp\n",
      "bbma\n",
      "king-sized\n",
      "DG/DG-DG/DGDG\n",
      "lynch/\n",
      "inexpensivew\n",
      "confusi\n",
      "glaz\n",
      "codered\n",
      "140usd/night\n",
      "2017i\n",
      "hi-line\n",
      "ladydi\n",
      "guest-\n",
      "DG..DGDGDGDG\n",
      "under-delivered\n",
      "6-9th\n",
      "restaraunt\n",
      "accre\n",
      "disappointing.smoky\n",
      "place.rooms\n",
      "lobby/lounge\n",
      "squiare\n",
      "hoooorrrrrrriiiibblle\n",
      "conviene\n",
      "descrete\n",
      "heating/ac\n",
      "vegasvaca2017\n",
      ".mostly\n",
      "preisstruktur\n",
      "ostentati\n",
      "traditiona\n",
      "timer~\n",
      "mattando\n",
      "ice-maker\n",
      "versary\n",
      "anxie\n",
      "-manhattan\n",
      "no4\n",
      "amenities/service\n",
      "fantasticfood\n",
      "carneg\n",
      "well-situ\n",
      "high-q\n",
      "DGDG+\n",
      "thereloved\n",
      "life.i\n",
      "stunni\n",
      "exstremely\n",
      "wuee\n",
      "conveient\n",
      "airb\n",
      "iv√©\n",
      "broadway49\n",
      "greay\n",
      "orignal\n",
      "compriomise\n",
      "ok-ish\n",
      "bwplus\n",
      "casino-vibe\n",
      "beckys\n",
      "skep\n",
      "lobby/ent\n",
      "beatifully\n",
      "persaonable\n",
      "surprise..surprise\n",
      "2014for\n",
      "outrageousl\n",
      "charlamane\n",
      "courtes\n",
      "muitos\n",
      "rooms/very\n",
      "nights,7\n",
      "month.ho\n",
      "epect\n",
      "11nights\n",
      "about..\n",
      "walk-to\n",
      "mate.the\n",
      "weftec\n",
      "100/ni\n",
      "hotel35\n",
      "ballys_indigo\n",
      ".v\n",
      "wha5\n",
      "arrange/\n",
      "hotel.kids\n",
      "mlif\n",
      "tip..\n",
      "opposi\n",
      "discoun\n",
      "concierge-amy\n",
      "belagi\n",
      "favoite\n",
      "Îàârooms\n",
      "clean-welcoming\n",
      "-could\n",
      "beligio\n",
      "zelos-sept\n",
      "conrad~\n",
      ":DG\n",
      "quailty\n",
      "expirences\n",
      "pallante\n",
      "wonder..a\n",
      "relativel\n",
      "comming\n",
      "prenoted\n",
      "tolie\n",
      "spendy\n",
      "lights-good\n",
      "riverbar\n",
      "typical/nondescrip\n",
      "w-ny\n",
      "‚ù§Ô∏è‚ù§Ô∏è\n",
      "communicati\n",
      "t6his\n",
      "expirience\n",
      "cicro\n",
      "*charming\n",
      "w-type\n",
      "halfmoon710\n",
      "unautho\n",
      "decour\n",
      "comfortabme\n",
      "DG:DGDG-DG:DGDG\n",
      "pool..you\n",
      "tllfayel\n",
      "meetroyale.com\n",
      "understatement.r\n",
      "palace-everything\n",
      "hiltoni\n",
      "caeraes\n",
      "inside..but\n",
      "/birthday\n",
      "datk\n",
      "water..really\n",
      "..interrrrrrrnet\n",
      "greatmont\n",
      "rock/summerlin\n",
      "daughter/gir\n",
      "loactaion\n",
      "ipadbegin\n",
      "unattracti\n",
      "refurb\n",
      "cassell-\n",
      "nature..\n",
      "big-\n",
      "2-bath\n",
      "adewoa\n",
      "t'aime\n",
      "showro\n",
      "pod51\n",
      "clean-friendly\n",
      "hotel.e\n",
      "impressionns\n",
      "recommendationwe\n",
      "sportsboo\n",
      "minimal-quality\n",
      "shtarkman\n",
      "DGDG¬∞\n",
      "licatio\n",
      "opportunity1\n",
      "palaccce\n",
      "booking/planni\n",
      "substan\n",
      "counrty\n",
      "m-life\n",
      "oulisse\n",
      "mile/str\n",
      "pensilvania\n",
      "sucks.internet\n",
      "n.y.n.y\n",
      "propeert\n",
      "hospitaity\n",
      "alarme\n",
      "private////\n",
      "re-vitalized\n",
      "jan-24\n",
      "middlin\n",
      "communicatio\n",
      "assortm\n",
      "vegas-wild\n",
      "unkemp\n",
      "loyol\n",
      "rinad\n",
      "notlitan\n",
      "'world\n",
      "twice..brillian\n",
      "l'ocasi√≥\n",
      "ccharacter\n",
      "sooooooo\n",
      "rought\n",
      "room‚Äîgreat\n",
      "managerd\n",
      "terriibly\n",
      "j.king\n",
      "absoutely\n",
      "hotel.char\n",
      "there-\n",
      "city-centric\n",
      "property/services\n",
      "misco\n",
      "probabl\n",
      "uphols\n",
      "locatiog\n",
      ".b\n",
      "ru√≠doso\n",
      "suites‚ù§Ô∏è\n",
      "srayrd\n",
      "cosmoprof\n",
      "üçπ\n",
      "eat.clo\n",
      "somptuous\n",
      "felix-mode\n",
      "lyi\n",
      "4bunk/private\n",
      "brilient\n",
      "pool/lounge\n",
      "-expected\n",
      "n◊ù\n",
      "bugs**\n",
      "purpor\n",
      "mommy/daughter\n",
      "self-drive\n",
      "cosmoploitian\n",
      "opend\n",
      "milleneum\n",
      "pre-judge\n",
      "station/madis\n",
      "chineese\n",
      "freezi\n",
      "agsin\n",
      "magaritaville\n",
      "assum\n",
      "location/pric\n",
      "coom\n",
      "financ\n",
      "cromewell\n",
      "worldwi\n",
      "apologiz\n",
      "experrence\n",
      "hollywood..\n",
      "pre-burthday\n",
      "hearbeat\n",
      "apears\n",
      "iistayed\n",
      "frothfest\n",
      "in-train\n",
      "mattre\n",
      "notiched\n",
      "plesent\n",
      "statisfied\n",
      "linq-\n",
      "gambler/a\n",
      "non-time\n",
      "place.to\n",
      "prepared-terrible\n",
      "pro'shotel\n",
      "DGDG/DG-DGDG/DGDG/DGDG\n",
      "trip/fun\n",
      "wgich\n",
      "wholelattafun\n",
      "in-fact\n",
      "all-aroun\n",
      "üíµüí∞üíµüí∞üí∏üí∞=üíéüíéüíéüíçüíçüíçüòÉüòÉüî±üî±üî±\n",
      "visity\n",
      "celebrating/visiting\n",
      "nicier\n",
      "zeppeli\n",
      "westgaate\n",
      "underdel\n",
      "disappointinng\n",
      "conces\n",
      "vusit\n",
      "kids-10\n",
      "cleaniest\n",
      "hptel\n",
      "vegas/last\n",
      "individu\n",
      "10.10.17wanted\n",
      "dead50\n",
      "experiernce\n",
      "midtoen\n",
      "again.willia\n",
      "average-good\n",
      "power/hairdryer\n",
      "wyndhan\n",
      "hotel.locatio\n",
      "vibed\n",
      "dissappoints\n",
      "stru\n",
      "dumpiest\n",
      "'oldie\n",
      "rocelyn\n",
      "midtown/central\n",
      "carpeto\n",
      "anmenities\n",
      "ewh\n",
      "grandvi\n",
      "xity\n",
      "overcrwoded\n",
      "hyattembarcaderogreat\n",
      "custimer\n",
      "down-under\n",
      "scarle\n",
      "receptionde\n",
      "chistmas\n",
      "DGDGDGDG-DG-DGDG\n",
      ".will\n",
      "clasiness\n",
      "hotel¬¥s\n",
      "cool..but\n",
      "uncomfortablela\n",
      "beyon\n",
      "hotel/price\n",
      "'boutique\n",
      "town.2\n",
      "earplugs..thank\n",
      "..is\n",
      "rooms-liv\n",
      "butmiss\n",
      "stovan\n",
      "lollapalooz\n",
      "luggage/bell\n",
      "servicesmallest\n",
      "flamingo..\n",
      "quirkyly\n",
      "DG/DGDG/\n",
      "beach-li\n",
      "quality/a\n",
      "curtians\n",
      "2-bdrm\n",
      "hotel-grea\n",
      "carou\n",
      "hotel/inn\n",
      "up.\n",
      "located-incredibly\n",
      "hard-\n",
      "complimentaries\n",
      "upgradin\n",
      "not-so-pe\n",
      ".brilliant\n",
      "overpr\n",
      "rio..\n",
      "us-we\n",
      "weekendüëØüëØ\n",
      "pharaohld\n",
      "aug'17\n",
      "l26c\n",
      "value.pool\n",
      "385good\n",
      "affinya\n",
      "dontown\n",
      "bulls-eye\n",
      "drinks..\n",
      "suites-the\n",
      "unproffessional\n",
      "exchellent\n",
      "carraige\n",
      "friendly/knowledgable\n",
      "-reviews\n",
      "elcortez\n",
      "howles\n",
      "overd\n",
      "DGDG-DGDG-DGDGDGDG\n",
      "place.in\n",
      "girls-gr\n",
      "-place\n",
      "hi-quality\n",
      "12.25pm\n",
      "customir\n",
      "chelsea‚Äîweekend\n",
      "/timeless\n",
      "expectat\n",
      "daymar\n",
      "micro-hotel\n",
      "pros-the\n",
      "hollywoof\n",
      "verd\n",
      "mini-vakay\n",
      "mgrs\n",
      "out-date\n",
      "marielen\n",
      "srip\n",
      "manhattan/times\n",
      "16-20,2015.all\n",
      "distamce\n",
      "17hour\n",
      "conferena\n",
      "week.vee\n",
      "profes\n",
      "pucked\n",
      "cheerlea\n",
      "'stay\n",
      "partn\n",
      "ganse\n",
      "*smoke\n",
      "misre\n",
      "tastyfoodz\n",
      "ofense\n",
      "bellagio/mgm\n",
      "inn-downtown\n",
      "stay..most\n",
      "recogniz\n",
      "greatthe\n",
      "outperfor\n",
      "finiky\n",
      "..disgusting\n",
      "softba\n",
      "üòÅpaloozaü§£\n",
      "location.friendly\n",
      "tryping\n",
      "calme\n",
      "otherwise..\n",
      "accommodatipm\n",
      "snowpacalypse\n",
      "3-da\n",
      "„Ç∑„É´„ÇØ„Éâ„ÇΩ„É¨„Éº„É¶\n",
      "-loud\n",
      "citizenm\n",
      "ecperance\n",
      "great.free\n",
      "frige\n",
      "luxirous\n",
      "mediocr\n",
      "greatbuff\n",
      "corridal\n",
      "business/personal\n",
      "lack-luster\n",
      "..wonderful\n",
      "missl\n",
      "'own\n",
      "desk/concierge\n",
      "nirth\n",
      "predo\n",
      "valuepack\n",
      "areas..\n",
      "üò°\n",
      "ronl2317king\n",
      "conviennent\n",
      "redeming\n",
      "casino/entertainment\n",
      "genral\n",
      "heat/ac\n",
      "-better\n",
      "famlies\n",
      "arggh\n",
      "ever-so\n",
      "bart/train\n",
      "pool/strip\n",
      "noisy-could\n",
      "expertis\n",
      "2015this\n",
      "well-maintaine\n",
      "laquista\n",
      "euro-feel\n",
      "gr√®at\n",
      "platoo\n",
      "peppo\n",
      "getawau\n",
      "laquinta-las\n",
      "hairdrye\n",
      "hotelfrom\n",
      "jbs0001\n",
      "birthday/graduation\n",
      "life-saver\n",
      "kitcgen\n",
      "shotshow\n",
      "show-\n",
      "detectores\n",
      "yagp\n",
      "dermatolo\n",
      "mudtown\n",
      "self-check-\n",
      "representativ\n",
      "nicle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allaspects\n",
      "aapex\n",
      "vintage-style\n",
      "macgical\n",
      "viewroom\n",
      "40/night\n",
      "hotelwonderful\n",
      "blue-\n",
      "pro-guest\n",
      "dreary..\n",
      "unknowen\n",
      "-v\n",
      "veva\n",
      "rooms.comfortable\n",
      "theater-goers\n",
      "uber/lyfts\n",
      "croweded\n",
      "oldish\n",
      "summer.fel\n",
      "advace\n",
      "rooms.we\n",
      "quarky\n",
      "manhattan-35th\n",
      "bathrrom\n",
      "stingyon\n",
      "unfortunatly\n",
      "yet-\n",
      "non-refund\n",
      "/things\n",
      "fast..\n",
      "winderful\n",
      "location‚Ä¶\n",
      "i‚ù§nyny\n",
      "not-so-little\n",
      "zoomanity\n",
      "uninterest\n",
      "-upper\n",
      "strande\n",
      "9yo\n",
      "hotel.casino\n",
      "myste\n",
      "recommandation\n",
      "wxperience\n",
      "akcabingirl\n",
      "madison-\n",
      "square/theater\n",
      "stressfree\n",
      ",this\n",
      "unrestful\n",
      "woweeee\n",
      "cordinators\n",
      "pickick\n",
      "hete\n",
      "camb\n",
      "crawl.dirty\n",
      "noicy\n",
      "bewiched\n",
      "..fa\n",
      "fabulousl\n",
      "jones-crew\n",
      "ahhh-mazing\n",
      "dissapponted\n",
      "..if\n",
      "registeration\n",
      "hyb\n",
      "belleclaire\n",
      "shmancy\n",
      "value-oriented\n",
      "put-ou\n",
      "park-sleep-fly\n",
      "firewor\n",
      "executivge\n",
      "30/70th\n",
      "aquariam\n",
      "stayment\n",
      "weatgate\n",
      "centri\n",
      "nyc/theatre\n",
      "hotel-even\n",
      "bellagio-hotel\n",
      "2nd-6th\n",
      "service.gambles\n",
      "-gougers\n",
      "wedn\n",
      "hamtoninn\n",
      "location/old\n",
      "pleasentely\n",
      "36526\n"
     ]
    }
   ],
   "source": [
    "\n",
    "embeddings_index = dict()\n",
    "f = open('vocab/glove.6B.100d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "\n",
    "#randomly generate unknown and digit embeddings\n",
    "start_token_embed = np.random.randn(model_params['embed_dim'])\n",
    "end_token_embed = np.random.randn(model_params['embed_dim'])\n",
    "unk_token_embed = np.random.randn(model_params['embed_dim'])\n",
    "digit_embed = np.random.randn(model_params['embed_dim'])\n",
    "\n",
    "embedding_matrix = np.zeros((ds.vocab.size, model_params['embed_dim']))\n",
    "\n",
    "count = 0\n",
    "word=[]\n",
    "for token, index in ds.vocab.word_to_id.items():\n",
    "    \n",
    "    #print(index)\n",
    "    #print(constants.START_TOKEN)\n",
    "    \n",
    "    if token == constants.START_TOKEN:\n",
    "        embedding_matrix[index] = start_token_embed\n",
    "    elif token == constants.END_TOKEN:\n",
    "        embedding_matrix[index] = end_token_embed\n",
    "    elif token == constants.UNK_TOKEN:\n",
    "        embedding_matrix[index] = unk_token_embed\n",
    "    elif token == 'DG':\n",
    "        embedding_matrix[index] = digit_embed\n",
    "    else:\n",
    "        if index > ds.vocab.size - 1:\n",
    "            print(\"something is wrong shouldn't be here\")\n",
    "            break\n",
    "        else:\n",
    "            embedding_vector = embeddings_index.get(token)\n",
    "            if embedding_vector is not None:\n",
    "                embedding_matrix[index] = embedding_vector\n",
    "            else:\n",
    "                word.append(token)  \n",
    "                count += 1\n",
    "                #print(token)\n",
    "                embedding_matrix[index] = np.random.randn(model_params['embed_dim'])\n",
    "print(count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def embedding_layer(ids_, V, embed_dim, init_scale=0.001):\n",
    "    \n",
    "    #W_embed_ = tf.get_variable(\"W_embed\", shape=[V, embed_dim], \\\n",
    "    #                           initializer=tf.random_uniform_initializer(-init_scale, init_scale), \\\n",
    "    #                           trainable=True)\n",
    "    \n",
    "    W_embed_ = tf.constant(embedding_matrix, dtype=tf.float32, name=\"W_embed\")\n",
    "    \n",
    "    xs_ = tf.nn.embedding_lookup(W_embed_, ids_, name=\"embed_x\")\n",
    "        \n",
    "    return xs_\n",
    "\n",
    "def fully_connected_layers(h0_, hidden_dims, activation=tf.nn.relu,\n",
    "                           dropout_rate=0, is_training=False):\n",
    "    h_ = h0_\n",
    "    for i, hdim in enumerate(hidden_dims):\n",
    "        h_ = tf.layers.dense(h_, hdim, activation=activation, name=(\"Hidden_%d\"%i))\n",
    "        if dropout_rate > 0:\n",
    "            h_ = tf.layers.dropout(h_, rate=dropout_rate, training=is_training )\n",
    "    return h_\n",
    "\n",
    "def softmax_output_layer(h_, labels_, num_classes):\n",
    "    \n",
    "    W_out_ = tf.get_variable(\"W_out\",  shape=[h_.get_shape().as_list()[1], num_classes], \\\n",
    "                               initializer=tf.random_normal_initializer())\n",
    "    b_out_ = tf.get_variable(\"b_out\", shape=[num_classes])\n",
    "\n",
    "    logits_ = tf.add(tf.matmul(h_, W_out_), b_out_)\n",
    "        \n",
    "    if labels_ is None:\n",
    "        return None, logits_\n",
    "    \n",
    "    with tf.variable_scope(\"Softmax_Layer\"):\n",
    "        #softmax_ = tf.nn.softmax_cross_entropy_with_logits_v2(labels=labels_, logits=logits_, name='softmax')\n",
    "        softmax_ = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels_, logits=logits_)\n",
    "        \n",
    "        loss_ = tf.reduce_mean(softmax_)\n",
    "    \n",
    "    return loss_, logits_\n",
    "\n",
    "def BOW(ids_, V, embed_dim, hidden_dims, dropout_rate=0, is_training=None):\n",
    "    assert is_training is not None, \"is_training must be explicitly set to True or False\"\n",
    "\n",
    "    with tf.variable_scope(\"Embedding_Layer\"):\n",
    "        xs_ = embedding_layer(ids_, V, embed_dim)\n",
    "     \n",
    "    sum_xs_ = tf.reduce_sum(xs_, 1)\n",
    "\n",
    "    h_ = fully_connected_layers(sum_xs_, hidden_dims, \\\n",
    "                           dropout_rate=dropout_rate, is_training=is_training)\n",
    "    return h_, xs_\n",
    "\n",
    "\n",
    "def conv_net(ids_, V, embed_dim, filter_sizes, num_filters, hidden_dims, input_length, dropout_rate=0.5, is_training=None):\n",
    "\n",
    "    assert is_training is not None, \"is_training must be explicitly set to True or False\"\n",
    "\n",
    "    with tf.variable_scope(\"Embedding_Layer\"):\n",
    "        xs_ = embedding_layer(ids_, V, embed_dim)\n",
    "\n",
    "    xs_ = tf.expand_dims(xs_, -1)\n",
    "        \n",
    "    pooled_outputs_ = []\n",
    "    for _, filter_size in enumerate(filter_sizes):\n",
    "        with tf.name_scope(\"Conv_MaxPool_%d\"%filter_size):\n",
    "            \n",
    "            # Convolution Layer\n",
    "            filter_shape = [filter_size, embed_dim, 1, num_filters]\n",
    "            W_ = tf.Variable(tf.truncated_normal(filter_shape, stddev=0.1), name=\"W\")\n",
    "            b_ = tf.Variable(tf.constant(0.1, shape=[num_filters]), name=\"b\")\n",
    "            conv_ = tf.nn.conv2d(\n",
    "                xs_,\n",
    "                W_,\n",
    "                strides=[1, 1, 1, 1],\n",
    "                padding=\"VALID\",\n",
    "                name=\"conv\")\n",
    "            \n",
    "            # Activation\n",
    "            h_ = tf.nn.relu(tf.nn.bias_add(conv_, b_), name=\"relu\")\n",
    "            \n",
    "            # Maxpooling \n",
    "            pooled_ = tf.nn.max_pool(\n",
    "                h_,\n",
    "                ksize=[1, input_length - filter_size + 1, 1, 1],\n",
    "                strides=[1, 1, 1, 1],\n",
    "                padding='VALID',\n",
    "                name=\"pool\")\n",
    "            pooled_outputs_.append(pooled_)\n",
    "            \n",
    "            variable_summaries(pooled_)\n",
    "\n",
    "    # Combine all the pooled features and flatten it\n",
    "    num_filters_total = num_filters * len(filter_sizes)\n",
    "    h_ = tf.concat(pooled_outputs_, 3)\n",
    "    h_ = tf.reshape(h_, [-1, num_filters_total])\n",
    "    \n",
    "    # fully connected layers\n",
    "    with tf.variable_scope(\"FC_Layer\"):\n",
    "        h_ = fully_connected_layers(h_, hidden_dims, is_training = is_training)\n",
    "\n",
    "    return h_, xs_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph() \n",
    "\n",
    "X = tf.placeholder(tf.int32, [None, input_length], name='input_x')\n",
    "Y = tf.placeholder(tf.int32, [None,], name='input_y')\n",
    "embedding_placeholder = tf.placeholder(tf.float32, [ds.vocab.size, model_params['embed_dim']])\n",
    "    \n",
    "\n",
    "if Y is None:\n",
    "    one_hot_y_ = None\n",
    "else:\n",
    "    one_hot_y_ = tf.one_hot(Y, model_params['num_classes'])\n",
    "\n",
    "\n",
    "if model_params['encoder_type'] == 'cnn':\n",
    "    h_, xs_ = conv_net(X, model_params['V'], \n",
    "                      model_params['embed_dim'], \n",
    "                      model_params['filter_sizes'], \n",
    "                      model_params['num_filters'], \n",
    "                      model_params['hidden_dims'],\n",
    "                      model_params['input_length'],\n",
    "                      is_training=True)\n",
    "elif model_params['encoder_type'] == 'bow':\n",
    "    h_, xs_ = BOW(X, model_params['V'], \n",
    "                      model_params['embed_dim'],  \n",
    "                      model_params['hidden_dims'],\n",
    "                      model_params['dropout_rate'],\n",
    "                      is_training=True)\n",
    "\n",
    "\n",
    "with tf.variable_scope(\"Output_Layer\"):\n",
    "    #ce_loss_, logits_ = softmax_output_layer(h_, one_hot_y_, model_params['num_classes'])\n",
    "    ce_loss_, logits_ = softmax_output_layer(h_, Y, model_params['num_classes'])\n",
    "    \n",
    "\n",
    "with tf.name_scope(\"Prediction\"):\n",
    "    pred_proba_ = tf.nn.softmax(logits_, name=\"pred_proba\")\n",
    "    pred_max_ = tf.argmax(logits_, 1, name=\"pred_max\")\n",
    "    predictions_dict = {\"proba\": pred_proba_, \"max\": pred_max_}\n",
    "\n",
    "with tf.variable_scope(\"Regularization\"):\n",
    "    l2_penalty_ = tf.nn.l2_loss(xs_)  # l2 loss on embeddings\n",
    "    for var_ in tf.trainable_variables():\n",
    "        if \"Embedding_Layer\" in var_.name:\n",
    "            continue\n",
    "        l2_penalty_ += tf.nn.l2_loss(var_)\n",
    "    l2_penalty_ *= model_params['beta']  # scale by regularization strength\n",
    "    tf.summary.scalar('l2_penalty', l2_penalty_)\n",
    "    regularized_loss_ = ce_loss_ + l2_penalty_\n",
    "    tf.summary.scalar('regularized_loss', regularized_loss_)\n",
    "\n",
    "with tf.variable_scope(\"Training\"):\n",
    "    if model_params['optimizer'] == 'adagrad':\n",
    "        optimizer_ = tf.train.AdagradOptimizer(model_params['lr'])\n",
    "    elif  model_params['optimizer'] == 'adam':\n",
    "        optimizer_ = tf.train.AdamOptimizer(model_params['lr'])\n",
    "    else:\n",
    "        optimizer_ = tf.train.GradientDescentOptimizer(model_params['lr'])\n",
    "    train_op_ = optimizer_.minimize(regularized_loss_,\n",
    "                    global_step=tf.train.get_global_step())\n",
    "\n",
    "\n",
    "with tf.name_scope(\"Evaluation\"):\n",
    "    cross_entropy_loss_ = tf.metrics.mean(ce_loss_)\n",
    "    #accuracy_ = tf.metrics.accuracy(Y, pred_max_)\n",
    "    \n",
    "    correct_pred_ = tf.equal(tf.argmax(logits_, 1), tf.argmax(one_hot_y_, 1))\n",
    "    #correct_pred_ = tf.equal(tf.argmax(logits_, 1), Y)\n",
    "    accuracy_ = tf.reduce_mean(tf.cast(correct_pred_, tf.float32))\n",
    "\n",
    "    eval_metrics = {\"cross_entropy_loss\": cross_entropy_loss_, \"accuracy\": accuracy_}\n",
    "    \n",
    "    tf.summary.scalar('cross_entropy', ce_loss_)\n",
    "    tf.summary.scalar('accuracy', accuracy_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsaver = tf.train.Saver()\\n\\nwith tf.Session() as sess:\\n  # Restore variables from disk.\\n    saver.restore(sess, \"./tmp/model_bow_test.ckpt\")\\n'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  # Restore variables from disk.\n",
    "    saver.restore(sess, \"./tmp/model_bow_test.ckpt\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorboard --logdir=./tmp/266_cnn_20181207-1306/train\n",
      "tensorboard --logdir=./tmp/266_cnn_20181207-1306/test\n",
      "1,600 examples, moving-average loss 12.96, train accuracy 0.32\n",
      "3,200 examples, moving-average loss 13.04, train accuracy 0.36\n",
      "4,800 examples, moving-average loss 12.96, train accuracy 0.38\n",
      "6,400 examples, moving-average loss 12.90, train accuracy 0.39\n",
      "8,000 examples, moving-average loss 12.95, train accuracy 0.40\n",
      "9,600 examples, moving-average loss 12.78, train accuracy 0.40\n",
      "11,200 examples, moving-average loss 12.75, train accuracy 0.41\n",
      "12,800 examples, moving-average loss 12.82, train accuracy 0.41\n",
      "14,400 examples, moving-average loss 12.72, train accuracy 0.42\n",
      "16,000 examples, moving-average loss 12.79, train accuracy 0.42\n",
      "17,600 examples, moving-average loss 12.74, train accuracy 0.42\n",
      "19,200 examples, moving-average loss 12.73, train accuracy 0.42\n",
      "20,800 examples, moving-average loss 12.80, train accuracy 0.42\n",
      "22,400 examples, moving-average loss 12.64, train accuracy 0.42\n",
      "24,000 examples, moving-average loss 12.67, train accuracy 0.42\n",
      "25,600 examples, moving-average loss 12.62, train accuracy 0.43\n",
      "27,200 examples, moving-average loss 12.70, train accuracy 0.43\n",
      "28,800 examples, moving-average loss 12.70, train accuracy 0.43\n",
      "30,400 examples, moving-average loss 12.62, train accuracy 0.43\n",
      "32,000 examples, moving-average loss 12.64, train accuracy 0.43\n",
      "33,600 examples, moving-average loss 12.71, train accuracy 0.43\n",
      "35,200 examples, moving-average loss 12.62, train accuracy 0.43\n",
      "36,800 examples, moving-average loss 12.64, train accuracy 0.43\n",
      "38,400 examples, moving-average loss 12.65, train accuracy 0.44\n",
      "40,000 examples, moving-average loss 12.50, train accuracy 0.44\n",
      "41,600 examples, moving-average loss 12.66, train accuracy 0.44\n",
      "43,200 examples, moving-average loss 12.55, train accuracy 0.44\n",
      "44,800 examples, moving-average loss 12.56, train accuracy 0.44\n",
      "46,400 examples, moving-average loss 12.56, train accuracy 0.44\n",
      "48,000 examples, moving-average loss 12.69, train accuracy 0.44\n",
      "49,600 examples, moving-average loss 12.50, train accuracy 0.44\n",
      "51,200 examples, moving-average loss 12.57, train accuracy 0.44\n",
      "52,800 examples, moving-average loss 12.55, train accuracy 0.44\n",
      "54,400 examples, moving-average loss 12.62, train accuracy 0.45\n",
      "56,000 examples, moving-average loss 12.57, train accuracy 0.45\n",
      "57,600 examples, moving-average loss 12.57, train accuracy 0.45\n",
      "59,200 examples, moving-average loss 12.53, train accuracy 0.45\n",
      "60,800 examples, moving-average loss 12.53, train accuracy 0.45\n",
      "62,400 examples, moving-average loss 12.62, train accuracy 0.45\n",
      "64,000 examples, moving-average loss 12.53, train accuracy 0.45\n",
      "65,600 examples, moving-average loss 12.59, train accuracy 0.45\n",
      "67,200 examples, moving-average loss 12.51, train accuracy 0.45\n",
      "68,800 examples, moving-average loss 12.48, train accuracy 0.45\n",
      "70,400 examples, moving-average loss 12.48, train accuracy 0.45\n",
      "72,000 examples, moving-average loss 12.52, train accuracy 0.45\n",
      "73,600 examples, moving-average loss 12.56, train accuracy 0.45\n",
      "75,200 examples, moving-average loss 12.50, train accuracy 0.45\n",
      "76,800 examples, moving-average loss 12.50, train accuracy 0.45\n",
      "78,400 examples, moving-average loss 12.53, train accuracy 0.45\n",
      "80,000 examples, moving-average loss 12.51, train accuracy 0.45\n",
      "81,600 examples, moving-average loss 12.49, train accuracy 0.45\n",
      "83,200 examples, moving-average loss 12.45, train accuracy 0.46\n",
      "84,800 examples, moving-average loss 12.55, train accuracy 0.46\n",
      "86,400 examples, moving-average loss 12.50, train accuracy 0.46\n",
      "88,000 examples, moving-average loss 12.46, train accuracy 0.46\n",
      "89,600 examples, moving-average loss 12.55, train accuracy 0.46\n",
      "91,200 examples, moving-average loss 12.51, train accuracy 0.46\n",
      "92,800 examples, moving-average loss 12.53, train accuracy 0.46\n",
      "94,400 examples, moving-average loss 12.59, train accuracy 0.46\n",
      "96,000 examples, moving-average loss 12.54, train accuracy 0.46\n",
      "97,600 examples, moving-average loss 12.51, train accuracy 0.46\n",
      "99,200 examples, moving-average loss 12.49, train accuracy 0.46\n",
      "100,800 examples, moving-average loss 12.47, train accuracy 0.46\n",
      "102,400 examples, moving-average loss 12.50, train accuracy 0.46\n",
      "104,000 examples, moving-average loss 12.47, train accuracy 0.46\n",
      "105,600 examples, moving-average loss 12.59, train accuracy 0.46\n",
      "107,200 examples, moving-average loss 12.48, train accuracy 0.46\n",
      "108,800 examples, moving-average loss 12.59, train accuracy 0.46\n",
      "110,400 examples, moving-average loss 12.44, train accuracy 0.46\n",
      "112,000 examples, moving-average loss 12.48, train accuracy 0.46\n",
      "113,600 examples, moving-average loss 12.54, train accuracy 0.46\n",
      "115,200 examples, moving-average loss 12.44, train accuracy 0.46\n",
      "116,800 examples, moving-average loss 12.42, train accuracy 0.46\n",
      "118,400 examples, moving-average loss 12.49, train accuracy 0.47\n",
      "120,000 examples, moving-average loss 12.53, train accuracy 0.47\n",
      "121,600 examples, moving-average loss 12.51, train accuracy 0.47\n",
      "123,200 examples, moving-average loss 12.45, train accuracy 0.47\n",
      "124,800 examples, moving-average loss 12.58, train accuracy 0.47\n",
      "126,400 examples, moving-average loss 12.42, train accuracy 0.47\n",
      "128,000 examples, moving-average loss 12.47, train accuracy 0.47\n",
      "129,600 examples, moving-average loss 12.43, train accuracy 0.47\n",
      "131,200 examples, moving-average loss 12.41, train accuracy 0.47\n",
      "132,800 examples, moving-average loss 12.43, train accuracy 0.47\n",
      "134,400 examples, moving-average loss 12.34, train accuracy 0.47\n",
      "136,000 examples, moving-average loss 12.57, train accuracy 0.47\n",
      "137,600 examples, moving-average loss 12.47, train accuracy 0.47\n",
      "139,200 examples, moving-average loss 12.48, train accuracy 0.47\n",
      "140,800 examples, moving-average loss 12.45, train accuracy 0.47\n",
      "142,400 examples, moving-average loss 12.45, train accuracy 0.47\n",
      "144,000 examples, moving-average loss 12.47, train accuracy 0.47\n",
      "145,600 examples, moving-average loss 12.44, train accuracy 0.47\n",
      "147,200 examples, moving-average loss 12.49, train accuracy 0.47\n",
      "148,800 examples, moving-average loss 12.41, train accuracy 0.47\n",
      "150,400 examples, moving-average loss 12.43, train accuracy 0.47\n",
      "152,000 examples, moving-average loss 12.39, train accuracy 0.47\n",
      "153,600 examples, moving-average loss 12.48, train accuracy 0.47\n",
      "155,200 examples, moving-average loss 12.39, train accuracy 0.47\n",
      "156,800 examples, moving-average loss 12.39, train accuracy 0.47\n",
      "158,400 examples, moving-average loss 12.41, train accuracy 0.48\n",
      "160,000 examples, moving-average loss 12.40, train accuracy 0.48\n",
      "161,600 examples, moving-average loss 12.44, train accuracy 0.48\n",
      "163,200 examples, moving-average loss 12.36, train accuracy 0.48\n",
      "164,800 examples, moving-average loss 12.44, train accuracy 0.48\n",
      "166,400 examples, moving-average loss 12.44, train accuracy 0.48\n",
      "168,000 examples, moving-average loss 12.44, train accuracy 0.48\n",
      "169,600 examples, moving-average loss 12.53, train accuracy 0.48\n",
      "171,200 examples, moving-average loss 12.46, train accuracy 0.48\n",
      "172,800 examples, moving-average loss 12.42, train accuracy 0.48\n",
      "174,400 examples, moving-average loss 12.42, train accuracy 0.48\n",
      "176,000 examples, moving-average loss 12.47, train accuracy 0.48\n",
      "177,600 examples, moving-average loss 12.46, train accuracy 0.48\n",
      "179,200 examples, moving-average loss 12.49, train accuracy 0.48\n",
      "180,800 examples, moving-average loss 12.40, train accuracy 0.48\n",
      "182,400 examples, moving-average loss 12.40, train accuracy 0.48\n",
      "184,000 examples, moving-average loss 12.44, train accuracy 0.48\n",
      "185,600 examples, moving-average loss 12.37, train accuracy 0.48\n",
      "187,200 examples, moving-average loss 12.42, train accuracy 0.48\n",
      "188,800 examples, moving-average loss 12.45, train accuracy 0.48\n",
      "190,400 examples, moving-average loss 12.42, train accuracy 0.48\n",
      "192,000 examples, moving-average loss 12.44, train accuracy 0.48\n",
      "193,600 examples, moving-average loss 12.43, train accuracy 0.48\n",
      "195,200 examples, moving-average loss 12.34, train accuracy 0.48\n",
      "196,800 examples, moving-average loss 12.45, train accuracy 0.48\n",
      "198,400 examples, moving-average loss 12.38, train accuracy 0.48\n",
      "200,000 examples, moving-average loss 12.34, train accuracy 0.48\n",
      "201,600 examples, moving-average loss 12.41, train accuracy 0.48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203,200 examples, moving-average loss 12.37, train accuracy 0.48\n",
      "204,800 examples, moving-average loss 12.33, train accuracy 0.48\n",
      "206,400 examples, moving-average loss 12.43, train accuracy 0.48\n",
      "208,000 examples, moving-average loss 12.37, train accuracy 0.48\n",
      "209,600 examples, moving-average loss 12.38, train accuracy 0.49\n",
      "211,200 examples, moving-average loss 12.42, train accuracy 0.49\n",
      "212,800 examples, moving-average loss 12.45, train accuracy 0.49\n",
      "214,400 examples, moving-average loss 12.42, train accuracy 0.49\n",
      "216,000 examples, moving-average loss 12.42, train accuracy 0.49\n",
      "217,600 examples, moving-average loss 12.40, train accuracy 0.49\n",
      "219,200 examples, moving-average loss 12.44, train accuracy 0.49\n",
      "220,800 examples, moving-average loss 12.40, train accuracy 0.49\n",
      "222,400 examples, moving-average loss 12.33, train accuracy 0.49\n",
      "224,000 examples, moving-average loss 12.34, train accuracy 0.49\n",
      "225,600 examples, moving-average loss 12.39, train accuracy 0.49\n",
      "227,200 examples, moving-average loss 12.35, train accuracy 0.49\n",
      "228,800 examples, moving-average loss 12.45, train accuracy 0.49\n",
      "230,400 examples, moving-average loss 12.39, train accuracy 0.49\n",
      "232,000 examples, moving-average loss 12.34, train accuracy 0.49\n",
      "233,600 examples, moving-average loss 12.35, train accuracy 0.49\n",
      "235,200 examples, moving-average loss 12.46, train accuracy 0.49\n",
      "236,800 examples, moving-average loss 12.37, train accuracy 0.49\n",
      "238,400 examples, moving-average loss 12.37, train accuracy 0.49\n",
      "240,000 examples, moving-average loss 12.30, train accuracy 0.49\n",
      "241,600 examples, moving-average loss 12.34, train accuracy 0.49\n",
      "243,200 examples, moving-average loss 12.34, train accuracy 0.49\n",
      "244,800 examples, moving-average loss 12.35, train accuracy 0.49\n",
      "246,400 examples, moving-average loss 12.30, train accuracy 0.49\n",
      "248,000 examples, moving-average loss 12.31, train accuracy 0.49\n",
      "249,600 examples, moving-average loss 12.35, train accuracy 0.49\n",
      "251,200 examples, moving-average loss 12.37, train accuracy 0.49\n",
      "252,800 examples, moving-average loss 12.27, train accuracy 0.49\n",
      "254,400 examples, moving-average loss 12.37, train accuracy 0.49\n",
      "256,000 examples, moving-average loss 12.36, train accuracy 0.49\n",
      "257,600 examples, moving-average loss 12.34, train accuracy 0.49\n",
      "259,200 examples, moving-average loss 12.42, train accuracy 0.49\n",
      "260,800 examples, moving-average loss 12.31, train accuracy 0.49\n",
      "262,400 examples, moving-average loss 12.36, train accuracy 0.49\n",
      "264,000 examples, moving-average loss 12.33, train accuracy 0.49\n",
      "265,600 examples, moving-average loss 12.32, train accuracy 0.49\n",
      "267,200 examples, moving-average loss 12.28, train accuracy 0.50\n",
      "268,800 examples, moving-average loss 12.37, train accuracy 0.50\n",
      "270,400 examples, moving-average loss 12.39, train accuracy 0.50\n",
      "272,000 examples, moving-average loss 12.43, train accuracy 0.50\n",
      "273,600 examples, moving-average loss 12.42, train accuracy 0.50\n",
      "275,200 examples, moving-average loss 12.32, train accuracy 0.50\n",
      "276,800 examples, moving-average loss 12.24, train accuracy 0.50\n",
      "278,400 examples, moving-average loss 12.28, train accuracy 0.50\n",
      "280,000 examples, moving-average loss 12.36, train accuracy 0.50\n",
      "281,600 examples, moving-average loss 12.43, train accuracy 0.50\n",
      "283,200 examples, moving-average loss 12.34, train accuracy 0.50\n",
      "284,800 examples, moving-average loss 12.42, train accuracy 0.50\n",
      "286,400 examples, moving-average loss 12.32, train accuracy 0.50\n",
      "288,000 examples, moving-average loss 12.34, train accuracy 0.50\n",
      "289,600 examples, moving-average loss 12.28, train accuracy 0.50\n",
      "291,200 examples, moving-average loss 12.27, train accuracy 0.50\n",
      "292,800 examples, moving-average loss 12.34, train accuracy 0.50\n",
      "294,400 examples, moving-average loss 12.38, train accuracy 0.50\n",
      "296,000 examples, moving-average loss 12.40, train accuracy 0.50\n",
      "297,600 examples, moving-average loss 12.35, train accuracy 0.50\n",
      "299,200 examples, moving-average loss 12.27, train accuracy 0.50\n",
      "300,800 examples, moving-average loss 12.30, train accuracy 0.50\n",
      "302,400 examples, moving-average loss 12.32, train accuracy 0.50\n",
      "304,000 examples, moving-average loss 12.37, train accuracy 0.50\n",
      "305,600 examples, moving-average loss 12.34, train accuracy 0.50\n",
      "307,200 examples, moving-average loss 12.32, train accuracy 0.50\n",
      "308,800 examples, moving-average loss 12.25, train accuracy 0.50\n",
      "310,400 examples, moving-average loss 12.39, train accuracy 0.50\n",
      "312,000 examples, moving-average loss 12.27, train accuracy 0.50\n",
      "313,600 examples, moving-average loss 12.29, train accuracy 0.50\n",
      "315,200 examples, moving-average loss 12.37, train accuracy 0.50\n",
      "316,800 examples, moving-average loss 12.33, train accuracy 0.50\n",
      "318,400 examples, moving-average loss 12.29, train accuracy 0.50\n",
      "320,000 examples, moving-average loss 12.35, train accuracy 0.50\n",
      "321,600 examples, moving-average loss 12.36, train accuracy 0.50\n",
      "323,200 examples, moving-average loss 12.33, train accuracy 0.50\n",
      "324,800 examples, moving-average loss 12.32, train accuracy 0.50\n",
      "326,400 examples, moving-average loss 12.28, train accuracy 0.50\n",
      "328,000 examples, moving-average loss 12.34, train accuracy 0.50\n",
      "329,600 examples, moving-average loss 12.31, train accuracy 0.50\n",
      "331,200 examples, moving-average loss 12.35, train accuracy 0.50\n",
      "332,800 examples, moving-average loss 12.34, train accuracy 0.50\n",
      "334,400 examples, moving-average loss 12.30, train accuracy 0.51\n",
      "336,000 examples, moving-average loss 12.35, train accuracy 0.51\n",
      "337,600 examples, moving-average loss 12.33, train accuracy 0.51\n",
      "339,200 examples, moving-average loss 12.36, train accuracy 0.51\n",
      "340,800 examples, moving-average loss 12.27, train accuracy 0.51\n",
      "342,400 examples, moving-average loss 12.26, train accuracy 0.51\n",
      "344,000 examples, moving-average loss 12.38, train accuracy 0.51\n",
      "345,600 examples, moving-average loss 12.37, train accuracy 0.51\n",
      "347,200 examples, moving-average loss 12.34, train accuracy 0.51\n",
      "348,800 examples, moving-average loss 12.37, train accuracy 0.51\n",
      "350,400 examples, moving-average loss 12.19, train accuracy 0.51\n",
      "352,000 examples, moving-average loss 12.18, train accuracy 0.51\n",
      "353,600 examples, moving-average loss 12.33, train accuracy 0.51\n",
      "355,200 examples, moving-average loss 12.28, train accuracy 0.51\n",
      "356,800 examples, moving-average loss 12.22, train accuracy 0.51\n",
      "358,400 examples, moving-average loss 12.30, train accuracy 0.51\n",
      "360,000 examples, moving-average loss 12.28, train accuracy 0.51\n",
      "361,600 examples, moving-average loss 12.34, train accuracy 0.51\n",
      "363,200 examples, moving-average loss 12.31, train accuracy 0.51\n",
      "364,800 examples, moving-average loss 12.23, train accuracy 0.51\n",
      "366,400 examples, moving-average loss 12.31, train accuracy 0.51\n",
      "368,000 examples, moving-average loss 12.27, train accuracy 0.51\n",
      "369,600 examples, moving-average loss 12.33, train accuracy 0.51\n",
      "371,200 examples, moving-average loss 12.40, train accuracy 0.51\n",
      "372,800 examples, moving-average loss 12.29, train accuracy 0.51\n",
      "374,400 examples, moving-average loss 12.26, train accuracy 0.51\n",
      "376,000 examples, moving-average loss 12.42, train accuracy 0.51\n",
      "377,600 examples, moving-average loss 12.28, train accuracy 0.51\n",
      "379,200 examples, moving-average loss 12.27, train accuracy 0.51\n",
      "380,800 examples, moving-average loss 12.29, train accuracy 0.51\n",
      "382,400 examples, moving-average loss 12.36, train accuracy 0.51\n",
      "384,000 examples, moving-average loss 12.35, train accuracy 0.51\n",
      "385,600 examples, moving-average loss 12.25, train accuracy 0.51\n",
      "387,200 examples, moving-average loss 12.29, train accuracy 0.51\n",
      "388,800 examples, moving-average loss 12.28, train accuracy 0.51\n",
      "390,400 examples, moving-average loss 12.33, train accuracy 0.51\n",
      "392,000 examples, moving-average loss 12.29, train accuracy 0.51\n",
      "393,600 examples, moving-average loss 12.26, train accuracy 0.51\n",
      "395,200 examples, moving-average loss 12.27, train accuracy 0.51\n",
      "396,800 examples, moving-average loss 12.34, train accuracy 0.51\n",
      "398,400 examples, moving-average loss 12.32, train accuracy 0.51\n",
      "400,000 examples, moving-average loss 12.26, train accuracy 0.51\n",
      "401,600 examples, moving-average loss 12.34, train accuracy 0.51\n",
      "403,200 examples, moving-average loss 12.24, train accuracy 0.51\n",
      "404,800 examples, moving-average loss 12.32, train accuracy 0.51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "406,400 examples, moving-average loss 12.36, train accuracy 0.51\n",
      "408,000 examples, moving-average loss 12.38, train accuracy 0.51\n",
      "409,600 examples, moving-average loss 12.35, train accuracy 0.51\n",
      "411,200 examples, moving-average loss 12.26, train accuracy 0.51\n",
      "412,800 examples, moving-average loss 12.32, train accuracy 0.51\n",
      "414,400 examples, moving-average loss 12.35, train accuracy 0.52\n",
      "416,000 examples, moving-average loss 12.31, train accuracy 0.52\n",
      "417,600 examples, moving-average loss 12.31, train accuracy 0.52\n",
      "419,200 examples, moving-average loss 12.29, train accuracy 0.52\n",
      "420,800 examples, moving-average loss 12.30, train accuracy 0.52\n",
      "422,400 examples, moving-average loss 12.26, train accuracy 0.52\n",
      "424,000 examples, moving-average loss 12.31, train accuracy 0.52\n",
      "425,600 examples, moving-average loss 12.26, train accuracy 0.52\n",
      "427,200 examples, moving-average loss 12.30, train accuracy 0.52\n",
      "428,800 examples, moving-average loss 12.24, train accuracy 0.52\n",
      "430,400 examples, moving-average loss 12.32, train accuracy 0.52\n",
      "432,000 examples, moving-average loss 12.35, train accuracy 0.52\n",
      "433,600 examples, moving-average loss 12.28, train accuracy 0.52\n",
      "435,200 examples, moving-average loss 12.29, train accuracy 0.52\n",
      "436,800 examples, moving-average loss 12.25, train accuracy 0.52\n",
      "438,400 examples, moving-average loss 12.31, train accuracy 0.52\n",
      "440,000 examples, moving-average loss 12.26, train accuracy 0.52\n",
      "441,600 examples, moving-average loss 12.27, train accuracy 0.52\n",
      "443,200 examples, moving-average loss 12.27, train accuracy 0.52\n",
      "444,800 examples, moving-average loss 12.34, train accuracy 0.52\n",
      "446,400 examples, moving-average loss 12.28, train accuracy 0.52\n",
      "448,000 examples, moving-average loss 12.33, train accuracy 0.52\n",
      "449,600 examples, moving-average loss 12.27, train accuracy 0.52\n",
      "451,200 examples, moving-average loss 12.30, train accuracy 0.52\n",
      "452,800 examples, moving-average loss 12.30, train accuracy 0.52\n",
      "454,400 examples, moving-average loss 12.21, train accuracy 0.52\n",
      "456,000 examples, moving-average loss 12.30, train accuracy 0.52\n",
      "457,600 examples, moving-average loss 12.26, train accuracy 0.52\n",
      "459,200 examples, moving-average loss 12.29, train accuracy 0.52\n",
      "460,800 examples, moving-average loss 12.33, train accuracy 0.52\n",
      "462,400 examples, moving-average loss 12.41, train accuracy 0.52\n",
      "464,000 examples, moving-average loss 12.30, train accuracy 0.52\n",
      "465,600 examples, moving-average loss 12.24, train accuracy 0.52\n",
      "467,200 examples, moving-average loss 12.30, train accuracy 0.52\n",
      "468,800 examples, moving-average loss 12.28, train accuracy 0.52\n",
      "470,400 examples, moving-average loss 12.26, train accuracy 0.52\n",
      "472,000 examples, moving-average loss 12.38, train accuracy 0.52\n",
      "473,600 examples, moving-average loss 12.24, train accuracy 0.52\n",
      "475,200 examples, moving-average loss 12.35, train accuracy 0.52\n",
      "476,800 examples, moving-average loss 12.26, train accuracy 0.52\n",
      "478,400 examples, moving-average loss 12.29, train accuracy 0.52\n",
      "480,000 examples, moving-average loss 12.29, train accuracy 0.52\n",
      "481,600 examples, moving-average loss 12.31, train accuracy 0.52\n",
      "483,200 examples, moving-average loss 12.31, train accuracy 0.52\n",
      "484,800 examples, moving-average loss 12.21, train accuracy 0.52\n",
      "486,400 examples, moving-average loss 12.26, train accuracy 0.52\n",
      "488,000 examples, moving-average loss 12.36, train accuracy 0.52\n",
      "489,600 examples, moving-average loss 12.33, train accuracy 0.52\n",
      "491,200 examples, moving-average loss 12.28, train accuracy 0.52\n",
      "492,800 examples, moving-average loss 12.22, train accuracy 0.52\n",
      "494,400 examples, moving-average loss 12.23, train accuracy 0.52\n",
      "496,000 examples, moving-average loss 12.23, train accuracy 0.52\n",
      "497,600 examples, moving-average loss 12.32, train accuracy 0.52\n",
      "499,200 examples, moving-average loss 12.18, train accuracy 0.52\n",
      "500,800 examples, moving-average loss 12.18, train accuracy 0.52\n",
      "502,400 examples, moving-average loss 12.24, train accuracy 0.52\n",
      "504,000 examples, moving-average loss 12.25, train accuracy 0.52\n",
      "505,600 examples, moving-average loss 12.28, train accuracy 0.52\n",
      "507,200 examples, moving-average loss 12.29, train accuracy 0.52\n",
      "508,800 examples, moving-average loss 12.29, train accuracy 0.52\n",
      "510,400 examples, moving-average loss 12.31, train accuracy 0.52\n",
      "512,000 examples, moving-average loss 12.33, train accuracy 0.52\n",
      "513,600 examples, moving-average loss 12.30, train accuracy 0.53\n",
      "515,200 examples, moving-average loss 12.23, train accuracy 0.53\n",
      "516,800 examples, moving-average loss 12.28, train accuracy 0.53\n",
      "518,400 examples, moving-average loss 12.28, train accuracy 0.53\n",
      "520,000 examples, moving-average loss 12.31, train accuracy 0.53\n",
      "521,600 examples, moving-average loss 12.23, train accuracy 0.53\n",
      "523,200 examples, moving-average loss 12.21, train accuracy 0.53\n",
      "524,800 examples, moving-average loss 12.21, train accuracy 0.53\n",
      "526,400 examples, moving-average loss 12.24, train accuracy 0.53\n",
      "528,000 examples, moving-average loss 12.27, train accuracy 0.53\n",
      "529,600 examples, moving-average loss 12.28, train accuracy 0.53\n",
      "531,200 examples, moving-average loss 12.23, train accuracy 0.53\n",
      "532,800 examples, moving-average loss 12.29, train accuracy 0.53\n",
      "534,400 examples, moving-average loss 12.29, train accuracy 0.53\n",
      "536,000 examples, moving-average loss 12.36, train accuracy 0.53\n",
      "537,600 examples, moving-average loss 12.24, train accuracy 0.53\n",
      "539,200 examples, moving-average loss 12.17, train accuracy 0.53\n",
      "540,800 examples, moving-average loss 12.29, train accuracy 0.53\n",
      "542,400 examples, moving-average loss 12.10, train accuracy 0.53\n",
      "544,000 examples, moving-average loss 12.19, train accuracy 0.53\n",
      "545,600 examples, moving-average loss 12.21, train accuracy 0.53\n",
      "547,200 examples, moving-average loss 12.20, train accuracy 0.53\n",
      "548,800 examples, moving-average loss 12.23, train accuracy 0.53\n",
      "550,400 examples, moving-average loss 12.26, train accuracy 0.53\n",
      "552,000 examples, moving-average loss 12.32, train accuracy 0.53\n",
      "553,600 examples, moving-average loss 12.32, train accuracy 0.53\n",
      "555,200 examples, moving-average loss 12.24, train accuracy 0.53\n",
      "556,800 examples, moving-average loss 12.39, train accuracy 0.53\n",
      "558,400 examples, moving-average loss 12.25, train accuracy 0.53\n",
      "560,000 examples, moving-average loss 12.26, train accuracy 0.53\n",
      "561,600 examples, moving-average loss 12.24, train accuracy 0.53\n",
      "563,200 examples, moving-average loss 12.24, train accuracy 0.53\n",
      "564,800 examples, moving-average loss 12.26, train accuracy 0.53\n",
      "566,400 examples, moving-average loss 12.26, train accuracy 0.53\n",
      "568,000 examples, moving-average loss 12.25, train accuracy 0.53\n",
      "569,600 examples, moving-average loss 12.24, train accuracy 0.53\n",
      "571,200 examples, moving-average loss 12.28, train accuracy 0.53\n",
      "572,800 examples, moving-average loss 12.30, train accuracy 0.53\n",
      "574,400 examples, moving-average loss 12.29, train accuracy 0.53\n",
      "576,000 examples, moving-average loss 12.20, train accuracy 0.53\n",
      "577,600 examples, moving-average loss 12.32, train accuracy 0.53\n",
      "579,200 examples, moving-average loss 12.25, train accuracy 0.53\n",
      "580,800 examples, moving-average loss 12.18, train accuracy 0.53\n",
      "582,400 examples, moving-average loss 12.16, train accuracy 0.53\n",
      "584,000 examples, moving-average loss 12.24, train accuracy 0.53\n",
      "585,600 examples, moving-average loss 12.18, train accuracy 0.53\n",
      "587,200 examples, moving-average loss 12.22, train accuracy 0.53\n",
      "588,800 examples, moving-average loss 12.28, train accuracy 0.53\n",
      "590,400 examples, moving-average loss 12.26, train accuracy 0.53\n",
      "592,000 examples, moving-average loss 12.29, train accuracy 0.53\n",
      "593,600 examples, moving-average loss 12.25, train accuracy 0.53\n",
      "595,200 examples, moving-average loss 12.16, train accuracy 0.53\n",
      "596,800 examples, moving-average loss 12.20, train accuracy 0.53\n",
      "598,400 examples, moving-average loss 12.19, train accuracy 0.53\n",
      "600,000 examples, moving-average loss 12.24, train accuracy 0.53\n",
      "601,600 examples, moving-average loss 12.26, train accuracy 0.53\n",
      "603,200 examples, moving-average loss 12.27, train accuracy 0.53\n",
      "604,800 examples, moving-average loss 12.19, train accuracy 0.53\n",
      "606,400 examples, moving-average loss 12.22, train accuracy 0.53\n",
      "608,000 examples, moving-average loss 12.25, train accuracy 0.53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "609,600 examples, moving-average loss 12.22, train accuracy 0.53\n",
      "611,200 examples, moving-average loss 12.21, train accuracy 0.53\n",
      "612,800 examples, moving-average loss 12.27, train accuracy 0.53\n",
      "614,400 examples, moving-average loss 12.30, train accuracy 0.53\n",
      "616,000 examples, moving-average loss 12.24, train accuracy 0.53\n",
      "617,600 examples, moving-average loss 12.18, train accuracy 0.53\n",
      "619,200 examples, moving-average loss 12.30, train accuracy 0.53\n",
      "620,800 examples, moving-average loss 12.27, train accuracy 0.53\n",
      "622,400 examples, moving-average loss 12.28, train accuracy 0.53\n",
      "624,000 examples, moving-average loss 12.19, train accuracy 0.53\n",
      "625,600 examples, moving-average loss 12.15, train accuracy 0.53\n",
      "627,200 examples, moving-average loss 12.25, train accuracy 0.54\n",
      "628,800 examples, moving-average loss 12.26, train accuracy 0.54\n",
      "630,400 examples, moving-average loss 12.32, train accuracy 0.54\n",
      "632,000 examples, moving-average loss 12.33, train accuracy 0.54\n",
      "633,600 examples, moving-average loss 12.20, train accuracy 0.54\n",
      "635,200 examples, moving-average loss 12.17, train accuracy 0.54\n",
      "636,800 examples, moving-average loss 12.15, train accuracy 0.54\n",
      "638,400 examples, moving-average loss 12.25, train accuracy 0.54\n",
      "640,000 examples, moving-average loss 12.17, train accuracy 0.54\n",
      "641,600 examples, moving-average loss 12.35, train accuracy 0.54\n",
      "643,200 examples, moving-average loss 12.25, train accuracy 0.54\n",
      "644,800 examples, moving-average loss 12.14, train accuracy 0.54\n",
      "646,400 examples, moving-average loss 12.25, train accuracy 0.54\n",
      "648,000 examples, moving-average loss 12.25, train accuracy 0.54\n",
      "649,600 examples, moving-average loss 12.24, train accuracy 0.54\n",
      "651,200 examples, moving-average loss 12.15, train accuracy 0.54\n",
      "652,800 examples, moving-average loss 12.22, train accuracy 0.54\n",
      "654,400 examples, moving-average loss 12.26, train accuracy 0.54\n",
      "656,000 examples, moving-average loss 12.26, train accuracy 0.54\n",
      "657,600 examples, moving-average loss 12.30, train accuracy 0.54\n",
      "659,200 examples, moving-average loss 12.23, train accuracy 0.54\n",
      "660,800 examples, moving-average loss 12.28, train accuracy 0.54\n",
      "662,400 examples, moving-average loss 12.26, train accuracy 0.54\n",
      "664,000 examples, moving-average loss 12.29, train accuracy 0.54\n",
      "665,600 examples, moving-average loss 12.20, train accuracy 0.54\n",
      "667,200 examples, moving-average loss 12.23, train accuracy 0.54\n",
      "668,800 examples, moving-average loss 12.21, train accuracy 0.54\n",
      "670,400 examples, moving-average loss 12.08, train accuracy 0.54\n",
      "672,000 examples, moving-average loss 12.22, train accuracy 0.54\n",
      "673,600 examples, moving-average loss 12.29, train accuracy 0.54\n",
      "675,200 examples, moving-average loss 12.17, train accuracy 0.54\n",
      "676,800 examples, moving-average loss 12.26, train accuracy 0.54\n",
      "678,400 examples, moving-average loss 12.26, train accuracy 0.54\n",
      "680,000 examples, moving-average loss 12.29, train accuracy 0.54\n",
      "681,600 examples, moving-average loss 12.17, train accuracy 0.54\n",
      "683,200 examples, moving-average loss 12.21, train accuracy 0.54\n",
      "684,800 examples, moving-average loss 12.22, train accuracy 0.54\n",
      "686,400 examples, moving-average loss 12.15, train accuracy 0.54\n",
      "688,000 examples, moving-average loss 12.16, train accuracy 0.54\n",
      "689,600 examples, moving-average loss 12.10, train accuracy 0.54\n",
      "691,200 examples, moving-average loss 12.20, train accuracy 0.54\n",
      "692,800 examples, moving-average loss 12.23, train accuracy 0.54\n",
      "694,400 examples, moving-average loss 12.23, train accuracy 0.54\n",
      "696,000 examples, moving-average loss 12.29, train accuracy 0.54\n",
      "697,600 examples, moving-average loss 12.25, train accuracy 0.54\n",
      "699,200 examples, moving-average loss 12.20, train accuracy 0.54\n",
      "700,800 examples, moving-average loss 12.23, train accuracy 0.54\n",
      "702,400 examples, moving-average loss 12.25, train accuracy 0.54\n",
      "704,000 examples, moving-average loss 12.25, train accuracy 0.54\n",
      "705,600 examples, moving-average loss 12.19, train accuracy 0.54\n",
      "707,200 examples, moving-average loss 12.18, train accuracy 0.54\n",
      "708,800 examples, moving-average loss 12.19, train accuracy 0.54\n",
      "710,400 examples, moving-average loss 12.20, train accuracy 0.54\n",
      "712,000 examples, moving-average loss 12.16, train accuracy 0.54\n",
      "713,600 examples, moving-average loss 12.26, train accuracy 0.54\n",
      "715,200 examples, moving-average loss 12.21, train accuracy 0.54\n",
      "716,800 examples, moving-average loss 12.23, train accuracy 0.54\n",
      "718,400 examples, moving-average loss 12.25, train accuracy 0.54\n",
      "720,000 examples, moving-average loss 12.30, train accuracy 0.54\n",
      "721,600 examples, moving-average loss 12.11, train accuracy 0.54\n",
      "723,200 examples, moving-average loss 12.25, train accuracy 0.54\n",
      "724,800 examples, moving-average loss 12.35, train accuracy 0.54\n",
      "726,400 examples, moving-average loss 12.23, train accuracy 0.54\n",
      "728,000 examples, moving-average loss 12.17, train accuracy 0.54\n",
      "729,600 examples, moving-average loss 12.17, train accuracy 0.54\n",
      "731,200 examples, moving-average loss 12.20, train accuracy 0.54\n",
      "732,800 examples, moving-average loss 12.24, train accuracy 0.54\n",
      "734,400 examples, moving-average loss 12.25, train accuracy 0.54\n",
      "736,000 examples, moving-average loss 12.23, train accuracy 0.54\n",
      "737,600 examples, moving-average loss 12.17, train accuracy 0.54\n",
      "739,200 examples, moving-average loss 12.11, train accuracy 0.54\n",
      "740,800 examples, moving-average loss 12.19, train accuracy 0.54\n",
      "742,400 examples, moving-average loss 12.19, train accuracy 0.54\n",
      "744,000 examples, moving-average loss 12.21, train accuracy 0.54\n",
      "745,600 examples, moving-average loss 12.19, train accuracy 0.54\n",
      "747,200 examples, moving-average loss 12.17, train accuracy 0.54\n",
      "748,800 examples, moving-average loss 12.24, train accuracy 0.54\n",
      "750,400 examples, moving-average loss 12.23, train accuracy 0.54\n",
      "752,000 examples, moving-average loss 12.21, train accuracy 0.54\n",
      "753,600 examples, moving-average loss 12.32, train accuracy 0.54\n",
      "755,200 examples, moving-average loss 12.22, train accuracy 0.54\n",
      "756,800 examples, moving-average loss 12.20, train accuracy 0.54\n",
      "758,400 examples, moving-average loss 12.33, train accuracy 0.54\n",
      "760,000 examples, moving-average loss 12.23, train accuracy 0.54\n",
      "761,600 examples, moving-average loss 12.26, train accuracy 0.55\n",
      "763,200 examples, moving-average loss 12.15, train accuracy 0.55\n",
      "764,800 examples, moving-average loss 12.20, train accuracy 0.55\n",
      "766,400 examples, moving-average loss 12.17, train accuracy 0.55\n",
      "768,000 examples, moving-average loss 12.16, train accuracy 0.55\n",
      "769,600 examples, moving-average loss 12.13, train accuracy 0.55\n",
      "771,200 examples, moving-average loss 12.27, train accuracy 0.55\n",
      "772,800 examples, moving-average loss 12.14, train accuracy 0.55\n",
      "774,400 examples, moving-average loss 12.18, train accuracy 0.55\n",
      "776,000 examples, moving-average loss 12.20, train accuracy 0.55\n",
      "777,600 examples, moving-average loss 12.18, train accuracy 0.55\n",
      "779,200 examples, moving-average loss 12.20, train accuracy 0.55\n",
      "780,800 examples, moving-average loss 12.22, train accuracy 0.55\n",
      "782,400 examples, moving-average loss 12.21, train accuracy 0.55\n",
      "784,000 examples, moving-average loss 12.15, train accuracy 0.55\n",
      "785,600 examples, moving-average loss 12.11, train accuracy 0.55\n",
      "787,200 examples, moving-average loss 12.24, train accuracy 0.55\n",
      "788,800 examples, moving-average loss 12.13, train accuracy 0.55\n",
      "790,400 examples, moving-average loss 12.14, train accuracy 0.55\n",
      "792,000 examples, moving-average loss 12.18, train accuracy 0.55\n",
      "793,600 examples, moving-average loss 12.24, train accuracy 0.55\n",
      "795,200 examples, moving-average loss 12.17, train accuracy 0.55\n",
      "796,800 examples, moving-average loss 12.24, train accuracy 0.55\n",
      "798,400 examples, moving-average loss 12.22, train accuracy 0.55\n",
      "800,000 examples, moving-average loss 12.26, train accuracy 0.55\n",
      "801,600 examples, moving-average loss 12.23, train accuracy 0.55\n",
      "803,200 examples, moving-average loss 12.14, train accuracy 0.55\n",
      "804,800 examples, moving-average loss 12.23, train accuracy 0.55\n",
      "806,400 examples, moving-average loss 12.19, train accuracy 0.55\n",
      "808,000 examples, moving-average loss 12.12, train accuracy 0.55\n",
      "809,600 examples, moving-average loss 12.18, train accuracy 0.55\n",
      "811,200 examples, moving-average loss 12.18, train accuracy 0.55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "812,800 examples, moving-average loss 12.18, train accuracy 0.55\n",
      "814,400 examples, moving-average loss 12.12, train accuracy 0.55\n",
      "816,000 examples, moving-average loss 12.16, train accuracy 0.55\n",
      "817,600 examples, moving-average loss 12.22, train accuracy 0.55\n",
      "819,200 examples, moving-average loss 12.18, train accuracy 0.55\n",
      "820,800 examples, moving-average loss 12.21, train accuracy 0.55\n",
      "822,400 examples, moving-average loss 12.19, train accuracy 0.55\n",
      "824,000 examples, moving-average loss 12.19, train accuracy 0.55\n",
      "825,600 examples, moving-average loss 12.21, train accuracy 0.55\n",
      "827,200 examples, moving-average loss 12.26, train accuracy 0.55\n",
      "828,800 examples, moving-average loss 12.17, train accuracy 0.55\n",
      "830,400 examples, moving-average loss 12.18, train accuracy 0.55\n",
      "832,000 examples, moving-average loss 12.17, train accuracy 0.55\n",
      "833,600 examples, moving-average loss 12.16, train accuracy 0.55\n",
      "835,200 examples, moving-average loss 12.22, train accuracy 0.55\n",
      "836,800 examples, moving-average loss 12.22, train accuracy 0.55\n",
      "838,400 examples, moving-average loss 12.17, train accuracy 0.55\n",
      "840,000 examples, moving-average loss 12.16, train accuracy 0.55\n",
      "Completed 0 epoch in 0:38:23\n",
      "Train accurary:0.55046\n",
      "Validate accuracy:0.60652\n",
      "841,550 examples, moving-average loss 11.47, train accuracy 0.34\n",
      "843,150 examples, moving-average loss 12.08, train accuracy 0.55\n",
      "844,750 examples, moving-average loss 12.19, train accuracy 0.57\n",
      "846,350 examples, moving-average loss 12.25, train accuracy 0.58\n",
      "847,950 examples, moving-average loss 12.18, train accuracy 0.58\n",
      "849,550 examples, moving-average loss 12.25, train accuracy 0.59\n",
      "851,150 examples, moving-average loss 12.18, train accuracy 0.59\n",
      "852,750 examples, moving-average loss 12.11, train accuracy 0.59\n",
      "854,350 examples, moving-average loss 12.25, train accuracy 0.59\n",
      "855,950 examples, moving-average loss 12.20, train accuracy 0.60\n",
      "857,550 examples, moving-average loss 12.23, train accuracy 0.60\n",
      "859,150 examples, moving-average loss 12.17, train accuracy 0.60\n",
      "860,750 examples, moving-average loss 12.22, train accuracy 0.60\n",
      "862,350 examples, moving-average loss 12.26, train accuracy 0.60\n",
      "863,950 examples, moving-average loss 12.18, train accuracy 0.60\n",
      "865,550 examples, moving-average loss 12.15, train accuracy 0.60\n",
      "867,150 examples, moving-average loss 12.13, train accuracy 0.60\n",
      "868,750 examples, moving-average loss 12.21, train accuracy 0.60\n",
      "870,350 examples, moving-average loss 12.17, train accuracy 0.60\n",
      "871,950 examples, moving-average loss 12.14, train accuracy 0.60\n",
      "873,550 examples, moving-average loss 12.19, train accuracy 0.60\n",
      "875,150 examples, moving-average loss 12.24, train accuracy 0.60\n",
      "876,750 examples, moving-average loss 12.13, train accuracy 0.60\n",
      "878,350 examples, moving-average loss 12.20, train accuracy 0.60\n",
      "879,950 examples, moving-average loss 12.20, train accuracy 0.60\n",
      "881,550 examples, moving-average loss 12.07, train accuracy 0.60\n",
      "883,150 examples, moving-average loss 12.20, train accuracy 0.60\n",
      "884,750 examples, moving-average loss 12.14, train accuracy 0.60\n",
      "886,350 examples, moving-average loss 12.17, train accuracy 0.60\n",
      "887,950 examples, moving-average loss 12.14, train accuracy 0.60\n",
      "889,550 examples, moving-average loss 12.25, train accuracy 0.61\n",
      "891,150 examples, moving-average loss 12.14, train accuracy 0.61\n",
      "892,750 examples, moving-average loss 12.08, train accuracy 0.61\n",
      "894,350 examples, moving-average loss 12.13, train accuracy 0.61\n",
      "895,950 examples, moving-average loss 12.22, train accuracy 0.61\n",
      "897,550 examples, moving-average loss 12.15, train accuracy 0.61\n",
      "899,150 examples, moving-average loss 12.16, train accuracy 0.61\n",
      "900,750 examples, moving-average loss 12.21, train accuracy 0.61\n",
      "902,350 examples, moving-average loss 12.18, train accuracy 0.61\n",
      "903,950 examples, moving-average loss 12.22, train accuracy 0.61\n",
      "905,550 examples, moving-average loss 12.14, train accuracy 0.61\n",
      "907,150 examples, moving-average loss 12.23, train accuracy 0.61\n",
      "908,750 examples, moving-average loss 12.12, train accuracy 0.61\n",
      "910,350 examples, moving-average loss 12.10, train accuracy 0.61\n",
      "911,950 examples, moving-average loss 12.12, train accuracy 0.61\n",
      "913,550 examples, moving-average loss 12.16, train accuracy 0.61\n",
      "915,150 examples, moving-average loss 12.17, train accuracy 0.61\n",
      "916,750 examples, moving-average loss 12.15, train accuracy 0.61\n",
      "918,350 examples, moving-average loss 12.12, train accuracy 0.61\n",
      "919,950 examples, moving-average loss 12.22, train accuracy 0.61\n",
      "921,550 examples, moving-average loss 12.14, train accuracy 0.61\n",
      "923,150 examples, moving-average loss 12.13, train accuracy 0.61\n",
      "924,750 examples, moving-average loss 12.12, train accuracy 0.61\n",
      "926,350 examples, moving-average loss 12.18, train accuracy 0.61\n",
      "927,950 examples, moving-average loss 12.17, train accuracy 0.61\n",
      "929,550 examples, moving-average loss 12.13, train accuracy 0.61\n",
      "931,150 examples, moving-average loss 12.15, train accuracy 0.61\n",
      "932,750 examples, moving-average loss 12.14, train accuracy 0.61\n",
      "934,350 examples, moving-average loss 12.22, train accuracy 0.61\n",
      "935,950 examples, moving-average loss 12.20, train accuracy 0.61\n",
      "937,550 examples, moving-average loss 12.16, train accuracy 0.61\n",
      "939,150 examples, moving-average loss 12.20, train accuracy 0.61\n",
      "940,750 examples, moving-average loss 12.16, train accuracy 0.61\n",
      "942,350 examples, moving-average loss 12.13, train accuracy 0.61\n",
      "943,950 examples, moving-average loss 12.18, train accuracy 0.61\n",
      "945,550 examples, moving-average loss 12.19, train accuracy 0.61\n",
      "947,150 examples, moving-average loss 12.24, train accuracy 0.61\n",
      "948,750 examples, moving-average loss 12.16, train accuracy 0.61\n",
      "950,350 examples, moving-average loss 12.30, train accuracy 0.61\n",
      "951,950 examples, moving-average loss 12.08, train accuracy 0.61\n",
      "953,550 examples, moving-average loss 12.20, train accuracy 0.61\n",
      "955,150 examples, moving-average loss 12.24, train accuracy 0.61\n",
      "956,750 examples, moving-average loss 12.13, train accuracy 0.61\n",
      "958,350 examples, moving-average loss 12.12, train accuracy 0.61\n",
      "959,950 examples, moving-average loss 12.19, train accuracy 0.61\n",
      "961,550 examples, moving-average loss 12.17, train accuracy 0.61\n",
      "963,150 examples, moving-average loss 12.16, train accuracy 0.61\n",
      "964,750 examples, moving-average loss 12.16, train accuracy 0.61\n",
      "966,350 examples, moving-average loss 12.23, train accuracy 0.61\n",
      "967,950 examples, moving-average loss 12.11, train accuracy 0.61\n",
      "969,550 examples, moving-average loss 12.14, train accuracy 0.61\n",
      "971,150 examples, moving-average loss 12.14, train accuracy 0.61\n",
      "972,750 examples, moving-average loss 12.13, train accuracy 0.61\n",
      "974,350 examples, moving-average loss 12.18, train accuracy 0.61\n",
      "975,950 examples, moving-average loss 12.06, train accuracy 0.61\n",
      "977,550 examples, moving-average loss 12.28, train accuracy 0.61\n",
      "979,150 examples, moving-average loss 12.15, train accuracy 0.61\n",
      "980,750 examples, moving-average loss 12.14, train accuracy 0.61\n",
      "982,350 examples, moving-average loss 12.17, train accuracy 0.61\n",
      "983,950 examples, moving-average loss 12.19, train accuracy 0.61\n",
      "985,550 examples, moving-average loss 12.24, train accuracy 0.61\n",
      "987,150 examples, moving-average loss 12.18, train accuracy 0.61\n",
      "988,750 examples, moving-average loss 12.25, train accuracy 0.61\n",
      "990,350 examples, moving-average loss 12.15, train accuracy 0.61\n",
      "991,950 examples, moving-average loss 12.11, train accuracy 0.61\n",
      "993,550 examples, moving-average loss 12.14, train accuracy 0.61\n",
      "995,150 examples, moving-average loss 12.17, train accuracy 0.61\n",
      "996,750 examples, moving-average loss 12.13, train accuracy 0.61\n",
      "998,350 examples, moving-average loss 12.17, train accuracy 0.61\n",
      "999,950 examples, moving-average loss 12.16, train accuracy 0.61\n",
      "1,001,550 examples, moving-average loss 12.16, train accuracy 0.61\n",
      "1,003,150 examples, moving-average loss 12.14, train accuracy 0.61\n",
      "1,004,750 examples, moving-average loss 12.08, train accuracy 0.61\n",
      "1,006,350 examples, moving-average loss 12.16, train accuracy 0.61\n",
      "1,007,950 examples, moving-average loss 12.22, train accuracy 0.61\n",
      "1,009,550 examples, moving-average loss 12.16, train accuracy 0.61\n",
      "1,011,150 examples, moving-average loss 12.19, train accuracy 0.61\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,012,750 examples, moving-average loss 12.17, train accuracy 0.61\n",
      "1,014,350 examples, moving-average loss 12.15, train accuracy 0.61\n",
      "1,015,950 examples, moving-average loss 12.16, train accuracy 0.61\n",
      "1,017,550 examples, moving-average loss 12.18, train accuracy 0.61\n",
      "1,019,150 examples, moving-average loss 12.20, train accuracy 0.61\n",
      "1,020,750 examples, moving-average loss 12.16, train accuracy 0.61\n",
      "1,022,350 examples, moving-average loss 12.12, train accuracy 0.61\n",
      "1,023,950 examples, moving-average loss 12.14, train accuracy 0.61\n",
      "1,025,550 examples, moving-average loss 12.16, train accuracy 0.61\n",
      "1,027,150 examples, moving-average loss 12.17, train accuracy 0.61\n",
      "1,028,750 examples, moving-average loss 12.21, train accuracy 0.61\n",
      "1,030,350 examples, moving-average loss 12.24, train accuracy 0.61\n",
      "1,031,950 examples, moving-average loss 12.17, train accuracy 0.61\n",
      "1,033,550 examples, moving-average loss 12.17, train accuracy 0.61\n",
      "1,035,150 examples, moving-average loss 12.09, train accuracy 0.61\n",
      "1,036,750 examples, moving-average loss 12.12, train accuracy 0.61\n",
      "1,038,350 examples, moving-average loss 12.25, train accuracy 0.61\n",
      "1,039,950 examples, moving-average loss 12.10, train accuracy 0.61\n",
      "1,041,550 examples, moving-average loss 12.10, train accuracy 0.61\n",
      "1,043,150 examples, moving-average loss 12.15, train accuracy 0.61\n",
      "1,044,750 examples, moving-average loss 12.11, train accuracy 0.61\n",
      "1,046,350 examples, moving-average loss 12.08, train accuracy 0.61\n",
      "1,047,950 examples, moving-average loss 12.17, train accuracy 0.61\n",
      "1,049,550 examples, moving-average loss 12.11, train accuracy 0.61\n",
      "1,051,150 examples, moving-average loss 12.13, train accuracy 0.61\n",
      "1,052,750 examples, moving-average loss 12.14, train accuracy 0.61\n",
      "1,054,350 examples, moving-average loss 12.17, train accuracy 0.61\n",
      "1,055,950 examples, moving-average loss 12.17, train accuracy 0.61\n",
      "1,057,550 examples, moving-average loss 12.19, train accuracy 0.61\n",
      "1,059,150 examples, moving-average loss 12.17, train accuracy 0.61\n",
      "1,060,750 examples, moving-average loss 12.19, train accuracy 0.61\n",
      "1,062,350 examples, moving-average loss 12.17, train accuracy 0.61\n",
      "1,063,950 examples, moving-average loss 12.11, train accuracy 0.61\n",
      "1,065,550 examples, moving-average loss 12.05, train accuracy 0.61\n",
      "1,067,150 examples, moving-average loss 12.15, train accuracy 0.61\n",
      "1,068,750 examples, moving-average loss 12.18, train accuracy 0.61\n",
      "1,070,350 examples, moving-average loss 12.20, train accuracy 0.61\n",
      "1,071,950 examples, moving-average loss 12.16, train accuracy 0.61\n",
      "1,073,550 examples, moving-average loss 12.10, train accuracy 0.61\n",
      "1,075,150 examples, moving-average loss 12.07, train accuracy 0.61\n",
      "1,076,750 examples, moving-average loss 12.19, train accuracy 0.61\n",
      "1,078,350 examples, moving-average loss 12.17, train accuracy 0.61\n",
      "1,079,950 examples, moving-average loss 12.11, train accuracy 0.61\n",
      "1,081,550 examples, moving-average loss 12.03, train accuracy 0.61\n",
      "1,083,150 examples, moving-average loss 12.14, train accuracy 0.61\n",
      "1,084,750 examples, moving-average loss 12.13, train accuracy 0.61\n",
      "1,086,350 examples, moving-average loss 12.15, train accuracy 0.61\n",
      "1,087,950 examples, moving-average loss 12.13, train accuracy 0.61\n",
      "1,089,550 examples, moving-average loss 12.15, train accuracy 0.61\n",
      "1,091,150 examples, moving-average loss 12.19, train accuracy 0.61\n",
      "1,092,750 examples, moving-average loss 12.17, train accuracy 0.61\n",
      "1,094,350 examples, moving-average loss 12.09, train accuracy 0.61\n",
      "1,095,950 examples, moving-average loss 12.16, train accuracy 0.61\n",
      "1,097,550 examples, moving-average loss 12.11, train accuracy 0.61\n",
      "1,099,150 examples, moving-average loss 12.15, train accuracy 0.61\n",
      "1,100,750 examples, moving-average loss 12.17, train accuracy 0.61\n",
      "1,102,350 examples, moving-average loss 12.15, train accuracy 0.61\n",
      "1,103,950 examples, moving-average loss 12.15, train accuracy 0.61\n",
      "1,105,550 examples, moving-average loss 12.15, train accuracy 0.61\n",
      "1,107,150 examples, moving-average loss 12.09, train accuracy 0.61\n",
      "1,108,750 examples, moving-average loss 12.07, train accuracy 0.61\n",
      "1,110,350 examples, moving-average loss 12.15, train accuracy 0.61\n",
      "1,111,950 examples, moving-average loss 12.23, train accuracy 0.61\n",
      "1,113,550 examples, moving-average loss 12.19, train accuracy 0.61\n",
      "1,115,150 examples, moving-average loss 12.18, train accuracy 0.61\n",
      "1,116,750 examples, moving-average loss 12.10, train accuracy 0.61\n",
      "1,118,350 examples, moving-average loss 12.07, train accuracy 0.61\n",
      "1,119,950 examples, moving-average loss 12.09, train accuracy 0.61\n",
      "1,121,550 examples, moving-average loss 12.15, train accuracy 0.61\n",
      "1,123,150 examples, moving-average loss 12.22, train accuracy 0.61\n",
      "1,124,750 examples, moving-average loss 12.16, train accuracy 0.61\n",
      "1,126,350 examples, moving-average loss 12.17, train accuracy 0.61\n",
      "1,127,950 examples, moving-average loss 12.11, train accuracy 0.61\n",
      "1,129,550 examples, moving-average loss 12.18, train accuracy 0.61\n",
      "1,131,150 examples, moving-average loss 12.13, train accuracy 0.61\n",
      "1,132,750 examples, moving-average loss 12.04, train accuracy 0.61\n",
      "1,134,350 examples, moving-average loss 12.18, train accuracy 0.61\n",
      "1,135,950 examples, moving-average loss 12.16, train accuracy 0.61\n",
      "1,137,550 examples, moving-average loss 12.22, train accuracy 0.61\n",
      "1,139,150 examples, moving-average loss 12.15, train accuracy 0.61\n",
      "1,140,750 examples, moving-average loss 12.07, train accuracy 0.61\n",
      "1,142,350 examples, moving-average loss 12.13, train accuracy 0.61\n",
      "1,143,950 examples, moving-average loss 12.14, train accuracy 0.61\n",
      "1,145,550 examples, moving-average loss 12.18, train accuracy 0.61\n",
      "1,147,150 examples, moving-average loss 12.14, train accuracy 0.61\n",
      "1,148,750 examples, moving-average loss 12.08, train accuracy 0.61\n",
      "1,150,350 examples, moving-average loss 12.06, train accuracy 0.61\n",
      "1,151,950 examples, moving-average loss 12.21, train accuracy 0.61\n",
      "1,153,550 examples, moving-average loss 12.06, train accuracy 0.61\n",
      "1,155,150 examples, moving-average loss 12.11, train accuracy 0.61\n",
      "1,156,750 examples, moving-average loss 12.21, train accuracy 0.61\n",
      "1,158,350 examples, moving-average loss 12.13, train accuracy 0.61\n",
      "1,159,950 examples, moving-average loss 12.08, train accuracy 0.62\n",
      "1,161,550 examples, moving-average loss 12.16, train accuracy 0.62\n",
      "1,163,150 examples, moving-average loss 12.13, train accuracy 0.62\n",
      "1,164,750 examples, moving-average loss 12.13, train accuracy 0.62\n",
      "1,166,350 examples, moving-average loss 12.18, train accuracy 0.62\n",
      "1,167,950 examples, moving-average loss 12.08, train accuracy 0.62\n",
      "1,169,550 examples, moving-average loss 12.15, train accuracy 0.62\n",
      "1,171,150 examples, moving-average loss 12.16, train accuracy 0.62\n",
      "1,172,750 examples, moving-average loss 12.19, train accuracy 0.62\n",
      "1,174,350 examples, moving-average loss 12.10, train accuracy 0.62\n",
      "1,175,950 examples, moving-average loss 12.13, train accuracy 0.62\n",
      "1,177,550 examples, moving-average loss 12.17, train accuracy 0.62\n",
      "1,179,150 examples, moving-average loss 12.18, train accuracy 0.62\n",
      "1,180,750 examples, moving-average loss 12.12, train accuracy 0.62\n",
      "1,182,350 examples, moving-average loss 12.11, train accuracy 0.62\n",
      "1,183,950 examples, moving-average loss 12.09, train accuracy 0.62\n",
      "1,185,550 examples, moving-average loss 12.15, train accuracy 0.62\n",
      "1,187,150 examples, moving-average loss 12.19, train accuracy 0.62\n",
      "1,188,750 examples, moving-average loss 12.17, train accuracy 0.62\n",
      "1,190,350 examples, moving-average loss 12.21, train accuracy 0.62\n",
      "1,191,950 examples, moving-average loss 12.08, train accuracy 0.62\n",
      "1,193,550 examples, moving-average loss 12.00, train accuracy 0.62\n",
      "1,195,150 examples, moving-average loss 12.13, train accuracy 0.62\n",
      "1,196,750 examples, moving-average loss 12.10, train accuracy 0.62\n",
      "1,198,350 examples, moving-average loss 12.04, train accuracy 0.62\n",
      "1,199,950 examples, moving-average loss 12.15, train accuracy 0.62\n",
      "1,201,550 examples, moving-average loss 12.14, train accuracy 0.62\n",
      "1,203,150 examples, moving-average loss 12.19, train accuracy 0.62\n",
      "1,204,750 examples, moving-average loss 12.10, train accuracy 0.62\n",
      "1,206,350 examples, moving-average loss 12.04, train accuracy 0.62\n",
      "1,207,950 examples, moving-average loss 12.11, train accuracy 0.62\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,209,550 examples, moving-average loss 12.11, train accuracy 0.62\n",
      "1,211,150 examples, moving-average loss 12.10, train accuracy 0.62\n",
      "1,212,750 examples, moving-average loss 12.22, train accuracy 0.62\n",
      "1,214,350 examples, moving-average loss 12.18, train accuracy 0.62\n",
      "1,215,950 examples, moving-average loss 12.11, train accuracy 0.62\n",
      "1,217,550 examples, moving-average loss 12.26, train accuracy 0.62\n",
      "1,219,150 examples, moving-average loss 12.07, train accuracy 0.62\n",
      "1,220,750 examples, moving-average loss 12.14, train accuracy 0.62\n",
      "1,222,350 examples, moving-average loss 12.11, train accuracy 0.62\n",
      "1,223,950 examples, moving-average loss 12.18, train accuracy 0.62\n",
      "1,225,550 examples, moving-average loss 12.17, train accuracy 0.62\n",
      "1,227,150 examples, moving-average loss 12.11, train accuracy 0.62\n",
      "1,228,750 examples, moving-average loss 12.13, train accuracy 0.62\n",
      "1,230,350 examples, moving-average loss 12.13, train accuracy 0.62\n",
      "1,231,950 examples, moving-average loss 12.17, train accuracy 0.62\n",
      "1,233,550 examples, moving-average loss 12.15, train accuracy 0.62\n",
      "1,235,150 examples, moving-average loss 12.11, train accuracy 0.62\n",
      "1,236,750 examples, moving-average loss 12.11, train accuracy 0.62\n",
      "1,238,350 examples, moving-average loss 12.22, train accuracy 0.62\n",
      "1,239,950 examples, moving-average loss 12.15, train accuracy 0.62\n",
      "1,241,550 examples, moving-average loss 12.13, train accuracy 0.62\n",
      "1,243,150 examples, moving-average loss 12.14, train accuracy 0.62\n",
      "1,244,750 examples, moving-average loss 12.05, train accuracy 0.62\n",
      "1,246,350 examples, moving-average loss 12.13, train accuracy 0.62\n",
      "1,247,950 examples, moving-average loss 12.17, train accuracy 0.62\n",
      "1,249,550 examples, moving-average loss 12.18, train accuracy 0.62\n",
      "1,251,150 examples, moving-average loss 12.17, train accuracy 0.62\n",
      "1,252,750 examples, moving-average loss 12.10, train accuracy 0.62\n",
      "1,254,350 examples, moving-average loss 12.21, train accuracy 0.62\n",
      "1,255,950 examples, moving-average loss 12.19, train accuracy 0.62\n",
      "1,257,550 examples, moving-average loss 12.12, train accuracy 0.62\n",
      "1,259,150 examples, moving-average loss 12.13, train accuracy 0.62\n",
      "1,260,750 examples, moving-average loss 12.19, train accuracy 0.62\n",
      "1,262,350 examples, moving-average loss 12.17, train accuracy 0.62\n",
      "1,263,950 examples, moving-average loss 12.14, train accuracy 0.62\n",
      "1,265,550 examples, moving-average loss 12.08, train accuracy 0.62\n",
      "1,267,150 examples, moving-average loss 12.06, train accuracy 0.62\n",
      "1,268,750 examples, moving-average loss 12.08, train accuracy 0.62\n",
      "1,270,350 examples, moving-average loss 12.09, train accuracy 0.62\n",
      "1,271,950 examples, moving-average loss 12.17, train accuracy 0.62\n",
      "1,273,550 examples, moving-average loss 12.16, train accuracy 0.62\n",
      "1,275,150 examples, moving-average loss 12.16, train accuracy 0.62\n",
      "1,276,750 examples, moving-average loss 12.18, train accuracy 0.62\n",
      "1,278,350 examples, moving-average loss 12.09, train accuracy 0.62\n",
      "1,279,950 examples, moving-average loss 12.11, train accuracy 0.62\n",
      "1,281,550 examples, moving-average loss 12.15, train accuracy 0.62\n",
      "1,283,150 examples, moving-average loss 12.10, train accuracy 0.62\n",
      "1,284,750 examples, moving-average loss 12.15, train accuracy 0.62\n",
      "1,286,350 examples, moving-average loss 12.18, train accuracy 0.62\n",
      "1,287,950 examples, moving-average loss 12.12, train accuracy 0.62\n",
      "1,289,550 examples, moving-average loss 12.14, train accuracy 0.62\n",
      "1,291,150 examples, moving-average loss 12.12, train accuracy 0.62\n",
      "1,292,750 examples, moving-average loss 12.19, train accuracy 0.62\n",
      "1,294,350 examples, moving-average loss 12.16, train accuracy 0.62\n",
      "1,295,950 examples, moving-average loss 12.10, train accuracy 0.62\n",
      "1,297,550 examples, moving-average loss 12.13, train accuracy 0.62\n",
      "1,299,150 examples, moving-average loss 12.09, train accuracy 0.62\n",
      "1,300,750 examples, moving-average loss 12.13, train accuracy 0.62\n",
      "1,302,350 examples, moving-average loss 12.17, train accuracy 0.62\n",
      "1,303,950 examples, moving-average loss 12.23, train accuracy 0.62\n",
      "1,305,550 examples, moving-average loss 12.16, train accuracy 0.62\n",
      "1,307,150 examples, moving-average loss 12.11, train accuracy 0.62\n",
      "1,308,750 examples, moving-average loss 12.15, train accuracy 0.62\n",
      "1,310,350 examples, moving-average loss 12.10, train accuracy 0.62\n",
      "1,311,950 examples, moving-average loss 12.11, train accuracy 0.62\n",
      "1,313,550 examples, moving-average loss 12.25, train accuracy 0.62\n",
      "1,315,150 examples, moving-average loss 12.15, train accuracy 0.62\n",
      "1,316,750 examples, moving-average loss 12.15, train accuracy 0.62\n",
      "1,318,350 examples, moving-average loss 12.11, train accuracy 0.62\n",
      "1,319,950 examples, moving-average loss 12.14, train accuracy 0.62\n",
      "1,321,550 examples, moving-average loss 12.14, train accuracy 0.62\n",
      "1,323,150 examples, moving-average loss 12.17, train accuracy 0.62\n",
      "1,324,750 examples, moving-average loss 12.14, train accuracy 0.62\n",
      "1,326,350 examples, moving-average loss 12.05, train accuracy 0.62\n",
      "1,327,950 examples, moving-average loss 12.10, train accuracy 0.62\n",
      "1,329,550 examples, moving-average loss 12.16, train accuracy 0.62\n",
      "1,331,150 examples, moving-average loss 12.17, train accuracy 0.62\n",
      "1,332,750 examples, moving-average loss 12.19, train accuracy 0.62\n",
      "1,334,350 examples, moving-average loss 12.05, train accuracy 0.62\n",
      "1,335,950 examples, moving-average loss 12.09, train accuracy 0.62\n",
      "1,337,550 examples, moving-average loss 12.11, train accuracy 0.62\n",
      "1,339,150 examples, moving-average loss 12.15, train accuracy 0.62\n",
      "1,340,750 examples, moving-average loss 12.09, train accuracy 0.62\n",
      "1,342,350 examples, moving-average loss 12.05, train accuracy 0.62\n",
      "1,343,950 examples, moving-average loss 12.06, train accuracy 0.62\n",
      "1,345,550 examples, moving-average loss 12.10, train accuracy 0.62\n",
      "1,347,150 examples, moving-average loss 12.11, train accuracy 0.62\n",
      "1,348,750 examples, moving-average loss 12.11, train accuracy 0.62\n",
      "1,350,350 examples, moving-average loss 12.15, train accuracy 0.62\n",
      "1,351,950 examples, moving-average loss 12.10, train accuracy 0.62\n",
      "1,353,550 examples, moving-average loss 12.22, train accuracy 0.62\n",
      "1,355,150 examples, moving-average loss 12.16, train accuracy 0.62\n",
      "1,356,750 examples, moving-average loss 12.09, train accuracy 0.62\n",
      "1,358,350 examples, moving-average loss 12.15, train accuracy 0.62\n",
      "1,359,950 examples, moving-average loss 12.08, train accuracy 0.62\n",
      "1,361,550 examples, moving-average loss 12.14, train accuracy 0.62\n",
      "1,363,150 examples, moving-average loss 12.07, train accuracy 0.62\n",
      "1,364,750 examples, moving-average loss 12.12, train accuracy 0.62\n",
      "1,366,350 examples, moving-average loss 12.08, train accuracy 0.62\n",
      "1,367,950 examples, moving-average loss 12.11, train accuracy 0.62\n",
      "1,369,550 examples, moving-average loss 12.17, train accuracy 0.62\n",
      "1,371,150 examples, moving-average loss 12.16, train accuracy 0.62\n",
      "1,372,750 examples, moving-average loss 12.12, train accuracy 0.62\n",
      "1,374,350 examples, moving-average loss 12.20, train accuracy 0.62\n",
      "1,375,950 examples, moving-average loss 12.13, train accuracy 0.62\n",
      "1,377,550 examples, moving-average loss 12.22, train accuracy 0.62\n",
      "1,379,150 examples, moving-average loss 12.09, train accuracy 0.62\n",
      "1,380,750 examples, moving-average loss 12.02, train accuracy 0.62\n",
      "1,382,350 examples, moving-average loss 12.19, train accuracy 0.62\n",
      "1,383,950 examples, moving-average loss 11.97, train accuracy 0.62\n",
      "1,385,550 examples, moving-average loss 12.07, train accuracy 0.62\n",
      "1,387,150 examples, moving-average loss 12.09, train accuracy 0.62\n",
      "1,388,750 examples, moving-average loss 12.09, train accuracy 0.62\n",
      "1,390,350 examples, moving-average loss 12.09, train accuracy 0.62\n",
      "1,391,950 examples, moving-average loss 12.13, train accuracy 0.62\n",
      "1,393,550 examples, moving-average loss 12.18, train accuracy 0.62\n",
      "1,395,150 examples, moving-average loss 12.21, train accuracy 0.62\n",
      "1,396,750 examples, moving-average loss 12.12, train accuracy 0.62\n",
      "1,398,350 examples, moving-average loss 12.27, train accuracy 0.62\n",
      "1,399,950 examples, moving-average loss 12.13, train accuracy 0.62\n",
      "1,401,550 examples, moving-average loss 12.11, train accuracy 0.62\n",
      "1,403,150 examples, moving-average loss 12.15, train accuracy 0.62\n",
      "1,404,750 examples, moving-average loss 12.08, train accuracy 0.62\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,406,350 examples, moving-average loss 12.08, train accuracy 0.62\n",
      "1,407,950 examples, moving-average loss 12.14, train accuracy 0.62\n",
      "1,409,550 examples, moving-average loss 12.11, train accuracy 0.62\n",
      "1,411,150 examples, moving-average loss 12.06, train accuracy 0.62\n",
      "1,412,750 examples, moving-average loss 12.15, train accuracy 0.62\n",
      "1,414,350 examples, moving-average loss 12.15, train accuracy 0.62\n",
      "1,415,950 examples, moving-average loss 12.17, train accuracy 0.62\n",
      "1,417,550 examples, moving-average loss 12.13, train accuracy 0.62\n",
      "1,419,150 examples, moving-average loss 12.22, train accuracy 0.62\n",
      "1,420,750 examples, moving-average loss 12.14, train accuracy 0.62\n",
      "1,422,350 examples, moving-average loss 12.04, train accuracy 0.62\n",
      "1,423,950 examples, moving-average loss 12.07, train accuracy 0.62\n",
      "1,425,550 examples, moving-average loss 12.11, train accuracy 0.62\n",
      "1,427,150 examples, moving-average loss 12.08, train accuracy 0.62\n",
      "1,428,750 examples, moving-average loss 12.09, train accuracy 0.62\n",
      "1,430,350 examples, moving-average loss 12.15, train accuracy 0.62\n",
      "1,431,950 examples, moving-average loss 12.14, train accuracy 0.62\n",
      "1,433,550 examples, moving-average loss 12.19, train accuracy 0.62\n",
      "1,435,150 examples, moving-average loss 12.06, train accuracy 0.62\n",
      "1,436,750 examples, moving-average loss 12.04, train accuracy 0.62\n",
      "1,438,350 examples, moving-average loss 12.10, train accuracy 0.62\n",
      "1,439,950 examples, moving-average loss 12.07, train accuracy 0.62\n",
      "1,441,550 examples, moving-average loss 12.14, train accuracy 0.62\n",
      "1,443,150 examples, moving-average loss 12.14, train accuracy 0.62\n",
      "1,444,750 examples, moving-average loss 12.16, train accuracy 0.62\n",
      "1,446,350 examples, moving-average loss 12.07, train accuracy 0.62\n",
      "1,447,950 examples, moving-average loss 12.05, train accuracy 0.62\n",
      "1,449,550 examples, moving-average loss 12.14, train accuracy 0.62\n",
      "1,451,150 examples, moving-average loss 12.12, train accuracy 0.62\n",
      "1,452,750 examples, moving-average loss 12.12, train accuracy 0.62\n",
      "1,454,350 examples, moving-average loss 12.16, train accuracy 0.62\n",
      "1,455,950 examples, moving-average loss 12.21, train accuracy 0.62\n",
      "1,457,550 examples, moving-average loss 12.13, train accuracy 0.62\n",
      "1,459,150 examples, moving-average loss 12.06, train accuracy 0.62\n",
      "1,460,750 examples, moving-average loss 12.15, train accuracy 0.62\n",
      "1,462,350 examples, moving-average loss 12.14, train accuracy 0.62\n",
      "1,463,950 examples, moving-average loss 12.16, train accuracy 0.62\n",
      "1,465,550 examples, moving-average loss 12.11, train accuracy 0.62\n",
      "1,467,150 examples, moving-average loss 12.05, train accuracy 0.62\n",
      "1,468,750 examples, moving-average loss 12.15, train accuracy 0.62\n",
      "1,470,350 examples, moving-average loss 12.15, train accuracy 0.62\n",
      "1,471,950 examples, moving-average loss 12.12, train accuracy 0.62\n",
      "1,473,550 examples, moving-average loss 12.22, train accuracy 0.62\n",
      "1,475,150 examples, moving-average loss 12.09, train accuracy 0.62\n",
      "1,476,750 examples, moving-average loss 12.09, train accuracy 0.62\n",
      "1,478,350 examples, moving-average loss 12.05, train accuracy 0.62\n",
      "1,479,950 examples, moving-average loss 12.09, train accuracy 0.62\n",
      "1,481,550 examples, moving-average loss 12.08, train accuracy 0.62\n",
      "1,483,150 examples, moving-average loss 12.24, train accuracy 0.62\n",
      "1,484,750 examples, moving-average loss 12.16, train accuracy 0.62\n",
      "1,486,350 examples, moving-average loss 12.07, train accuracy 0.62\n",
      "1,487,950 examples, moving-average loss 12.15, train accuracy 0.62\n",
      "1,489,550 examples, moving-average loss 12.13, train accuracy 0.62\n",
      "1,491,150 examples, moving-average loss 12.14, train accuracy 0.62\n",
      "1,492,750 examples, moving-average loss 12.01, train accuracy 0.62\n",
      "1,494,350 examples, moving-average loss 12.15, train accuracy 0.62\n",
      "1,495,950 examples, moving-average loss 12.15, train accuracy 0.62\n",
      "1,497,550 examples, moving-average loss 12.13, train accuracy 0.62\n",
      "1,499,150 examples, moving-average loss 12.17, train accuracy 0.62\n",
      "1,500,750 examples, moving-average loss 12.16, train accuracy 0.62\n",
      "1,502,350 examples, moving-average loss 12.14, train accuracy 0.62\n",
      "1,503,950 examples, moving-average loss 12.18, train accuracy 0.62\n",
      "1,505,550 examples, moving-average loss 12.14, train accuracy 0.62\n",
      "1,507,150 examples, moving-average loss 12.11, train accuracy 0.62\n",
      "1,508,750 examples, moving-average loss 12.14, train accuracy 0.62\n",
      "1,510,350 examples, moving-average loss 12.08, train accuracy 0.62\n",
      "1,511,950 examples, moving-average loss 12.03, train accuracy 0.62\n",
      "1,513,550 examples, moving-average loss 12.08, train accuracy 0.62\n",
      "1,515,150 examples, moving-average loss 12.17, train accuracy 0.62\n",
      "1,516,750 examples, moving-average loss 12.06, train accuracy 0.62\n",
      "1,518,350 examples, moving-average loss 12.18, train accuracy 0.62\n",
      "1,519,950 examples, moving-average loss 12.13, train accuracy 0.62\n",
      "1,521,550 examples, moving-average loss 12.20, train accuracy 0.62\n",
      "1,523,150 examples, moving-average loss 12.06, train accuracy 0.62\n",
      "1,524,750 examples, moving-average loss 12.13, train accuracy 0.62\n",
      "1,526,350 examples, moving-average loss 12.10, train accuracy 0.62\n",
      "1,527,950 examples, moving-average loss 12.05, train accuracy 0.62\n",
      "1,529,550 examples, moving-average loss 12.08, train accuracy 0.62\n",
      "1,531,150 examples, moving-average loss 12.01, train accuracy 0.62\n",
      "1,532,750 examples, moving-average loss 12.10, train accuracy 0.62\n",
      "1,534,350 examples, moving-average loss 12.11, train accuracy 0.62\n",
      "1,535,950 examples, moving-average loss 12.12, train accuracy 0.62\n",
      "1,537,550 examples, moving-average loss 12.22, train accuracy 0.62\n",
      "1,539,150 examples, moving-average loss 12.14, train accuracy 0.62\n",
      "1,540,750 examples, moving-average loss 12.13, train accuracy 0.62\n",
      "1,542,350 examples, moving-average loss 12.12, train accuracy 0.62\n",
      "1,543,950 examples, moving-average loss 12.17, train accuracy 0.62\n",
      "1,545,550 examples, moving-average loss 12.14, train accuracy 0.62\n",
      "1,547,150 examples, moving-average loss 12.08, train accuracy 0.62\n",
      "1,548,750 examples, moving-average loss 12.04, train accuracy 0.62\n",
      "1,550,350 examples, moving-average loss 12.10, train accuracy 0.62\n",
      "1,551,950 examples, moving-average loss 12.11, train accuracy 0.62\n",
      "1,553,550 examples, moving-average loss 12.08, train accuracy 0.62\n",
      "1,555,150 examples, moving-average loss 12.16, train accuracy 0.62\n",
      "1,556,750 examples, moving-average loss 12.10, train accuracy 0.62\n",
      "1,558,350 examples, moving-average loss 12.12, train accuracy 0.62\n",
      "1,559,950 examples, moving-average loss 12.16, train accuracy 0.62\n",
      "1,561,550 examples, moving-average loss 12.19, train accuracy 0.62\n",
      "1,563,150 examples, moving-average loss 12.05, train accuracy 0.62\n",
      "1,564,750 examples, moving-average loss 12.16, train accuracy 0.62\n",
      "1,566,350 examples, moving-average loss 12.23, train accuracy 0.62\n",
      "1,567,950 examples, moving-average loss 12.14, train accuracy 0.62\n",
      "1,569,550 examples, moving-average loss 12.05, train accuracy 0.62\n",
      "1,571,150 examples, moving-average loss 12.07, train accuracy 0.62\n",
      "1,572,750 examples, moving-average loss 12.11, train accuracy 0.62\n",
      "1,574,350 examples, moving-average loss 12.14, train accuracy 0.62\n",
      "1,575,950 examples, moving-average loss 12.11, train accuracy 0.62\n",
      "1,577,550 examples, moving-average loss 12.14, train accuracy 0.62\n",
      "1,579,150 examples, moving-average loss 12.10, train accuracy 0.62\n",
      "1,580,750 examples, moving-average loss 12.01, train accuracy 0.62\n",
      "1,582,350 examples, moving-average loss 12.07, train accuracy 0.63\n",
      "1,583,950 examples, moving-average loss 12.09, train accuracy 0.63\n",
      "1,585,550 examples, moving-average loss 12.13, train accuracy 0.63\n",
      "1,587,150 examples, moving-average loss 12.06, train accuracy 0.63\n",
      "1,588,750 examples, moving-average loss 12.11, train accuracy 0.63\n",
      "1,590,350 examples, moving-average loss 12.13, train accuracy 0.63\n",
      "1,591,950 examples, moving-average loss 12.17, train accuracy 0.63\n",
      "1,593,550 examples, moving-average loss 12.11, train accuracy 0.63\n",
      "1,595,150 examples, moving-average loss 12.16, train accuracy 0.63\n",
      "1,596,750 examples, moving-average loss 12.08, train accuracy 0.63\n",
      "1,598,350 examples, moving-average loss 12.11, train accuracy 0.63\n",
      "1,599,950 examples, moving-average loss 12.21, train accuracy 0.63\n",
      "1,601,550 examples, moving-average loss 12.14, train accuracy 0.63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,603,150 examples, moving-average loss 12.15, train accuracy 0.63\n",
      "1,604,750 examples, moving-average loss 12.09, train accuracy 0.63\n",
      "1,606,350 examples, moving-average loss 12.10, train accuracy 0.63\n",
      "1,607,950 examples, moving-average loss 12.07, train accuracy 0.63\n",
      "1,609,550 examples, moving-average loss 12.10, train accuracy 0.63\n",
      "1,611,150 examples, moving-average loss 12.06, train accuracy 0.63\n",
      "1,612,750 examples, moving-average loss 12.15, train accuracy 0.63\n",
      "1,614,350 examples, moving-average loss 12.02, train accuracy 0.63\n",
      "1,615,950 examples, moving-average loss 12.10, train accuracy 0.63\n",
      "1,617,550 examples, moving-average loss 12.12, train accuracy 0.63\n",
      "1,619,150 examples, moving-average loss 12.01, train accuracy 0.63\n",
      "1,620,750 examples, moving-average loss 12.05, train accuracy 0.63\n",
      "1,622,350 examples, moving-average loss 12.10, train accuracy 0.63\n",
      "1,623,950 examples, moving-average loss 12.10, train accuracy 0.63\n",
      "1,625,550 examples, moving-average loss 12.10, train accuracy 0.63\n",
      "1,627,150 examples, moving-average loss 12.07, train accuracy 0.63\n",
      "1,628,750 examples, moving-average loss 12.18, train accuracy 0.63\n",
      "1,630,350 examples, moving-average loss 12.08, train accuracy 0.63\n",
      "1,631,950 examples, moving-average loss 12.04, train accuracy 0.63\n",
      "1,633,550 examples, moving-average loss 12.09, train accuracy 0.63\n",
      "1,635,150 examples, moving-average loss 12.13, train accuracy 0.63\n",
      "1,636,750 examples, moving-average loss 12.07, train accuracy 0.63\n",
      "1,638,350 examples, moving-average loss 12.16, train accuracy 0.63\n",
      "1,639,950 examples, moving-average loss 12.15, train accuracy 0.63\n",
      "1,641,550 examples, moving-average loss 12.16, train accuracy 0.63\n",
      "1,643,150 examples, moving-average loss 12.06, train accuracy 0.63\n",
      "1,644,750 examples, moving-average loss 12.05, train accuracy 0.63\n",
      "1,646,350 examples, moving-average loss 12.14, train accuracy 0.63\n",
      "1,647,950 examples, moving-average loss 12.11, train accuracy 0.63\n",
      "1,649,550 examples, moving-average loss 12.03, train accuracy 0.63\n",
      "1,651,150 examples, moving-average loss 12.13, train accuracy 0.63\n",
      "1,652,750 examples, moving-average loss 12.06, train accuracy 0.63\n",
      "1,654,350 examples, moving-average loss 12.09, train accuracy 0.63\n",
      "1,655,950 examples, moving-average loss 12.05, train accuracy 0.63\n",
      "1,657,550 examples, moving-average loss 12.03, train accuracy 0.63\n",
      "1,659,150 examples, moving-average loss 12.16, train accuracy 0.63\n",
      "1,660,750 examples, moving-average loss 12.10, train accuracy 0.63\n",
      "1,662,350 examples, moving-average loss 12.13, train accuracy 0.63\n",
      "1,663,950 examples, moving-average loss 12.10, train accuracy 0.63\n",
      "1,665,550 examples, moving-average loss 12.09, train accuracy 0.63\n",
      "1,667,150 examples, moving-average loss 12.12, train accuracy 0.63\n",
      "1,668,750 examples, moving-average loss 12.12, train accuracy 0.63\n",
      "1,670,350 examples, moving-average loss 12.09, train accuracy 0.63\n",
      "1,671,950 examples, moving-average loss 12.10, train accuracy 0.63\n",
      "1,673,550 examples, moving-average loss 12.08, train accuracy 0.63\n",
      "1,675,150 examples, moving-average loss 12.06, train accuracy 0.63\n",
      "1,676,750 examples, moving-average loss 12.09, train accuracy 0.63\n",
      "1,678,350 examples, moving-average loss 12.11, train accuracy 0.63\n",
      "1,679,950 examples, moving-average loss 12.08, train accuracy 0.63\n",
      "1,681,550 examples, moving-average loss 12.11, train accuracy 0.63\n",
      "Completed 1 epoch in 0:38:22\n",
      "Train accurary:0.62725\n",
      "Validate accuracy:0.64534\n",
      "1,683,100 examples, moving-average loss 11.53, train accuracy 0.48\n",
      "1,684,700 examples, moving-average loss 12.00, train accuracy 0.60\n",
      "1,686,300 examples, moving-average loss 12.10, train accuracy 0.62\n",
      "1,687,900 examples, moving-average loss 12.14, train accuracy 0.62\n",
      "1,689,500 examples, moving-average loss 12.07, train accuracy 0.63\n",
      "1,691,100 examples, moving-average loss 12.09, train accuracy 0.63\n",
      "1,692,700 examples, moving-average loss 12.12, train accuracy 0.63\n",
      "1,694,300 examples, moving-average loss 12.02, train accuracy 0.63\n",
      "1,695,900 examples, moving-average loss 12.12, train accuracy 0.63\n",
      "1,697,500 examples, moving-average loss 12.10, train accuracy 0.64\n",
      "1,699,100 examples, moving-average loss 12.14, train accuracy 0.64\n",
      "1,700,700 examples, moving-average loss 12.10, train accuracy 0.64\n",
      "1,702,300 examples, moving-average loss 12.13, train accuracy 0.64\n",
      "1,703,900 examples, moving-average loss 12.11, train accuracy 0.64\n",
      "1,705,500 examples, moving-average loss 12.06, train accuracy 0.64\n",
      "1,707,100 examples, moving-average loss 12.03, train accuracy 0.64\n",
      "1,708,700 examples, moving-average loss 12.05, train accuracy 0.64\n",
      "1,710,300 examples, moving-average loss 12.13, train accuracy 0.64\n",
      "1,711,900 examples, moving-average loss 12.09, train accuracy 0.64\n",
      "1,713,500 examples, moving-average loss 12.09, train accuracy 0.64\n",
      "1,715,100 examples, moving-average loss 12.11, train accuracy 0.64\n",
      "1,716,700 examples, moving-average loss 12.19, train accuracy 0.64\n",
      "1,718,300 examples, moving-average loss 12.05, train accuracy 0.64\n",
      "1,719,900 examples, moving-average loss 12.13, train accuracy 0.64\n",
      "1,721,500 examples, moving-average loss 12.14, train accuracy 0.64\n",
      "1,723,100 examples, moving-average loss 12.04, train accuracy 0.64\n",
      "1,724,700 examples, moving-average loss 12.13, train accuracy 0.64\n",
      "1,726,300 examples, moving-average loss 12.08, train accuracy 0.64\n",
      "1,727,900 examples, moving-average loss 12.04, train accuracy 0.64\n",
      "1,729,500 examples, moving-average loss 12.06, train accuracy 0.64\n",
      "1,731,100 examples, moving-average loss 12.17, train accuracy 0.64\n",
      "1,732,700 examples, moving-average loss 12.06, train accuracy 0.64\n",
      "1,734,300 examples, moving-average loss 11.98, train accuracy 0.64\n",
      "1,735,900 examples, moving-average loss 12.05, train accuracy 0.64\n",
      "1,737,500 examples, moving-average loss 12.16, train accuracy 0.64\n",
      "1,739,100 examples, moving-average loss 12.05, train accuracy 0.64\n",
      "1,740,700 examples, moving-average loss 12.09, train accuracy 0.64\n",
      "1,742,300 examples, moving-average loss 12.10, train accuracy 0.64\n",
      "1,743,900 examples, moving-average loss 12.11, train accuracy 0.64\n",
      "1,745,500 examples, moving-average loss 12.14, train accuracy 0.64\n",
      "1,747,100 examples, moving-average loss 12.02, train accuracy 0.64\n",
      "1,748,700 examples, moving-average loss 12.12, train accuracy 0.64\n",
      "1,750,300 examples, moving-average loss 12.03, train accuracy 0.64\n",
      "1,751,900 examples, moving-average loss 12.01, train accuracy 0.64\n",
      "1,753,500 examples, moving-average loss 12.03, train accuracy 0.64\n",
      "1,755,100 examples, moving-average loss 12.08, train accuracy 0.64\n",
      "1,756,700 examples, moving-average loss 12.08, train accuracy 0.64\n",
      "1,758,300 examples, moving-average loss 12.00, train accuracy 0.64\n",
      "1,759,900 examples, moving-average loss 12.02, train accuracy 0.64\n",
      "1,761,500 examples, moving-average loss 12.12, train accuracy 0.64\n",
      "1,763,100 examples, moving-average loss 12.04, train accuracy 0.64\n",
      "1,764,700 examples, moving-average loss 12.03, train accuracy 0.64\n",
      "1,766,300 examples, moving-average loss 12.11, train accuracy 0.64\n",
      "1,767,900 examples, moving-average loss 12.14, train accuracy 0.64\n",
      "1,769,500 examples, moving-average loss 12.10, train accuracy 0.64\n",
      "1,771,100 examples, moving-average loss 12.00, train accuracy 0.65\n",
      "1,772,700 examples, moving-average loss 12.07, train accuracy 0.65\n",
      "1,774,300 examples, moving-average loss 12.07, train accuracy 0.65\n",
      "1,775,900 examples, moving-average loss 12.14, train accuracy 0.65\n",
      "1,777,500 examples, moving-average loss 12.10, train accuracy 0.65\n",
      "1,779,100 examples, moving-average loss 12.08, train accuracy 0.65\n",
      "1,780,700 examples, moving-average loss 12.12, train accuracy 0.65\n",
      "1,782,300 examples, moving-average loss 12.07, train accuracy 0.65\n",
      "1,783,900 examples, moving-average loss 12.06, train accuracy 0.65\n",
      "1,785,500 examples, moving-average loss 12.16, train accuracy 0.65\n",
      "1,787,100 examples, moving-average loss 12.10, train accuracy 0.65\n",
      "1,788,700 examples, moving-average loss 12.13, train accuracy 0.65\n",
      "1,790,300 examples, moving-average loss 12.07, train accuracy 0.65\n",
      "1,791,900 examples, moving-average loss 12.13, train accuracy 0.65\n",
      "1,793,500 examples, moving-average loss 12.05, train accuracy 0.65\n",
      "1,795,100 examples, moving-average loss 12.10, train accuracy 0.65\n",
      "1,796,700 examples, moving-average loss 12.16, train accuracy 0.65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,798,300 examples, moving-average loss 12.06, train accuracy 0.65\n",
      "1,799,900 examples, moving-average loss 12.06, train accuracy 0.65\n",
      "1,801,500 examples, moving-average loss 12.13, train accuracy 0.65\n",
      "1,803,100 examples, moving-average loss 12.09, train accuracy 0.65\n",
      "1,804,700 examples, moving-average loss 12.09, train accuracy 0.65\n",
      "1,806,300 examples, moving-average loss 12.09, train accuracy 0.65\n",
      "1,807,900 examples, moving-average loss 12.16, train accuracy 0.65\n",
      "1,809,500 examples, moving-average loss 12.08, train accuracy 0.65\n",
      "1,811,100 examples, moving-average loss 12.07, train accuracy 0.65\n",
      "1,812,700 examples, moving-average loss 12.05, train accuracy 0.65\n",
      "1,814,300 examples, moving-average loss 12.11, train accuracy 0.65\n",
      "1,815,900 examples, moving-average loss 12.14, train accuracy 0.65\n",
      "1,817,500 examples, moving-average loss 12.02, train accuracy 0.65\n",
      "1,819,100 examples, moving-average loss 12.13, train accuracy 0.65\n",
      "1,820,700 examples, moving-average loss 12.06, train accuracy 0.65\n",
      "1,822,300 examples, moving-average loss 12.11, train accuracy 0.65\n",
      "1,823,900 examples, moving-average loss 12.09, train accuracy 0.65\n",
      "1,825,500 examples, moving-average loss 12.10, train accuracy 0.65\n",
      "1,827,100 examples, moving-average loss 12.14, train accuracy 0.65\n",
      "1,828,700 examples, moving-average loss 12.09, train accuracy 0.65\n",
      "1,830,300 examples, moving-average loss 12.17, train accuracy 0.65\n",
      "1,831,900 examples, moving-average loss 12.03, train accuracy 0.65\n",
      "1,833,500 examples, moving-average loss 12.00, train accuracy 0.65\n",
      "1,835,100 examples, moving-average loss 12.06, train accuracy 0.65\n",
      "1,836,700 examples, moving-average loss 12.11, train accuracy 0.65\n",
      "1,838,300 examples, moving-average loss 12.04, train accuracy 0.65\n",
      "1,839,900 examples, moving-average loss 12.09, train accuracy 0.65\n",
      "1,841,500 examples, moving-average loss 12.07, train accuracy 0.65\n",
      "1,843,100 examples, moving-average loss 12.09, train accuracy 0.65\n",
      "1,844,700 examples, moving-average loss 12.07, train accuracy 0.65\n",
      "1,846,300 examples, moving-average loss 12.02, train accuracy 0.65\n",
      "1,847,900 examples, moving-average loss 12.12, train accuracy 0.65\n",
      "1,849,500 examples, moving-average loss 12.15, train accuracy 0.65\n",
      "1,851,100 examples, moving-average loss 12.11, train accuracy 0.65\n",
      "1,852,700 examples, moving-average loss 12.09, train accuracy 0.65\n",
      "1,854,300 examples, moving-average loss 12.11, train accuracy 0.65\n",
      "1,855,900 examples, moving-average loss 12.03, train accuracy 0.65\n",
      "1,857,500 examples, moving-average loss 12.17, train accuracy 0.65\n",
      "1,859,100 examples, moving-average loss 12.08, train accuracy 0.65\n",
      "1,860,700 examples, moving-average loss 12.13, train accuracy 0.64\n",
      "1,862,300 examples, moving-average loss 12.08, train accuracy 0.64\n",
      "1,863,900 examples, moving-average loss 12.04, train accuracy 0.64\n",
      "1,865,500 examples, moving-average loss 12.11, train accuracy 0.64\n",
      "1,867,100 examples, moving-average loss 12.08, train accuracy 0.64\n",
      "1,868,700 examples, moving-average loss 12.09, train accuracy 0.64\n",
      "1,870,300 examples, moving-average loss 12.14, train accuracy 0.64\n",
      "1,871,900 examples, moving-average loss 12.13, train accuracy 0.64\n",
      "1,873,500 examples, moving-average loss 12.07, train accuracy 0.64\n",
      "1,875,100 examples, moving-average loss 12.09, train accuracy 0.64\n",
      "1,876,700 examples, moving-average loss 12.05, train accuracy 0.64\n",
      "1,878,300 examples, moving-average loss 12.02, train accuracy 0.64\n",
      "1,879,900 examples, moving-average loss 12.16, train accuracy 0.64\n",
      "1,881,500 examples, moving-average loss 12.08, train accuracy 0.64\n",
      "1,883,100 examples, moving-average loss 12.05, train accuracy 0.64\n",
      "1,884,700 examples, moving-average loss 12.04, train accuracy 0.64\n",
      "1,886,300 examples, moving-average loss 12.06, train accuracy 0.64\n",
      "1,887,900 examples, moving-average loss 11.97, train accuracy 0.64\n",
      "1,889,500 examples, moving-average loss 12.11, train accuracy 0.64\n",
      "1,891,100 examples, moving-average loss 12.06, train accuracy 0.64\n",
      "1,892,700 examples, moving-average loss 12.08, train accuracy 0.65\n",
      "1,894,300 examples, moving-average loss 12.05, train accuracy 0.65\n",
      "1,895,900 examples, moving-average loss 12.14, train accuracy 0.65\n",
      "1,897,500 examples, moving-average loss 12.09, train accuracy 0.65\n",
      "1,899,100 examples, moving-average loss 12.15, train accuracy 0.65\n",
      "1,900,700 examples, moving-average loss 12.12, train accuracy 0.65\n",
      "1,902,300 examples, moving-average loss 12.04, train accuracy 0.65\n",
      "1,903,900 examples, moving-average loss 12.05, train accuracy 0.65\n",
      "1,905,500 examples, moving-average loss 12.05, train accuracy 0.65\n",
      "1,907,100 examples, moving-average loss 12.01, train accuracy 0.65\n",
      "1,908,700 examples, moving-average loss 12.07, train accuracy 0.65\n",
      "1,910,300 examples, moving-average loss 12.12, train accuracy 0.65\n",
      "1,911,900 examples, moving-average loss 12.12, train accuracy 0.65\n",
      "1,913,500 examples, moving-average loss 12.10, train accuracy 0.65\n",
      "1,915,100 examples, moving-average loss 12.04, train accuracy 0.65\n",
      "1,916,700 examples, moving-average loss 12.04, train accuracy 0.65\n",
      "1,918,300 examples, moving-average loss 12.13, train accuracy 0.65\n",
      "1,919,900 examples, moving-average loss 12.09, train accuracy 0.65\n",
      "1,921,500 examples, moving-average loss 12.05, train accuracy 0.65\n",
      "1,923,100 examples, moving-average loss 11.97, train accuracy 0.65\n",
      "1,924,700 examples, moving-average loss 12.11, train accuracy 0.65\n",
      "1,926,300 examples, moving-average loss 12.05, train accuracy 0.65\n",
      "1,927,900 examples, moving-average loss 12.14, train accuracy 0.65\n",
      "1,929,500 examples, moving-average loss 12.09, train accuracy 0.65\n",
      "1,931,100 examples, moving-average loss 12.08, train accuracy 0.65\n",
      "1,932,700 examples, moving-average loss 12.12, train accuracy 0.65\n",
      "1,934,300 examples, moving-average loss 12.06, train accuracy 0.65\n",
      "1,935,900 examples, moving-average loss 12.02, train accuracy 0.65\n",
      "1,937,500 examples, moving-average loss 12.06, train accuracy 0.65\n",
      "1,939,100 examples, moving-average loss 12.04, train accuracy 0.65\n",
      "1,940,700 examples, moving-average loss 12.08, train accuracy 0.65\n",
      "1,942,300 examples, moving-average loss 12.11, train accuracy 0.65\n",
      "1,943,900 examples, moving-average loss 12.12, train accuracy 0.65\n",
      "1,945,500 examples, moving-average loss 12.02, train accuracy 0.65\n",
      "1,947,100 examples, moving-average loss 12.07, train accuracy 0.65\n",
      "1,948,700 examples, moving-average loss 12.01, train accuracy 0.65\n",
      "1,950,300 examples, moving-average loss 12.02, train accuracy 0.65\n",
      "1,951,900 examples, moving-average loss 12.09, train accuracy 0.65\n",
      "1,953,500 examples, moving-average loss 12.16, train accuracy 0.65\n",
      "1,955,100 examples, moving-average loss 12.14, train accuracy 0.65\n",
      "1,956,700 examples, moving-average loss 12.11, train accuracy 0.65\n",
      "1,958,300 examples, moving-average loss 12.00, train accuracy 0.65\n",
      "1,959,900 examples, moving-average loss 12.03, train accuracy 0.65\n",
      "1,961,500 examples, moving-average loss 12.02, train accuracy 0.65\n",
      "1,963,100 examples, moving-average loss 12.10, train accuracy 0.65\n",
      "1,964,700 examples, moving-average loss 12.16, train accuracy 0.65\n",
      "1,966,300 examples, moving-average loss 12.08, train accuracy 0.65\n",
      "1,967,900 examples, moving-average loss 12.05, train accuracy 0.65\n",
      "1,969,500 examples, moving-average loss 12.08, train accuracy 0.65\n",
      "1,971,100 examples, moving-average loss 12.11, train accuracy 0.65\n",
      "1,972,700 examples, moving-average loss 12.10, train accuracy 0.65\n",
      "1,974,300 examples, moving-average loss 12.02, train accuracy 0.65\n",
      "1,975,900 examples, moving-average loss 12.14, train accuracy 0.65\n",
      "1,977,500 examples, moving-average loss 12.07, train accuracy 0.65\n",
      "1,979,100 examples, moving-average loss 12.11, train accuracy 0.65\n",
      "1,980,700 examples, moving-average loss 12.05, train accuracy 0.65\n",
      "1,982,300 examples, moving-average loss 12.02, train accuracy 0.65\n",
      "1,983,900 examples, moving-average loss 12.09, train accuracy 0.65\n",
      "1,985,500 examples, moving-average loss 12.10, train accuracy 0.65\n",
      "1,987,100 examples, moving-average loss 12.13, train accuracy 0.65\n",
      "1,988,700 examples, moving-average loss 12.06, train accuracy 0.65\n",
      "1,990,300 examples, moving-average loss 12.04, train accuracy 0.65\n",
      "1,991,900 examples, moving-average loss 12.05, train accuracy 0.65\n",
      "1,993,500 examples, moving-average loss 12.13, train accuracy 0.65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,995,100 examples, moving-average loss 12.02, train accuracy 0.65\n",
      "1,996,700 examples, moving-average loss 12.00, train accuracy 0.65\n",
      "1,998,300 examples, moving-average loss 12.09, train accuracy 0.65\n",
      "1,999,900 examples, moving-average loss 12.10, train accuracy 0.65\n",
      "2,001,500 examples, moving-average loss 12.09, train accuracy 0.65\n",
      "2,003,100 examples, moving-average loss 12.08, train accuracy 0.65\n",
      "2,004,700 examples, moving-average loss 12.14, train accuracy 0.65\n",
      "2,006,300 examples, moving-average loss 12.05, train accuracy 0.65\n",
      "2,007,900 examples, moving-average loss 12.10, train accuracy 0.65\n",
      "2,009,500 examples, moving-average loss 12.01, train accuracy 0.65\n",
      "2,011,100 examples, moving-average loss 12.06, train accuracy 0.65\n",
      "2,012,700 examples, moving-average loss 12.11, train accuracy 0.65\n",
      "2,014,300 examples, moving-average loss 12.11, train accuracy 0.65\n",
      "2,015,900 examples, moving-average loss 12.02, train accuracy 0.65\n",
      "2,017,500 examples, moving-average loss 12.10, train accuracy 0.65\n",
      "2,019,100 examples, moving-average loss 12.13, train accuracy 0.65\n",
      "2,020,700 examples, moving-average loss 12.10, train accuracy 0.65\n",
      "2,022,300 examples, moving-average loss 12.03, train accuracy 0.65\n",
      "2,023,900 examples, moving-average loss 12.03, train accuracy 0.65\n",
      "2,025,500 examples, moving-average loss 11.99, train accuracy 0.65\n",
      "2,027,100 examples, moving-average loss 12.12, train accuracy 0.65\n",
      "2,028,700 examples, moving-average loss 12.09, train accuracy 0.65\n",
      "2,030,300 examples, moving-average loss 12.08, train accuracy 0.65\n",
      "2,031,900 examples, moving-average loss 12.14, train accuracy 0.65\n",
      "2,033,500 examples, moving-average loss 12.01, train accuracy 0.65\n",
      "2,035,100 examples, moving-average loss 12.00, train accuracy 0.65\n",
      "2,036,700 examples, moving-average loss 12.09, train accuracy 0.65\n",
      "2,038,300 examples, moving-average loss 12.06, train accuracy 0.65\n",
      "2,039,900 examples, moving-average loss 12.01, train accuracy 0.65\n",
      "2,041,500 examples, moving-average loss 12.12, train accuracy 0.65\n",
      "2,043,100 examples, moving-average loss 12.02, train accuracy 0.65\n",
      "2,044,700 examples, moving-average loss 12.13, train accuracy 0.65\n",
      "2,046,300 examples, moving-average loss 11.99, train accuracy 0.65\n",
      "2,047,900 examples, moving-average loss 12.00, train accuracy 0.65\n",
      "2,049,500 examples, moving-average loss 12.07, train accuracy 0.65\n",
      "2,051,100 examples, moving-average loss 12.07, train accuracy 0.65\n",
      "2,052,700 examples, moving-average loss 12.01, train accuracy 0.65\n",
      "2,054,300 examples, moving-average loss 12.23, train accuracy 0.65\n",
      "2,055,900 examples, moving-average loss 12.10, train accuracy 0.65\n",
      "2,057,500 examples, moving-average loss 12.11, train accuracy 0.65\n",
      "2,059,100 examples, moving-average loss 12.17, train accuracy 0.65\n",
      "2,060,700 examples, moving-average loss 12.02, train accuracy 0.65\n",
      "2,062,300 examples, moving-average loss 12.11, train accuracy 0.65\n",
      "2,063,900 examples, moving-average loss 12.07, train accuracy 0.65\n",
      "2,065,500 examples, moving-average loss 12.09, train accuracy 0.65\n",
      "2,067,100 examples, moving-average loss 12.08, train accuracy 0.65\n",
      "2,068,700 examples, moving-average loss 12.05, train accuracy 0.65\n",
      "2,070,300 examples, moving-average loss 12.07, train accuracy 0.65\n",
      "2,071,900 examples, moving-average loss 12.12, train accuracy 0.65\n",
      "2,073,500 examples, moving-average loss 12.14, train accuracy 0.65\n",
      "2,075,100 examples, moving-average loss 12.09, train accuracy 0.65\n",
      "2,076,700 examples, moving-average loss 12.08, train accuracy 0.65\n",
      "2,078,300 examples, moving-average loss 12.04, train accuracy 0.65\n",
      "2,079,900 examples, moving-average loss 12.12, train accuracy 0.65\n",
      "2,081,500 examples, moving-average loss 12.09, train accuracy 0.65\n",
      "2,083,100 examples, moving-average loss 12.08, train accuracy 0.65\n",
      "2,084,700 examples, moving-average loss 12.09, train accuracy 0.65\n",
      "2,086,300 examples, moving-average loss 12.04, train accuracy 0.65\n",
      "2,087,900 examples, moving-average loss 12.07, train accuracy 0.65\n",
      "2,089,500 examples, moving-average loss 12.13, train accuracy 0.65\n",
      "2,091,100 examples, moving-average loss 12.13, train accuracy 0.65\n",
      "2,092,700 examples, moving-average loss 12.13, train accuracy 0.65\n",
      "2,094,300 examples, moving-average loss 12.09, train accuracy 0.65\n",
      "2,095,900 examples, moving-average loss 12.15, train accuracy 0.65\n",
      "2,097,500 examples, moving-average loss 12.17, train accuracy 0.65\n",
      "2,099,100 examples, moving-average loss 12.01, train accuracy 0.65\n",
      "2,100,700 examples, moving-average loss 12.10, train accuracy 0.65\n",
      "2,102,300 examples, moving-average loss 12.17, train accuracy 0.65\n",
      "2,103,900 examples, moving-average loss 12.08, train accuracy 0.65\n",
      "2,105,500 examples, moving-average loss 12.13, train accuracy 0.65\n",
      "2,107,100 examples, moving-average loss 12.06, train accuracy 0.65\n",
      "2,108,700 examples, moving-average loss 12.02, train accuracy 0.65\n",
      "2,110,300 examples, moving-average loss 12.05, train accuracy 0.65\n",
      "2,111,900 examples, moving-average loss 12.03, train accuracy 0.65\n",
      "2,113,500 examples, moving-average loss 12.12, train accuracy 0.65\n",
      "2,115,100 examples, moving-average loss 12.09, train accuracy 0.65\n",
      "2,116,700 examples, moving-average loss 12.09, train accuracy 0.65\n",
      "2,118,300 examples, moving-average loss 12.09, train accuracy 0.65\n",
      "2,119,900 examples, moving-average loss 12.00, train accuracy 0.65\n",
      "2,121,500 examples, moving-average loss 12.06, train accuracy 0.65\n",
      "2,123,100 examples, moving-average loss 12.07, train accuracy 0.65\n",
      "2,124,700 examples, moving-average loss 12.04, train accuracy 0.65\n",
      "2,126,300 examples, moving-average loss 12.09, train accuracy 0.65\n",
      "2,127,900 examples, moving-average loss 12.14, train accuracy 0.65\n",
      "2,129,500 examples, moving-average loss 12.09, train accuracy 0.65\n",
      "2,131,100 examples, moving-average loss 12.11, train accuracy 0.65\n",
      "2,132,700 examples, moving-average loss 12.14, train accuracy 0.65\n",
      "2,134,300 examples, moving-average loss 12.17, train accuracy 0.65\n",
      "2,135,900 examples, moving-average loss 12.13, train accuracy 0.65\n",
      "2,137,500 examples, moving-average loss 12.03, train accuracy 0.65\n",
      "2,139,100 examples, moving-average loss 12.12, train accuracy 0.65\n",
      "2,140,700 examples, moving-average loss 12.04, train accuracy 0.65\n",
      "2,142,300 examples, moving-average loss 12.09, train accuracy 0.65\n",
      "2,143,900 examples, moving-average loss 12.13, train accuracy 0.65\n",
      "2,145,500 examples, moving-average loss 12.15, train accuracy 0.65\n",
      "2,147,100 examples, moving-average loss 12.11, train accuracy 0.65\n",
      "2,148,700 examples, moving-average loss 12.07, train accuracy 0.65\n",
      "2,150,300 examples, moving-average loss 12.09, train accuracy 0.65\n",
      "2,151,900 examples, moving-average loss 12.01, train accuracy 0.65\n",
      "2,153,500 examples, moving-average loss 12.08, train accuracy 0.65\n",
      "2,155,100 examples, moving-average loss 12.19, train accuracy 0.65\n",
      "2,156,700 examples, moving-average loss 12.08, train accuracy 0.65\n",
      "2,158,300 examples, moving-average loss 12.09, train accuracy 0.65\n",
      "2,159,900 examples, moving-average loss 12.09, train accuracy 0.65\n",
      "2,161,500 examples, moving-average loss 12.04, train accuracy 0.65\n",
      "2,163,100 examples, moving-average loss 12.05, train accuracy 0.65\n",
      "2,164,700 examples, moving-average loss 12.07, train accuracy 0.65\n",
      "2,166,300 examples, moving-average loss 12.12, train accuracy 0.65\n",
      "2,167,900 examples, moving-average loss 12.00, train accuracy 0.65\n",
      "2,169,500 examples, moving-average loss 12.08, train accuracy 0.65\n",
      "2,171,100 examples, moving-average loss 12.12, train accuracy 0.65\n",
      "2,172,700 examples, moving-average loss 12.13, train accuracy 0.65\n",
      "2,174,300 examples, moving-average loss 12.15, train accuracy 0.65\n",
      "2,175,900 examples, moving-average loss 12.00, train accuracy 0.65\n",
      "2,177,500 examples, moving-average loss 12.05, train accuracy 0.65\n",
      "2,179,100 examples, moving-average loss 12.03, train accuracy 0.65\n",
      "2,180,700 examples, moving-average loss 12.11, train accuracy 0.65\n",
      "2,182,300 examples, moving-average loss 12.03, train accuracy 0.65\n",
      "2,183,900 examples, moving-average loss 11.99, train accuracy 0.65\n",
      "2,185,500 examples, moving-average loss 12.00, train accuracy 0.65\n",
      "2,187,100 examples, moving-average loss 12.05, train accuracy 0.65\n",
      "2,188,700 examples, moving-average loss 12.02, train accuracy 0.65\n",
      "2,190,300 examples, moving-average loss 12.03, train accuracy 0.65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,191,900 examples, moving-average loss 12.09, train accuracy 0.65\n",
      "2,193,500 examples, moving-average loss 12.09, train accuracy 0.65\n",
      "2,195,100 examples, moving-average loss 12.14, train accuracy 0.65\n",
      "2,196,700 examples, moving-average loss 12.10, train accuracy 0.65\n",
      "2,198,300 examples, moving-average loss 12.06, train accuracy 0.65\n",
      "2,199,900 examples, moving-average loss 12.11, train accuracy 0.65\n",
      "2,201,500 examples, moving-average loss 11.99, train accuracy 0.65\n",
      "2,203,100 examples, moving-average loss 12.11, train accuracy 0.65\n",
      "2,204,700 examples, moving-average loss 11.99, train accuracy 0.65\n",
      "2,206,300 examples, moving-average loss 12.06, train accuracy 0.65\n",
      "2,207,900 examples, moving-average loss 12.08, train accuracy 0.65\n",
      "2,209,500 examples, moving-average loss 12.10, train accuracy 0.65\n",
      "2,211,100 examples, moving-average loss 12.16, train accuracy 0.65\n",
      "2,212,700 examples, moving-average loss 12.12, train accuracy 0.65\n",
      "2,214,300 examples, moving-average loss 12.05, train accuracy 0.65\n",
      "2,215,900 examples, moving-average loss 12.16, train accuracy 0.65\n",
      "2,217,500 examples, moving-average loss 12.05, train accuracy 0.65\n",
      "2,219,100 examples, moving-average loss 12.16, train accuracy 0.65\n",
      "2,220,700 examples, moving-average loss 12.00, train accuracy 0.65\n",
      "2,222,300 examples, moving-average loss 12.01, train accuracy 0.65\n",
      "2,223,900 examples, moving-average loss 12.14, train accuracy 0.65\n",
      "2,225,500 examples, moving-average loss 11.95, train accuracy 0.65\n",
      "2,227,100 examples, moving-average loss 12.02, train accuracy 0.65\n",
      "2,228,700 examples, moving-average loss 11.99, train accuracy 0.65\n",
      "2,230,300 examples, moving-average loss 12.04, train accuracy 0.65\n",
      "2,231,900 examples, moving-average loss 12.04, train accuracy 0.65\n",
      "2,233,500 examples, moving-average loss 12.09, train accuracy 0.65\n",
      "2,235,100 examples, moving-average loss 12.13, train accuracy 0.65\n",
      "2,236,700 examples, moving-average loss 12.14, train accuracy 0.65\n",
      "2,238,300 examples, moving-average loss 12.08, train accuracy 0.65\n",
      "2,239,900 examples, moving-average loss 12.21, train accuracy 0.65\n",
      "2,241,500 examples, moving-average loss 12.04, train accuracy 0.65\n",
      "2,243,100 examples, moving-average loss 11.99, train accuracy 0.65\n",
      "2,244,700 examples, moving-average loss 12.12, train accuracy 0.65\n",
      "2,246,300 examples, moving-average loss 12.00, train accuracy 0.65\n",
      "2,247,900 examples, moving-average loss 12.02, train accuracy 0.65\n",
      "2,249,500 examples, moving-average loss 12.10, train accuracy 0.65\n",
      "2,251,100 examples, moving-average loss 12.05, train accuracy 0.65\n",
      "2,252,700 examples, moving-average loss 12.01, train accuracy 0.65\n",
      "2,254,300 examples, moving-average loss 12.10, train accuracy 0.65\n",
      "2,255,900 examples, moving-average loss 12.11, train accuracy 0.65\n",
      "2,257,500 examples, moving-average loss 12.10, train accuracy 0.65\n",
      "2,259,100 examples, moving-average loss 12.08, train accuracy 0.65\n",
      "2,260,700 examples, moving-average loss 12.15, train accuracy 0.65\n",
      "2,262,300 examples, moving-average loss 12.09, train accuracy 0.65\n",
      "2,263,900 examples, moving-average loss 12.02, train accuracy 0.65\n",
      "2,265,500 examples, moving-average loss 12.03, train accuracy 0.65\n",
      "2,267,100 examples, moving-average loss 12.04, train accuracy 0.65\n",
      "2,268,700 examples, moving-average loss 12.03, train accuracy 0.65\n",
      "2,270,300 examples, moving-average loss 12.05, train accuracy 0.65\n",
      "2,271,900 examples, moving-average loss 12.07, train accuracy 0.65\n",
      "2,273,500 examples, moving-average loss 12.11, train accuracy 0.65\n",
      "2,275,100 examples, moving-average loss 12.11, train accuracy 0.65\n",
      "2,276,700 examples, moving-average loss 11.99, train accuracy 0.65\n",
      "2,278,300 examples, moving-average loss 12.02, train accuracy 0.65\n",
      "2,279,900 examples, moving-average loss 12.04, train accuracy 0.65\n",
      "2,281,500 examples, moving-average loss 12.06, train accuracy 0.65\n",
      "2,283,100 examples, moving-average loss 12.08, train accuracy 0.65\n",
      "2,284,700 examples, moving-average loss 12.09, train accuracy 0.65\n",
      "2,286,300 examples, moving-average loss 12.18, train accuracy 0.65\n",
      "2,287,900 examples, moving-average loss 12.07, train accuracy 0.65\n",
      "2,289,500 examples, moving-average loss 12.04, train accuracy 0.65\n",
      "2,291,100 examples, moving-average loss 12.11, train accuracy 0.65\n",
      "2,292,700 examples, moving-average loss 12.04, train accuracy 0.65\n",
      "2,294,300 examples, moving-average loss 12.09, train accuracy 0.65\n",
      "2,295,900 examples, moving-average loss 12.09, train accuracy 0.65\n",
      "2,297,500 examples, moving-average loss 12.07, train accuracy 0.65\n",
      "2,299,100 examples, moving-average loss 12.08, train accuracy 0.65\n",
      "2,300,700 examples, moving-average loss 11.97, train accuracy 0.65\n",
      "2,302,300 examples, moving-average loss 12.09, train accuracy 0.65\n",
      "2,303,900 examples, moving-average loss 12.08, train accuracy 0.65\n",
      "2,305,500 examples, moving-average loss 12.13, train accuracy 0.65\n",
      "2,307,100 examples, moving-average loss 12.13, train accuracy 0.65\n",
      "2,308,700 examples, moving-average loss 12.04, train accuracy 0.65\n",
      "2,310,300 examples, moving-average loss 12.09, train accuracy 0.65\n",
      "2,311,900 examples, moving-average loss 12.13, train accuracy 0.65\n",
      "2,313,500 examples, moving-average loss 12.11, train accuracy 0.65\n",
      "2,315,100 examples, moving-average loss 12.18, train accuracy 0.65\n",
      "2,316,700 examples, moving-average loss 12.06, train accuracy 0.65\n",
      "2,318,300 examples, moving-average loss 12.03, train accuracy 0.65\n",
      "2,319,900 examples, moving-average loss 12.01, train accuracy 0.65\n",
      "2,321,500 examples, moving-average loss 12.05, train accuracy 0.65\n",
      "2,323,100 examples, moving-average loss 11.97, train accuracy 0.65\n",
      "2,324,700 examples, moving-average loss 12.17, train accuracy 0.65\n",
      "2,326,300 examples, moving-average loss 12.12, train accuracy 0.65\n",
      "2,327,900 examples, moving-average loss 12.05, train accuracy 0.65\n",
      "2,329,500 examples, moving-average loss 12.09, train accuracy 0.65\n",
      "2,331,100 examples, moving-average loss 12.04, train accuracy 0.65\n",
      "2,332,700 examples, moving-average loss 12.04, train accuracy 0.65\n",
      "2,334,300 examples, moving-average loss 12.02, train accuracy 0.65\n",
      "2,335,900 examples, moving-average loss 12.07, train accuracy 0.65\n",
      "2,337,500 examples, moving-average loss 12.13, train accuracy 0.65\n",
      "2,339,100 examples, moving-average loss 12.10, train accuracy 0.65\n",
      "2,340,700 examples, moving-average loss 12.12, train accuracy 0.65\n",
      "2,342,300 examples, moving-average loss 12.12, train accuracy 0.65\n",
      "2,343,900 examples, moving-average loss 12.09, train accuracy 0.65\n",
      "2,345,500 examples, moving-average loss 12.15, train accuracy 0.65\n",
      "2,347,100 examples, moving-average loss 12.10, train accuracy 0.65\n",
      "2,348,700 examples, moving-average loss 12.08, train accuracy 0.65\n",
      "2,350,300 examples, moving-average loss 12.10, train accuracy 0.65\n",
      "2,351,900 examples, moving-average loss 12.10, train accuracy 0.65\n",
      "2,353,500 examples, moving-average loss 11.97, train accuracy 0.65\n",
      "2,355,100 examples, moving-average loss 12.10, train accuracy 0.65\n",
      "2,356,700 examples, moving-average loss 12.13, train accuracy 0.65\n",
      "2,358,300 examples, moving-average loss 12.00, train accuracy 0.65\n",
      "2,359,900 examples, moving-average loss 12.11, train accuracy 0.65\n",
      "2,361,500 examples, moving-average loss 12.12, train accuracy 0.65\n",
      "2,363,100 examples, moving-average loss 12.12, train accuracy 0.65\n",
      "2,364,700 examples, moving-average loss 12.03, train accuracy 0.65\n",
      "2,366,300 examples, moving-average loss 12.10, train accuracy 0.65\n",
      "2,367,900 examples, moving-average loss 12.07, train accuracy 0.65\n",
      "2,369,500 examples, moving-average loss 11.99, train accuracy 0.65\n",
      "2,371,100 examples, moving-average loss 12.01, train accuracy 0.65\n",
      "2,372,700 examples, moving-average loss 11.99, train accuracy 0.65\n",
      "2,374,300 examples, moving-average loss 12.10, train accuracy 0.65\n",
      "2,375,900 examples, moving-average loss 12.05, train accuracy 0.65\n",
      "2,377,500 examples, moving-average loss 12.09, train accuracy 0.65\n",
      "2,379,100 examples, moving-average loss 12.15, train accuracy 0.65\n",
      "2,380,700 examples, moving-average loss 12.12, train accuracy 0.65\n",
      "2,382,300 examples, moving-average loss 12.06, train accuracy 0.65\n",
      "2,383,900 examples, moving-average loss 12.03, train accuracy 0.65\n",
      "2,385,500 examples, moving-average loss 12.16, train accuracy 0.65\n",
      "2,387,100 examples, moving-average loss 12.06, train accuracy 0.65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,388,700 examples, moving-average loss 12.09, train accuracy 0.65\n",
      "2,390,300 examples, moving-average loss 11.98, train accuracy 0.65\n",
      "2,391,900 examples, moving-average loss 12.07, train accuracy 0.65\n",
      "2,393,500 examples, moving-average loss 12.10, train accuracy 0.65\n",
      "2,395,100 examples, moving-average loss 12.09, train accuracy 0.65\n",
      "2,396,700 examples, moving-average loss 12.07, train accuracy 0.65\n",
      "2,398,300 examples, moving-average loss 12.04, train accuracy 0.65\n",
      "2,399,900 examples, moving-average loss 12.15, train accuracy 0.65\n",
      "2,401,500 examples, moving-average loss 12.14, train accuracy 0.65\n",
      "2,403,100 examples, moving-average loss 12.08, train accuracy 0.65\n",
      "2,404,700 examples, moving-average loss 12.01, train accuracy 0.65\n",
      "2,406,300 examples, moving-average loss 12.17, train accuracy 0.65\n",
      "2,407,900 examples, moving-average loss 12.20, train accuracy 0.65\n",
      "2,409,500 examples, moving-average loss 12.05, train accuracy 0.65\n",
      "2,411,100 examples, moving-average loss 12.02, train accuracy 0.65\n",
      "2,412,700 examples, moving-average loss 12.06, train accuracy 0.65\n",
      "2,414,300 examples, moving-average loss 12.08, train accuracy 0.65\n",
      "2,415,900 examples, moving-average loss 12.11, train accuracy 0.65\n",
      "2,417,500 examples, moving-average loss 12.08, train accuracy 0.65\n",
      "2,419,100 examples, moving-average loss 12.12, train accuracy 0.65\n",
      "2,420,700 examples, moving-average loss 12.01, train accuracy 0.65\n",
      "2,422,300 examples, moving-average loss 12.01, train accuracy 0.65\n",
      "2,423,900 examples, moving-average loss 12.05, train accuracy 0.65\n",
      "2,425,500 examples, moving-average loss 12.05, train accuracy 0.65\n",
      "2,427,100 examples, moving-average loss 12.04, train accuracy 0.65\n",
      "2,428,700 examples, moving-average loss 12.01, train accuracy 0.65\n",
      "2,430,300 examples, moving-average loss 12.07, train accuracy 0.65\n",
      "2,431,900 examples, moving-average loss 12.03, train accuracy 0.65\n",
      "2,433,500 examples, moving-average loss 12.13, train accuracy 0.65\n",
      "2,435,100 examples, moving-average loss 12.06, train accuracy 0.65\n",
      "2,436,700 examples, moving-average loss 12.19, train accuracy 0.65\n",
      "2,438,300 examples, moving-average loss 12.04, train accuracy 0.65\n",
      "2,439,900 examples, moving-average loss 12.07, train accuracy 0.65\n",
      "2,441,500 examples, moving-average loss 12.16, train accuracy 0.65\n",
      "2,443,100 examples, moving-average loss 12.09, train accuracy 0.65\n",
      "2,444,700 examples, moving-average loss 12.08, train accuracy 0.65\n",
      "2,446,300 examples, moving-average loss 12.07, train accuracy 0.65\n",
      "2,447,900 examples, moving-average loss 12.04, train accuracy 0.65\n",
      "2,449,500 examples, moving-average loss 12.03, train accuracy 0.65\n",
      "2,451,100 examples, moving-average loss 12.09, train accuracy 0.65\n",
      "2,452,700 examples, moving-average loss 12.02, train accuracy 0.65\n",
      "2,454,300 examples, moving-average loss 12.08, train accuracy 0.65\n",
      "2,455,900 examples, moving-average loss 11.99, train accuracy 0.65\n",
      "2,457,500 examples, moving-average loss 12.07, train accuracy 0.65\n",
      "2,459,100 examples, moving-average loss 12.07, train accuracy 0.65\n",
      "2,460,700 examples, moving-average loss 11.98, train accuracy 0.65\n",
      "2,462,300 examples, moving-average loss 12.07, train accuracy 0.65\n",
      "2,463,900 examples, moving-average loss 12.01, train accuracy 0.65\n",
      "2,465,500 examples, moving-average loss 12.03, train accuracy 0.65\n",
      "2,467,100 examples, moving-average loss 12.07, train accuracy 0.65\n",
      "2,468,700 examples, moving-average loss 12.05, train accuracy 0.65\n",
      "2,470,300 examples, moving-average loss 12.15, train accuracy 0.65\n",
      "2,471,900 examples, moving-average loss 12.06, train accuracy 0.65\n",
      "2,473,500 examples, moving-average loss 12.02, train accuracy 0.65\n",
      "2,475,100 examples, moving-average loss 12.05, train accuracy 0.65\n",
      "2,476,700 examples, moving-average loss 12.07, train accuracy 0.65\n",
      "2,478,300 examples, moving-average loss 12.09, train accuracy 0.65\n",
      "2,479,900 examples, moving-average loss 12.12, train accuracy 0.65\n",
      "2,481,500 examples, moving-average loss 12.11, train accuracy 0.65\n",
      "2,483,100 examples, moving-average loss 12.12, train accuracy 0.65\n",
      "2,484,700 examples, moving-average loss 11.99, train accuracy 0.65\n",
      "2,486,300 examples, moving-average loss 12.03, train accuracy 0.65\n",
      "2,487,900 examples, moving-average loss 12.07, train accuracy 0.65\n",
      "2,489,500 examples, moving-average loss 12.06, train accuracy 0.65\n",
      "2,491,100 examples, moving-average loss 12.00, train accuracy 0.65\n",
      "2,492,700 examples, moving-average loss 12.10, train accuracy 0.65\n",
      "2,494,300 examples, moving-average loss 12.02, train accuracy 0.65\n",
      "2,495,900 examples, moving-average loss 12.03, train accuracy 0.65\n",
      "2,497,500 examples, moving-average loss 12.03, train accuracy 0.65\n",
      "2,499,100 examples, moving-average loss 11.97, train accuracy 0.65\n",
      "2,500,700 examples, moving-average loss 12.10, train accuracy 0.65\n",
      "2,502,300 examples, moving-average loss 12.13, train accuracy 0.65\n",
      "2,503,900 examples, moving-average loss 12.07, train accuracy 0.65\n",
      "2,505,500 examples, moving-average loss 12.05, train accuracy 0.65\n",
      "2,507,100 examples, moving-average loss 12.10, train accuracy 0.65\n",
      "2,508,700 examples, moving-average loss 12.08, train accuracy 0.65\n",
      "2,510,300 examples, moving-average loss 12.07, train accuracy 0.65\n",
      "2,511,900 examples, moving-average loss 12.01, train accuracy 0.65\n",
      "2,513,500 examples, moving-average loss 12.05, train accuracy 0.65\n",
      "2,515,100 examples, moving-average loss 12.01, train accuracy 0.65\n",
      "2,516,700 examples, moving-average loss 12.04, train accuracy 0.65\n",
      "2,518,300 examples, moving-average loss 12.05, train accuracy 0.65\n",
      "2,519,900 examples, moving-average loss 12.09, train accuracy 0.65\n",
      "2,521,500 examples, moving-average loss 12.04, train accuracy 0.65\n",
      "2,523,100 examples, moving-average loss 12.07, train accuracy 0.65\n",
      "Completed 2 epoch in 0:38:14\n",
      "Train accurary:0.65297\n",
      "Validate accuracy:0.66324\n",
      "2,524,650 examples, moving-average loss 11.62, train accuracy 0.53\n",
      "2,526,250 examples, moving-average loss 11.97, train accuracy 0.63\n",
      "2,527,850 examples, moving-average loss 12.08, train accuracy 0.64\n",
      "2,529,450 examples, moving-average loss 12.09, train accuracy 0.65\n",
      "2,531,050 examples, moving-average loss 12.05, train accuracy 0.65\n",
      "2,532,650 examples, moving-average loss 12.07, train accuracy 0.65\n",
      "2,534,250 examples, moving-average loss 12.10, train accuracy 0.65\n",
      "2,535,850 examples, moving-average loss 12.01, train accuracy 0.66\n",
      "2,537,450 examples, moving-average loss 12.05, train accuracy 0.66\n",
      "2,539,050 examples, moving-average loss 12.03, train accuracy 0.66\n",
      "2,540,650 examples, moving-average loss 12.05, train accuracy 0.66\n",
      "2,542,250 examples, moving-average loss 12.10, train accuracy 0.66\n",
      "2,543,850 examples, moving-average loss 12.11, train accuracy 0.66\n",
      "2,545,450 examples, moving-average loss 12.09, train accuracy 0.66\n",
      "2,547,050 examples, moving-average loss 12.05, train accuracy 0.66\n",
      "2,548,650 examples, moving-average loss 12.02, train accuracy 0.66\n",
      "2,550,250 examples, moving-average loss 12.08, train accuracy 0.66\n",
      "2,551,850 examples, moving-average loss 12.09, train accuracy 0.66\n",
      "2,553,450 examples, moving-average loss 12.01, train accuracy 0.66\n",
      "2,555,050 examples, moving-average loss 12.08, train accuracy 0.66\n",
      "2,556,650 examples, moving-average loss 12.09, train accuracy 0.66\n",
      "2,558,250 examples, moving-average loss 12.11, train accuracy 0.66\n",
      "2,559,850 examples, moving-average loss 12.01, train accuracy 0.66\n",
      "2,561,450 examples, moving-average loss 12.07, train accuracy 0.66\n",
      "2,563,050 examples, moving-average loss 12.08, train accuracy 0.66\n",
      "2,564,650 examples, moving-average loss 12.03, train accuracy 0.66\n",
      "2,566,250 examples, moving-average loss 12.08, train accuracy 0.66\n",
      "2,567,850 examples, moving-average loss 12.01, train accuracy 0.66\n",
      "2,569,450 examples, moving-average loss 12.02, train accuracy 0.66\n",
      "2,571,050 examples, moving-average loss 12.05, train accuracy 0.66\n",
      "2,572,650 examples, moving-average loss 12.14, train accuracy 0.66\n",
      "2,574,250 examples, moving-average loss 12.06, train accuracy 0.66\n",
      "2,575,850 examples, moving-average loss 11.94, train accuracy 0.66\n",
      "2,577,450 examples, moving-average loss 12.03, train accuracy 0.66\n",
      "2,579,050 examples, moving-average loss 12.12, train accuracy 0.66\n",
      "2,580,650 examples, moving-average loss 12.03, train accuracy 0.66\n",
      "2,582,250 examples, moving-average loss 12.03, train accuracy 0.66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,583,850 examples, moving-average loss 12.09, train accuracy 0.66\n",
      "2,585,450 examples, moving-average loss 12.09, train accuracy 0.66\n",
      "2,587,050 examples, moving-average loss 12.11, train accuracy 0.66\n",
      "2,588,650 examples, moving-average loss 12.02, train accuracy 0.66\n",
      "2,590,250 examples, moving-average loss 12.11, train accuracy 0.66\n",
      "2,591,850 examples, moving-average loss 11.99, train accuracy 0.66\n",
      "2,593,450 examples, moving-average loss 12.02, train accuracy 0.66\n",
      "2,595,050 examples, moving-average loss 12.00, train accuracy 0.66\n",
      "2,596,650 examples, moving-average loss 12.09, train accuracy 0.66\n",
      "2,598,250 examples, moving-average loss 12.04, train accuracy 0.66\n",
      "2,599,850 examples, moving-average loss 11.96, train accuracy 0.66\n",
      "2,601,450 examples, moving-average loss 11.98, train accuracy 0.66\n",
      "2,603,050 examples, moving-average loss 12.07, train accuracy 0.66\n",
      "2,604,650 examples, moving-average loss 11.98, train accuracy 0.66\n",
      "2,606,250 examples, moving-average loss 11.99, train accuracy 0.66\n",
      "2,607,850 examples, moving-average loss 12.09, train accuracy 0.66\n",
      "2,609,450 examples, moving-average loss 12.10, train accuracy 0.66\n",
      "2,611,050 examples, moving-average loss 12.04, train accuracy 0.66\n",
      "2,612,650 examples, moving-average loss 11.99, train accuracy 0.66\n",
      "2,614,250 examples, moving-average loss 12.04, train accuracy 0.66\n",
      "2,615,850 examples, moving-average loss 12.02, train accuracy 0.66\n",
      "2,617,450 examples, moving-average loss 12.12, train accuracy 0.66\n",
      "2,619,050 examples, moving-average loss 12.05, train accuracy 0.66\n",
      "2,620,650 examples, moving-average loss 12.02, train accuracy 0.66\n",
      "2,622,250 examples, moving-average loss 12.07, train accuracy 0.66\n",
      "2,623,850 examples, moving-average loss 12.04, train accuracy 0.66\n",
      "2,625,450 examples, moving-average loss 12.06, train accuracy 0.66\n",
      "2,627,050 examples, moving-average loss 12.09, train accuracy 0.66\n",
      "2,628,650 examples, moving-average loss 12.11, train accuracy 0.66\n",
      "2,630,250 examples, moving-average loss 12.06, train accuracy 0.66\n",
      "2,631,850 examples, moving-average loss 12.05, train accuracy 0.66\n",
      "2,633,450 examples, moving-average loss 12.09, train accuracy 0.66\n",
      "2,635,050 examples, moving-average loss 12.03, train accuracy 0.66\n",
      "2,636,650 examples, moving-average loss 12.12, train accuracy 0.66\n",
      "2,638,250 examples, moving-average loss 12.11, train accuracy 0.66\n",
      "2,639,850 examples, moving-average loss 12.05, train accuracy 0.66\n",
      "2,641,450 examples, moving-average loss 12.03, train accuracy 0.66\n",
      "2,643,050 examples, moving-average loss 12.12, train accuracy 0.66\n",
      "2,644,650 examples, moving-average loss 12.04, train accuracy 0.66\n",
      "2,646,250 examples, moving-average loss 12.07, train accuracy 0.66\n",
      "2,647,850 examples, moving-average loss 12.07, train accuracy 0.66\n",
      "2,649,450 examples, moving-average loss 12.10, train accuracy 0.66\n",
      "2,651,050 examples, moving-average loss 12.06, train accuracy 0.66\n",
      "2,652,650 examples, moving-average loss 12.06, train accuracy 0.66\n",
      "2,654,250 examples, moving-average loss 11.97, train accuracy 0.66\n",
      "2,655,850 examples, moving-average loss 12.06, train accuracy 0.66\n",
      "2,657,450 examples, moving-average loss 12.08, train accuracy 0.66\n",
      "2,659,050 examples, moving-average loss 12.06, train accuracy 0.66\n",
      "2,660,650 examples, moving-average loss 12.07, train accuracy 0.66\n",
      "2,662,250 examples, moving-average loss 12.05, train accuracy 0.66\n",
      "2,663,850 examples, moving-average loss 12.06, train accuracy 0.66\n",
      "2,665,450 examples, moving-average loss 12.06, train accuracy 0.66\n",
      "2,667,050 examples, moving-average loss 12.10, train accuracy 0.66\n",
      "2,668,650 examples, moving-average loss 12.11, train accuracy 0.66\n",
      "2,670,250 examples, moving-average loss 11.98, train accuracy 0.66\n",
      "2,671,850 examples, moving-average loss 12.15, train accuracy 0.66\n",
      "2,673,450 examples, moving-average loss 12.00, train accuracy 0.66\n",
      "2,675,050 examples, moving-average loss 12.00, train accuracy 0.66\n",
      "2,676,650 examples, moving-average loss 12.06, train accuracy 0.66\n",
      "2,678,250 examples, moving-average loss 12.11, train accuracy 0.66\n",
      "2,679,850 examples, moving-average loss 11.99, train accuracy 0.66\n",
      "2,681,450 examples, moving-average loss 12.04, train accuracy 0.66\n",
      "2,683,050 examples, moving-average loss 12.01, train accuracy 0.66\n",
      "2,684,650 examples, moving-average loss 12.05, train accuracy 0.66\n",
      "2,686,250 examples, moving-average loss 12.01, train accuracy 0.66\n",
      "2,687,850 examples, moving-average loss 11.97, train accuracy 0.66\n",
      "2,689,450 examples, moving-average loss 12.02, train accuracy 0.66\n",
      "2,691,050 examples, moving-average loss 12.10, train accuracy 0.66\n",
      "2,692,650 examples, moving-average loss 12.11, train accuracy 0.66\n",
      "2,694,250 examples, moving-average loss 12.02, train accuracy 0.66\n",
      "2,695,850 examples, moving-average loss 12.10, train accuracy 0.66\n",
      "2,697,450 examples, moving-average loss 12.00, train accuracy 0.66\n",
      "2,699,050 examples, moving-average loss 12.10, train accuracy 0.66\n",
      "2,700,650 examples, moving-average loss 12.06, train accuracy 0.66\n",
      "2,702,250 examples, moving-average loss 12.11, train accuracy 0.66\n",
      "2,703,850 examples, moving-average loss 12.07, train accuracy 0.66\n",
      "2,705,450 examples, moving-average loss 12.07, train accuracy 0.66\n",
      "2,707,050 examples, moving-average loss 12.10, train accuracy 0.66\n",
      "2,708,650 examples, moving-average loss 12.07, train accuracy 0.66\n",
      "2,710,250 examples, moving-average loss 12.05, train accuracy 0.66\n",
      "2,711,850 examples, moving-average loss 12.09, train accuracy 0.66\n",
      "2,713,450 examples, moving-average loss 12.10, train accuracy 0.66\n",
      "2,715,050 examples, moving-average loss 12.04, train accuracy 0.66\n",
      "2,716,650 examples, moving-average loss 12.05, train accuracy 0.66\n",
      "2,718,250 examples, moving-average loss 12.01, train accuracy 0.66\n",
      "2,719,850 examples, moving-average loss 11.97, train accuracy 0.66\n",
      "2,721,450 examples, moving-average loss 12.14, train accuracy 0.66\n",
      "2,723,050 examples, moving-average loss 12.02, train accuracy 0.66\n",
      "2,724,650 examples, moving-average loss 12.00, train accuracy 0.66\n",
      "2,726,250 examples, moving-average loss 12.00, train accuracy 0.66\n",
      "2,727,850 examples, moving-average loss 12.10, train accuracy 0.66\n",
      "2,729,450 examples, moving-average loss 12.00, train accuracy 0.66\n",
      "2,731,050 examples, moving-average loss 12.09, train accuracy 0.66\n",
      "2,732,650 examples, moving-average loss 12.02, train accuracy 0.66\n",
      "2,734,250 examples, moving-average loss 12.06, train accuracy 0.66\n",
      "2,735,850 examples, moving-average loss 11.96, train accuracy 0.66\n",
      "2,737,450 examples, moving-average loss 12.05, train accuracy 0.66\n",
      "2,739,050 examples, moving-average loss 12.09, train accuracy 0.66\n",
      "2,740,650 examples, moving-average loss 12.11, train accuracy 0.66\n",
      "2,742,250 examples, moving-average loss 12.11, train accuracy 0.66\n",
      "2,743,850 examples, moving-average loss 12.00, train accuracy 0.66\n",
      "2,745,450 examples, moving-average loss 12.03, train accuracy 0.66\n",
      "2,747,050 examples, moving-average loss 11.96, train accuracy 0.66\n",
      "2,748,650 examples, moving-average loss 11.97, train accuracy 0.66\n",
      "2,750,250 examples, moving-average loss 12.05, train accuracy 0.66\n",
      "2,751,850 examples, moving-average loss 12.09, train accuracy 0.66\n",
      "2,753,450 examples, moving-average loss 12.07, train accuracy 0.66\n",
      "2,755,050 examples, moving-average loss 12.11, train accuracy 0.66\n",
      "2,756,650 examples, moving-average loss 12.03, train accuracy 0.66\n",
      "2,758,250 examples, moving-average loss 12.01, train accuracy 0.66\n",
      "2,759,850 examples, moving-average loss 12.11, train accuracy 0.66\n",
      "2,761,450 examples, moving-average loss 12.09, train accuracy 0.66\n",
      "2,763,050 examples, moving-average loss 12.05, train accuracy 0.66\n",
      "2,764,650 examples, moving-average loss 11.98, train accuracy 0.66\n",
      "2,766,250 examples, moving-average loss 12.08, train accuracy 0.66\n",
      "2,767,850 examples, moving-average loss 12.01, train accuracy 0.66\n",
      "2,769,450 examples, moving-average loss 12.07, train accuracy 0.66\n",
      "2,771,050 examples, moving-average loss 12.05, train accuracy 0.66\n",
      "2,772,650 examples, moving-average loss 12.02, train accuracy 0.66\n",
      "2,774,250 examples, moving-average loss 12.06, train accuracy 0.66\n",
      "2,775,850 examples, moving-average loss 12.04, train accuracy 0.66\n",
      "2,777,450 examples, moving-average loss 12.05, train accuracy 0.66\n",
      "2,779,050 examples, moving-average loss 12.02, train accuracy 0.66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,780,650 examples, moving-average loss 12.03, train accuracy 0.66\n",
      "2,782,250 examples, moving-average loss 12.08, train accuracy 0.66\n",
      "2,783,850 examples, moving-average loss 12.12, train accuracy 0.66\n",
      "2,785,450 examples, moving-average loss 12.10, train accuracy 0.66\n",
      "2,787,050 examples, moving-average loss 11.99, train accuracy 0.66\n",
      "2,788,650 examples, moving-average loss 12.04, train accuracy 0.66\n",
      "2,790,250 examples, moving-average loss 11.99, train accuracy 0.66\n",
      "2,791,850 examples, moving-average loss 12.05, train accuracy 0.66\n",
      "2,793,450 examples, moving-average loss 12.04, train accuracy 0.66\n",
      "2,795,050 examples, moving-average loss 12.09, train accuracy 0.66\n",
      "2,796,650 examples, moving-average loss 12.10, train accuracy 0.66\n",
      "2,798,250 examples, moving-average loss 12.10, train accuracy 0.66\n",
      "2,799,850 examples, moving-average loss 11.99, train accuracy 0.66\n",
      "2,801,450 examples, moving-average loss 12.02, train accuracy 0.66\n",
      "2,803,050 examples, moving-average loss 12.00, train accuracy 0.66\n",
      "2,804,650 examples, moving-average loss 12.07, train accuracy 0.66\n",
      "2,806,250 examples, moving-average loss 12.14, train accuracy 0.66\n",
      "2,807,850 examples, moving-average loss 11.98, train accuracy 0.66\n",
      "2,809,450 examples, moving-average loss 12.01, train accuracy 0.66\n",
      "2,811,050 examples, moving-average loss 12.04, train accuracy 0.66\n",
      "2,812,650 examples, moving-average loss 12.05, train accuracy 0.66\n",
      "2,814,250 examples, moving-average loss 12.07, train accuracy 0.66\n",
      "2,815,850 examples, moving-average loss 12.03, train accuracy 0.66\n",
      "2,817,450 examples, moving-average loss 12.09, train accuracy 0.66\n",
      "2,819,050 examples, moving-average loss 12.02, train accuracy 0.66\n",
      "2,820,650 examples, moving-average loss 12.10, train accuracy 0.66\n",
      "2,822,250 examples, moving-average loss 11.98, train accuracy 0.66\n",
      "2,823,850 examples, moving-average loss 11.98, train accuracy 0.66\n",
      "2,825,450 examples, moving-average loss 12.05, train accuracy 0.66\n",
      "2,827,050 examples, moving-average loss 12.10, train accuracy 0.66\n",
      "2,828,650 examples, moving-average loss 12.05, train accuracy 0.66\n",
      "2,830,250 examples, moving-average loss 12.02, train accuracy 0.66\n",
      "2,831,850 examples, moving-average loss 12.02, train accuracy 0.66\n",
      "2,833,450 examples, moving-average loss 12.03, train accuracy 0.66\n",
      "2,835,050 examples, moving-average loss 12.06, train accuracy 0.66\n",
      "2,836,650 examples, moving-average loss 12.00, train accuracy 0.66\n",
      "2,838,250 examples, moving-average loss 12.01, train accuracy 0.66\n",
      "2,839,850 examples, moving-average loss 12.03, train accuracy 0.66\n",
      "2,841,450 examples, moving-average loss 12.05, train accuracy 0.66\n",
      "2,843,050 examples, moving-average loss 12.03, train accuracy 0.66\n",
      "2,844,650 examples, moving-average loss 12.07, train accuracy 0.66\n",
      "2,846,250 examples, moving-average loss 12.13, train accuracy 0.66\n",
      "2,847,850 examples, moving-average loss 12.08, train accuracy 0.66\n",
      "2,849,450 examples, moving-average loss 12.03, train accuracy 0.66\n",
      "2,851,050 examples, moving-average loss 11.99, train accuracy 0.66\n",
      "2,852,650 examples, moving-average loss 12.03, train accuracy 0.66\n",
      "2,854,250 examples, moving-average loss 12.07, train accuracy 0.66\n",
      "2,855,850 examples, moving-average loss 12.09, train accuracy 0.66\n",
      "2,857,450 examples, moving-average loss 12.03, train accuracy 0.66\n",
      "2,859,050 examples, moving-average loss 12.07, train accuracy 0.66\n",
      "2,860,650 examples, moving-average loss 12.11, train accuracy 0.66\n",
      "2,862,250 examples, moving-average loss 12.04, train accuracy 0.66\n",
      "2,863,850 examples, moving-average loss 12.06, train accuracy 0.66\n",
      "2,865,450 examples, moving-average loss 12.06, train accuracy 0.66\n",
      "2,867,050 examples, moving-average loss 11.90, train accuracy 0.66\n",
      "2,868,650 examples, moving-average loss 12.05, train accuracy 0.66\n",
      "2,870,250 examples, moving-average loss 12.06, train accuracy 0.66\n",
      "2,871,850 examples, moving-average loss 12.06, train accuracy 0.66\n",
      "2,873,450 examples, moving-average loss 12.09, train accuracy 0.66\n",
      "2,875,050 examples, moving-average loss 11.98, train accuracy 0.66\n",
      "2,876,650 examples, moving-average loss 12.03, train accuracy 0.66\n",
      "2,878,250 examples, moving-average loss 12.04, train accuracy 0.66\n",
      "2,879,850 examples, moving-average loss 12.05, train accuracy 0.66\n",
      "2,881,450 examples, moving-average loss 12.00, train accuracy 0.66\n",
      "2,883,050 examples, moving-average loss 12.05, train accuracy 0.66\n",
      "2,884,650 examples, moving-average loss 12.03, train accuracy 0.66\n",
      "2,886,250 examples, moving-average loss 12.05, train accuracy 0.66\n",
      "2,887,850 examples, moving-average loss 12.00, train accuracy 0.66\n",
      "2,889,450 examples, moving-average loss 11.98, train accuracy 0.66\n",
      "2,891,050 examples, moving-average loss 12.02, train accuracy 0.66\n",
      "2,892,650 examples, moving-average loss 12.02, train accuracy 0.66\n",
      "2,894,250 examples, moving-average loss 11.98, train accuracy 0.66\n",
      "2,895,850 examples, moving-average loss 12.21, train accuracy 0.66\n",
      "2,897,450 examples, moving-average loss 12.08, train accuracy 0.66\n",
      "2,899,050 examples, moving-average loss 12.09, train accuracy 0.66\n",
      "2,900,650 examples, moving-average loss 12.14, train accuracy 0.66\n",
      "2,902,250 examples, moving-average loss 11.98, train accuracy 0.66\n",
      "2,903,850 examples, moving-average loss 12.07, train accuracy 0.66\n",
      "2,905,450 examples, moving-average loss 12.02, train accuracy 0.66\n",
      "2,907,050 examples, moving-average loss 12.05, train accuracy 0.66\n",
      "2,908,650 examples, moving-average loss 12.07, train accuracy 0.66\n",
      "2,910,250 examples, moving-average loss 11.99, train accuracy 0.66\n",
      "2,911,850 examples, moving-average loss 12.00, train accuracy 0.66\n",
      "2,913,450 examples, moving-average loss 12.06, train accuracy 0.66\n",
      "2,915,050 examples, moving-average loss 12.12, train accuracy 0.66\n",
      "2,916,650 examples, moving-average loss 12.06, train accuracy 0.66\n",
      "2,918,250 examples, moving-average loss 12.02, train accuracy 0.66\n",
      "2,919,850 examples, moving-average loss 12.01, train accuracy 0.66\n",
      "2,921,450 examples, moving-average loss 12.06, train accuracy 0.66\n",
      "2,923,050 examples, moving-average loss 12.09, train accuracy 0.66\n",
      "2,924,650 examples, moving-average loss 12.07, train accuracy 0.66\n",
      "2,926,250 examples, moving-average loss 12.05, train accuracy 0.66\n",
      "2,927,850 examples, moving-average loss 12.05, train accuracy 0.66\n",
      "2,929,450 examples, moving-average loss 12.07, train accuracy 0.66\n",
      "2,931,050 examples, moving-average loss 12.07, train accuracy 0.66\n",
      "2,932,650 examples, moving-average loss 12.12, train accuracy 0.66\n",
      "2,934,250 examples, moving-average loss 12.14, train accuracy 0.66\n",
      "2,935,850 examples, moving-average loss 12.08, train accuracy 0.66\n",
      "2,937,450 examples, moving-average loss 12.14, train accuracy 0.66\n",
      "2,939,050 examples, moving-average loss 12.13, train accuracy 0.66\n",
      "2,940,650 examples, moving-average loss 12.01, train accuracy 0.66\n",
      "2,942,250 examples, moving-average loss 12.05, train accuracy 0.66\n",
      "2,943,850 examples, moving-average loss 12.14, train accuracy 0.66\n",
      "2,945,450 examples, moving-average loss 12.08, train accuracy 0.66\n",
      "2,947,050 examples, moving-average loss 12.09, train accuracy 0.66\n",
      "2,948,650 examples, moving-average loss 12.05, train accuracy 0.66\n",
      "2,950,250 examples, moving-average loss 11.95, train accuracy 0.66\n",
      "2,951,850 examples, moving-average loss 12.02, train accuracy 0.66\n",
      "2,953,450 examples, moving-average loss 12.04, train accuracy 0.66\n",
      "2,955,050 examples, moving-average loss 12.08, train accuracy 0.66\n",
      "2,956,650 examples, moving-average loss 12.11, train accuracy 0.66\n",
      "2,958,250 examples, moving-average loss 12.03, train accuracy 0.66\n",
      "2,959,850 examples, moving-average loss 12.08, train accuracy 0.66\n",
      "2,961,450 examples, moving-average loss 11.97, train accuracy 0.66\n",
      "2,963,050 examples, moving-average loss 12.05, train accuracy 0.66\n",
      "2,964,650 examples, moving-average loss 12.05, train accuracy 0.66\n",
      "2,966,250 examples, moving-average loss 12.06, train accuracy 0.66\n",
      "2,967,850 examples, moving-average loss 12.10, train accuracy 0.66\n",
      "2,969,450 examples, moving-average loss 12.09, train accuracy 0.66\n",
      "2,971,050 examples, moving-average loss 12.03, train accuracy 0.66\n",
      "2,972,650 examples, moving-average loss 12.08, train accuracy 0.66\n",
      "2,974,250 examples, moving-average loss 12.09, train accuracy 0.66\n",
      "2,975,850 examples, moving-average loss 12.16, train accuracy 0.66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,977,450 examples, moving-average loss 12.10, train accuracy 0.66\n",
      "2,979,050 examples, moving-average loss 12.07, train accuracy 0.66\n",
      "2,980,650 examples, moving-average loss 12.08, train accuracy 0.66\n",
      "2,982,250 examples, moving-average loss 12.01, train accuracy 0.66\n",
      "2,983,850 examples, moving-average loss 12.03, train accuracy 0.66\n",
      "2,985,450 examples, moving-average loss 12.11, train accuracy 0.66\n",
      "2,987,050 examples, moving-average loss 12.14, train accuracy 0.66\n",
      "2,988,650 examples, moving-average loss 12.12, train accuracy 0.66\n",
      "2,990,250 examples, moving-average loss 12.02, train accuracy 0.66\n",
      "2,991,850 examples, moving-average loss 12.01, train accuracy 0.66\n",
      "2,993,450 examples, moving-average loss 11.97, train accuracy 0.66\n",
      "2,995,050 examples, moving-average loss 12.07, train accuracy 0.66\n",
      "2,996,650 examples, moving-average loss 12.13, train accuracy 0.66\n",
      "2,998,250 examples, moving-average loss 12.05, train accuracy 0.66\n",
      "2,999,850 examples, moving-average loss 12.06, train accuracy 0.66\n",
      "3,001,450 examples, moving-average loss 12.04, train accuracy 0.66\n",
      "3,003,050 examples, moving-average loss 11.98, train accuracy 0.66\n",
      "3,004,650 examples, moving-average loss 12.04, train accuracy 0.66\n",
      "3,006,250 examples, moving-average loss 12.02, train accuracy 0.66\n",
      "3,007,850 examples, moving-average loss 12.10, train accuracy 0.66\n",
      "3,009,450 examples, moving-average loss 12.01, train accuracy 0.66\n",
      "3,011,050 examples, moving-average loss 12.07, train accuracy 0.66\n",
      "3,012,650 examples, moving-average loss 12.07, train accuracy 0.66\n",
      "3,014,250 examples, moving-average loss 12.10, train accuracy 0.66\n",
      "3,015,850 examples, moving-average loss 12.12, train accuracy 0.66\n",
      "3,017,450 examples, moving-average loss 12.00, train accuracy 0.66\n",
      "3,019,050 examples, moving-average loss 12.03, train accuracy 0.66\n",
      "3,020,650 examples, moving-average loss 12.03, train accuracy 0.66\n",
      "3,022,250 examples, moving-average loss 12.09, train accuracy 0.66\n",
      "3,023,850 examples, moving-average loss 11.97, train accuracy 0.66\n",
      "3,025,450 examples, moving-average loss 11.97, train accuracy 0.66\n",
      "3,027,050 examples, moving-average loss 11.98, train accuracy 0.66\n",
      "3,028,650 examples, moving-average loss 11.99, train accuracy 0.66\n",
      "3,030,250 examples, moving-average loss 12.03, train accuracy 0.66\n",
      "3,031,850 examples, moving-average loss 12.01, train accuracy 0.66\n",
      "3,033,450 examples, moving-average loss 12.02, train accuracy 0.66\n",
      "3,035,050 examples, moving-average loss 12.04, train accuracy 0.66\n",
      "3,036,650 examples, moving-average loss 12.13, train accuracy 0.66\n",
      "3,038,250 examples, moving-average loss 12.07, train accuracy 0.66\n",
      "3,039,850 examples, moving-average loss 12.07, train accuracy 0.66\n",
      "3,041,450 examples, moving-average loss 12.06, train accuracy 0.66\n",
      "3,043,050 examples, moving-average loss 11.95, train accuracy 0.66\n",
      "3,044,650 examples, moving-average loss 12.11, train accuracy 0.66\n",
      "3,046,250 examples, moving-average loss 11.99, train accuracy 0.66\n",
      "3,047,850 examples, moving-average loss 12.03, train accuracy 0.66\n",
      "3,049,450 examples, moving-average loss 12.06, train accuracy 0.66\n",
      "3,051,050 examples, moving-average loss 12.12, train accuracy 0.66\n",
      "3,052,650 examples, moving-average loss 12.13, train accuracy 0.66\n",
      "3,054,250 examples, moving-average loss 12.08, train accuracy 0.66\n",
      "3,055,850 examples, moving-average loss 12.08, train accuracy 0.66\n",
      "3,057,450 examples, moving-average loss 12.10, train accuracy 0.66\n",
      "3,059,050 examples, moving-average loss 12.00, train accuracy 0.66\n",
      "3,060,650 examples, moving-average loss 12.13, train accuracy 0.66\n",
      "3,062,250 examples, moving-average loss 11.93, train accuracy 0.66\n",
      "3,063,850 examples, moving-average loss 11.98, train accuracy 0.66\n",
      "3,065,450 examples, moving-average loss 12.09, train accuracy 0.66\n",
      "3,067,050 examples, moving-average loss 11.96, train accuracy 0.66\n",
      "3,068,650 examples, moving-average loss 11.99, train accuracy 0.66\n",
      "3,070,250 examples, moving-average loss 11.94, train accuracy 0.66\n",
      "3,071,850 examples, moving-average loss 12.02, train accuracy 0.66\n",
      "3,073,450 examples, moving-average loss 12.02, train accuracy 0.66\n",
      "3,075,050 examples, moving-average loss 12.04, train accuracy 0.66\n",
      "3,076,650 examples, moving-average loss 12.11, train accuracy 0.66\n",
      "3,078,250 examples, moving-average loss 12.14, train accuracy 0.66\n",
      "3,079,850 examples, moving-average loss 12.06, train accuracy 0.66\n",
      "3,081,450 examples, moving-average loss 12.12, train accuracy 0.66\n",
      "3,083,050 examples, moving-average loss 12.03, train accuracy 0.66\n",
      "3,084,650 examples, moving-average loss 11.95, train accuracy 0.66\n",
      "3,086,250 examples, moving-average loss 12.09, train accuracy 0.66\n",
      "3,087,850 examples, moving-average loss 12.01, train accuracy 0.66\n",
      "3,089,450 examples, moving-average loss 12.04, train accuracy 0.66\n",
      "3,091,050 examples, moving-average loss 12.09, train accuracy 0.66\n",
      "3,092,650 examples, moving-average loss 12.01, train accuracy 0.66\n",
      "3,094,250 examples, moving-average loss 12.02, train accuracy 0.66\n",
      "3,095,850 examples, moving-average loss 12.09, train accuracy 0.66\n",
      "3,097,450 examples, moving-average loss 12.06, train accuracy 0.66\n",
      "3,099,050 examples, moving-average loss 12.09, train accuracy 0.66\n",
      "3,100,650 examples, moving-average loss 12.12, train accuracy 0.66\n",
      "3,102,250 examples, moving-average loss 12.14, train accuracy 0.66\n",
      "3,103,850 examples, moving-average loss 12.08, train accuracy 0.66\n",
      "3,105,450 examples, moving-average loss 12.06, train accuracy 0.66\n",
      "3,107,050 examples, moving-average loss 12.04, train accuracy 0.66\n",
      "3,108,650 examples, moving-average loss 12.02, train accuracy 0.66\n",
      "3,110,250 examples, moving-average loss 12.07, train accuracy 0.66\n",
      "3,111,850 examples, moving-average loss 12.06, train accuracy 0.66\n",
      "3,113,450 examples, moving-average loss 11.98, train accuracy 0.66\n",
      "3,115,050 examples, moving-average loss 12.05, train accuracy 0.66\n",
      "3,116,650 examples, moving-average loss 12.06, train accuracy 0.66\n",
      "3,118,250 examples, moving-average loss 12.01, train accuracy 0.66\n",
      "3,119,850 examples, moving-average loss 11.98, train accuracy 0.66\n",
      "3,121,450 examples, moving-average loss 12.06, train accuracy 0.66\n",
      "3,123,050 examples, moving-average loss 12.07, train accuracy 0.66\n",
      "3,124,650 examples, moving-average loss 12.04, train accuracy 0.66\n",
      "3,126,250 examples, moving-average loss 12.05, train accuracy 0.66\n",
      "3,127,850 examples, moving-average loss 12.12, train accuracy 0.66\n",
      "3,129,450 examples, moving-average loss 12.02, train accuracy 0.66\n",
      "3,131,050 examples, moving-average loss 11.97, train accuracy 0.66\n",
      "3,132,650 examples, moving-average loss 12.08, train accuracy 0.66\n",
      "3,134,250 examples, moving-average loss 12.01, train accuracy 0.66\n",
      "3,135,850 examples, moving-average loss 12.07, train accuracy 0.66\n",
      "3,137,450 examples, moving-average loss 12.10, train accuracy 0.66\n",
      "3,139,050 examples, moving-average loss 12.07, train accuracy 0.66\n",
      "3,140,650 examples, moving-average loss 12.05, train accuracy 0.66\n",
      "3,142,250 examples, moving-average loss 12.03, train accuracy 0.66\n",
      "3,143,850 examples, moving-average loss 12.04, train accuracy 0.66\n",
      "3,145,450 examples, moving-average loss 12.07, train accuracy 0.66\n",
      "3,147,050 examples, moving-average loss 12.09, train accuracy 0.66\n",
      "3,148,650 examples, moving-average loss 12.07, train accuracy 0.66\n",
      "3,150,250 examples, moving-average loss 12.02, train accuracy 0.66\n",
      "3,151,850 examples, moving-average loss 12.07, train accuracy 0.66\n",
      "3,153,450 examples, moving-average loss 12.07, train accuracy 0.66\n",
      "3,155,050 examples, moving-average loss 12.09, train accuracy 0.66\n",
      "3,156,650 examples, moving-average loss 12.08, train accuracy 0.66\n",
      "3,158,250 examples, moving-average loss 12.04, train accuracy 0.66\n",
      "3,159,850 examples, moving-average loss 12.01, train accuracy 0.66\n",
      "3,161,450 examples, moving-average loss 12.02, train accuracy 0.66\n",
      "3,163,050 examples, moving-average loss 12.03, train accuracy 0.66\n",
      "3,164,650 examples, moving-average loss 11.93, train accuracy 0.66\n",
      "3,166,250 examples, moving-average loss 12.11, train accuracy 0.66\n",
      "3,167,850 examples, moving-average loss 12.11, train accuracy 0.66\n",
      "3,169,450 examples, moving-average loss 12.08, train accuracy 0.66\n",
      "3,171,050 examples, moving-average loss 12.05, train accuracy 0.66\n",
      "3,172,650 examples, moving-average loss 12.02, train accuracy 0.67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3,174,250 examples, moving-average loss 12.01, train accuracy 0.67\n",
      "3,175,850 examples, moving-average loss 11.99, train accuracy 0.67\n",
      "3,177,450 examples, moving-average loss 12.03, train accuracy 0.67\n",
      "3,179,050 examples, moving-average loss 12.09, train accuracy 0.67\n",
      "3,180,650 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "3,182,250 examples, moving-average loss 12.11, train accuracy 0.67\n",
      "3,183,850 examples, moving-average loss 12.08, train accuracy 0.67\n",
      "3,185,450 examples, moving-average loss 12.05, train accuracy 0.67\n",
      "3,187,050 examples, moving-average loss 12.12, train accuracy 0.67\n",
      "3,188,650 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "3,190,250 examples, moving-average loss 12.02, train accuracy 0.67\n",
      "3,191,850 examples, moving-average loss 12.08, train accuracy 0.67\n",
      "3,193,450 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "3,195,050 examples, moving-average loss 12.05, train accuracy 0.67\n",
      "3,196,650 examples, moving-average loss 12.05, train accuracy 0.67\n",
      "3,198,250 examples, moving-average loss 12.05, train accuracy 0.67\n",
      "3,199,850 examples, moving-average loss 11.96, train accuracy 0.67\n",
      "3,201,450 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "3,203,050 examples, moving-average loss 12.05, train accuracy 0.67\n",
      "3,204,650 examples, moving-average loss 12.05, train accuracy 0.67\n",
      "3,206,250 examples, moving-average loss 12.02, train accuracy 0.67\n",
      "3,207,850 examples, moving-average loss 12.05, train accuracy 0.67\n",
      "3,209,450 examples, moving-average loss 12.05, train accuracy 0.67\n",
      "3,211,050 examples, moving-average loss 12.02, train accuracy 0.67\n",
      "3,212,650 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "3,214,250 examples, moving-average loss 11.98, train accuracy 0.67\n",
      "3,215,850 examples, moving-average loss 12.07, train accuracy 0.67\n",
      "3,217,450 examples, moving-average loss 12.02, train accuracy 0.67\n",
      "3,219,050 examples, moving-average loss 12.08, train accuracy 0.67\n",
      "3,220,650 examples, moving-average loss 12.08, train accuracy 0.67\n",
      "3,222,250 examples, moving-average loss 12.05, train accuracy 0.67\n",
      "3,223,850 examples, moving-average loss 12.09, train accuracy 0.67\n",
      "3,225,450 examples, moving-average loss 12.01, train accuracy 0.67\n",
      "3,227,050 examples, moving-average loss 12.13, train accuracy 0.67\n",
      "3,228,650 examples, moving-average loss 12.05, train accuracy 0.67\n",
      "3,230,250 examples, moving-average loss 12.09, train accuracy 0.67\n",
      "3,231,850 examples, moving-average loss 11.99, train accuracy 0.67\n",
      "3,233,450 examples, moving-average loss 12.08, train accuracy 0.67\n",
      "3,235,050 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "3,236,650 examples, moving-average loss 12.01, train accuracy 0.67\n",
      "3,238,250 examples, moving-average loss 12.08, train accuracy 0.67\n",
      "3,239,850 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "3,241,450 examples, moving-average loss 12.10, train accuracy 0.67\n",
      "3,243,050 examples, moving-average loss 12.10, train accuracy 0.67\n",
      "3,244,650 examples, moving-average loss 12.07, train accuracy 0.67\n",
      "3,246,250 examples, moving-average loss 11.98, train accuracy 0.67\n",
      "3,247,850 examples, moving-average loss 12.09, train accuracy 0.67\n",
      "3,249,450 examples, moving-average loss 12.15, train accuracy 0.67\n",
      "3,251,050 examples, moving-average loss 12.02, train accuracy 0.67\n",
      "3,252,650 examples, moving-average loss 11.99, train accuracy 0.67\n",
      "3,254,250 examples, moving-average loss 12.01, train accuracy 0.67\n",
      "3,255,850 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "3,257,450 examples, moving-average loss 12.10, train accuracy 0.67\n",
      "3,259,050 examples, moving-average loss 12.05, train accuracy 0.67\n",
      "3,260,650 examples, moving-average loss 12.07, train accuracy 0.67\n",
      "3,262,250 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "3,263,850 examples, moving-average loss 12.03, train accuracy 0.67\n",
      "3,265,450 examples, moving-average loss 12.02, train accuracy 0.67\n",
      "3,267,050 examples, moving-average loss 11.99, train accuracy 0.67\n",
      "3,268,650 examples, moving-average loss 12.02, train accuracy 0.67\n",
      "3,270,250 examples, moving-average loss 12.00, train accuracy 0.67\n",
      "3,271,850 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "3,273,450 examples, moving-average loss 12.03, train accuracy 0.67\n",
      "3,275,050 examples, moving-average loss 12.12, train accuracy 0.67\n",
      "3,276,650 examples, moving-average loss 12.08, train accuracy 0.67\n",
      "3,278,250 examples, moving-average loss 12.14, train accuracy 0.67\n",
      "3,279,850 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "3,281,450 examples, moving-average loss 12.02, train accuracy 0.67\n",
      "3,283,050 examples, moving-average loss 12.05, train accuracy 0.67\n",
      "3,284,650 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "3,286,250 examples, moving-average loss 12.07, train accuracy 0.67\n",
      "3,287,850 examples, moving-average loss 12.07, train accuracy 0.67\n",
      "3,289,450 examples, moving-average loss 12.01, train accuracy 0.67\n",
      "3,291,050 examples, moving-average loss 12.00, train accuracy 0.67\n",
      "3,292,650 examples, moving-average loss 11.99, train accuracy 0.67\n",
      "3,294,250 examples, moving-average loss 12.07, train accuracy 0.67\n",
      "3,295,850 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "3,297,450 examples, moving-average loss 11.96, train accuracy 0.67\n",
      "3,299,050 examples, moving-average loss 12.02, train accuracy 0.67\n",
      "3,300,650 examples, moving-average loss 12.03, train accuracy 0.67\n",
      "3,302,250 examples, moving-average loss 12.03, train accuracy 0.67\n",
      "3,303,850 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "3,305,450 examples, moving-average loss 11.97, train accuracy 0.67\n",
      "3,307,050 examples, moving-average loss 12.02, train accuracy 0.67\n",
      "3,308,650 examples, moving-average loss 12.03, train accuracy 0.67\n",
      "3,310,250 examples, moving-average loss 12.02, train accuracy 0.67\n",
      "3,311,850 examples, moving-average loss 12.09, train accuracy 0.67\n",
      "3,313,450 examples, moving-average loss 12.05, train accuracy 0.67\n",
      "3,315,050 examples, moving-average loss 12.00, train accuracy 0.67\n",
      "3,316,650 examples, moving-average loss 12.03, train accuracy 0.67\n",
      "3,318,250 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "3,319,850 examples, moving-average loss 12.12, train accuracy 0.67\n",
      "3,321,450 examples, moving-average loss 12.07, train accuracy 0.67\n",
      "3,323,050 examples, moving-average loss 12.11, train accuracy 0.67\n",
      "3,324,650 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "3,326,250 examples, moving-average loss 11.99, train accuracy 0.67\n",
      "3,327,850 examples, moving-average loss 12.01, train accuracy 0.67\n",
      "3,329,450 examples, moving-average loss 12.01, train accuracy 0.67\n",
      "3,331,050 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "3,332,650 examples, moving-average loss 11.99, train accuracy 0.67\n",
      "3,334,250 examples, moving-average loss 12.07, train accuracy 0.67\n",
      "3,335,850 examples, moving-average loss 11.97, train accuracy 0.67\n",
      "3,337,450 examples, moving-average loss 12.03, train accuracy 0.67\n",
      "3,339,050 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "3,340,650 examples, moving-average loss 12.00, train accuracy 0.67\n",
      "3,342,250 examples, moving-average loss 12.11, train accuracy 0.67\n",
      "3,343,850 examples, moving-average loss 12.12, train accuracy 0.67\n",
      "3,345,450 examples, moving-average loss 11.95, train accuracy 0.67\n",
      "3,347,050 examples, moving-average loss 12.05, train accuracy 0.67\n",
      "3,348,650 examples, moving-average loss 12.03, train accuracy 0.67\n",
      "3,350,250 examples, moving-average loss 12.05, train accuracy 0.67\n",
      "3,351,850 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "3,353,450 examples, moving-average loss 12.00, train accuracy 0.67\n",
      "3,355,050 examples, moving-average loss 12.02, train accuracy 0.67\n",
      "3,356,650 examples, moving-average loss 11.99, train accuracy 0.67\n",
      "3,358,250 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "3,359,850 examples, moving-average loss 12.03, train accuracy 0.67\n",
      "3,361,450 examples, moving-average loss 12.12, train accuracy 0.67\n",
      "3,363,050 examples, moving-average loss 12.08, train accuracy 0.67\n",
      "3,364,650 examples, moving-average loss 12.02, train accuracy 0.67\n",
      "Completed 3 epoch in 0:38:17\n",
      "Train accurary:0.66634\n",
      "Validate accuracy:0.67296\n",
      "3,366,200 examples, moving-average loss 11.67, train accuracy 0.57\n",
      "3,367,800 examples, moving-average loss 11.93, train accuracy 0.65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3,369,400 examples, moving-average loss 12.06, train accuracy 0.66\n",
      "3,371,000 examples, moving-average loss 12.09, train accuracy 0.66\n",
      "3,372,600 examples, moving-average loss 12.02, train accuracy 0.66\n",
      "3,374,200 examples, moving-average loss 12.07, train accuracy 0.66\n",
      "3,375,800 examples, moving-average loss 12.01, train accuracy 0.66\n",
      "3,377,400 examples, moving-average loss 11.97, train accuracy 0.67\n",
      "3,379,000 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "3,380,600 examples, moving-average loss 11.99, train accuracy 0.67\n",
      "3,382,200 examples, moving-average loss 12.08, train accuracy 0.67\n",
      "3,383,800 examples, moving-average loss 12.03, train accuracy 0.67\n",
      "3,385,400 examples, moving-average loss 12.09, train accuracy 0.67\n",
      "3,387,000 examples, moving-average loss 12.09, train accuracy 0.67\n",
      "3,388,600 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "3,390,200 examples, moving-average loss 11.99, train accuracy 0.67\n",
      "3,391,800 examples, moving-average loss 11.97, train accuracy 0.67\n",
      "3,393,400 examples, moving-average loss 12.05, train accuracy 0.67\n",
      "3,395,000 examples, moving-average loss 12.02, train accuracy 0.67\n",
      "3,396,600 examples, moving-average loss 12.07, train accuracy 0.67\n",
      "3,398,200 examples, moving-average loss 12.07, train accuracy 0.67\n",
      "3,399,800 examples, moving-average loss 12.07, train accuracy 0.67\n",
      "3,401,400 examples, moving-average loss 11.99, train accuracy 0.67\n",
      "3,403,000 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "3,404,600 examples, moving-average loss 12.08, train accuracy 0.67\n",
      "3,406,200 examples, moving-average loss 12.00, train accuracy 0.67\n",
      "3,407,800 examples, moving-average loss 12.10, train accuracy 0.67\n",
      "3,409,400 examples, moving-average loss 12.03, train accuracy 0.67\n",
      "3,411,000 examples, moving-average loss 12.01, train accuracy 0.67\n",
      "3,412,600 examples, moving-average loss 12.07, train accuracy 0.67\n",
      "3,414,200 examples, moving-average loss 12.09, train accuracy 0.67\n",
      "3,415,800 examples, moving-average loss 12.01, train accuracy 0.67\n",
      "3,417,400 examples, moving-average loss 11.99, train accuracy 0.67\n",
      "3,419,000 examples, moving-average loss 11.97, train accuracy 0.67\n",
      "3,420,600 examples, moving-average loss 12.11, train accuracy 0.67\n",
      "3,422,200 examples, moving-average loss 12.02, train accuracy 0.67\n",
      "3,423,800 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "3,425,400 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "3,427,000 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "3,428,600 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "3,430,200 examples, moving-average loss 11.98, train accuracy 0.67\n",
      "3,431,800 examples, moving-average loss 12.01, train accuracy 0.67\n",
      "3,433,400 examples, moving-average loss 12.02, train accuracy 0.67\n",
      "3,435,000 examples, moving-average loss 11.95, train accuracy 0.67\n",
      "3,436,600 examples, moving-average loss 11.98, train accuracy 0.67\n",
      "3,438,200 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "3,439,800 examples, moving-average loss 11.96, train accuracy 0.67\n",
      "3,441,400 examples, moving-average loss 11.93, train accuracy 0.67\n",
      "3,443,000 examples, moving-average loss 12.01, train accuracy 0.67\n",
      "3,444,600 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "3,446,200 examples, moving-average loss 11.93, train accuracy 0.67\n",
      "3,447,800 examples, moving-average loss 11.95, train accuracy 0.67\n",
      "3,449,400 examples, moving-average loss 12.12, train accuracy 0.67\n",
      "3,451,000 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "3,452,600 examples, moving-average loss 12.03, train accuracy 0.67\n",
      "3,454,200 examples, moving-average loss 12.03, train accuracy 0.67\n",
      "3,455,800 examples, moving-average loss 12.01, train accuracy 0.67\n",
      "3,457,400 examples, moving-average loss 12.01, train accuracy 0.67\n",
      "3,459,000 examples, moving-average loss 12.08, train accuracy 0.67\n",
      "3,460,600 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "3,462,200 examples, moving-average loss 12.01, train accuracy 0.67\n",
      "3,463,800 examples, moving-average loss 12.08, train accuracy 0.67\n",
      "3,465,400 examples, moving-average loss 12.03, train accuracy 0.67\n",
      "3,467,000 examples, moving-average loss 12.00, train accuracy 0.67\n",
      "3,468,600 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "3,470,200 examples, moving-average loss 12.11, train accuracy 0.67\n",
      "3,471,800 examples, moving-average loss 12.08, train accuracy 0.67\n",
      "3,473,400 examples, moving-average loss 12.03, train accuracy 0.67\n",
      "3,475,000 examples, moving-average loss 12.07, train accuracy 0.67\n",
      "3,476,600 examples, moving-average loss 12.00, train accuracy 0.67\n",
      "3,478,200 examples, moving-average loss 12.08, train accuracy 0.67\n",
      "3,479,800 examples, moving-average loss 12.11, train accuracy 0.67\n",
      "3,481,400 examples, moving-average loss 12.02, train accuracy 0.67\n",
      "3,483,000 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "3,484,600 examples, moving-average loss 12.07, train accuracy 0.67\n",
      "3,486,200 examples, moving-average loss 12.01, train accuracy 0.67\n",
      "3,487,800 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "3,489,400 examples, moving-average loss 11.99, train accuracy 0.67\n",
      "3,491,000 examples, moving-average loss 12.08, train accuracy 0.67\n",
      "3,492,600 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "3,494,200 examples, moving-average loss 12.03, train accuracy 0.67\n",
      "3,495,800 examples, moving-average loss 11.95, train accuracy 0.67\n",
      "3,497,400 examples, moving-average loss 12.07, train accuracy 0.67\n",
      "3,499,000 examples, moving-average loss 12.03, train accuracy 0.67\n",
      "3,500,600 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "3,502,200 examples, moving-average loss 12.07, train accuracy 0.67\n",
      "3,503,800 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "3,505,400 examples, moving-average loss 12.05, train accuracy 0.67\n",
      "3,507,000 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "3,508,600 examples, moving-average loss 12.08, train accuracy 0.67\n",
      "3,510,200 examples, moving-average loss 12.10, train accuracy 0.67\n",
      "3,511,800 examples, moving-average loss 11.98, train accuracy 0.67\n",
      "3,513,400 examples, moving-average loss 12.14, train accuracy 0.67\n",
      "3,515,000 examples, moving-average loss 12.00, train accuracy 0.67\n",
      "3,516,600 examples, moving-average loss 12.03, train accuracy 0.67\n",
      "3,518,200 examples, moving-average loss 12.05, train accuracy 0.67\n",
      "3,519,800 examples, moving-average loss 12.05, train accuracy 0.67\n",
      "3,521,400 examples, moving-average loss 12.00, train accuracy 0.67\n",
      "3,523,000 examples, moving-average loss 11.99, train accuracy 0.67\n",
      "3,524,600 examples, moving-average loss 11.97, train accuracy 0.67\n",
      "3,526,200 examples, moving-average loss 12.03, train accuracy 0.67\n",
      "3,527,800 examples, moving-average loss 12.00, train accuracy 0.67\n",
      "3,529,400 examples, moving-average loss 12.00, train accuracy 0.67\n",
      "3,531,000 examples, moving-average loss 11.96, train accuracy 0.67\n",
      "3,532,600 examples, moving-average loss 12.07, train accuracy 0.67\n",
      "3,534,200 examples, moving-average loss 12.07, train accuracy 0.67\n",
      "3,535,800 examples, moving-average loss 12.00, train accuracy 0.67\n",
      "3,537,400 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "3,539,000 examples, moving-average loss 11.98, train accuracy 0.67\n",
      "3,540,600 examples, moving-average loss 12.10, train accuracy 0.67\n",
      "3,542,200 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "3,543,800 examples, moving-average loss 12.08, train accuracy 0.67\n",
      "3,545,400 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "3,547,000 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "3,548,600 examples, moving-average loss 12.10, train accuracy 0.67\n",
      "3,550,200 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "3,551,800 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "3,553,400 examples, moving-average loss 12.05, train accuracy 0.67\n",
      "3,555,000 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "3,556,600 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "3,558,200 examples, moving-average loss 12.00, train accuracy 0.67\n",
      "3,559,800 examples, moving-average loss 12.01, train accuracy 0.67\n",
      "3,561,400 examples, moving-average loss 11.95, train accuracy 0.67\n",
      "3,563,000 examples, moving-average loss 12.09, train accuracy 0.67\n",
      "3,564,600 examples, moving-average loss 12.02, train accuracy 0.67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3,566,200 examples, moving-average loss 11.99, train accuracy 0.67\n",
      "3,567,800 examples, moving-average loss 11.99, train accuracy 0.67\n",
      "3,569,400 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "3,571,000 examples, moving-average loss 11.99, train accuracy 0.67\n",
      "3,572,600 examples, moving-average loss 12.05, train accuracy 0.67\n",
      "3,574,200 examples, moving-average loss 11.98, train accuracy 0.67\n",
      "3,575,800 examples, moving-average loss 12.07, train accuracy 0.67\n",
      "3,577,400 examples, moving-average loss 11.97, train accuracy 0.67\n",
      "3,579,000 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "3,580,600 examples, moving-average loss 12.03, train accuracy 0.67\n",
      "3,582,200 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "3,583,800 examples, moving-average loss 12.02, train accuracy 0.67\n",
      "3,585,400 examples, moving-average loss 11.95, train accuracy 0.67\n",
      "3,587,000 examples, moving-average loss 11.92, train accuracy 0.67\n",
      "3,588,600 examples, moving-average loss 11.93, train accuracy 0.67\n",
      "3,590,200 examples, moving-average loss 11.99, train accuracy 0.67\n",
      "3,591,800 examples, moving-average loss 12.05, train accuracy 0.67\n",
      "3,593,400 examples, moving-average loss 12.11, train accuracy 0.67\n",
      "3,595,000 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "3,596,600 examples, moving-average loss 12.07, train accuracy 0.67\n",
      "3,598,200 examples, moving-average loss 12.03, train accuracy 0.67\n",
      "3,599,800 examples, moving-average loss 11.99, train accuracy 0.67\n",
      "3,601,400 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "3,603,000 examples, moving-average loss 12.08, train accuracy 0.67\n",
      "3,604,600 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "3,606,200 examples, moving-average loss 12.00, train accuracy 0.67\n",
      "3,607,800 examples, moving-average loss 12.07, train accuracy 0.67\n",
      "3,609,400 examples, moving-average loss 11.93, train accuracy 0.67\n",
      "3,611,000 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "3,612,600 examples, moving-average loss 11.98, train accuracy 0.67\n",
      "3,614,200 examples, moving-average loss 12.00, train accuracy 0.67\n",
      "3,615,800 examples, moving-average loss 12.07, train accuracy 0.67\n",
      "3,617,400 examples, moving-average loss 12.05, train accuracy 0.67\n",
      "3,619,000 examples, moving-average loss 12.01, train accuracy 0.67\n",
      "3,620,600 examples, moving-average loss 12.00, train accuracy 0.67\n",
      "3,622,200 examples, moving-average loss 11.99, train accuracy 0.67\n",
      "3,623,800 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "3,625,400 examples, moving-average loss 12.11, train accuracy 0.67\n",
      "3,627,000 examples, moving-average loss 12.05, train accuracy 0.67\n",
      "3,628,600 examples, moving-average loss 11.98, train accuracy 0.67\n",
      "3,630,200 examples, moving-average loss 12.03, train accuracy 0.67\n",
      "3,631,800 examples, moving-average loss 11.97, train accuracy 0.67\n",
      "3,633,400 examples, moving-average loss 12.02, train accuracy 0.67\n",
      "3,635,000 examples, moving-average loss 12.00, train accuracy 0.67\n",
      "3,636,600 examples, moving-average loss 12.05, train accuracy 0.67\n",
      "3,638,200 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "3,639,800 examples, moving-average loss 12.09, train accuracy 0.67\n",
      "3,641,400 examples, moving-average loss 11.96, train accuracy 0.67\n",
      "3,643,000 examples, moving-average loss 12.02, train accuracy 0.67\n",
      "3,644,600 examples, moving-average loss 12.03, train accuracy 0.67\n",
      "3,646,200 examples, moving-average loss 12.03, train accuracy 0.67\n",
      "3,647,800 examples, moving-average loss 12.14, train accuracy 0.67\n",
      "3,649,400 examples, moving-average loss 11.92, train accuracy 0.67\n",
      "3,651,000 examples, moving-average loss 11.99, train accuracy 0.67\n",
      "3,652,600 examples, moving-average loss 12.00, train accuracy 0.67\n",
      "3,654,200 examples, moving-average loss 12.01, train accuracy 0.67\n",
      "3,655,800 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "3,657,400 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "3,659,000 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "3,660,600 examples, moving-average loss 12.02, train accuracy 0.67\n",
      "3,662,200 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "3,663,800 examples, moving-average loss 11.99, train accuracy 0.67\n",
      "3,665,400 examples, moving-average loss 11.99, train accuracy 0.67\n",
      "3,667,000 examples, moving-average loss 12.01, train accuracy 0.67\n",
      "3,668,600 examples, moving-average loss 12.07, train accuracy 0.67\n",
      "3,670,200 examples, moving-average loss 11.98, train accuracy 0.67\n",
      "3,671,800 examples, moving-average loss 12.01, train accuracy 0.67\n",
      "3,673,400 examples, moving-average loss 11.99, train accuracy 0.67\n",
      "3,675,000 examples, moving-average loss 12.07, train accuracy 0.67\n",
      "3,676,600 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "3,678,200 examples, moving-average loss 12.02, train accuracy 0.67\n",
      "3,679,800 examples, moving-average loss 12.05, train accuracy 0.67\n",
      "3,681,400 examples, moving-average loss 12.00, train accuracy 0.67\n",
      "3,683,000 examples, moving-average loss 12.01, train accuracy 0.67\n",
      "3,684,600 examples, moving-average loss 12.01, train accuracy 0.67\n",
      "3,686,200 examples, moving-average loss 12.10, train accuracy 0.67\n",
      "3,687,800 examples, moving-average loss 12.10, train accuracy 0.67\n",
      "3,689,400 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "3,691,000 examples, moving-average loss 11.99, train accuracy 0.67\n",
      "3,692,600 examples, moving-average loss 11.95, train accuracy 0.67\n",
      "3,694,200 examples, moving-average loss 11.98, train accuracy 0.67\n",
      "3,695,800 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "3,697,400 examples, moving-average loss 12.08, train accuracy 0.67\n",
      "3,699,000 examples, moving-average loss 12.00, train accuracy 0.67\n",
      "3,700,600 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "3,702,200 examples, moving-average loss 12.01, train accuracy 0.67\n",
      "3,703,800 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "3,705,400 examples, moving-average loss 12.07, train accuracy 0.67\n",
      "3,707,000 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "3,708,600 examples, moving-average loss 11.93, train accuracy 0.67\n",
      "3,710,200 examples, moving-average loss 12.02, train accuracy 0.67\n",
      "3,711,800 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "3,713,400 examples, moving-average loss 12.03, train accuracy 0.67\n",
      "3,715,000 examples, moving-average loss 12.02, train accuracy 0.67\n",
      "3,716,600 examples, moving-average loss 11.96, train accuracy 0.67\n",
      "3,718,200 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "3,719,800 examples, moving-average loss 12.07, train accuracy 0.67\n",
      "3,721,400 examples, moving-average loss 12.01, train accuracy 0.67\n",
      "3,723,000 examples, moving-average loss 11.95, train accuracy 0.67\n",
      "3,724,600 examples, moving-average loss 12.05, train accuracy 0.67\n",
      "3,726,200 examples, moving-average loss 11.99, train accuracy 0.67\n",
      "3,727,800 examples, moving-average loss 12.09, train accuracy 0.67\n",
      "3,729,400 examples, moving-average loss 11.98, train accuracy 0.67\n",
      "3,731,000 examples, moving-average loss 11.96, train accuracy 0.67\n",
      "3,732,600 examples, moving-average loss 12.02, train accuracy 0.67\n",
      "3,734,200 examples, moving-average loss 11.95, train accuracy 0.67\n",
      "3,735,800 examples, moving-average loss 12.01, train accuracy 0.67\n",
      "3,737,400 examples, moving-average loss 12.16, train accuracy 0.67\n",
      "3,739,000 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "3,740,600 examples, moving-average loss 12.08, train accuracy 0.67\n",
      "3,742,200 examples, moving-average loss 12.13, train accuracy 0.67\n",
      "3,743,800 examples, moving-average loss 11.94, train accuracy 0.67\n",
      "3,745,400 examples, moving-average loss 12.03, train accuracy 0.67\n",
      "3,747,000 examples, moving-average loss 12.00, train accuracy 0.67\n",
      "3,748,600 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "3,750,200 examples, moving-average loss 12.00, train accuracy 0.67\n",
      "3,751,800 examples, moving-average loss 11.93, train accuracy 0.67\n",
      "3,753,400 examples, moving-average loss 11.99, train accuracy 0.67\n",
      "3,755,000 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "3,756,600 examples, moving-average loss 12.08, train accuracy 0.67\n",
      "3,758,200 examples, moving-average loss 12.05, train accuracy 0.67\n",
      "3,759,800 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "3,761,400 examples, moving-average loss 11.98, train accuracy 0.67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3,763,000 examples, moving-average loss 12.03, train accuracy 0.67\n",
      "3,764,600 examples, moving-average loss 12.05, train accuracy 0.67\n",
      "3,766,200 examples, moving-average loss 12.03, train accuracy 0.67\n",
      "3,767,800 examples, moving-average loss 11.99, train accuracy 0.67\n",
      "3,769,400 examples, moving-average loss 12.01, train accuracy 0.67\n",
      "3,771,000 examples, moving-average loss 12.05, train accuracy 0.67\n",
      "3,772,600 examples, moving-average loss 12.07, train accuracy 0.67\n",
      "3,774,200 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "3,775,800 examples, moving-average loss 12.07, train accuracy 0.67\n",
      "3,777,400 examples, moving-average loss 12.12, train accuracy 0.67\n",
      "3,779,000 examples, moving-average loss 12.12, train accuracy 0.67\n",
      "3,780,600 examples, moving-average loss 12.12, train accuracy 0.67\n",
      "3,782,200 examples, moving-average loss 12.01, train accuracy 0.67\n",
      "3,783,800 examples, moving-average loss 12.05, train accuracy 0.67\n",
      "3,785,400 examples, moving-average loss 12.08, train accuracy 0.67\n",
      "3,787,000 examples, moving-average loss 12.03, train accuracy 0.67\n",
      "3,788,600 examples, moving-average loss 12.11, train accuracy 0.67\n",
      "3,790,200 examples, moving-average loss 12.05, train accuracy 0.67\n",
      "3,791,800 examples, moving-average loss 11.92, train accuracy 0.67\n",
      "3,793,400 examples, moving-average loss 12.03, train accuracy 0.67\n",
      "3,795,000 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "3,796,600 examples, moving-average loss 12.08, train accuracy 0.67\n",
      "3,798,200 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "3,799,800 examples, moving-average loss 12.03, train accuracy 0.67\n",
      "3,801,400 examples, moving-average loss 12.02, train accuracy 0.67\n",
      "3,803,000 examples, moving-average loss 11.99, train accuracy 0.67\n",
      "3,804,600 examples, moving-average loss 12.00, train accuracy 0.67\n",
      "3,806,200 examples, moving-average loss 12.02, train accuracy 0.67\n",
      "3,807,800 examples, moving-average loss 12.09, train accuracy 0.67\n",
      "3,809,400 examples, moving-average loss 12.07, train accuracy 0.67\n",
      "3,811,000 examples, moving-average loss 12.09, train accuracy 0.67\n",
      "3,812,600 examples, moving-average loss 12.02, train accuracy 0.67\n",
      "3,814,200 examples, moving-average loss 12.08, train accuracy 0.67\n",
      "3,815,800 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "3,817,400 examples, moving-average loss 12.12, train accuracy 0.67\n",
      "3,819,000 examples, moving-average loss 12.09, train accuracy 0.67\n",
      "3,820,600 examples, moving-average loss 12.07, train accuracy 0.67\n",
      "3,822,200 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "3,823,800 examples, moving-average loss 12.02, train accuracy 0.67\n",
      "3,825,400 examples, moving-average loss 12.02, train accuracy 0.67\n",
      "3,827,000 examples, moving-average loss 12.08, train accuracy 0.67\n",
      "3,828,600 examples, moving-average loss 12.17, train accuracy 0.67\n",
      "3,830,200 examples, moving-average loss 12.07, train accuracy 0.67\n",
      "3,831,800 examples, moving-average loss 12.01, train accuracy 0.67\n",
      "3,833,400 examples, moving-average loss 12.02, train accuracy 0.67\n",
      "3,835,000 examples, moving-average loss 11.93, train accuracy 0.67\n",
      "3,836,600 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "3,838,200 examples, moving-average loss 12.05, train accuracy 0.67\n",
      "3,839,800 examples, moving-average loss 11.95, train accuracy 0.67\n",
      "3,841,400 examples, moving-average loss 11.99, train accuracy 0.67\n",
      "3,843,000 examples, moving-average loss 12.03, train accuracy 0.67\n",
      "3,844,600 examples, moving-average loss 11.98, train accuracy 0.67\n",
      "3,846,200 examples, moving-average loss 12.03, train accuracy 0.67\n",
      "3,847,800 examples, moving-average loss 11.97, train accuracy 0.67\n",
      "3,849,400 examples, moving-average loss 12.07, train accuracy 0.67\n",
      "3,851,000 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "3,852,600 examples, moving-average loss 12.09, train accuracy 0.67\n",
      "3,854,200 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "3,855,800 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "3,857,400 examples, moving-average loss 12.08, train accuracy 0.67\n",
      "3,859,000 examples, moving-average loss 12.01, train accuracy 0.67\n",
      "3,860,600 examples, moving-average loss 11.98, train accuracy 0.67\n",
      "3,862,200 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "3,863,800 examples, moving-average loss 12.02, train accuracy 0.67\n",
      "3,865,400 examples, moving-average loss 12.00, train accuracy 0.67\n",
      "3,867,000 examples, moving-average loss 11.97, train accuracy 0.67\n",
      "3,868,600 examples, moving-average loss 11.98, train accuracy 0.67\n",
      "3,870,200 examples, moving-average loss 11.97, train accuracy 0.67\n",
      "3,871,800 examples, moving-average loss 12.07, train accuracy 0.67\n",
      "3,873,400 examples, moving-average loss 12.00, train accuracy 0.67\n",
      "3,875,000 examples, moving-average loss 12.01, train accuracy 0.67\n",
      "3,876,600 examples, moving-average loss 12.00, train accuracy 0.67\n",
      "3,878,200 examples, moving-average loss 12.12, train accuracy 0.67\n",
      "3,879,800 examples, moving-average loss 12.09, train accuracy 0.67\n",
      "3,881,400 examples, moving-average loss 12.08, train accuracy 0.67\n",
      "3,883,000 examples, moving-average loss 12.03, train accuracy 0.67\n",
      "3,884,600 examples, moving-average loss 11.96, train accuracy 0.67\n",
      "3,886,200 examples, moving-average loss 12.13, train accuracy 0.67\n",
      "3,887,800 examples, moving-average loss 11.96, train accuracy 0.67\n",
      "3,889,400 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "3,891,000 examples, moving-average loss 12.03, train accuracy 0.67\n",
      "3,892,600 examples, moving-average loss 12.11, train accuracy 0.67\n",
      "3,894,200 examples, moving-average loss 12.13, train accuracy 0.67\n",
      "3,895,800 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "3,897,400 examples, moving-average loss 12.05, train accuracy 0.67\n",
      "3,899,000 examples, moving-average loss 12.07, train accuracy 0.67\n",
      "3,900,600 examples, moving-average loss 11.99, train accuracy 0.67\n",
      "3,902,200 examples, moving-average loss 12.08, train accuracy 0.67\n",
      "3,903,800 examples, moving-average loss 11.91, train accuracy 0.67\n",
      "3,905,400 examples, moving-average loss 11.96, train accuracy 0.67\n",
      "3,907,000 examples, moving-average loss 12.08, train accuracy 0.67\n",
      "3,908,600 examples, moving-average loss 11.98, train accuracy 0.67\n",
      "3,910,200 examples, moving-average loss 11.99, train accuracy 0.67\n",
      "3,911,800 examples, moving-average loss 11.92, train accuracy 0.67\n",
      "3,913,400 examples, moving-average loss 12.02, train accuracy 0.67\n",
      "3,915,000 examples, moving-average loss 12.05, train accuracy 0.67\n",
      "3,916,600 examples, moving-average loss 12.01, train accuracy 0.67\n",
      "3,918,200 examples, moving-average loss 12.08, train accuracy 0.67\n",
      "3,919,800 examples, moving-average loss 12.09, train accuracy 0.67\n",
      "3,921,400 examples, moving-average loss 12.07, train accuracy 0.67\n",
      "3,923,000 examples, moving-average loss 12.08, train accuracy 0.67\n",
      "3,924,600 examples, moving-average loss 11.97, train accuracy 0.67\n",
      "3,926,200 examples, moving-average loss 12.00, train accuracy 0.67\n",
      "3,927,800 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "3,929,400 examples, moving-average loss 12.01, train accuracy 0.67\n",
      "3,931,000 examples, moving-average loss 11.96, train accuracy 0.67\n",
      "3,932,600 examples, moving-average loss 12.08, train accuracy 0.67\n",
      "3,934,200 examples, moving-average loss 11.94, train accuracy 0.67\n",
      "3,935,800 examples, moving-average loss 12.03, train accuracy 0.67\n",
      "3,937,400 examples, moving-average loss 12.07, train accuracy 0.67\n",
      "3,939,000 examples, moving-average loss 11.99, train accuracy 0.67\n",
      "3,940,600 examples, moving-average loss 12.05, train accuracy 0.67\n",
      "3,942,200 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "3,943,800 examples, moving-average loss 12.10, train accuracy 0.67\n",
      "3,945,400 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "3,947,000 examples, moving-average loss 12.05, train accuracy 0.67\n",
      "3,948,600 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "3,950,200 examples, moving-average loss 12.00, train accuracy 0.67\n",
      "3,951,800 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "3,953,400 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "3,955,000 examples, moving-average loss 11.93, train accuracy 0.67\n",
      "3,956,600 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "3,958,200 examples, moving-average loss 12.04, train accuracy 0.67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3,959,800 examples, moving-average loss 11.97, train accuracy 0.67\n",
      "3,961,400 examples, moving-average loss 11.95, train accuracy 0.67\n",
      "3,963,000 examples, moving-average loss 12.02, train accuracy 0.67\n",
      "3,964,600 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "3,966,200 examples, moving-average loss 12.03, train accuracy 0.67\n",
      "3,967,800 examples, moving-average loss 12.02, train accuracy 0.67\n",
      "3,969,400 examples, moving-average loss 12.11, train accuracy 0.67\n",
      "3,971,000 examples, moving-average loss 11.96, train accuracy 0.67\n",
      "3,972,600 examples, moving-average loss 11.99, train accuracy 0.67\n",
      "3,974,200 examples, moving-average loss 12.05, train accuracy 0.67\n",
      "3,975,800 examples, moving-average loss 12.00, train accuracy 0.67\n",
      "3,977,400 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "3,979,000 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "3,980,600 examples, moving-average loss 12.08, train accuracy 0.67\n",
      "3,982,200 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "3,983,800 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "3,985,400 examples, moving-average loss 12.03, train accuracy 0.67\n",
      "3,987,000 examples, moving-average loss 12.02, train accuracy 0.67\n",
      "3,988,600 examples, moving-average loss 12.09, train accuracy 0.67\n",
      "3,990,200 examples, moving-average loss 12.05, train accuracy 0.67\n",
      "3,991,800 examples, moving-average loss 11.99, train accuracy 0.67\n",
      "3,993,400 examples, moving-average loss 12.08, train accuracy 0.67\n",
      "3,995,000 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "3,996,600 examples, moving-average loss 12.11, train accuracy 0.67\n",
      "3,998,200 examples, moving-average loss 12.07, train accuracy 0.67\n",
      "3,999,800 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "4,001,400 examples, moving-average loss 11.98, train accuracy 0.67\n",
      "4,003,000 examples, moving-average loss 12.07, train accuracy 0.67\n",
      "4,004,600 examples, moving-average loss 12.01, train accuracy 0.67\n",
      "4,006,200 examples, moving-average loss 11.95, train accuracy 0.67\n",
      "4,007,800 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "4,009,400 examples, moving-average loss 12.09, train accuracy 0.67\n",
      "4,011,000 examples, moving-average loss 12.05, train accuracy 0.67\n",
      "4,012,600 examples, moving-average loss 12.05, train accuracy 0.67\n",
      "4,014,200 examples, moving-average loss 11.98, train accuracy 0.67\n",
      "4,015,800 examples, moving-average loss 12.02, train accuracy 0.67\n",
      "4,017,400 examples, moving-average loss 12.02, train accuracy 0.67\n",
      "4,019,000 examples, moving-average loss 12.07, train accuracy 0.67\n",
      "4,020,600 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "4,022,200 examples, moving-average loss 12.05, train accuracy 0.67\n",
      "4,023,800 examples, moving-average loss 12.07, train accuracy 0.67\n",
      "4,025,400 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "4,027,000 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "4,028,600 examples, moving-average loss 12.09, train accuracy 0.67\n",
      "4,030,200 examples, moving-average loss 12.01, train accuracy 0.67\n",
      "4,031,800 examples, moving-average loss 11.98, train accuracy 0.67\n",
      "4,033,400 examples, moving-average loss 12.07, train accuracy 0.67\n",
      "4,035,000 examples, moving-average loss 12.02, train accuracy 0.67\n",
      "4,036,600 examples, moving-average loss 11.99, train accuracy 0.67\n",
      "4,038,200 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "4,039,800 examples, moving-average loss 12.03, train accuracy 0.67\n",
      "4,041,400 examples, moving-average loss 11.94, train accuracy 0.67\n",
      "4,043,000 examples, moving-average loss 12.05, train accuracy 0.67\n",
      "4,044,600 examples, moving-average loss 12.07, train accuracy 0.67\n",
      "4,046,200 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "4,047,800 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "4,049,400 examples, moving-average loss 12.03, train accuracy 0.67\n",
      "4,051,000 examples, moving-average loss 12.07, train accuracy 0.67\n",
      "4,052,600 examples, moving-average loss 11.97, train accuracy 0.67\n",
      "4,054,200 examples, moving-average loss 12.05, train accuracy 0.67\n",
      "4,055,800 examples, moving-average loss 11.99, train accuracy 0.67\n",
      "4,057,400 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "4,059,000 examples, moving-average loss 11.98, train accuracy 0.67\n",
      "4,060,600 examples, moving-average loss 12.03, train accuracy 0.67\n",
      "4,062,200 examples, moving-average loss 12.01, train accuracy 0.67\n",
      "4,063,800 examples, moving-average loss 12.01, train accuracy 0.67\n",
      "4,065,400 examples, moving-average loss 12.05, train accuracy 0.67\n",
      "4,067,000 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "4,068,600 examples, moving-average loss 12.10, train accuracy 0.67\n",
      "4,070,200 examples, moving-average loss 12.08, train accuracy 0.67\n",
      "4,071,800 examples, moving-average loss 12.03, train accuracy 0.67\n",
      "4,073,400 examples, moving-average loss 11.98, train accuracy 0.67\n",
      "4,075,000 examples, moving-average loss 12.10, train accuracy 0.67\n",
      "4,076,600 examples, moving-average loss 12.03, train accuracy 0.67\n",
      "4,078,200 examples, moving-average loss 12.01, train accuracy 0.67\n",
      "4,079,800 examples, moving-average loss 12.09, train accuracy 0.67\n",
      "4,081,400 examples, moving-average loss 12.02, train accuracy 0.67\n",
      "4,083,000 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "4,084,600 examples, moving-average loss 12.09, train accuracy 0.67\n",
      "4,086,200 examples, moving-average loss 12.10, train accuracy 0.67\n",
      "4,087,800 examples, moving-average loss 11.95, train accuracy 0.67\n",
      "4,089,400 examples, moving-average loss 12.08, train accuracy 0.67\n",
      "4,091,000 examples, moving-average loss 12.16, train accuracy 0.67\n",
      "4,092,600 examples, moving-average loss 11.97, train accuracy 0.67\n",
      "4,094,200 examples, moving-average loss 12.01, train accuracy 0.67\n",
      "4,095,800 examples, moving-average loss 12.02, train accuracy 0.67\n",
      "4,097,400 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "4,099,000 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "4,100,600 examples, moving-average loss 12.02, train accuracy 0.67\n",
      "4,102,200 examples, moving-average loss 12.09, train accuracy 0.67\n",
      "4,103,800 examples, moving-average loss 12.02, train accuracy 0.67\n",
      "4,105,400 examples, moving-average loss 12.02, train accuracy 0.67\n",
      "4,107,000 examples, moving-average loss 11.99, train accuracy 0.67\n",
      "4,108,600 examples, moving-average loss 12.01, train accuracy 0.67\n",
      "4,110,200 examples, moving-average loss 12.00, train accuracy 0.67\n",
      "4,111,800 examples, moving-average loss 11.98, train accuracy 0.67\n",
      "4,113,400 examples, moving-average loss 12.08, train accuracy 0.67\n",
      "4,115,000 examples, moving-average loss 12.01, train accuracy 0.67\n",
      "4,116,600 examples, moving-average loss 12.11, train accuracy 0.67\n",
      "4,118,200 examples, moving-average loss 12.03, train accuracy 0.67\n",
      "4,119,800 examples, moving-average loss 12.09, train accuracy 0.67\n",
      "4,121,400 examples, moving-average loss 12.00, train accuracy 0.67\n",
      "4,123,000 examples, moving-average loss 12.02, train accuracy 0.67\n",
      "4,124,600 examples, moving-average loss 12.02, train accuracy 0.67\n",
      "4,126,200 examples, moving-average loss 11.97, train accuracy 0.67\n",
      "4,127,800 examples, moving-average loss 12.03, train accuracy 0.67\n",
      "4,129,400 examples, moving-average loss 12.03, train accuracy 0.67\n",
      "4,131,000 examples, moving-average loss 12.01, train accuracy 0.67\n",
      "4,132,600 examples, moving-average loss 11.93, train accuracy 0.67\n",
      "4,134,200 examples, moving-average loss 11.99, train accuracy 0.67\n",
      "4,135,800 examples, moving-average loss 12.05, train accuracy 0.67\n",
      "4,137,400 examples, moving-average loss 12.02, train accuracy 0.67\n",
      "4,139,000 examples, moving-average loss 11.95, train accuracy 0.67\n",
      "4,140,600 examples, moving-average loss 12.03, train accuracy 0.67\n",
      "4,142,200 examples, moving-average loss 12.01, train accuracy 0.67\n",
      "4,143,800 examples, moving-average loss 12.02, train accuracy 0.67\n",
      "4,145,400 examples, moving-average loss 11.95, train accuracy 0.67\n",
      "4,147,000 examples, moving-average loss 12.01, train accuracy 0.67\n",
      "4,148,600 examples, moving-average loss 12.01, train accuracy 0.67\n",
      "4,150,200 examples, moving-average loss 11.99, train accuracy 0.67\n",
      "4,151,800 examples, moving-average loss 12.00, train accuracy 0.67\n",
      "4,153,400 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "4,155,000 examples, moving-average loss 12.06, train accuracy 0.67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4,156,600 examples, moving-average loss 11.97, train accuracy 0.67\n",
      "4,158,200 examples, moving-average loss 12.03, train accuracy 0.67\n",
      "4,159,800 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "4,161,400 examples, moving-average loss 12.07, train accuracy 0.67\n",
      "4,163,000 examples, moving-average loss 12.03, train accuracy 0.67\n",
      "4,164,600 examples, moving-average loss 12.08, train accuracy 0.67\n",
      "4,166,200 examples, moving-average loss 12.07, train accuracy 0.67\n",
      "4,167,800 examples, moving-average loss 11.98, train accuracy 0.67\n",
      "4,169,400 examples, moving-average loss 11.99, train accuracy 0.67\n",
      "4,171,000 examples, moving-average loss 11.99, train accuracy 0.67\n",
      "4,172,600 examples, moving-average loss 12.03, train accuracy 0.67\n",
      "4,174,200 examples, moving-average loss 11.98, train accuracy 0.67\n",
      "4,175,800 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "4,177,400 examples, moving-average loss 11.96, train accuracy 0.67\n",
      "4,179,000 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "4,180,600 examples, moving-average loss 11.95, train accuracy 0.67\n",
      "4,182,200 examples, moving-average loss 11.98, train accuracy 0.67\n",
      "4,183,800 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "4,185,400 examples, moving-average loss 12.08, train accuracy 0.67\n",
      "4,187,000 examples, moving-average loss 11.89, train accuracy 0.67\n",
      "4,188,600 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "4,190,200 examples, moving-average loss 12.04, train accuracy 0.67\n",
      "4,191,800 examples, moving-average loss 12.05, train accuracy 0.67\n",
      "4,193,400 examples, moving-average loss 12.03, train accuracy 0.68\n",
      "4,195,000 examples, moving-average loss 11.98, train accuracy 0.68\n",
      "4,196,600 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,198,200 examples, moving-average loss 11.96, train accuracy 0.68\n",
      "4,199,800 examples, moving-average loss 12.05, train accuracy 0.68\n",
      "4,201,400 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,203,000 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "4,204,600 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,206,200 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "Completed 4 epoch in 0:38:32\n",
      "Train accurary:0.67520\n",
      "Validate accuracy:0.68002\n",
      "4,207,750 examples, moving-average loss 11.71, train accuracy 0.59\n",
      "4,209,350 examples, moving-average loss 11.94, train accuracy 0.66\n",
      "4,210,950 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "4,212,550 examples, moving-average loss 12.02, train accuracy 0.67\n",
      "4,214,150 examples, moving-average loss 12.05, train accuracy 0.67\n",
      "4,215,750 examples, moving-average loss 12.06, train accuracy 0.67\n",
      "4,217,350 examples, moving-average loss 12.01, train accuracy 0.67\n",
      "4,218,950 examples, moving-average loss 11.98, train accuracy 0.67\n",
      "4,220,550 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "4,222,150 examples, moving-average loss 11.98, train accuracy 0.68\n",
      "4,223,750 examples, moving-average loss 12.05, train accuracy 0.68\n",
      "4,225,350 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "4,226,950 examples, moving-average loss 12.07, train accuracy 0.68\n",
      "4,228,550 examples, moving-average loss 12.09, train accuracy 0.68\n",
      "4,230,150 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "4,231,750 examples, moving-average loss 11.99, train accuracy 0.68\n",
      "4,233,350 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "4,234,950 examples, moving-average loss 12.08, train accuracy 0.68\n",
      "4,236,550 examples, moving-average loss 12.06, train accuracy 0.68\n",
      "4,238,150 examples, moving-average loss 12.07, train accuracy 0.68\n",
      "4,239,750 examples, moving-average loss 12.03, train accuracy 0.68\n",
      "4,241,350 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "4,242,950 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "4,244,550 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,246,150 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,247,750 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "4,249,350 examples, moving-average loss 12.05, train accuracy 0.68\n",
      "4,250,950 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "4,252,550 examples, moving-average loss 11.96, train accuracy 0.68\n",
      "4,254,150 examples, moving-average loss 12.08, train accuracy 0.68\n",
      "4,255,750 examples, moving-average loss 12.06, train accuracy 0.68\n",
      "4,257,350 examples, moving-average loss 11.94, train accuracy 0.68\n",
      "4,258,950 examples, moving-average loss 11.97, train accuracy 0.68\n",
      "4,260,550 examples, moving-average loss 11.93, train accuracy 0.68\n",
      "4,262,150 examples, moving-average loss 12.08, train accuracy 0.68\n",
      "4,263,750 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,265,350 examples, moving-average loss 12.06, train accuracy 0.68\n",
      "4,266,950 examples, moving-average loss 12.03, train accuracy 0.68\n",
      "4,268,550 examples, moving-average loss 12.05, train accuracy 0.68\n",
      "4,270,150 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,271,750 examples, moving-average loss 11.97, train accuracy 0.68\n",
      "4,273,350 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "4,274,950 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "4,276,550 examples, moving-average loss 11.91, train accuracy 0.68\n",
      "4,278,150 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "4,279,750 examples, moving-average loss 11.99, train accuracy 0.68\n",
      "4,281,350 examples, moving-average loss 11.99, train accuracy 0.68\n",
      "4,282,950 examples, moving-average loss 11.89, train accuracy 0.68\n",
      "4,284,550 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,286,150 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "4,287,750 examples, moving-average loss 11.94, train accuracy 0.68\n",
      "4,289,350 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "4,290,950 examples, moving-average loss 12.12, train accuracy 0.68\n",
      "4,292,550 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,294,150 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "4,295,750 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,297,350 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "4,298,950 examples, moving-average loss 11.97, train accuracy 0.68\n",
      "4,300,550 examples, moving-average loss 12.03, train accuracy 0.68\n",
      "4,302,150 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "4,303,750 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "4,305,350 examples, moving-average loss 12.09, train accuracy 0.68\n",
      "4,306,950 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,308,550 examples, moving-average loss 11.97, train accuracy 0.68\n",
      "4,310,150 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,311,750 examples, moving-average loss 12.06, train accuracy 0.68\n",
      "4,313,350 examples, moving-average loss 12.06, train accuracy 0.68\n",
      "4,314,950 examples, moving-average loss 12.03, train accuracy 0.68\n",
      "4,316,550 examples, moving-average loss 12.08, train accuracy 0.68\n",
      "4,318,150 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "4,319,750 examples, moving-average loss 12.06, train accuracy 0.68\n",
      "4,321,350 examples, moving-average loss 12.06, train accuracy 0.68\n",
      "4,322,950 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,324,550 examples, moving-average loss 11.99, train accuracy 0.68\n",
      "4,326,150 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "4,327,750 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "4,329,350 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "4,330,950 examples, moving-average loss 12.03, train accuracy 0.68\n",
      "4,332,550 examples, moving-average loss 12.06, train accuracy 0.68\n",
      "4,334,150 examples, moving-average loss 12.05, train accuracy 0.68\n",
      "4,335,750 examples, moving-average loss 12.03, train accuracy 0.68\n",
      "4,337,350 examples, moving-average loss 11.97, train accuracy 0.68\n",
      "4,338,950 examples, moving-average loss 12.06, train accuracy 0.68\n",
      "4,340,550 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "4,342,150 examples, moving-average loss 12.08, train accuracy 0.68\n",
      "4,343,750 examples, moving-average loss 12.07, train accuracy 0.68\n",
      "4,345,350 examples, moving-average loss 12.07, train accuracy 0.68\n",
      "4,346,950 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "4,348,550 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "4,350,150 examples, moving-average loss 12.05, train accuracy 0.68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4,351,750 examples, moving-average loss 12.09, train accuracy 0.68\n",
      "4,353,350 examples, moving-average loss 11.96, train accuracy 0.68\n",
      "4,354,950 examples, moving-average loss 12.10, train accuracy 0.68\n",
      "4,356,550 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "4,358,150 examples, moving-average loss 12.03, train accuracy 0.68\n",
      "4,359,750 examples, moving-average loss 12.07, train accuracy 0.68\n",
      "4,361,350 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "4,362,950 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "4,364,550 examples, moving-average loss 11.94, train accuracy 0.68\n",
      "4,366,150 examples, moving-average loss 11.96, train accuracy 0.68\n",
      "4,367,750 examples, moving-average loss 12.07, train accuracy 0.68\n",
      "4,369,350 examples, moving-average loss 11.98, train accuracy 0.68\n",
      "4,370,950 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "4,372,550 examples, moving-average loss 11.93, train accuracy 0.68\n",
      "4,374,150 examples, moving-average loss 12.08, train accuracy 0.68\n",
      "4,375,750 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "4,377,350 examples, moving-average loss 11.98, train accuracy 0.68\n",
      "4,378,950 examples, moving-average loss 12.05, train accuracy 0.68\n",
      "4,380,550 examples, moving-average loss 11.97, train accuracy 0.68\n",
      "4,382,150 examples, moving-average loss 12.08, train accuracy 0.68\n",
      "4,383,750 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "4,385,350 examples, moving-average loss 12.10, train accuracy 0.68\n",
      "4,386,950 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,388,550 examples, moving-average loss 11.98, train accuracy 0.68\n",
      "4,390,150 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "4,391,750 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,393,350 examples, moving-average loss 12.08, train accuracy 0.68\n",
      "4,394,950 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,396,550 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "4,398,150 examples, moving-average loss 12.03, train accuracy 0.68\n",
      "4,399,750 examples, moving-average loss 11.98, train accuracy 0.68\n",
      "4,401,350 examples, moving-average loss 11.99, train accuracy 0.68\n",
      "4,402,950 examples, moving-average loss 11.95, train accuracy 0.68\n",
      "4,404,550 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "4,406,150 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,407,750 examples, moving-average loss 12.03, train accuracy 0.68\n",
      "4,409,350 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "4,410,950 examples, moving-average loss 12.08, train accuracy 0.68\n",
      "4,412,550 examples, moving-average loss 11.93, train accuracy 0.68\n",
      "4,414,150 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "4,415,750 examples, moving-average loss 11.93, train accuracy 0.68\n",
      "4,417,350 examples, moving-average loss 12.09, train accuracy 0.68\n",
      "4,418,950 examples, moving-average loss 11.95, train accuracy 0.68\n",
      "4,420,550 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,422,150 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "4,423,750 examples, moving-average loss 12.06, train accuracy 0.68\n",
      "4,425,350 examples, moving-average loss 12.07, train accuracy 0.68\n",
      "4,426,950 examples, moving-average loss 11.96, train accuracy 0.68\n",
      "4,428,550 examples, moving-average loss 11.91, train accuracy 0.68\n",
      "4,430,150 examples, moving-average loss 11.92, train accuracy 0.68\n",
      "4,431,750 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "4,433,350 examples, moving-average loss 12.06, train accuracy 0.68\n",
      "4,434,950 examples, moving-average loss 12.10, train accuracy 0.68\n",
      "4,436,550 examples, moving-average loss 12.06, train accuracy 0.68\n",
      "4,438,150 examples, moving-average loss 12.07, train accuracy 0.68\n",
      "4,439,750 examples, moving-average loss 11.98, train accuracy 0.68\n",
      "4,441,350 examples, moving-average loss 11.99, train accuracy 0.68\n",
      "4,442,950 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,444,550 examples, moving-average loss 12.09, train accuracy 0.68\n",
      "4,446,150 examples, moving-average loss 12.03, train accuracy 0.68\n",
      "4,447,750 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,449,350 examples, moving-average loss 12.05, train accuracy 0.68\n",
      "4,450,950 examples, moving-average loss 11.95, train accuracy 0.68\n",
      "4,452,550 examples, moving-average loss 12.03, train accuracy 0.68\n",
      "4,454,150 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "4,455,750 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "4,457,350 examples, moving-average loss 12.03, train accuracy 0.68\n",
      "4,458,950 examples, moving-average loss 12.07, train accuracy 0.68\n",
      "4,460,550 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,462,150 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "4,463,750 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "4,465,350 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,466,950 examples, moving-average loss 12.13, train accuracy 0.68\n",
      "4,468,550 examples, moving-average loss 12.03, train accuracy 0.68\n",
      "4,470,150 examples, moving-average loss 11.93, train accuracy 0.68\n",
      "4,471,750 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "4,473,350 examples, moving-average loss 11.95, train accuracy 0.68\n",
      "4,474,950 examples, moving-average loss 12.03, train accuracy 0.68\n",
      "4,476,550 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,478,150 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,479,750 examples, moving-average loss 12.07, train accuracy 0.68\n",
      "4,481,350 examples, moving-average loss 12.11, train accuracy 0.68\n",
      "4,482,950 examples, moving-average loss 11.98, train accuracy 0.68\n",
      "4,484,550 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "4,486,150 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "4,487,750 examples, moving-average loss 12.06, train accuracy 0.68\n",
      "4,489,350 examples, moving-average loss 12.12, train accuracy 0.68\n",
      "4,490,950 examples, moving-average loss 11.94, train accuracy 0.68\n",
      "4,492,550 examples, moving-average loss 11.98, train accuracy 0.68\n",
      "4,494,150 examples, moving-average loss 11.98, train accuracy 0.68\n",
      "4,495,750 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "4,497,350 examples, moving-average loss 12.03, train accuracy 0.68\n",
      "4,498,950 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,500,550 examples, moving-average loss 12.05, train accuracy 0.68\n",
      "4,502,150 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,503,750 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "4,505,350 examples, moving-average loss 11.99, train accuracy 0.68\n",
      "4,506,950 examples, moving-average loss 11.97, train accuracy 0.68\n",
      "4,508,550 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "4,510,150 examples, moving-average loss 12.05, train accuracy 0.68\n",
      "4,511,750 examples, moving-average loss 11.94, train accuracy 0.68\n",
      "4,513,350 examples, moving-average loss 11.94, train accuracy 0.68\n",
      "4,514,950 examples, moving-average loss 11.98, train accuracy 0.68\n",
      "4,516,550 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "4,518,150 examples, moving-average loss 11.98, train accuracy 0.68\n",
      "4,519,750 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "4,521,350 examples, moving-average loss 12.03, train accuracy 0.68\n",
      "4,522,950 examples, moving-average loss 11.98, train accuracy 0.68\n",
      "4,524,550 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,526,150 examples, moving-average loss 11.97, train accuracy 0.68\n",
      "4,527,750 examples, moving-average loss 12.07, train accuracy 0.68\n",
      "4,529,350 examples, moving-average loss 12.09, train accuracy 0.68\n",
      "4,530,950 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "4,532,550 examples, moving-average loss 11.96, train accuracy 0.68\n",
      "4,534,150 examples, moving-average loss 11.97, train accuracy 0.68\n",
      "4,535,750 examples, moving-average loss 11.98, train accuracy 0.68\n",
      "4,537,350 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,538,950 examples, moving-average loss 12.05, train accuracy 0.68\n",
      "4,540,550 examples, moving-average loss 11.93, train accuracy 0.68\n",
      "4,542,150 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "4,543,750 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,545,350 examples, moving-average loss 11.98, train accuracy 0.68\n",
      "4,546,950 examples, moving-average loss 12.04, train accuracy 0.68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4,548,550 examples, moving-average loss 11.99, train accuracy 0.68\n",
      "4,550,150 examples, moving-average loss 11.93, train accuracy 0.68\n",
      "4,551,750 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "4,553,350 examples, moving-average loss 12.05, train accuracy 0.68\n",
      "4,554,950 examples, moving-average loss 11.99, train accuracy 0.68\n",
      "4,556,550 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "4,558,150 examples, moving-average loss 11.93, train accuracy 0.68\n",
      "4,559,750 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,561,350 examples, moving-average loss 12.08, train accuracy 0.68\n",
      "4,562,950 examples, moving-average loss 11.96, train accuracy 0.68\n",
      "4,564,550 examples, moving-average loss 11.98, train accuracy 0.68\n",
      "4,566,150 examples, moving-average loss 12.05, train accuracy 0.68\n",
      "4,567,750 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,569,350 examples, moving-average loss 12.06, train accuracy 0.68\n",
      "4,570,950 examples, moving-average loss 11.95, train accuracy 0.68\n",
      "4,572,550 examples, moving-average loss 11.93, train accuracy 0.68\n",
      "4,574,150 examples, moving-average loss 12.03, train accuracy 0.68\n",
      "4,575,750 examples, moving-average loss 11.96, train accuracy 0.68\n",
      "4,577,350 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "4,578,950 examples, moving-average loss 12.14, train accuracy 0.68\n",
      "4,580,550 examples, moving-average loss 11.95, train accuracy 0.68\n",
      "4,582,150 examples, moving-average loss 12.07, train accuracy 0.68\n",
      "4,583,750 examples, moving-average loss 12.08, train accuracy 0.68\n",
      "4,585,350 examples, moving-average loss 11.99, train accuracy 0.68\n",
      "4,586,950 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,588,550 examples, moving-average loss 11.97, train accuracy 0.68\n",
      "4,590,150 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,591,750 examples, moving-average loss 11.99, train accuracy 0.68\n",
      "4,593,350 examples, moving-average loss 11.94, train accuracy 0.68\n",
      "4,594,950 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "4,596,550 examples, moving-average loss 12.05, train accuracy 0.68\n",
      "4,598,150 examples, moving-average loss 12.10, train accuracy 0.68\n",
      "4,599,750 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "4,601,350 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "4,602,950 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "4,604,550 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "4,606,150 examples, moving-average loss 12.03, train accuracy 0.68\n",
      "4,607,750 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,609,350 examples, moving-average loss 11.93, train accuracy 0.68\n",
      "4,610,950 examples, moving-average loss 12.03, train accuracy 0.68\n",
      "4,612,550 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "4,614,150 examples, moving-average loss 12.05, train accuracy 0.68\n",
      "4,615,750 examples, moving-average loss 12.05, train accuracy 0.68\n",
      "4,617,350 examples, moving-average loss 12.07, train accuracy 0.68\n",
      "4,618,950 examples, moving-average loss 12.10, train accuracy 0.68\n",
      "4,620,550 examples, moving-average loss 12.11, train accuracy 0.68\n",
      "4,622,150 examples, moving-average loss 12.09, train accuracy 0.68\n",
      "4,623,750 examples, moving-average loss 11.99, train accuracy 0.68\n",
      "4,625,350 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,626,950 examples, moving-average loss 12.07, train accuracy 0.68\n",
      "4,628,550 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "4,630,150 examples, moving-average loss 12.10, train accuracy 0.68\n",
      "4,631,750 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,633,350 examples, moving-average loss 11.98, train accuracy 0.68\n",
      "4,634,950 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,636,550 examples, moving-average loss 12.06, train accuracy 0.68\n",
      "4,638,150 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "4,639,750 examples, moving-average loss 12.06, train accuracy 0.68\n",
      "4,641,350 examples, moving-average loss 12.03, train accuracy 0.68\n",
      "4,642,950 examples, moving-average loss 11.98, train accuracy 0.68\n",
      "4,644,550 examples, moving-average loss 11.97, train accuracy 0.68\n",
      "4,646,150 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "4,647,750 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "4,649,350 examples, moving-average loss 12.07, train accuracy 0.68\n",
      "4,650,950 examples, moving-average loss 12.06, train accuracy 0.68\n",
      "4,652,550 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "4,654,150 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,655,750 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "4,657,350 examples, moving-average loss 12.05, train accuracy 0.68\n",
      "4,658,950 examples, moving-average loss 12.09, train accuracy 0.68\n",
      "4,660,550 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "4,662,150 examples, moving-average loss 12.08, train accuracy 0.68\n",
      "4,663,750 examples, moving-average loss 12.06, train accuracy 0.68\n",
      "4,665,350 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "4,666,950 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,668,550 examples, moving-average loss 12.10, train accuracy 0.68\n",
      "4,670,150 examples, moving-average loss 12.11, train accuracy 0.68\n",
      "4,671,750 examples, moving-average loss 11.99, train accuracy 0.68\n",
      "4,673,350 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "4,674,950 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "4,676,550 examples, moving-average loss 11.95, train accuracy 0.68\n",
      "4,678,150 examples, moving-average loss 12.05, train accuracy 0.68\n",
      "4,679,750 examples, moving-average loss 12.05, train accuracy 0.68\n",
      "4,681,350 examples, moving-average loss 11.97, train accuracy 0.68\n",
      "4,682,950 examples, moving-average loss 11.98, train accuracy 0.68\n",
      "4,684,550 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "4,686,150 examples, moving-average loss 11.96, train accuracy 0.68\n",
      "4,687,750 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,689,350 examples, moving-average loss 11.98, train accuracy 0.68\n",
      "4,690,950 examples, moving-average loss 12.06, train accuracy 0.68\n",
      "4,692,550 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,694,150 examples, moving-average loss 12.08, train accuracy 0.68\n",
      "4,695,750 examples, moving-average loss 12.03, train accuracy 0.68\n",
      "4,697,350 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "4,698,950 examples, moving-average loss 12.05, train accuracy 0.68\n",
      "4,700,550 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "4,702,150 examples, moving-average loss 11.97, train accuracy 0.68\n",
      "4,703,750 examples, moving-average loss 12.03, train accuracy 0.68\n",
      "4,705,350 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "4,706,950 examples, moving-average loss 11.96, train accuracy 0.68\n",
      "4,708,550 examples, moving-average loss 11.94, train accuracy 0.68\n",
      "4,710,150 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "4,711,750 examples, moving-average loss 11.98, train accuracy 0.68\n",
      "4,713,350 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "4,714,950 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "4,716,550 examples, moving-average loss 11.99, train accuracy 0.68\n",
      "4,718,150 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "4,719,750 examples, moving-average loss 12.08, train accuracy 0.68\n",
      "4,721,350 examples, moving-average loss 12.06, train accuracy 0.68\n",
      "4,722,950 examples, moving-average loss 12.03, train accuracy 0.68\n",
      "4,724,550 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "4,726,150 examples, moving-average loss 11.99, train accuracy 0.68\n",
      "4,727,750 examples, moving-average loss 12.05, train accuracy 0.68\n",
      "4,729,350 examples, moving-average loss 11.98, train accuracy 0.68\n",
      "4,730,950 examples, moving-average loss 12.05, train accuracy 0.68\n",
      "4,732,550 examples, moving-average loss 11.95, train accuracy 0.68\n",
      "4,734,150 examples, moving-average loss 12.11, train accuracy 0.68\n",
      "4,735,750 examples, moving-average loss 12.05, train accuracy 0.68\n",
      "4,737,350 examples, moving-average loss 12.05, train accuracy 0.68\n",
      "4,738,950 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,740,550 examples, moving-average loss 12.07, train accuracy 0.68\n",
      "4,742,150 examples, moving-average loss 11.98, train accuracy 0.68\n",
      "4,743,750 examples, moving-average loss 12.01, train accuracy 0.68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4,745,350 examples, moving-average loss 11.94, train accuracy 0.68\n",
      "4,746,950 examples, moving-average loss 11.97, train accuracy 0.68\n",
      "4,748,550 examples, moving-average loss 12.06, train accuracy 0.68\n",
      "4,750,150 examples, moving-average loss 11.99, train accuracy 0.68\n",
      "4,751,750 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,753,350 examples, moving-average loss 11.90, train accuracy 0.68\n",
      "4,754,950 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "4,756,550 examples, moving-average loss 12.06, train accuracy 0.68\n",
      "4,758,150 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "4,759,750 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "4,761,350 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "4,762,950 examples, moving-average loss 12.06, train accuracy 0.68\n",
      "4,764,550 examples, moving-average loss 12.03, train accuracy 0.68\n",
      "4,766,150 examples, moving-average loss 11.93, train accuracy 0.68\n",
      "4,767,750 examples, moving-average loss 11.96, train accuracy 0.68\n",
      "4,769,350 examples, moving-average loss 12.07, train accuracy 0.68\n",
      "4,770,950 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,772,550 examples, moving-average loss 11.98, train accuracy 0.68\n",
      "4,774,150 examples, moving-average loss 12.03, train accuracy 0.68\n",
      "4,775,750 examples, moving-average loss 11.95, train accuracy 0.68\n",
      "4,777,350 examples, moving-average loss 12.03, train accuracy 0.68\n",
      "4,778,950 examples, moving-average loss 12.05, train accuracy 0.68\n",
      "4,780,550 examples, moving-average loss 11.97, train accuracy 0.68\n",
      "4,782,150 examples, moving-average loss 12.03, train accuracy 0.68\n",
      "4,783,750 examples, moving-average loss 12.03, train accuracy 0.68\n",
      "4,785,350 examples, moving-average loss 12.07, train accuracy 0.68\n",
      "4,786,950 examples, moving-average loss 12.03, train accuracy 0.68\n",
      "4,788,550 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "4,790,150 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "4,791,750 examples, moving-average loss 11.99, train accuracy 0.68\n",
      "4,793,350 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "4,794,950 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "4,796,550 examples, moving-average loss 11.94, train accuracy 0.68\n",
      "4,798,150 examples, moving-average loss 12.05, train accuracy 0.68\n",
      "4,799,750 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "4,801,350 examples, moving-average loss 11.97, train accuracy 0.68\n",
      "4,802,950 examples, moving-average loss 11.97, train accuracy 0.68\n",
      "4,804,550 examples, moving-average loss 11.99, train accuracy 0.68\n",
      "4,806,150 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "4,807,750 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "4,809,350 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "4,810,950 examples, moving-average loss 12.06, train accuracy 0.68\n",
      "4,812,550 examples, moving-average loss 11.91, train accuracy 0.68\n",
      "4,814,150 examples, moving-average loss 11.99, train accuracy 0.68\n",
      "4,815,750 examples, moving-average loss 12.03, train accuracy 0.68\n",
      "4,817,350 examples, moving-average loss 11.96, train accuracy 0.68\n",
      "4,818,950 examples, moving-average loss 12.05, train accuracy 0.68\n",
      "4,820,550 examples, moving-average loss 12.08, train accuracy 0.68\n",
      "4,822,150 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "4,823,750 examples, moving-average loss 12.05, train accuracy 0.68\n",
      "4,825,350 examples, moving-average loss 12.03, train accuracy 0.68\n",
      "4,826,950 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "4,828,550 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,830,150 examples, moving-average loss 12.07, train accuracy 0.68\n",
      "4,831,750 examples, moving-average loss 12.03, train accuracy 0.68\n",
      "4,833,350 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "4,834,950 examples, moving-average loss 12.07, train accuracy 0.68\n",
      "4,836,550 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "4,838,150 examples, moving-average loss 12.12, train accuracy 0.68\n",
      "4,839,750 examples, moving-average loss 12.05, train accuracy 0.68\n",
      "4,841,350 examples, moving-average loss 11.97, train accuracy 0.68\n",
      "4,842,950 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "4,844,550 examples, moving-average loss 12.03, train accuracy 0.68\n",
      "4,846,150 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "4,847,750 examples, moving-average loss 11.99, train accuracy 0.68\n",
      "4,849,350 examples, moving-average loss 12.09, train accuracy 0.68\n",
      "4,850,950 examples, moving-average loss 12.07, train accuracy 0.68\n",
      "4,852,550 examples, moving-average loss 12.05, train accuracy 0.68\n",
      "4,854,150 examples, moving-average loss 12.07, train accuracy 0.68\n",
      "4,855,750 examples, moving-average loss 11.99, train accuracy 0.68\n",
      "4,857,350 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "4,858,950 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "4,860,550 examples, moving-average loss 12.05, train accuracy 0.68\n",
      "4,862,150 examples, moving-average loss 12.10, train accuracy 0.68\n",
      "4,863,750 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,865,350 examples, moving-average loss 12.07, train accuracy 0.68\n",
      "4,866,950 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "4,868,550 examples, moving-average loss 11.99, train accuracy 0.68\n",
      "4,870,150 examples, moving-average loss 12.11, train accuracy 0.68\n",
      "4,871,750 examples, moving-average loss 11.99, train accuracy 0.68\n",
      "4,873,350 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "4,874,950 examples, moving-average loss 12.03, train accuracy 0.68\n",
      "4,876,550 examples, moving-average loss 11.99, train accuracy 0.68\n",
      "4,878,150 examples, moving-average loss 11.98, train accuracy 0.68\n",
      "4,879,750 examples, moving-average loss 12.06, train accuracy 0.68\n",
      "4,881,350 examples, moving-average loss 11.99, train accuracy 0.68\n",
      "4,882,950 examples, moving-average loss 11.95, train accuracy 0.68\n",
      "4,884,550 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,886,150 examples, moving-average loss 12.05, train accuracy 0.68\n",
      "4,887,750 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "4,889,350 examples, moving-average loss 12.03, train accuracy 0.68\n",
      "4,890,950 examples, moving-average loss 12.03, train accuracy 0.68\n",
      "4,892,550 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,894,150 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,895,750 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "4,897,350 examples, moving-average loss 11.96, train accuracy 0.68\n",
      "4,898,950 examples, moving-average loss 12.05, train accuracy 0.68\n",
      "4,900,550 examples, moving-average loss 11.98, train accuracy 0.68\n",
      "4,902,150 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "4,903,750 examples, moving-average loss 11.99, train accuracy 0.68\n",
      "4,905,350 examples, moving-average loss 11.96, train accuracy 0.68\n",
      "4,906,950 examples, moving-average loss 12.06, train accuracy 0.68\n",
      "4,908,550 examples, moving-average loss 12.03, train accuracy 0.68\n",
      "4,910,150 examples, moving-average loss 12.07, train accuracy 0.68\n",
      "4,911,750 examples, moving-average loss 12.08, train accuracy 0.68\n",
      "4,913,350 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "4,914,950 examples, moving-average loss 11.99, train accuracy 0.68\n",
      "4,916,550 examples, moving-average loss 12.07, train accuracy 0.68\n",
      "4,918,150 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "4,919,750 examples, moving-average loss 11.97, train accuracy 0.68\n",
      "4,921,350 examples, moving-average loss 12.06, train accuracy 0.68\n",
      "4,922,950 examples, moving-average loss 12.05, train accuracy 0.68\n",
      "4,924,550 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "4,926,150 examples, moving-average loss 12.06, train accuracy 0.68\n",
      "4,927,750 examples, moving-average loss 12.05, train accuracy 0.68\n",
      "4,929,350 examples, moving-average loss 11.92, train accuracy 0.68\n",
      "4,930,950 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "4,932,550 examples, moving-average loss 12.14, train accuracy 0.68\n",
      "4,934,150 examples, moving-average loss 11.99, train accuracy 0.68\n",
      "4,935,750 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "4,937,350 examples, moving-average loss 11.99, train accuracy 0.68\n",
      "4,938,950 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,940,550 examples, moving-average loss 12.01, train accuracy 0.68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4,942,150 examples, moving-average loss 12.06, train accuracy 0.68\n",
      "4,943,750 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "4,945,350 examples, moving-average loss 11.98, train accuracy 0.68\n",
      "4,946,950 examples, moving-average loss 11.97, train accuracy 0.68\n",
      "4,948,550 examples, moving-average loss 11.95, train accuracy 0.68\n",
      "4,950,150 examples, moving-average loss 12.03, train accuracy 0.68\n",
      "4,951,750 examples, moving-average loss 11.95, train accuracy 0.68\n",
      "4,953,350 examples, moving-average loss 11.97, train accuracy 0.68\n",
      "4,954,950 examples, moving-average loss 12.12, train accuracy 0.68\n",
      "4,956,550 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,958,150 examples, moving-average loss 12.08, train accuracy 0.68\n",
      "4,959,750 examples, moving-average loss 12.08, train accuracy 0.68\n",
      "4,961,350 examples, moving-average loss 12.05, train accuracy 0.68\n",
      "4,962,950 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "4,964,550 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "4,966,150 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "4,967,750 examples, moving-average loss 11.97, train accuracy 0.68\n",
      "4,969,350 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "4,970,950 examples, moving-average loss 11.99, train accuracy 0.68\n",
      "4,972,550 examples, moving-average loss 11.98, train accuracy 0.68\n",
      "4,974,150 examples, moving-average loss 11.93, train accuracy 0.68\n",
      "4,975,750 examples, moving-average loss 11.96, train accuracy 0.68\n",
      "4,977,350 examples, moving-average loss 12.06, train accuracy 0.68\n",
      "4,978,950 examples, moving-average loss 12.05, train accuracy 0.68\n",
      "4,980,550 examples, moving-average loss 11.98, train accuracy 0.68\n",
      "4,982,150 examples, moving-average loss 12.05, train accuracy 0.68\n",
      "4,983,750 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "4,985,350 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "4,986,950 examples, moving-average loss 11.92, train accuracy 0.68\n",
      "4,988,550 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "4,990,150 examples, moving-average loss 11.96, train accuracy 0.68\n",
      "4,991,750 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "4,993,350 examples, moving-average loss 11.99, train accuracy 0.68\n",
      "4,994,950 examples, moving-average loss 12.06, train accuracy 0.68\n",
      "4,996,550 examples, moving-average loss 12.05, train accuracy 0.68\n",
      "4,998,150 examples, moving-average loss 11.97, train accuracy 0.68\n",
      "4,999,750 examples, moving-average loss 12.03, train accuracy 0.68\n",
      "5,001,350 examples, moving-average loss 12.03, train accuracy 0.68\n",
      "5,002,950 examples, moving-average loss 12.06, train accuracy 0.68\n",
      "5,004,550 examples, moving-average loss 12.03, train accuracy 0.68\n",
      "5,006,150 examples, moving-average loss 12.07, train accuracy 0.68\n",
      "5,007,750 examples, moving-average loss 12.05, train accuracy 0.68\n",
      "5,009,350 examples, moving-average loss 11.95, train accuracy 0.68\n",
      "5,010,950 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "5,012,550 examples, moving-average loss 11.98, train accuracy 0.68\n",
      "5,014,150 examples, moving-average loss 11.99, train accuracy 0.68\n",
      "5,015,750 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "5,017,350 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "5,018,950 examples, moving-average loss 11.97, train accuracy 0.68\n",
      "5,020,550 examples, moving-average loss 11.98, train accuracy 0.68\n",
      "5,022,150 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "5,023,750 examples, moving-average loss 11.97, train accuracy 0.68\n",
      "5,025,350 examples, moving-average loss 12.09, train accuracy 0.68\n",
      "5,026,950 examples, moving-average loss 12.07, train accuracy 0.68\n",
      "5,028,550 examples, moving-average loss 11.94, train accuracy 0.68\n",
      "5,030,150 examples, moving-average loss 12.03, train accuracy 0.68\n",
      "5,031,750 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "5,033,350 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "5,034,950 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "5,036,550 examples, moving-average loss 11.96, train accuracy 0.68\n",
      "5,038,150 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "5,039,750 examples, moving-average loss 11.95, train accuracy 0.68\n",
      "5,041,350 examples, moving-average loss 12.07, train accuracy 0.68\n",
      "5,042,950 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "5,044,550 examples, moving-average loss 11.97, train accuracy 0.68\n",
      "5,046,150 examples, moving-average loss 12.06, train accuracy 0.68\n",
      "5,047,750 examples, moving-average loss 11.99, train accuracy 0.68\n",
      "Completed 5 epoch in 0:38:21\n",
      "Train accurary:0.68169\n",
      "Validate accuracy:0.68465\n",
      "5,049,300 examples, moving-average loss 11.79, train accuracy 0.61\n",
      "5,050,900 examples, moving-average loss 11.98, train accuracy 0.67\n",
      "5,052,500 examples, moving-average loss 12.06, train accuracy 0.68\n",
      "5,054,100 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "5,055,700 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "5,057,300 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "5,058,900 examples, moving-average loss 11.98, train accuracy 0.68\n",
      "5,060,500 examples, moving-average loss 11.99, train accuracy 0.68\n",
      "5,062,100 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "5,063,700 examples, moving-average loss 11.98, train accuracy 0.68\n",
      "5,065,300 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "5,066,900 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "5,068,500 examples, moving-average loss 12.06, train accuracy 0.68\n",
      "5,070,100 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "5,071,700 examples, moving-average loss 11.99, train accuracy 0.68\n",
      "5,073,300 examples, moving-average loss 11.97, train accuracy 0.68\n",
      "5,074,900 examples, moving-average loss 11.96, train accuracy 0.68\n",
      "5,076,500 examples, moving-average loss 12.07, train accuracy 0.68\n",
      "5,078,100 examples, moving-average loss 12.09, train accuracy 0.68\n",
      "5,079,700 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "5,081,300 examples, moving-average loss 11.97, train accuracy 0.68\n",
      "5,082,900 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "5,084,500 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "5,086,100 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "5,087,700 examples, moving-average loss 11.98, train accuracy 0.68\n",
      "5,089,300 examples, moving-average loss 11.97, train accuracy 0.68\n",
      "5,090,900 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "5,092,500 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "5,094,100 examples, moving-average loss 11.96, train accuracy 0.68\n",
      "5,095,700 examples, moving-average loss 12.08, train accuracy 0.68\n",
      "5,097,300 examples, moving-average loss 12.03, train accuracy 0.68\n",
      "5,098,900 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "5,100,500 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "5,102,100 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "5,103,700 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "5,105,300 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "5,106,900 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "5,108,500 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "5,110,100 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "5,111,700 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "5,113,300 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "5,114,900 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "5,116,500 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "5,118,100 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "5,119,700 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "5,121,300 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "5,122,900 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "5,124,500 examples, moving-average loss 11.91, train accuracy 0.69\n",
      "5,126,100 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "5,127,700 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "5,129,300 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "5,130,900 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "5,132,500 examples, moving-average loss 12.09, train accuracy 0.69\n",
      "5,134,100 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "5,135,700 examples, moving-average loss 11.99, train accuracy 0.69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5,137,300 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "5,138,900 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "5,140,500 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "5,142,100 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "5,143,700 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "5,145,300 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "5,146,900 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "5,148,500 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "5,150,100 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "5,151,700 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "5,153,300 examples, moving-average loss 12.07, train accuracy 0.69\n",
      "5,154,900 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "5,156,500 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "5,158,100 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "5,159,700 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "5,161,300 examples, moving-average loss 12.05, train accuracy 0.68\n",
      "5,162,900 examples, moving-average loss 12.05, train accuracy 0.68\n",
      "5,164,500 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "5,166,100 examples, moving-average loss 11.95, train accuracy 0.68\n",
      "5,167,700 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "5,169,300 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "5,170,900 examples, moving-average loss 11.98, train accuracy 0.68\n",
      "5,172,500 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "5,174,100 examples, moving-average loss 12.05, train accuracy 0.68\n",
      "5,175,700 examples, moving-average loss 12.08, train accuracy 0.68\n",
      "5,177,300 examples, moving-average loss 11.98, train accuracy 0.68\n",
      "5,178,900 examples, moving-average loss 11.95, train accuracy 0.68\n",
      "5,180,500 examples, moving-average loss 12.07, train accuracy 0.68\n",
      "5,182,100 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "5,183,700 examples, moving-average loss 12.09, train accuracy 0.68\n",
      "5,185,300 examples, moving-average loss 12.11, train accuracy 0.68\n",
      "5,186,900 examples, moving-average loss 12.07, train accuracy 0.68\n",
      "5,188,500 examples, moving-average loss 12.06, train accuracy 0.68\n",
      "5,190,100 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "5,191,700 examples, moving-average loss 12.03, train accuracy 0.68\n",
      "5,193,300 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "5,194,900 examples, moving-average loss 11.99, train accuracy 0.68\n",
      "5,196,500 examples, moving-average loss 12.10, train accuracy 0.68\n",
      "5,198,100 examples, moving-average loss 11.99, train accuracy 0.68\n",
      "5,199,700 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "5,201,300 examples, moving-average loss 12.08, train accuracy 0.68\n",
      "5,202,900 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "5,204,500 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "5,206,100 examples, moving-average loss 11.92, train accuracy 0.68\n",
      "5,207,700 examples, moving-average loss 11.99, train accuracy 0.68\n",
      "5,209,300 examples, moving-average loss 12.03, train accuracy 0.68\n",
      "5,210,900 examples, moving-average loss 11.94, train accuracy 0.68\n",
      "5,212,500 examples, moving-average loss 11.97, train accuracy 0.68\n",
      "5,214,100 examples, moving-average loss 11.93, train accuracy 0.68\n",
      "5,215,700 examples, moving-average loss 12.06, train accuracy 0.68\n",
      "5,217,300 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "5,218,900 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "5,220,500 examples, moving-average loss 12.03, train accuracy 0.68\n",
      "5,222,100 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "5,223,700 examples, moving-average loss 12.08, train accuracy 0.68\n",
      "5,225,300 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "5,226,900 examples, moving-average loss 12.08, train accuracy 0.68\n",
      "5,228,500 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "5,230,100 examples, moving-average loss 11.98, train accuracy 0.68\n",
      "5,231,700 examples, moving-average loss 12.03, train accuracy 0.68\n",
      "5,233,300 examples, moving-average loss 11.97, train accuracy 0.68\n",
      "5,234,900 examples, moving-average loss 12.05, train accuracy 0.68\n",
      "5,236,500 examples, moving-average loss 12.07, train accuracy 0.68\n",
      "5,238,100 examples, moving-average loss 11.96, train accuracy 0.68\n",
      "5,239,700 examples, moving-average loss 12.03, train accuracy 0.68\n",
      "5,241,300 examples, moving-average loss 11.99, train accuracy 0.68\n",
      "5,242,900 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "5,244,500 examples, moving-average loss 11.97, train accuracy 0.68\n",
      "5,246,100 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "5,247,700 examples, moving-average loss 12.06, train accuracy 0.68\n",
      "5,249,300 examples, moving-average loss 11.97, train accuracy 0.68\n",
      "5,250,900 examples, moving-average loss 11.99, train accuracy 0.68\n",
      "5,252,500 examples, moving-average loss 12.06, train accuracy 0.68\n",
      "5,254,100 examples, moving-average loss 11.89, train accuracy 0.68\n",
      "5,255,700 examples, moving-average loss 11.99, train accuracy 0.68\n",
      "5,257,300 examples, moving-average loss 11.92, train accuracy 0.68\n",
      "5,258,900 examples, moving-average loss 12.08, train accuracy 0.68\n",
      "5,260,500 examples, moving-average loss 11.95, train accuracy 0.68\n",
      "5,262,100 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "5,263,700 examples, moving-average loss 12.08, train accuracy 0.68\n",
      "5,265,300 examples, moving-average loss 12.09, train accuracy 0.68\n",
      "5,266,900 examples, moving-average loss 12.10, train accuracy 0.68\n",
      "5,268,500 examples, moving-average loss 11.94, train accuracy 0.68\n",
      "5,270,100 examples, moving-average loss 11.91, train accuracy 0.68\n",
      "5,271,700 examples, moving-average loss 11.90, train accuracy 0.68\n",
      "5,273,300 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "5,274,900 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "5,276,500 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "5,278,100 examples, moving-average loss 12.05, train accuracy 0.68\n",
      "5,279,700 examples, moving-average loss 12.03, train accuracy 0.68\n",
      "5,281,300 examples, moving-average loss 11.93, train accuracy 0.68\n",
      "5,282,900 examples, moving-average loss 11.94, train accuracy 0.68\n",
      "5,284,500 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "5,286,100 examples, moving-average loss 12.09, train accuracy 0.68\n",
      "5,287,700 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "5,289,300 examples, moving-average loss 11.98, train accuracy 0.68\n",
      "5,290,900 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "5,292,500 examples, moving-average loss 11.95, train accuracy 0.68\n",
      "5,294,100 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "5,295,700 examples, moving-average loss 11.96, train accuracy 0.68\n",
      "5,297,300 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "5,298,900 examples, moving-average loss 12.08, train accuracy 0.68\n",
      "5,300,500 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "5,302,100 examples, moving-average loss 11.99, train accuracy 0.68\n",
      "5,303,700 examples, moving-average loss 11.98, train accuracy 0.68\n",
      "5,305,300 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "5,306,900 examples, moving-average loss 11.99, train accuracy 0.68\n",
      "5,308,500 examples, moving-average loss 12.10, train accuracy 0.68\n",
      "5,310,100 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "5,311,700 examples, moving-average loss 11.93, train accuracy 0.68\n",
      "5,313,300 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "5,314,900 examples, moving-average loss 11.98, train accuracy 0.68\n",
      "5,316,500 examples, moving-average loss 11.99, train accuracy 0.68\n",
      "5,318,100 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "5,319,700 examples, moving-average loss 11.98, train accuracy 0.68\n",
      "5,321,300 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "5,322,900 examples, moving-average loss 12.10, train accuracy 0.68\n",
      "5,324,500 examples, moving-average loss 11.94, train accuracy 0.68\n",
      "5,326,100 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "5,327,700 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "5,329,300 examples, moving-average loss 12.03, train accuracy 0.68\n",
      "5,330,900 examples, moving-average loss 12.11, train accuracy 0.68\n",
      "5,332,500 examples, moving-average loss 11.96, train accuracy 0.68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5,334,100 examples, moving-average loss 11.95, train accuracy 0.68\n",
      "5,335,700 examples, moving-average loss 11.92, train accuracy 0.68\n",
      "5,337,300 examples, moving-average loss 12.01, train accuracy 0.68\n",
      "5,338,900 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "5,340,500 examples, moving-average loss 11.98, train accuracy 0.68\n",
      "5,342,100 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "5,343,700 examples, moving-average loss 11.99, train accuracy 0.68\n",
      "5,345,300 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "5,346,900 examples, moving-average loss 11.98, train accuracy 0.68\n",
      "5,348,500 examples, moving-average loss 12.00, train accuracy 0.68\n",
      "5,350,100 examples, moving-average loss 11.94, train accuracy 0.68\n",
      "5,351,700 examples, moving-average loss 12.04, train accuracy 0.68\n",
      "5,353,300 examples, moving-average loss 11.94, train accuracy 0.68\n",
      "5,354,900 examples, moving-average loss 11.93, train accuracy 0.68\n",
      "5,356,500 examples, moving-average loss 11.96, train accuracy 0.68\n",
      "5,358,100 examples, moving-average loss 11.98, train accuracy 0.68\n",
      "5,359,700 examples, moving-average loss 11.92, train accuracy 0.69\n",
      "5,361,300 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "5,362,900 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "5,364,500 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "5,366,100 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "5,367,700 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "5,369,300 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "5,370,900 examples, moving-average loss 12.07, train accuracy 0.69\n",
      "5,372,500 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "5,374,100 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "5,375,700 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "5,377,300 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "5,378,900 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "5,380,500 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "5,382,100 examples, moving-average loss 11.93, train accuracy 0.69\n",
      "5,383,700 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "5,385,300 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "5,386,900 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "5,388,500 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "5,390,100 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "5,391,700 examples, moving-average loss 11.94, train accuracy 0.69\n",
      "5,393,300 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "5,394,900 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "5,396,500 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "5,398,100 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "5,399,700 examples, moving-average loss 11.89, train accuracy 0.69\n",
      "5,401,300 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "5,402,900 examples, moving-average loss 12.08, train accuracy 0.69\n",
      "5,404,500 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "5,406,100 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "5,407,700 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "5,409,300 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "5,410,900 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "5,412,500 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "5,414,100 examples, moving-average loss 11.91, train accuracy 0.69\n",
      "5,415,700 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "5,417,300 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "5,418,900 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "5,420,500 examples, moving-average loss 12.14, train accuracy 0.69\n",
      "5,422,100 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "5,423,700 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "5,425,300 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "5,426,900 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "5,428,500 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "5,430,100 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "5,431,700 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "5,433,300 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "5,434,900 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "5,436,500 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "5,438,100 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "5,439,700 examples, moving-average loss 12.09, train accuracy 0.69\n",
      "5,441,300 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "5,442,900 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "5,444,500 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "5,446,100 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "5,447,700 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "5,449,300 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "5,450,900 examples, moving-average loss 11.92, train accuracy 0.69\n",
      "5,452,500 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "5,454,100 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "5,455,700 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "5,457,300 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "5,458,900 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "5,460,500 examples, moving-average loss 12.07, train accuracy 0.69\n",
      "5,462,100 examples, moving-average loss 12.13, train accuracy 0.69\n",
      "5,463,700 examples, moving-average loss 12.08, train accuracy 0.69\n",
      "5,465,300 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "5,466,900 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "5,468,500 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "5,470,100 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "5,471,700 examples, moving-average loss 12.08, train accuracy 0.69\n",
      "5,473,300 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "5,474,900 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "5,476,500 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "5,478,100 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "5,479,700 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "5,481,300 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "5,482,900 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "5,484,500 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "5,486,100 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "5,487,700 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "5,489,300 examples, moving-average loss 11.94, train accuracy 0.69\n",
      "5,490,900 examples, moving-average loss 12.08, train accuracy 0.69\n",
      "5,492,500 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "5,494,100 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "5,495,700 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "5,497,300 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "5,498,900 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "5,500,500 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "5,502,100 examples, moving-average loss 11.94, train accuracy 0.69\n",
      "5,503,700 examples, moving-average loss 12.07, train accuracy 0.69\n",
      "5,505,300 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "5,506,900 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "5,508,500 examples, moving-average loss 11.94, train accuracy 0.69\n",
      "5,510,100 examples, moving-average loss 12.07, train accuracy 0.69\n",
      "5,511,700 examples, moving-average loss 12.08, train accuracy 0.69\n",
      "5,513,300 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "5,514,900 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "5,516,500 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "5,518,100 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "5,519,700 examples, moving-average loss 12.07, train accuracy 0.69\n",
      "5,521,300 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "5,522,900 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "5,524,500 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "5,526,100 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "5,527,700 examples, moving-average loss 11.93, train accuracy 0.69\n",
      "5,529,300 examples, moving-average loss 11.97, train accuracy 0.69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5,530,900 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "5,532,500 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "5,534,100 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "5,535,700 examples, moving-average loss 12.08, train accuracy 0.69\n",
      "5,537,300 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "5,538,900 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "5,540,500 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "5,542,100 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "5,543,700 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "5,545,300 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "5,546,900 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "5,548,500 examples, moving-average loss 11.94, train accuracy 0.69\n",
      "5,550,100 examples, moving-average loss 11.89, train accuracy 0.69\n",
      "5,551,700 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "5,553,300 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "5,554,900 examples, moving-average loss 12.07, train accuracy 0.69\n",
      "5,556,500 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "5,558,100 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "5,559,700 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "5,561,300 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "5,562,900 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "5,564,500 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "5,566,100 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "5,567,700 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "5,569,300 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "5,570,900 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "5,572,500 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "5,574,100 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "5,575,700 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "5,577,300 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "5,578,900 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "5,580,500 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "5,582,100 examples, moving-average loss 12.07, train accuracy 0.69\n",
      "5,583,700 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "5,585,300 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "5,586,900 examples, moving-average loss 11.92, train accuracy 0.69\n",
      "5,588,500 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "5,590,100 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "5,591,700 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "5,593,300 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "5,594,900 examples, moving-average loss 11.90, train accuracy 0.69\n",
      "5,596,500 examples, moving-average loss 12.09, train accuracy 0.69\n",
      "5,598,100 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "5,599,700 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "5,601,300 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "5,602,900 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "5,604,500 examples, moving-average loss 12.07, train accuracy 0.69\n",
      "5,606,100 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "5,607,700 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "5,609,300 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "5,610,900 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "5,612,500 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "5,614,100 examples, moving-average loss 11.93, train accuracy 0.69\n",
      "5,615,700 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "5,617,300 examples, moving-average loss 11.92, train accuracy 0.69\n",
      "5,618,900 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "5,620,500 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "5,622,100 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "5,623,700 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "5,625,300 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "5,626,900 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "5,628,500 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "5,630,100 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "5,631,700 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "5,633,300 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "5,634,900 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "5,636,500 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "5,638,100 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "5,639,700 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "5,641,300 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "5,642,900 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "5,644,500 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "5,646,100 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "5,647,700 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "5,649,300 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "5,650,900 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "5,652,500 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "5,654,100 examples, moving-average loss 11.88, train accuracy 0.69\n",
      "5,655,700 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "5,657,300 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "5,658,900 examples, moving-average loss 11.93, train accuracy 0.69\n",
      "5,660,500 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "5,662,100 examples, moving-average loss 12.10, train accuracy 0.69\n",
      "5,663,700 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "5,665,300 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "5,666,900 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "5,668,500 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "5,670,100 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "5,671,700 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "5,673,300 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "5,674,900 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "5,676,500 examples, moving-average loss 12.07, train accuracy 0.69\n",
      "5,678,100 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "5,679,700 examples, moving-average loss 12.08, train accuracy 0.69\n",
      "5,681,300 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "5,682,900 examples, moving-average loss 11.91, train accuracy 0.69\n",
      "5,684,500 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "5,686,100 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "5,687,700 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "5,689,300 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "5,690,900 examples, moving-average loss 12.09, train accuracy 0.69\n",
      "5,692,500 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "5,694,100 examples, moving-average loss 12.10, train accuracy 0.69\n",
      "5,695,700 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "5,697,300 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "5,698,900 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "5,700,500 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "5,702,100 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "5,703,700 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "5,705,300 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "5,706,900 examples, moving-average loss 12.10, train accuracy 0.69\n",
      "5,708,500 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "5,710,100 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "5,711,700 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "5,713,300 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "5,714,900 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "5,716,500 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "5,718,100 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "5,719,700 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "5,721,300 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "5,722,900 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "5,724,500 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "5,726,100 examples, moving-average loss 12.01, train accuracy 0.69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5,727,700 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "5,729,300 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "5,730,900 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "5,732,500 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "5,734,100 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "5,735,700 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "5,737,300 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "5,738,900 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "5,740,500 examples, moving-average loss 12.07, train accuracy 0.69\n",
      "5,742,100 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "5,743,700 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "5,745,300 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "5,746,900 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "5,748,500 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "5,750,100 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "5,751,700 examples, moving-average loss 12.09, train accuracy 0.69\n",
      "5,753,300 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "5,754,900 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "5,756,500 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "5,758,100 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "5,759,700 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "5,761,300 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "5,762,900 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "5,764,500 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "5,766,100 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "5,767,700 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "5,769,300 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "5,770,900 examples, moving-average loss 11.92, train accuracy 0.69\n",
      "5,772,500 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "5,774,100 examples, moving-average loss 12.11, train accuracy 0.69\n",
      "5,775,700 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "5,777,300 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "5,778,900 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "5,780,500 examples, moving-average loss 12.09, train accuracy 0.69\n",
      "5,782,100 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "5,783,700 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "5,785,300 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "5,786,900 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "5,788,500 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "5,790,100 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "5,791,700 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "5,793,300 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "5,794,900 examples, moving-average loss 11.92, train accuracy 0.69\n",
      "5,796,500 examples, moving-average loss 12.09, train accuracy 0.69\n",
      "5,798,100 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "5,799,700 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "5,801,300 examples, moving-average loss 12.10, train accuracy 0.69\n",
      "5,802,900 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "5,804,500 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "5,806,100 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "5,807,700 examples, moving-average loss 12.08, train accuracy 0.69\n",
      "5,809,300 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "5,810,900 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "5,812,500 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "5,814,100 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "5,815,700 examples, moving-average loss 11.94, train accuracy 0.69\n",
      "5,817,300 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "5,818,900 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "5,820,500 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "5,822,100 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "5,823,700 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "5,825,300 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "5,826,900 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "5,828,500 examples, moving-average loss 11.92, train accuracy 0.69\n",
      "5,830,100 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "5,831,700 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "5,833,300 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "5,834,900 examples, moving-average loss 11.94, train accuracy 0.69\n",
      "5,836,500 examples, moving-average loss 12.07, train accuracy 0.69\n",
      "5,838,100 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "5,839,700 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "5,841,300 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "5,842,900 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "5,844,500 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "5,846,100 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "5,847,700 examples, moving-average loss 12.08, train accuracy 0.69\n",
      "5,849,300 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "5,850,900 examples, moving-average loss 11.94, train accuracy 0.69\n",
      "5,852,500 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "5,854,100 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "5,855,700 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "5,857,300 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "5,858,900 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "5,860,500 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "5,862,100 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "5,863,700 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "5,865,300 examples, moving-average loss 11.94, train accuracy 0.69\n",
      "5,866,900 examples, moving-average loss 12.07, train accuracy 0.69\n",
      "5,868,500 examples, moving-average loss 12.08, train accuracy 0.69\n",
      "5,870,100 examples, moving-average loss 11.91, train accuracy 0.69\n",
      "5,871,700 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "5,873,300 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "5,874,900 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "5,876,500 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "5,878,100 examples, moving-average loss 11.91, train accuracy 0.69\n",
      "5,879,700 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "5,881,300 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "5,882,900 examples, moving-average loss 12.09, train accuracy 0.69\n",
      "5,884,500 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "5,886,100 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "5,887,700 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "5,889,300 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "Completed 6 epoch in 0:38:17\n",
      "Train accurary:0.68685\n",
      "Validate accuracy:0.68793\n",
      "5,890,850 examples, moving-average loss 11.85, train accuracy 0.62\n",
      "5,892,450 examples, moving-average loss 12.00, train accuracy 0.67\n",
      "5,894,050 examples, moving-average loss 12.06, train accuracy 0.68\n",
      "5,895,650 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "5,897,250 examples, moving-average loss 12.05, train accuracy 0.68\n",
      "5,898,850 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "5,900,450 examples, moving-average loss 11.99, train accuracy 0.68\n",
      "5,902,050 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "5,903,650 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "5,905,250 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "5,906,850 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "5,908,450 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "5,910,050 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "5,911,650 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "5,913,250 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "5,914,850 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "5,916,450 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "5,918,050 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "5,919,650 examples, moving-average loss 12.08, train accuracy 0.69\n",
      "5,921,250 examples, moving-average loss 12.03, train accuracy 0.69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5,922,850 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "5,924,450 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "5,926,050 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "5,927,650 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "5,929,250 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "5,930,850 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "5,932,450 examples, moving-average loss 11.94, train accuracy 0.69\n",
      "5,934,050 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "5,935,650 examples, moving-average loss 11.91, train accuracy 0.69\n",
      "5,937,250 examples, moving-average loss 12.08, train accuracy 0.69\n",
      "5,938,850 examples, moving-average loss 12.07, train accuracy 0.69\n",
      "5,940,450 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "5,942,050 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "5,943,650 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "5,945,250 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "5,946,850 examples, moving-average loss 11.93, train accuracy 0.69\n",
      "5,948,450 examples, moving-average loss 12.07, train accuracy 0.69\n",
      "5,950,050 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "5,951,650 examples, moving-average loss 12.08, train accuracy 0.69\n",
      "5,953,250 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "5,954,850 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "5,956,450 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "5,958,050 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "5,959,650 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "5,961,250 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "5,962,850 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "5,964,450 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "5,966,050 examples, moving-average loss 11.94, train accuracy 0.69\n",
      "5,967,650 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "5,969,250 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "5,970,850 examples, moving-average loss 11.92, train accuracy 0.69\n",
      "5,972,450 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "5,974,050 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "5,975,650 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "5,977,250 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "5,978,850 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "5,980,450 examples, moving-average loss 11.94, train accuracy 0.69\n",
      "5,982,050 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "5,983,650 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "5,985,250 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "5,986,850 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "5,988,450 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "5,990,050 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "5,991,650 examples, moving-average loss 11.93, train accuracy 0.69\n",
      "5,993,250 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "5,994,850 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "5,996,450 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "5,998,050 examples, moving-average loss 12.10, train accuracy 0.69\n",
      "5,999,650 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "6,001,250 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "6,002,850 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "6,004,450 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "6,006,050 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "6,007,650 examples, moving-average loss 11.92, train accuracy 0.69\n",
      "6,009,250 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "6,010,850 examples, moving-average loss 12.07, train accuracy 0.69\n",
      "6,012,450 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "6,014,050 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "6,015,650 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "6,017,250 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "6,018,850 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "6,020,450 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "6,022,050 examples, moving-average loss 12.07, train accuracy 0.69\n",
      "6,023,650 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,025,250 examples, moving-average loss 12.08, train accuracy 0.69\n",
      "6,026,850 examples, moving-average loss 12.10, train accuracy 0.69\n",
      "6,028,450 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "6,030,050 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "6,031,650 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "6,033,250 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "6,034,850 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "6,036,450 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "6,038,050 examples, moving-average loss 12.09, train accuracy 0.69\n",
      "6,039,650 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,041,250 examples, moving-average loss 11.94, train accuracy 0.69\n",
      "6,042,850 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "6,044,450 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "6,046,050 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "6,047,650 examples, moving-average loss 11.93, train accuracy 0.69\n",
      "6,049,250 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "6,050,850 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "6,052,450 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "6,054,050 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "6,055,650 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "6,057,250 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "6,058,850 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "6,060,450 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "6,062,050 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "6,063,650 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,065,250 examples, moving-average loss 12.09, train accuracy 0.69\n",
      "6,066,850 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "6,068,450 examples, moving-average loss 12.09, train accuracy 0.69\n",
      "6,070,050 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "6,071,650 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "6,073,250 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "6,074,850 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "6,076,450 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "6,078,050 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "6,079,650 examples, moving-average loss 11.93, train accuracy 0.69\n",
      "6,081,250 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "6,082,850 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,084,450 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "6,086,050 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "6,087,650 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "6,089,250 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "6,090,850 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,092,450 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "6,094,050 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "6,095,650 examples, moving-average loss 11.91, train accuracy 0.69\n",
      "6,097,250 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "6,098,850 examples, moving-average loss 11.91, train accuracy 0.69\n",
      "6,100,450 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "6,102,050 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "6,103,650 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "6,105,250 examples, moving-average loss 12.07, train accuracy 0.69\n",
      "6,106,850 examples, moving-average loss 12.09, train accuracy 0.69\n",
      "6,108,450 examples, moving-average loss 12.10, train accuracy 0.69\n",
      "6,110,050 examples, moving-average loss 11.93, train accuracy 0.69\n",
      "6,111,650 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "6,113,250 examples, moving-average loss 11.87, train accuracy 0.69\n",
      "6,114,850 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "6,116,450 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "6,118,050 examples, moving-average loss 12.04, train accuracy 0.69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6,119,650 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "6,121,250 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,122,850 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "6,124,450 examples, moving-average loss 11.89, train accuracy 0.69\n",
      "6,126,050 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "6,127,650 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "6,129,250 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "6,130,850 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "6,132,450 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "6,134,050 examples, moving-average loss 11.90, train accuracy 0.69\n",
      "6,135,650 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,137,250 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "6,138,850 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,140,450 examples, moving-average loss 12.07, train accuracy 0.69\n",
      "6,142,050 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,143,650 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "6,145,250 examples, moving-average loss 11.94, train accuracy 0.69\n",
      "6,146,850 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "6,148,450 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "6,150,050 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "6,151,650 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "6,153,250 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "6,154,850 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "6,156,450 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,158,050 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,159,650 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "6,161,250 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "6,162,850 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,164,450 examples, moving-average loss 12.10, train accuracy 0.69\n",
      "6,166,050 examples, moving-average loss 11.93, train accuracy 0.69\n",
      "6,167,650 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "6,169,250 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "6,170,850 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "6,172,450 examples, moving-average loss 12.08, train accuracy 0.69\n",
      "6,174,050 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "6,175,650 examples, moving-average loss 11.93, train accuracy 0.69\n",
      "6,177,250 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "6,178,850 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "6,180,450 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "6,182,050 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "6,183,650 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,185,250 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,186,850 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "6,188,450 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,190,050 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "6,191,650 examples, moving-average loss 11.94, train accuracy 0.69\n",
      "6,193,250 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "6,194,850 examples, moving-average loss 11.93, train accuracy 0.69\n",
      "6,196,450 examples, moving-average loss 11.93, train accuracy 0.69\n",
      "6,198,050 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "6,199,650 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "6,201,250 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "6,202,850 examples, moving-average loss 11.93, train accuracy 0.69\n",
      "6,204,450 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "6,206,050 examples, moving-average loss 11.93, train accuracy 0.69\n",
      "6,207,650 examples, moving-average loss 11.94, train accuracy 0.69\n",
      "6,209,250 examples, moving-average loss 11.92, train accuracy 0.69\n",
      "6,210,850 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "6,212,450 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "6,214,050 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,215,650 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,217,250 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "6,218,850 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "6,220,450 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "6,222,050 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,223,650 examples, moving-average loss 11.92, train accuracy 0.69\n",
      "6,225,250 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "6,226,850 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "6,228,450 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "6,230,050 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "6,231,650 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "6,233,250 examples, moving-average loss 11.90, train accuracy 0.69\n",
      "6,234,850 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "6,236,450 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "6,238,050 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "6,239,650 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "6,241,250 examples, moving-average loss 11.93, train accuracy 0.69\n",
      "6,242,850 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,244,450 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "6,246,050 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "6,247,650 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "6,249,250 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,250,850 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "6,252,450 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "6,254,050 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "6,255,650 examples, moving-average loss 11.93, train accuracy 0.69\n",
      "6,257,250 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "6,258,850 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,260,450 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "6,262,050 examples, moving-average loss 12.13, train accuracy 0.69\n",
      "6,263,650 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,265,250 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "6,266,850 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "6,268,450 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "6,270,050 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "6,271,650 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "6,273,250 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,274,850 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,276,450 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "6,278,050 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "6,279,650 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "6,281,250 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "6,282,850 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "6,284,450 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "6,286,050 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "6,287,650 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "6,289,250 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "6,290,850 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,292,450 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "6,294,050 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "6,295,650 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "6,297,250 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "6,298,850 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "6,300,450 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "6,302,050 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "6,303,650 examples, moving-average loss 12.10, train accuracy 0.69\n",
      "6,305,250 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,306,850 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "6,308,450 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "6,310,050 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "6,311,650 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "6,313,250 examples, moving-average loss 12.07, train accuracy 0.69\n",
      "6,314,850 examples, moving-average loss 11.98, train accuracy 0.69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6,316,450 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "6,318,050 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,319,650 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,321,250 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "6,322,850 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "6,324,450 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,326,050 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "6,327,650 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "6,329,250 examples, moving-average loss 11.91, train accuracy 0.69\n",
      "6,330,850 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "6,332,450 examples, moving-average loss 12.08, train accuracy 0.69\n",
      "6,334,050 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "6,335,650 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "6,337,250 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,338,850 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "6,340,450 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "6,342,050 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "6,343,650 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "6,345,250 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "6,346,850 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "6,348,450 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "6,350,050 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,351,650 examples, moving-average loss 12.08, train accuracy 0.69\n",
      "6,353,250 examples, moving-average loss 12.08, train accuracy 0.69\n",
      "6,354,850 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,356,450 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "6,358,050 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,359,650 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "6,361,250 examples, moving-average loss 12.07, train accuracy 0.69\n",
      "6,362,850 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "6,364,450 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "6,366,050 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "6,367,650 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "6,369,250 examples, moving-average loss 11.90, train accuracy 0.69\n",
      "6,370,850 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "6,372,450 examples, moving-average loss 11.92, train accuracy 0.69\n",
      "6,374,050 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,375,650 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,377,250 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "6,378,850 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "6,380,450 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,382,050 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "6,383,650 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "6,385,250 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,386,850 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "6,388,450 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "6,390,050 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "6,391,650 examples, moving-average loss 11.91, train accuracy 0.69\n",
      "6,393,250 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "6,394,850 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "6,396,450 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "6,398,050 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "6,399,650 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "6,401,250 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "6,402,850 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "6,404,450 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "6,406,050 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "6,407,650 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "6,409,250 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,410,850 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,412,450 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "6,414,050 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "6,415,650 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "6,417,250 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "6,418,850 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "6,420,450 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "6,422,050 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "6,423,650 examples, moving-average loss 12.09, train accuracy 0.69\n",
      "6,425,250 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,426,850 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "6,428,450 examples, moving-average loss 11.93, train accuracy 0.69\n",
      "6,430,050 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "6,431,650 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "6,433,250 examples, moving-average loss 11.93, train accuracy 0.69\n",
      "6,434,850 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,436,450 examples, moving-average loss 11.89, train accuracy 0.69\n",
      "6,438,050 examples, moving-average loss 12.07, train accuracy 0.69\n",
      "6,439,650 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "6,441,250 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "6,442,850 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "6,444,450 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,446,050 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "6,447,650 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "6,449,250 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,450,850 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "6,452,450 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "6,454,050 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "6,455,650 examples, moving-average loss 11.94, train accuracy 0.69\n",
      "6,457,250 examples, moving-average loss 12.07, train accuracy 0.69\n",
      "6,458,850 examples, moving-average loss 11.94, train accuracy 0.69\n",
      "6,460,450 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "6,462,050 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "6,463,650 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "6,465,250 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "6,466,850 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "6,468,450 examples, moving-average loss 12.10, train accuracy 0.69\n",
      "6,470,050 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "6,471,650 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "6,473,250 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "6,474,850 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "6,476,450 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "6,478,050 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,479,650 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,481,250 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "6,482,850 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "6,484,450 examples, moving-average loss 11.91, train accuracy 0.69\n",
      "6,486,050 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "6,487,650 examples, moving-average loss 11.94, train accuracy 0.69\n",
      "6,489,250 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "6,490,850 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "6,492,450 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "6,494,050 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,495,650 examples, moving-average loss 11.90, train accuracy 0.69\n",
      "6,497,250 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "6,498,850 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,500,450 examples, moving-average loss 11.90, train accuracy 0.69\n",
      "6,502,050 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "6,503,650 examples, moving-average loss 12.10, train accuracy 0.69\n",
      "6,505,250 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "6,506,850 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "6,508,450 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "6,510,050 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,511,650 examples, moving-average loss 11.96, train accuracy 0.69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6,513,250 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,514,850 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "6,516,450 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "6,518,050 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "6,519,650 examples, moving-average loss 12.07, train accuracy 0.69\n",
      "6,521,250 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "6,522,850 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "6,524,450 examples, moving-average loss 11.90, train accuracy 0.69\n",
      "6,526,050 examples, moving-average loss 11.93, train accuracy 0.69\n",
      "6,527,650 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "6,529,250 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,530,850 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "6,532,450 examples, moving-average loss 12.07, train accuracy 0.69\n",
      "6,534,050 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,535,650 examples, moving-average loss 12.09, train accuracy 0.69\n",
      "6,537,250 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,538,850 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "6,540,450 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,542,050 examples, moving-average loss 11.94, train accuracy 0.69\n",
      "6,543,650 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "6,545,250 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,546,850 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "6,548,450 examples, moving-average loss 12.08, train accuracy 0.69\n",
      "6,550,050 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "6,551,650 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "6,553,250 examples, moving-average loss 12.07, train accuracy 0.69\n",
      "6,554,850 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "6,556,450 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "6,558,050 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "6,559,650 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "6,561,250 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,562,850 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "6,564,450 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "6,566,050 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "6,567,650 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "6,569,250 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "6,570,850 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "6,572,450 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,574,050 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "6,575,650 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "6,577,250 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,578,850 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,580,450 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "6,582,050 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "6,583,650 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,585,250 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "6,586,850 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,588,450 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,590,050 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "6,591,650 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,593,250 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "6,594,850 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "6,596,450 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "6,598,050 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,599,650 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "6,601,250 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,602,850 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "6,604,450 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "6,606,050 examples, moving-average loss 12.07, train accuracy 0.69\n",
      "6,607,650 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "6,609,250 examples, moving-average loss 12.11, train accuracy 0.69\n",
      "6,610,850 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,612,450 examples, moving-average loss 11.93, train accuracy 0.69\n",
      "6,614,050 examples, moving-average loss 12.09, train accuracy 0.69\n",
      "6,615,650 examples, moving-average loss 12.13, train accuracy 0.69\n",
      "6,617,250 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "6,618,850 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "6,620,450 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "6,622,050 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "6,623,650 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,625,250 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "6,626,850 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "6,628,450 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,630,050 examples, moving-average loss 11.93, train accuracy 0.69\n",
      "6,631,650 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "6,633,250 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "6,634,850 examples, moving-average loss 11.92, train accuracy 0.69\n",
      "6,636,450 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "6,638,050 examples, moving-average loss 12.10, train accuracy 0.69\n",
      "6,639,650 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "6,641,250 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "6,642,850 examples, moving-average loss 12.07, train accuracy 0.69\n",
      "6,644,450 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "6,646,050 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "6,647,650 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "6,649,250 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "6,650,850 examples, moving-average loss 11.93, train accuracy 0.69\n",
      "6,652,450 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "6,654,050 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "6,655,650 examples, moving-average loss 11.93, train accuracy 0.69\n",
      "6,657,250 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "6,658,850 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "6,660,450 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "6,662,050 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,663,650 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "6,665,250 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "6,666,850 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,668,450 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "6,670,050 examples, moving-average loss 11.93, train accuracy 0.69\n",
      "6,671,650 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "6,673,250 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "6,674,850 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "6,676,450 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "6,678,050 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "6,679,650 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "6,681,250 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,682,850 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "6,684,450 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "6,686,050 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "6,687,650 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "6,689,250 examples, moving-average loss 12.07, train accuracy 0.69\n",
      "6,690,850 examples, moving-average loss 12.10, train accuracy 0.69\n",
      "6,692,450 examples, moving-average loss 11.94, train accuracy 0.69\n",
      "6,694,050 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "6,695,650 examples, moving-average loss 11.94, train accuracy 0.69\n",
      "6,697,250 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,698,850 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "6,700,450 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "6,702,050 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "6,703,650 examples, moving-average loss 11.93, train accuracy 0.69\n",
      "6,705,250 examples, moving-average loss 11.94, train accuracy 0.69\n",
      "6,706,850 examples, moving-average loss 11.91, train accuracy 0.69\n",
      "6,708,450 examples, moving-average loss 12.06, train accuracy 0.69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6,710,050 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "6,711,650 examples, moving-average loss 11.93, train accuracy 0.69\n",
      "6,713,250 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "6,714,850 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "6,716,450 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "6,718,050 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,719,650 examples, moving-average loss 11.90, train accuracy 0.69\n",
      "6,721,250 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,722,850 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "6,724,450 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "6,726,050 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "6,727,650 examples, moving-average loss 11.94, train accuracy 0.69\n",
      "6,729,250 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "6,730,850 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "Completed 7 epoch in 0:38:41\n",
      "Train accurary:0.69135\n",
      "Validate accuracy:0.69025\n",
      "6,732,400 examples, moving-average loss 11.88, train accuracy 0.62\n",
      "6,734,000 examples, moving-average loss 11.98, train accuracy 0.67\n",
      "6,735,600 examples, moving-average loss 12.02, train accuracy 0.68\n",
      "6,737,200 examples, moving-average loss 12.06, train accuracy 0.68\n",
      "6,738,800 examples, moving-average loss 12.05, train accuracy 0.68\n",
      "6,740,400 examples, moving-average loss 11.99, train accuracy 0.68\n",
      "6,742,000 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "6,743,600 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "6,745,200 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "6,746,800 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,748,400 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "6,750,000 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,751,600 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,753,200 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,754,800 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "6,756,400 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "6,758,000 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "6,759,600 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "6,761,200 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "6,762,800 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,764,400 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "6,766,000 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "6,767,600 examples, moving-average loss 11.94, train accuracy 0.69\n",
      "6,769,200 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "6,770,800 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,772,400 examples, moving-average loss 11.90, train accuracy 0.69\n",
      "6,774,000 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "6,775,600 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "6,777,200 examples, moving-average loss 11.92, train accuracy 0.69\n",
      "6,778,800 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "6,780,400 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "6,782,000 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "6,783,600 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "6,785,200 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "6,786,800 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,788,400 examples, moving-average loss 11.91, train accuracy 0.69\n",
      "6,790,000 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "6,791,600 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "6,793,200 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "6,794,800 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,796,400 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,798,000 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "6,799,600 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "6,801,200 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "6,802,800 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "6,804,400 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "6,806,000 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,807,600 examples, moving-average loss 11.93, train accuracy 0.69\n",
      "6,809,200 examples, moving-average loss 11.93, train accuracy 0.69\n",
      "6,810,800 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "6,812,400 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "6,814,000 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "6,815,600 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "6,817,200 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "6,818,800 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "6,820,400 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,822,000 examples, moving-average loss 11.93, train accuracy 0.69\n",
      "6,823,600 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "6,825,200 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "6,826,800 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "6,828,400 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "6,830,000 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,831,600 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "6,833,200 examples, moving-average loss 11.90, train accuracy 0.69\n",
      "6,834,800 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "6,836,400 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "6,838,000 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "6,839,600 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "6,841,200 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "6,842,800 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "6,844,400 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "6,846,000 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "6,847,600 examples, moving-average loss 11.92, train accuracy 0.69\n",
      "6,849,200 examples, moving-average loss 11.92, train accuracy 0.69\n",
      "6,850,800 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,852,400 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "6,854,000 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "6,855,600 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,857,200 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,858,800 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "6,860,400 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "6,862,000 examples, moving-average loss 11.94, train accuracy 0.69\n",
      "6,863,600 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,865,200 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "6,866,800 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "6,868,400 examples, moving-average loss 12.07, train accuracy 0.69\n",
      "6,870,000 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,871,600 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "6,873,200 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,874,800 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "6,876,400 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "6,878,000 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,879,600 examples, moving-average loss 12.08, train accuracy 0.69\n",
      "6,881,200 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "6,882,800 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "6,884,400 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "6,886,000 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "6,887,600 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "6,889,200 examples, moving-average loss 11.94, train accuracy 0.69\n",
      "6,890,800 examples, moving-average loss 11.94, train accuracy 0.69\n",
      "6,892,400 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "6,894,000 examples, moving-average loss 11.93, train accuracy 0.69\n",
      "6,895,600 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "6,897,200 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "6,898,800 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,900,400 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "6,902,000 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,903,600 examples, moving-average loss 12.02, train accuracy 0.69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6,905,200 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,906,800 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "6,908,400 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "6,910,000 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "6,911,600 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "6,913,200 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "6,914,800 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "6,916,400 examples, moving-average loss 11.93, train accuracy 0.69\n",
      "6,918,000 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "6,919,600 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,921,200 examples, moving-average loss 11.94, train accuracy 0.69\n",
      "6,922,800 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "6,924,400 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,926,000 examples, moving-average loss 11.93, train accuracy 0.69\n",
      "6,927,600 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "6,929,200 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "6,930,800 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "6,932,400 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "6,934,000 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "6,935,600 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,937,200 examples, moving-average loss 11.94, train accuracy 0.69\n",
      "6,938,800 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "6,940,400 examples, moving-average loss 11.90, train accuracy 0.69\n",
      "6,942,000 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "6,943,600 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "6,945,200 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "6,946,800 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "6,948,400 examples, moving-average loss 12.10, train accuracy 0.69\n",
      "6,950,000 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "6,951,600 examples, moving-average loss 11.93, train accuracy 0.69\n",
      "6,953,200 examples, moving-average loss 11.92, train accuracy 0.69\n",
      "6,954,800 examples, moving-average loss 11.88, train accuracy 0.69\n",
      "6,956,400 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "6,958,000 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,959,600 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "6,961,200 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "6,962,800 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,964,400 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "6,966,000 examples, moving-average loss 11.93, train accuracy 0.69\n",
      "6,967,600 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,969,200 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "6,970,800 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "6,972,400 examples, moving-average loss 11.94, train accuracy 0.69\n",
      "6,974,000 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,975,600 examples, moving-average loss 11.90, train accuracy 0.69\n",
      "6,977,200 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "6,978,800 examples, moving-average loss 11.94, train accuracy 0.69\n",
      "6,980,400 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "6,982,000 examples, moving-average loss 12.07, train accuracy 0.69\n",
      "6,983,600 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "6,985,200 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "6,986,800 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "6,988,400 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "6,990,000 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,991,600 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "6,993,200 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "6,994,800 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "6,996,400 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "6,998,000 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "6,999,600 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "7,001,200 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "7,002,800 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "7,004,400 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "7,006,000 examples, moving-average loss 12.08, train accuracy 0.69\n",
      "7,007,600 examples, moving-average loss 11.88, train accuracy 0.69\n",
      "7,009,200 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "7,010,800 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "7,012,400 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "7,014,000 examples, moving-average loss 12.07, train accuracy 0.69\n",
      "7,015,600 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "7,017,200 examples, moving-average loss 11.93, train accuracy 0.69\n",
      "7,018,800 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "7,020,400 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "7,022,000 examples, moving-average loss 11.94, train accuracy 0.69\n",
      "7,023,600 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "7,025,200 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "7,026,800 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "7,028,400 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "7,030,000 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "7,031,600 examples, moving-average loss 11.94, train accuracy 0.69\n",
      "7,033,200 examples, moving-average loss 11.92, train accuracy 0.69\n",
      "7,034,800 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "7,036,400 examples, moving-average loss 11.94, train accuracy 0.69\n",
      "7,038,000 examples, moving-average loss 11.90, train accuracy 0.69\n",
      "7,039,600 examples, moving-average loss 11.91, train accuracy 0.69\n",
      "7,041,200 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "7,042,800 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "7,044,400 examples, moving-average loss 11.94, train accuracy 0.69\n",
      "7,046,000 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "7,047,600 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "7,049,200 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "7,050,800 examples, moving-average loss 11.92, train accuracy 0.69\n",
      "7,052,400 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "7,054,000 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "7,055,600 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "7,057,200 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "7,058,800 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "7,060,400 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "7,062,000 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "7,063,600 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "7,065,200 examples, moving-average loss 11.94, train accuracy 0.69\n",
      "7,066,800 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "7,068,400 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "7,070,000 examples, moving-average loss 11.94, train accuracy 0.69\n",
      "7,071,600 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "7,073,200 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "7,074,800 examples, moving-average loss 11.90, train accuracy 0.69\n",
      "7,076,400 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "7,078,000 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "7,079,600 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "7,081,200 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "7,082,800 examples, moving-average loss 11.92, train accuracy 0.69\n",
      "7,084,400 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "7,086,000 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "7,087,600 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "7,089,200 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "7,090,800 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "7,092,400 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "7,094,000 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "7,095,600 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "7,097,200 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "7,098,800 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "7,100,400 examples, moving-average loss 12.00, train accuracy 0.69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7,102,000 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "7,103,600 examples, moving-average loss 12.12, train accuracy 0.69\n",
      "7,105,200 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "7,106,800 examples, moving-average loss 12.08, train accuracy 0.69\n",
      "7,108,400 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "7,110,000 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "7,111,600 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "7,113,200 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "7,114,800 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "7,116,400 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "7,118,000 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "7,119,600 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "7,121,200 examples, moving-average loss 12.08, train accuracy 0.69\n",
      "7,122,800 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "7,124,400 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "7,126,000 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "7,127,600 examples, moving-average loss 11.94, train accuracy 0.69\n",
      "7,129,200 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "7,130,800 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "7,132,400 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "7,134,000 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "7,135,600 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "7,137,200 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "7,138,800 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "7,140,400 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "7,142,000 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "7,143,600 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "7,145,200 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "7,146,800 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "7,148,400 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "7,150,000 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "7,151,600 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "7,153,200 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "7,154,800 examples, moving-average loss 12.09, train accuracy 0.69\n",
      "7,156,400 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "7,158,000 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "7,159,600 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "7,161,200 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "7,162,800 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "7,164,400 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "7,166,000 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "7,167,600 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "7,169,200 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "7,170,800 examples, moving-average loss 11.88, train accuracy 0.69\n",
      "7,172,400 examples, moving-average loss 11.91, train accuracy 0.69\n",
      "7,174,000 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "7,175,600 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "7,177,200 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "7,178,800 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "7,180,400 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "7,182,000 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "7,183,600 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "7,185,200 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "7,186,800 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "7,188,400 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "7,190,000 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "7,191,600 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "7,193,200 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "7,194,800 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "7,196,400 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "7,198,000 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "7,199,600 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "7,201,200 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "7,202,800 examples, moving-average loss 12.07, train accuracy 0.69\n",
      "7,204,400 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "7,206,000 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "7,207,600 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "7,209,200 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "7,210,800 examples, moving-average loss 11.92, train accuracy 0.69\n",
      "7,212,400 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "7,214,000 examples, moving-average loss 11.91, train accuracy 0.69\n",
      "7,215,600 examples, moving-average loss 11.94, train accuracy 0.69\n",
      "7,217,200 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "7,218,800 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "7,220,400 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "7,222,000 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "7,223,600 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "7,225,200 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "7,226,800 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "7,228,400 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "7,230,000 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "7,231,600 examples, moving-average loss 11.92, train accuracy 0.69\n",
      "7,233,200 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "7,234,800 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "7,236,400 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "7,238,000 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "7,239,600 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "7,241,200 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "7,242,800 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "7,244,400 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "7,246,000 examples, moving-average loss 11.92, train accuracy 0.69\n",
      "7,247,600 examples, moving-average loss 11.94, train accuracy 0.69\n",
      "7,249,200 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "7,250,800 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "7,252,400 examples, moving-average loss 11.94, train accuracy 0.69\n",
      "7,254,000 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "7,255,600 examples, moving-average loss 11.93, train accuracy 0.69\n",
      "7,257,200 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "7,258,800 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "7,260,400 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "7,262,000 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "7,263,600 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "7,265,200 examples, moving-average loss 12.10, train accuracy 0.69\n",
      "7,266,800 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "7,268,400 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "7,270,000 examples, moving-average loss 11.88, train accuracy 0.69\n",
      "7,271,600 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "7,273,200 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "7,274,800 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "7,276,400 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "7,278,000 examples, moving-average loss 11.91, train accuracy 0.69\n",
      "7,279,600 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "7,281,200 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "7,282,800 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "7,284,400 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "7,286,000 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "7,287,600 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "7,289,200 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "7,290,800 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "7,292,400 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "7,294,000 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "7,295,600 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "7,297,200 examples, moving-average loss 11.93, train accuracy 0.69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7,298,800 examples, moving-average loss 12.08, train accuracy 0.69\n",
      "7,300,400 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "7,302,000 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "7,303,600 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "7,305,200 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "7,306,800 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "7,308,400 examples, moving-average loss 12.07, train accuracy 0.69\n",
      "7,310,000 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "7,311,600 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "7,313,200 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "7,314,800 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "7,316,400 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "7,318,000 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "7,319,600 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "7,321,200 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "7,322,800 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "7,324,400 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "7,326,000 examples, moving-average loss 11.92, train accuracy 0.69\n",
      "7,327,600 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "7,329,200 examples, moving-average loss 11.92, train accuracy 0.69\n",
      "7,330,800 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "7,332,400 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "7,334,000 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "7,335,600 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "7,337,200 examples, moving-average loss 11.88, train accuracy 0.69\n",
      "7,338,800 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "7,340,400 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "7,342,000 examples, moving-average loss 11.92, train accuracy 0.69\n",
      "7,343,600 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "7,345,200 examples, moving-average loss 12.09, train accuracy 0.69\n",
      "7,346,800 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "7,348,400 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "7,350,000 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "7,351,600 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "7,353,200 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "7,354,800 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "7,356,400 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "7,358,000 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "7,359,600 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "7,361,200 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "7,362,800 examples, moving-average loss 12.08, train accuracy 0.69\n",
      "7,364,400 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "7,366,000 examples, moving-average loss 11.92, train accuracy 0.69\n",
      "7,367,600 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "7,369,200 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "7,370,800 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "7,372,400 examples, moving-average loss 12.07, train accuracy 0.69\n",
      "7,374,000 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "7,375,600 examples, moving-average loss 11.93, train accuracy 0.69\n",
      "7,377,200 examples, moving-average loss 12.07, train accuracy 0.69\n",
      "7,378,800 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "7,380,400 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "7,382,000 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "7,383,600 examples, moving-average loss 11.90, train accuracy 0.69\n",
      "7,385,200 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "7,386,800 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "7,388,400 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "7,390,000 examples, moving-average loss 12.09, train accuracy 0.69\n",
      "7,391,600 examples, moving-average loss 11.94, train accuracy 0.69\n",
      "7,393,200 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "7,394,800 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "7,396,400 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "7,398,000 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "7,399,600 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "7,401,200 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "7,402,800 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "7,404,400 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "7,406,000 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "7,407,600 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "7,409,200 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "7,410,800 examples, moving-average loss 12.07, train accuracy 0.69\n",
      "7,412,400 examples, moving-average loss 11.90, train accuracy 0.69\n",
      "7,414,000 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "7,415,600 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "7,417,200 examples, moving-average loss 11.93, train accuracy 0.69\n",
      "7,418,800 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "7,420,400 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "7,422,000 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "7,423,600 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "7,425,200 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "7,426,800 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "7,428,400 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "7,430,000 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "7,431,600 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "7,433,200 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "7,434,800 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "7,436,400 examples, moving-average loss 12.07, train accuracy 0.69\n",
      "7,438,000 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "7,439,600 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "7,441,200 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "7,442,800 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "7,444,400 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "7,446,000 examples, moving-average loss 12.08, train accuracy 0.69\n",
      "7,447,600 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "7,449,200 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "7,450,800 examples, moving-average loss 12.09, train accuracy 0.69\n",
      "7,452,400 examples, moving-average loss 11.94, train accuracy 0.69\n",
      "7,454,000 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "7,455,600 examples, moving-average loss 12.13, train accuracy 0.69\n",
      "7,457,200 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "7,458,800 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "7,460,400 examples, moving-average loss 11.94, train accuracy 0.69\n",
      "7,462,000 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "7,463,600 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "7,465,200 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "7,466,800 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "7,468,400 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "7,470,000 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "7,471,600 examples, moving-average loss 11.91, train accuracy 0.69\n",
      "7,473,200 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "7,474,800 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "7,476,400 examples, moving-average loss 11.95, train accuracy 0.69\n",
      "7,478,000 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "7,479,600 examples, moving-average loss 12.10, train accuracy 0.69\n",
      "7,481,200 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "7,482,800 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "7,484,400 examples, moving-average loss 12.04, train accuracy 0.69\n",
      "7,486,000 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "7,487,600 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "7,489,200 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "7,490,800 examples, moving-average loss 12.06, train accuracy 0.69\n",
      "7,492,400 examples, moving-average loss 11.93, train accuracy 0.69\n",
      "7,494,000 examples, moving-average loss 11.99, train accuracy 0.69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7,495,600 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "7,497,200 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "7,498,800 examples, moving-average loss 11.92, train accuracy 0.69\n",
      "7,500,400 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "7,502,000 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "7,503,600 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "7,505,200 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "7,506,800 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "7,508,400 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "7,510,000 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "7,511,600 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "7,513,200 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "7,514,800 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "7,516,400 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "7,518,000 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "7,519,600 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "7,521,200 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "7,522,800 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "7,524,400 examples, moving-average loss 12.05, train accuracy 0.70\n",
      "7,526,000 examples, moving-average loss 12.05, train accuracy 0.70\n",
      "7,527,600 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "7,529,200 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "7,530,800 examples, moving-average loss 12.06, train accuracy 0.70\n",
      "7,532,400 examples, moving-average loss 12.06, train accuracy 0.70\n",
      "7,534,000 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "7,535,600 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "7,537,200 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "7,538,800 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "7,540,400 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "7,542,000 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "7,543,600 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "7,545,200 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "7,546,800 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "7,548,400 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "7,550,000 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "7,551,600 examples, moving-average loss 12.07, train accuracy 0.70\n",
      "7,553,200 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "7,554,800 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "7,556,400 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "7,558,000 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "7,559,600 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "7,561,200 examples, moving-average loss 11.87, train accuracy 0.70\n",
      "7,562,800 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "7,564,400 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "7,566,000 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "7,567,600 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "7,569,200 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "7,570,800 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "7,572,400 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "Completed 8 epoch in 0:38:52\n",
      "Train accurary:0.69536\n",
      "Validate accuracy:0.69277\n",
      "7,573,950 examples, moving-average loss 11.87, train accuracy 0.63\n",
      "7,575,550 examples, moving-average loss 11.98, train accuracy 0.67\n",
      "7,577,150 examples, moving-average loss 11.99, train accuracy 0.68\n",
      "7,578,750 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "7,580,350 examples, moving-average loss 12.02, train accuracy 0.69\n",
      "7,581,950 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "7,583,550 examples, moving-average loss 11.94, train accuracy 0.69\n",
      "7,585,150 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "7,586,750 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "7,588,350 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "7,589,950 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "7,591,550 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "7,593,150 examples, moving-average loss 11.97, train accuracy 0.69\n",
      "7,594,750 examples, moving-average loss 12.01, train accuracy 0.69\n",
      "7,596,350 examples, moving-average loss 11.94, train accuracy 0.69\n",
      "7,597,950 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "7,599,550 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "7,601,150 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "7,602,750 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "7,604,350 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "7,605,950 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "7,607,550 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "7,609,150 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "7,610,750 examples, moving-average loss 12.07, train accuracy 0.70\n",
      "7,612,350 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "7,613,950 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "7,615,550 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "7,617,150 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "7,618,750 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "7,620,350 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "7,621,950 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "7,623,550 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "7,625,150 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "7,626,750 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "7,628,350 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "7,629,950 examples, moving-average loss 11.89, train accuracy 0.70\n",
      "7,631,550 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "7,633,150 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "7,634,750 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "7,636,350 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "7,637,950 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "7,639,550 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "7,641,150 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "7,642,750 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "7,644,350 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "7,645,950 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "7,647,550 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "7,649,150 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "7,650,750 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "7,652,350 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "7,653,950 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "7,655,550 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "7,657,150 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "7,658,750 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "7,660,350 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "7,661,950 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "7,663,550 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "7,665,150 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "7,666,750 examples, moving-average loss 12.06, train accuracy 0.70\n",
      "7,668,350 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "7,669,950 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "7,671,550 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "7,673,150 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "7,674,750 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "7,676,350 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "7,677,950 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "7,679,550 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "7,681,150 examples, moving-average loss 12.08, train accuracy 0.70\n",
      "7,682,750 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "7,684,350 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "7,685,950 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "7,687,550 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "7,689,150 examples, moving-average loss 11.91, train accuracy 0.70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7,690,750 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "7,692,350 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "7,693,950 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "7,695,550 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "7,697,150 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "7,698,750 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "7,700,350 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "7,701,950 examples, moving-average loss 11.90, train accuracy 0.70\n",
      "7,703,550 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "7,705,150 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "7,706,750 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "7,708,350 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "7,709,950 examples, moving-average loss 12.06, train accuracy 0.70\n",
      "7,711,550 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "7,713,150 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "7,714,750 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "7,716,350 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "7,717,950 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "7,719,550 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "7,721,150 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "7,722,750 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "7,724,350 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "7,725,950 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "7,727,550 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "7,729,150 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "7,730,750 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "7,732,350 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "7,733,950 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "7,735,550 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "7,737,150 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "7,738,750 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "7,740,350 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "7,741,950 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "7,743,550 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "7,745,150 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "7,746,750 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "7,748,350 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "7,749,950 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "7,751,550 examples, moving-average loss 12.08, train accuracy 0.70\n",
      "7,753,150 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "7,754,750 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "7,756,350 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "7,757,950 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "7,759,550 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "7,761,150 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "7,762,750 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "7,764,350 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "7,765,950 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "7,767,550 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "7,769,150 examples, moving-average loss 12.05, train accuracy 0.70\n",
      "7,770,750 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "7,772,350 examples, moving-average loss 12.06, train accuracy 0.70\n",
      "7,773,950 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "7,775,550 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "7,777,150 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "7,778,750 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "7,780,350 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "7,781,950 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "7,783,550 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "7,785,150 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "7,786,750 examples, moving-average loss 12.07, train accuracy 0.70\n",
      "7,788,350 examples, moving-average loss 12.09, train accuracy 0.70\n",
      "7,789,950 examples, moving-average loss 12.06, train accuracy 0.70\n",
      "7,791,550 examples, moving-average loss 12.05, train accuracy 0.70\n",
      "7,793,150 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "7,794,750 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "7,796,350 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "7,797,950 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "7,799,550 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "7,801,150 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "7,802,750 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "7,804,350 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "7,805,950 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "7,807,550 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "7,809,150 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "7,810,750 examples, moving-average loss 12.09, train accuracy 0.70\n",
      "7,812,350 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "7,813,950 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "7,815,550 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "7,817,150 examples, moving-average loss 11.89, train accuracy 0.70\n",
      "7,818,750 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "7,820,350 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "7,821,950 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "7,823,550 examples, moving-average loss 12.06, train accuracy 0.70\n",
      "7,825,150 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "7,826,750 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "7,828,350 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "7,829,950 examples, moving-average loss 11.89, train accuracy 0.70\n",
      "7,831,550 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "7,833,150 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "7,834,750 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "7,836,350 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "7,837,950 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "7,839,550 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "7,841,150 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "7,842,750 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "7,844,350 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "7,845,950 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "7,847,550 examples, moving-average loss 12.07, train accuracy 0.70\n",
      "7,849,150 examples, moving-average loss 11.85, train accuracy 0.70\n",
      "7,850,750 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "7,852,350 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "7,853,950 examples, moving-average loss 12.06, train accuracy 0.70\n",
      "7,855,550 examples, moving-average loss 12.07, train accuracy 0.70\n",
      "7,857,150 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "7,858,750 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "7,860,350 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "7,861,950 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "7,863,550 examples, moving-average loss 11.87, train accuracy 0.70\n",
      "7,865,150 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "7,866,750 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "7,868,350 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "7,869,950 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "7,871,550 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "7,873,150 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "7,874,750 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "7,876,350 examples, moving-average loss 12.06, train accuracy 0.70\n",
      "7,877,950 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "7,879,550 examples, moving-average loss 11.90, train accuracy 0.70\n",
      "7,881,150 examples, moving-average loss 11.84, train accuracy 0.70\n",
      "7,882,750 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "7,884,350 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "7,885,950 examples, moving-average loss 11.96, train accuracy 0.70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7,887,550 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "7,889,150 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "7,890,750 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "7,892,350 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "7,893,950 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "7,895,550 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "7,897,150 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "7,898,750 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "7,900,350 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "7,901,950 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "7,903,550 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "7,905,150 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "7,906,750 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "7,908,350 examples, moving-average loss 12.06, train accuracy 0.70\n",
      "7,909,950 examples, moving-average loss 12.05, train accuracy 0.70\n",
      "7,911,550 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "7,913,150 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "7,914,750 examples, moving-average loss 11.90, train accuracy 0.70\n",
      "7,916,350 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "7,917,950 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "7,919,550 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "7,921,150 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "7,922,750 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "7,924,350 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "7,925,950 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "7,927,550 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "7,929,150 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "7,930,750 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "7,932,350 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "7,933,950 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "7,935,550 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "7,937,150 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "7,938,750 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "7,940,350 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "7,941,950 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "7,943,550 examples, moving-average loss 12.07, train accuracy 0.70\n",
      "7,945,150 examples, moving-average loss 12.06, train accuracy 0.70\n",
      "7,946,750 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "7,948,350 examples, moving-average loss 12.08, train accuracy 0.70\n",
      "7,949,950 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "7,951,550 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "7,953,150 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "7,954,750 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "7,956,350 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "7,957,950 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "7,959,550 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "7,961,150 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "7,962,750 examples, moving-average loss 12.06, train accuracy 0.70\n",
      "7,964,350 examples, moving-average loss 12.07, train accuracy 0.70\n",
      "7,965,950 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "7,967,550 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "7,969,150 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "7,970,750 examples, moving-average loss 12.05, train accuracy 0.70\n",
      "7,972,350 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "7,973,950 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "7,975,550 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "7,977,150 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "7,978,750 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "7,980,350 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "7,981,950 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "7,983,550 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "7,985,150 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "7,986,750 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "7,988,350 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "7,989,950 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "7,991,550 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "7,993,150 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "7,994,750 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "7,996,350 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "7,997,950 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "7,999,550 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "8,001,150 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,002,750 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "8,004,350 examples, moving-average loss 12.08, train accuracy 0.70\n",
      "8,005,950 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,007,550 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,009,150 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,010,750 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "8,012,350 examples, moving-average loss 11.90, train accuracy 0.70\n",
      "8,013,950 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "8,015,550 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,017,150 examples, moving-average loss 12.08, train accuracy 0.70\n",
      "8,018,750 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "8,020,350 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "8,021,950 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "8,023,550 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "8,025,150 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "8,026,750 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,028,350 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,029,950 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "8,031,550 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "8,033,150 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "8,034,750 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "8,036,350 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "8,037,950 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "8,039,550 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,041,150 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "8,042,750 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,044,350 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "8,045,950 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "8,047,550 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "8,049,150 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,050,750 examples, moving-average loss 12.09, train accuracy 0.70\n",
      "8,052,350 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "8,053,950 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "8,055,550 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,057,150 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "8,058,750 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,060,350 examples, moving-average loss 12.06, train accuracy 0.70\n",
      "8,061,950 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "8,063,550 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,065,150 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,066,750 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "8,068,350 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "8,069,950 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,071,550 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,073,150 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "8,074,750 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "8,076,350 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,077,950 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "8,079,550 examples, moving-average loss 12.06, train accuracy 0.70\n",
      "8,081,150 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "8,082,750 examples, moving-average loss 11.97, train accuracy 0.70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8,084,350 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "8,085,950 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "8,087,550 examples, moving-average loss 11.89, train accuracy 0.70\n",
      "8,089,150 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "8,090,750 examples, moving-average loss 12.05, train accuracy 0.70\n",
      "8,092,350 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "8,093,950 examples, moving-average loss 11.90, train accuracy 0.70\n",
      "8,095,550 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "8,097,150 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "8,098,750 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,100,350 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,101,950 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,103,550 examples, moving-average loss 12.08, train accuracy 0.70\n",
      "8,105,150 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "8,106,750 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "8,108,350 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,109,950 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "8,111,550 examples, moving-average loss 11.86, train accuracy 0.70\n",
      "8,113,150 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "8,114,750 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "8,116,350 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,117,950 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,119,550 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "8,121,150 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "8,122,750 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "8,124,350 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,125,950 examples, moving-average loss 12.05, train accuracy 0.70\n",
      "8,127,550 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "8,129,150 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "8,130,750 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,132,350 examples, moving-average loss 12.05, train accuracy 0.70\n",
      "8,133,950 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "8,135,550 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "8,137,150 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "8,138,750 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "8,140,350 examples, moving-average loss 12.05, train accuracy 0.70\n",
      "8,141,950 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,143,550 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "8,145,150 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,146,750 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,148,350 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,149,950 examples, moving-average loss 12.08, train accuracy 0.70\n",
      "8,151,550 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "8,153,150 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,154,750 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,156,350 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "8,157,950 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,159,550 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,161,150 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "8,162,750 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "8,164,350 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,165,950 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,167,550 examples, moving-average loss 11.89, train accuracy 0.70\n",
      "8,169,150 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "8,170,750 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "8,172,350 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,173,950 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "8,175,550 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "8,177,150 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "8,178,750 examples, moving-average loss 11.89, train accuracy 0.70\n",
      "8,180,350 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "8,181,950 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,183,550 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "8,185,150 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "8,186,750 examples, moving-average loss 12.06, train accuracy 0.70\n",
      "8,188,350 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "8,189,950 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "8,191,550 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,193,150 examples, moving-average loss 12.06, train accuracy 0.70\n",
      "8,194,750 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,196,350 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,197,950 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "8,199,550 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "8,201,150 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "8,202,750 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "8,204,350 examples, moving-average loss 12.08, train accuracy 0.70\n",
      "8,205,950 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,207,550 examples, moving-average loss 11.90, train accuracy 0.70\n",
      "8,209,150 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "8,210,750 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,212,350 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "8,213,950 examples, moving-average loss 12.08, train accuracy 0.70\n",
      "8,215,550 examples, moving-average loss 12.06, train accuracy 0.70\n",
      "8,217,150 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "8,218,750 examples, moving-average loss 12.06, train accuracy 0.70\n",
      "8,220,350 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "8,221,950 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "8,223,550 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,225,150 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "8,226,750 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "8,228,350 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "8,229,950 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,231,550 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "8,233,150 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,234,750 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "8,236,350 examples, moving-average loss 12.07, train accuracy 0.70\n",
      "8,237,950 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,239,550 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "8,241,150 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,242,750 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "8,244,350 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "8,245,950 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "8,247,550 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "8,249,150 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "8,250,750 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "8,252,350 examples, moving-average loss 12.09, train accuracy 0.70\n",
      "8,253,950 examples, moving-average loss 11.87, train accuracy 0.70\n",
      "8,255,550 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,257,150 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,258,750 examples, moving-average loss 11.90, train accuracy 0.70\n",
      "8,260,350 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "8,261,950 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "8,263,550 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "8,265,150 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,266,750 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,268,350 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "8,269,950 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "8,271,550 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "8,273,150 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "8,274,750 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,276,350 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "8,277,950 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "8,279,550 examples, moving-average loss 11.96, train accuracy 0.70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8,281,150 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "8,282,750 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,284,350 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "8,285,950 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "8,287,550 examples, moving-average loss 12.05, train accuracy 0.70\n",
      "8,289,150 examples, moving-average loss 12.07, train accuracy 0.70\n",
      "8,290,750 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "8,292,350 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "8,293,950 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "8,295,550 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,297,150 examples, moving-average loss 12.11, train accuracy 0.70\n",
      "8,298,750 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,300,350 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "8,301,950 examples, moving-average loss 11.86, train accuracy 0.70\n",
      "8,303,550 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,305,150 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "8,306,750 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "8,308,350 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "8,309,950 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,311,550 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "8,313,150 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "8,314,750 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "8,316,350 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "8,317,950 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "8,319,550 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "8,321,150 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "8,322,750 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "8,324,350 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,325,950 examples, moving-average loss 12.06, train accuracy 0.70\n",
      "8,327,550 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,329,150 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "8,330,750 examples, moving-average loss 12.07, train accuracy 0.70\n",
      "8,332,350 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "8,333,950 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "8,335,550 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "8,337,150 examples, moving-average loss 11.89, train accuracy 0.70\n",
      "8,338,750 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "8,340,350 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "8,341,950 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,343,550 examples, moving-average loss 12.05, train accuracy 0.70\n",
      "8,345,150 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "8,346,750 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "8,348,350 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "8,349,950 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,351,550 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "8,353,150 examples, moving-average loss 11.89, train accuracy 0.70\n",
      "8,354,750 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,356,350 examples, moving-average loss 11.89, train accuracy 0.70\n",
      "8,357,950 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "8,359,550 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "8,361,150 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "8,362,750 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,364,350 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,365,950 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "8,367,550 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "8,369,150 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "8,370,750 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "8,372,350 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "8,373,950 examples, moving-average loss 12.10, train accuracy 0.70\n",
      "8,375,550 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "8,377,150 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "8,378,750 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,380,350 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "8,381,950 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "8,383,550 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "8,385,150 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,386,750 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "8,388,350 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "8,389,950 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,391,550 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "8,393,150 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "8,394,750 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "8,396,350 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "8,397,950 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "8,399,550 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "8,401,150 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,402,750 examples, moving-average loss 11.90, train accuracy 0.70\n",
      "8,404,350 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,405,950 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "8,407,550 examples, moving-average loss 12.05, train accuracy 0.70\n",
      "8,409,150 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,410,750 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "8,412,350 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "8,413,950 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "Completed 9 epoch in 0:38:46\n",
      "Train accurary:0.69862\n",
      "Validate accuracy:0.69490\n",
      "8,415,500 examples, moving-average loss 11.85, train accuracy 0.64\n",
      "8,417,100 examples, moving-average loss 11.94, train accuracy 0.68\n",
      "8,418,700 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "8,420,300 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "8,421,900 examples, moving-average loss 12.05, train accuracy 0.69\n",
      "8,423,500 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "8,425,100 examples, moving-average loss 11.92, train accuracy 0.69\n",
      "8,426,700 examples, moving-average loss 11.93, train accuracy 0.69\n",
      "8,428,300 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,429,900 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "8,431,500 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "8,433,100 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "8,434,700 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,436,300 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "8,437,900 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "8,439,500 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "8,441,100 examples, moving-average loss 12.05, train accuracy 0.70\n",
      "8,442,700 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,444,300 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,445,900 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "8,447,500 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "8,449,100 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "8,450,700 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "8,452,300 examples, moving-average loss 12.05, train accuracy 0.70\n",
      "8,453,900 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "8,455,500 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "8,457,100 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,458,700 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "8,460,300 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "8,461,900 examples, moving-average loss 12.07, train accuracy 0.70\n",
      "8,463,500 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "8,465,100 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,466,700 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,468,300 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "8,469,900 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "8,471,500 examples, moving-average loss 11.84, train accuracy 0.70\n",
      "8,473,100 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "8,474,700 examples, moving-average loss 11.96, train accuracy 0.70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8,476,300 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "8,477,900 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,479,500 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "8,481,100 examples, moving-average loss 11.88, train accuracy 0.70\n",
      "8,482,700 examples, moving-average loss 11.90, train accuracy 0.70\n",
      "8,484,300 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "8,485,900 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "8,487,500 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "8,489,100 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "8,490,700 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "8,492,300 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "8,493,900 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "8,495,500 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "8,497,100 examples, moving-average loss 11.90, train accuracy 0.70\n",
      "8,498,700 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "8,500,300 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "8,501,900 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "8,503,500 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,505,100 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "8,506,700 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,508,300 examples, moving-average loss 12.07, train accuracy 0.70\n",
      "8,509,900 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "8,511,500 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "8,513,100 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "8,514,700 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "8,516,300 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,517,900 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "8,519,500 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "8,521,100 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "8,522,700 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "8,524,300 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "8,525,900 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "8,527,500 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,529,100 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,530,700 examples, moving-average loss 11.90, train accuracy 0.70\n",
      "8,532,300 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "8,533,900 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "8,535,500 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,537,100 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "8,538,700 examples, moving-average loss 12.05, train accuracy 0.70\n",
      "8,540,300 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "8,541,900 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "8,543,500 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "8,545,100 examples, moving-average loss 11.88, train accuracy 0.70\n",
      "8,546,700 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,548,300 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,549,900 examples, moving-average loss 12.06, train accuracy 0.70\n",
      "8,551,500 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "8,553,100 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "8,554,700 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,556,300 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "8,557,900 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,559,500 examples, moving-average loss 11.90, train accuracy 0.70\n",
      "8,561,100 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,562,700 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "8,564,300 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,565,900 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "8,567,500 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,569,100 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "8,570,700 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,572,300 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,573,900 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "8,575,500 examples, moving-average loss 12.05, train accuracy 0.70\n",
      "8,577,100 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "8,578,700 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,580,300 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "8,581,900 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "8,583,500 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,585,100 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "8,586,700 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,588,300 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,589,900 examples, moving-average loss 12.05, train accuracy 0.70\n",
      "8,591,500 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "8,593,100 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "8,594,700 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "8,596,300 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "8,597,900 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "8,599,500 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "8,601,100 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "8,602,700 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,604,300 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,605,900 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "8,607,500 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,609,100 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "8,610,700 examples, moving-average loss 12.06, train accuracy 0.70\n",
      "8,612,300 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "8,613,900 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "8,615,500 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "8,617,100 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "8,618,700 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "8,620,300 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,621,900 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "8,623,500 examples, moving-average loss 11.89, train accuracy 0.70\n",
      "8,625,100 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,626,700 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "8,628,300 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "8,629,900 examples, moving-average loss 12.05, train accuracy 0.70\n",
      "8,631,500 examples, moving-average loss 12.06, train accuracy 0.70\n",
      "8,633,100 examples, moving-average loss 12.07, train accuracy 0.70\n",
      "8,634,700 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "8,636,300 examples, moving-average loss 11.86, train accuracy 0.70\n",
      "8,637,900 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "8,639,500 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "8,641,100 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "8,642,700 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,644,300 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,645,900 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,647,500 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "8,649,100 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "8,650,700 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "8,652,300 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "8,653,900 examples, moving-average loss 11.86, train accuracy 0.70\n",
      "8,655,500 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "8,657,100 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "8,658,700 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "8,660,300 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "8,661,900 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "8,663,500 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,665,100 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,666,700 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "8,668,300 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "8,669,900 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "8,671,500 examples, moving-average loss 11.88, train accuracy 0.70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8,673,100 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "8,674,700 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "8,676,300 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "8,677,900 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "8,679,500 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "8,681,100 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,682,700 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,684,300 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,685,900 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "8,687,500 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,689,100 examples, moving-average loss 12.05, train accuracy 0.70\n",
      "8,690,700 examples, moving-average loss 11.85, train accuracy 0.70\n",
      "8,692,300 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "8,693,900 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "8,695,500 examples, moving-average loss 12.06, train accuracy 0.70\n",
      "8,697,100 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "8,698,700 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "8,700,300 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,701,900 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "8,703,500 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "8,705,100 examples, moving-average loss 11.88, train accuracy 0.70\n",
      "8,706,700 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,708,300 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "8,709,900 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,711,500 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "8,713,100 examples, moving-average loss 11.88, train accuracy 0.70\n",
      "8,714,700 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "8,716,300 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "8,717,900 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "8,719,500 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,721,100 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "8,722,700 examples, moving-average loss 11.84, train accuracy 0.70\n",
      "8,724,300 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,725,900 examples, moving-average loss 11.89, train accuracy 0.70\n",
      "8,727,500 examples, moving-average loss 11.89, train accuracy 0.70\n",
      "8,729,100 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "8,730,700 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,732,300 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,733,900 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "8,735,500 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,737,100 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "8,738,700 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "8,740,300 examples, moving-average loss 11.90, train accuracy 0.70\n",
      "8,741,900 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,743,500 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "8,745,100 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "8,746,700 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "8,748,300 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "8,749,900 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "8,751,500 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "8,753,100 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,754,700 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,756,300 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "8,757,900 examples, moving-average loss 11.90, train accuracy 0.70\n",
      "8,759,500 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "8,761,100 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "8,762,700 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "8,764,300 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "8,765,900 examples, moving-average loss 11.90, train accuracy 0.70\n",
      "8,767,500 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "8,769,100 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,770,700 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "8,772,300 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "8,773,900 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "8,775,500 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "8,777,100 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "8,778,700 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "8,780,300 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "8,781,900 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,783,500 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,785,100 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "8,786,700 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "8,788,300 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "8,789,900 examples, moving-average loss 12.11, train accuracy 0.70\n",
      "8,791,500 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "8,793,100 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,794,700 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "8,796,300 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "8,797,900 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,799,500 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "8,801,100 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "8,802,700 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "8,804,300 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "8,805,900 examples, moving-average loss 12.05, train accuracy 0.70\n",
      "8,807,500 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "8,809,100 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "8,810,700 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "8,812,300 examples, moving-average loss 12.06, train accuracy 0.70\n",
      "8,813,900 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,815,500 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,817,100 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "8,818,700 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,820,300 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,821,900 examples, moving-average loss 12.05, train accuracy 0.70\n",
      "8,823,500 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,825,100 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,826,700 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,828,300 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,829,900 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "8,831,500 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "8,833,100 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "8,834,700 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,836,300 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,837,900 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "8,839,500 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "8,841,100 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,842,700 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "8,844,300 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "8,845,900 examples, moving-average loss 12.08, train accuracy 0.70\n",
      "8,847,500 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "8,849,100 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "8,850,700 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "8,852,300 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,853,900 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "8,855,500 examples, moving-average loss 11.88, train accuracy 0.70\n",
      "8,857,100 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,858,700 examples, moving-average loss 12.07, train accuracy 0.70\n",
      "8,860,300 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,861,900 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,863,500 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "8,865,100 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "8,866,700 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "8,868,300 examples, moving-average loss 11.89, train accuracy 0.70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8,869,900 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "8,871,500 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,873,100 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,874,700 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "8,876,300 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,877,900 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "8,879,500 examples, moving-average loss 11.88, train accuracy 0.70\n",
      "8,881,100 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,882,700 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "8,884,300 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,885,900 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "8,887,500 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,889,100 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,890,700 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "8,892,300 examples, moving-average loss 12.09, train accuracy 0.70\n",
      "8,893,900 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "8,895,500 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,897,100 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "8,898,700 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "8,900,300 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,901,900 examples, moving-average loss 12.05, train accuracy 0.70\n",
      "8,903,500 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,905,100 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,906,700 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "8,908,300 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "8,909,900 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "8,911,500 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,913,100 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "8,914,700 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "8,916,300 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "8,917,900 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,919,500 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,921,100 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "8,922,700 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "8,924,300 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,925,900 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "8,927,500 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,929,100 examples, moving-average loss 11.90, train accuracy 0.70\n",
      "8,930,700 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "8,932,300 examples, moving-average loss 12.05, train accuracy 0.70\n",
      "8,933,900 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "8,935,500 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "8,937,100 examples, moving-average loss 11.90, train accuracy 0.70\n",
      "8,938,700 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "8,940,300 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,941,900 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "8,943,500 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,945,100 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "8,946,700 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "8,948,300 examples, moving-average loss 12.05, train accuracy 0.70\n",
      "8,949,900 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "8,951,500 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,953,100 examples, moving-average loss 11.86, train accuracy 0.70\n",
      "8,954,700 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,956,300 examples, moving-average loss 11.83, train accuracy 0.70\n",
      "8,957,900 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,959,500 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,961,100 examples, moving-average loss 11.90, train accuracy 0.70\n",
      "8,962,700 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,964,300 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,965,900 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,967,500 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "8,969,100 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "8,970,700 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "8,972,300 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "8,973,900 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "8,975,500 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "8,977,100 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "8,978,700 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,980,300 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "8,981,900 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "8,983,500 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,985,100 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "8,986,700 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "8,988,300 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "8,989,900 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "8,991,500 examples, moving-average loss 12.07, train accuracy 0.70\n",
      "8,993,100 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "8,994,700 examples, moving-average loss 11.90, train accuracy 0.70\n",
      "8,996,300 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "8,997,900 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "8,999,500 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "9,001,100 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "9,002,700 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,004,300 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,005,900 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "9,007,500 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "9,009,100 examples, moving-average loss 11.90, train accuracy 0.70\n",
      "9,010,700 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "9,012,300 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "9,013,900 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "9,015,500 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,017,100 examples, moving-average loss 12.05, train accuracy 0.70\n",
      "9,018,700 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,020,300 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "9,021,900 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "9,023,500 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "9,025,100 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "9,026,700 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,028,300 examples, moving-average loss 12.06, train accuracy 0.70\n",
      "9,029,900 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,031,500 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,033,100 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "9,034,700 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "9,036,300 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,037,900 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "9,039,500 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "9,041,100 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "9,042,700 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "9,044,300 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "9,045,900 examples, moving-average loss 12.09, train accuracy 0.70\n",
      "9,047,500 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "9,049,100 examples, moving-average loss 11.90, train accuracy 0.70\n",
      "9,050,700 examples, moving-average loss 11.87, train accuracy 0.70\n",
      "9,052,300 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "9,053,900 examples, moving-average loss 11.89, train accuracy 0.70\n",
      "9,055,500 examples, moving-average loss 12.06, train accuracy 0.70\n",
      "9,057,100 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "9,058,700 examples, moving-average loss 11.90, train accuracy 0.70\n",
      "9,060,300 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "9,061,900 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "9,063,500 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "9,065,100 examples, moving-average loss 11.93, train accuracy 0.70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9,066,700 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "9,068,300 examples, moving-average loss 12.05, train accuracy 0.70\n",
      "9,069,900 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "9,071,500 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "9,073,100 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "9,074,700 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,076,300 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "9,077,900 examples, moving-average loss 12.05, train accuracy 0.70\n",
      "9,079,500 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "9,081,100 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,082,700 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "9,084,300 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "9,085,900 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,087,500 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "9,089,100 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "9,090,700 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,092,300 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,093,900 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "9,095,500 examples, moving-average loss 11.89, train accuracy 0.70\n",
      "9,097,100 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "9,098,700 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "9,100,300 examples, moving-average loss 11.89, train accuracy 0.70\n",
      "9,101,900 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "9,103,500 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "9,105,100 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "9,106,700 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "9,108,300 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,109,900 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "9,111,500 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "9,113,100 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "9,114,700 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "9,116,300 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "9,117,900 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,119,500 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "9,121,100 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "9,122,700 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,124,300 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "9,125,900 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "9,127,500 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "9,129,100 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "9,130,700 examples, moving-average loss 12.07, train accuracy 0.70\n",
      "9,132,300 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "9,133,900 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "9,135,500 examples, moving-average loss 11.89, train accuracy 0.70\n",
      "9,137,100 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "9,138,700 examples, moving-average loss 12.09, train accuracy 0.70\n",
      "9,140,300 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,141,900 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "9,143,500 examples, moving-average loss 11.86, train accuracy 0.70\n",
      "9,145,100 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "9,146,700 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "9,148,300 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "9,149,900 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "9,151,500 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "9,153,100 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "9,154,700 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "9,156,300 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "9,157,900 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "9,159,500 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "9,161,100 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "9,162,700 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "9,164,300 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "9,165,900 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "9,167,500 examples, moving-average loss 12.08, train accuracy 0.70\n",
      "9,169,100 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "9,170,700 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "9,172,300 examples, moving-average loss 12.09, train accuracy 0.70\n",
      "9,173,900 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "9,175,500 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "9,177,100 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "9,178,700 examples, moving-average loss 11.86, train accuracy 0.70\n",
      "9,180,300 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "9,181,900 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "9,183,500 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "9,185,100 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "9,186,700 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "9,188,300 examples, moving-average loss 11.90, train accuracy 0.70\n",
      "9,189,900 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "9,191,500 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,193,100 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "9,194,700 examples, moving-average loss 11.90, train accuracy 0.70\n",
      "9,196,300 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "9,197,900 examples, moving-average loss 11.89, train accuracy 0.70\n",
      "9,199,500 examples, moving-average loss 11.89, train accuracy 0.70\n",
      "9,201,100 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "9,202,700 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "9,204,300 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "9,205,900 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "9,207,500 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "9,209,100 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,210,700 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "9,212,300 examples, moving-average loss 12.06, train accuracy 0.70\n",
      "9,213,900 examples, moving-average loss 12.06, train accuracy 0.70\n",
      "9,215,500 examples, moving-average loss 12.08, train accuracy 0.70\n",
      "9,217,100 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "9,218,700 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "9,220,300 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "9,221,900 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "9,223,500 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "9,225,100 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "9,226,700 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "9,228,300 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "9,229,900 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,231,500 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "9,233,100 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,234,700 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,236,300 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,237,900 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "9,239,500 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "9,241,100 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "9,242,700 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "9,244,300 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "9,245,900 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "9,247,500 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,249,100 examples, moving-average loss 12.08, train accuracy 0.70\n",
      "9,250,700 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "9,252,300 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "9,253,900 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,255,500 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "Completed 10 epoch in 0:38:46\n",
      "Train accurary:0.70137\n",
      "Validate accuracy:0.69702\n",
      "9,257,050 examples, moving-average loss 11.85, train accuracy 0.64\n",
      "9,258,650 examples, moving-average loss 11.97, train accuracy 0.68\n",
      "9,260,250 examples, moving-average loss 11.98, train accuracy 0.69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9,261,850 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "9,263,450 examples, moving-average loss 12.03, train accuracy 0.69\n",
      "9,265,050 examples, moving-average loss 11.98, train accuracy 0.69\n",
      "9,266,650 examples, moving-average loss 11.94, train accuracy 0.69\n",
      "9,268,250 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "9,269,850 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,271,450 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "9,273,050 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "9,274,650 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,276,250 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,277,850 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "9,279,450 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "9,281,050 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,282,650 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "9,284,250 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "9,285,850 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "9,287,450 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,289,050 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,290,650 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "9,292,250 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "9,293,850 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,295,450 examples, moving-average loss 11.89, train accuracy 0.70\n",
      "9,297,050 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "9,298,650 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,300,250 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "9,301,850 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "9,303,450 examples, moving-average loss 12.06, train accuracy 0.70\n",
      "9,305,050 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,306,650 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "9,308,250 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "9,309,850 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "9,311,450 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "9,313,050 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "9,314,650 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "9,316,250 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "9,317,850 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "9,319,450 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,321,050 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "9,322,650 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "9,324,250 examples, moving-average loss 11.89, train accuracy 0.70\n",
      "9,325,850 examples, moving-average loss 11.90, train accuracy 0.70\n",
      "9,327,450 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "9,329,050 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "9,330,650 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "9,332,250 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "9,333,850 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "9,335,450 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "9,337,050 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "9,338,650 examples, moving-average loss 11.88, train accuracy 0.70\n",
      "9,340,250 examples, moving-average loss 12.05, train accuracy 0.70\n",
      "9,341,850 examples, moving-average loss 11.90, train accuracy 0.70\n",
      "9,343,450 examples, moving-average loss 11.90, train accuracy 0.70\n",
      "9,345,050 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,346,650 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "9,348,250 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "9,349,850 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "9,351,450 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,353,050 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "9,354,650 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "9,356,250 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "9,357,850 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "9,359,450 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "9,361,050 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,362,650 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,364,250 examples, moving-average loss 12.07, train accuracy 0.70\n",
      "9,365,850 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,367,450 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "9,369,050 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,370,650 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "9,372,250 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "9,373,850 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "9,375,450 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "9,377,050 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,378,650 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "9,380,250 examples, moving-average loss 12.05, train accuracy 0.70\n",
      "9,381,850 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "9,383,450 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,385,050 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "9,386,650 examples, moving-average loss 11.89, train accuracy 0.70\n",
      "9,388,250 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "9,389,850 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "9,391,450 examples, moving-average loss 12.07, train accuracy 0.70\n",
      "9,393,050 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "9,394,650 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,396,250 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,397,850 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "9,399,450 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "9,401,050 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "9,402,650 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "9,404,250 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,405,850 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "9,407,450 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "9,409,050 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "9,410,650 examples, moving-average loss 11.89, train accuracy 0.70\n",
      "9,412,250 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "9,413,850 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "9,415,450 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "9,417,050 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "9,418,650 examples, moving-average loss 11.90, train accuracy 0.70\n",
      "9,420,250 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "9,421,850 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,423,450 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "9,425,050 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "9,426,650 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "9,428,250 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "9,429,850 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "9,431,450 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "9,433,050 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "9,434,650 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "9,436,250 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "9,437,850 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,439,450 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "9,441,050 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "9,442,650 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "9,444,250 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "9,445,850 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "9,447,450 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "9,449,050 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "9,450,650 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "9,452,250 examples, moving-average loss 12.05, train accuracy 0.70\n",
      "9,453,850 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,455,450 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "9,457,050 examples, moving-average loss 12.01, train accuracy 0.70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9,458,650 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "9,460,250 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "9,461,850 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "9,463,450 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "9,465,050 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "9,466,650 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "9,468,250 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "9,469,850 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,471,450 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "9,473,050 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "9,474,650 examples, moving-average loss 12.05, train accuracy 0.70\n",
      "9,476,250 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "9,477,850 examples, moving-average loss 11.89, train accuracy 0.70\n",
      "9,479,450 examples, moving-average loss 11.89, train accuracy 0.70\n",
      "9,481,050 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,482,650 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "9,484,250 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "9,485,850 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "9,487,450 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "9,489,050 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "9,490,650 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "9,492,250 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "9,493,850 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,495,450 examples, moving-average loss 11.84, train accuracy 0.70\n",
      "9,497,050 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "9,498,650 examples, moving-average loss 12.06, train accuracy 0.70\n",
      "9,500,250 examples, moving-average loss 11.90, train accuracy 0.70\n",
      "9,501,850 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "9,503,450 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "9,505,050 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,506,650 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "9,508,250 examples, moving-average loss 11.90, train accuracy 0.70\n",
      "9,509,850 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,511,450 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "9,513,050 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "9,514,650 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "9,516,250 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "9,517,850 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "9,519,450 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "9,521,050 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "9,522,650 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "9,524,250 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "9,525,850 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "9,527,450 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "9,529,050 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "9,530,650 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "9,532,250 examples, moving-average loss 11.82, train accuracy 0.70\n",
      "9,533,850 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "9,535,450 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "9,537,050 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "9,538,650 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "9,540,250 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "9,541,850 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "9,543,450 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "9,545,050 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "9,546,650 examples, moving-average loss 11.90, train accuracy 0.70\n",
      "9,548,250 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,549,850 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "9,551,450 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "9,553,050 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "9,554,650 examples, moving-average loss 11.87, train accuracy 0.70\n",
      "9,556,250 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "9,557,850 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "9,559,450 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "9,561,050 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "9,562,650 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "9,564,250 examples, moving-average loss 11.83, train accuracy 0.70\n",
      "9,565,850 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "9,567,450 examples, moving-average loss 11.89, train accuracy 0.70\n",
      "9,569,050 examples, moving-average loss 11.88, train accuracy 0.70\n",
      "9,570,650 examples, moving-average loss 12.05, train accuracy 0.70\n",
      "9,572,250 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "9,573,850 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "9,575,450 examples, moving-average loss 11.88, train accuracy 0.70\n",
      "9,577,050 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,578,650 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,580,250 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "9,581,850 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "9,583,450 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "9,585,050 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "9,586,650 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "9,588,250 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "9,589,850 examples, moving-average loss 11.90, train accuracy 0.70\n",
      "9,591,450 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "9,593,050 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,594,650 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,596,250 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,597,850 examples, moving-average loss 11.89, train accuracy 0.70\n",
      "9,599,450 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "9,601,050 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "9,602,650 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "9,604,250 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,605,850 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "9,607,450 examples, moving-average loss 11.83, train accuracy 0.70\n",
      "9,609,050 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "9,610,650 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "9,612,250 examples, moving-average loss 11.89, train accuracy 0.70\n",
      "9,613,850 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,615,450 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "9,617,050 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "9,618,650 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "9,620,250 examples, moving-average loss 11.90, train accuracy 0.70\n",
      "9,621,850 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "9,623,450 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,625,050 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,626,650 examples, moving-average loss 12.06, train accuracy 0.70\n",
      "9,628,250 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "9,629,850 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,631,450 examples, moving-average loss 12.08, train accuracy 0.70\n",
      "9,633,050 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,634,650 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,636,250 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "9,637,850 examples, moving-average loss 12.05, train accuracy 0.70\n",
      "9,639,450 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "9,641,050 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "9,642,650 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "9,644,250 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "9,645,850 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "9,647,450 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,649,050 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "9,650,650 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "9,652,250 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "9,653,850 examples, moving-average loss 12.04, train accuracy 0.70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9,655,450 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,657,050 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "9,658,650 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "9,660,250 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "9,661,850 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "9,663,450 examples, moving-average loss 12.10, train accuracy 0.70\n",
      "9,665,050 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "9,666,650 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "9,668,250 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "9,669,850 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,671,450 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,673,050 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "9,674,650 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "9,676,250 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "9,677,850 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "9,679,450 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "9,681,050 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "9,682,650 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,684,250 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "9,685,850 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "9,687,450 examples, moving-average loss 12.06, train accuracy 0.70\n",
      "9,689,050 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "9,690,650 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "9,692,250 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "9,693,850 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "9,695,450 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "9,697,050 examples, moving-average loss 11.89, train accuracy 0.70\n",
      "9,698,650 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "9,700,250 examples, moving-average loss 12.09, train accuracy 0.70\n",
      "9,701,850 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,703,450 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "9,705,050 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "9,706,650 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "9,708,250 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "9,709,850 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "9,711,450 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "9,713,050 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "9,714,650 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,716,250 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "9,717,850 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "9,719,450 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "9,721,050 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "9,722,650 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,724,250 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "9,725,850 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "9,727,450 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,729,050 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "9,730,650 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "9,732,250 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "9,733,850 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "9,735,450 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "9,737,050 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,738,650 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,740,250 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "9,741,850 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "9,743,450 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "9,745,050 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,746,650 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "9,748,250 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "9,749,850 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "9,751,450 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "9,753,050 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,754,650 examples, moving-average loss 11.88, train accuracy 0.70\n",
      "9,756,250 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "9,757,850 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,759,450 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "9,761,050 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,762,650 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,764,250 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,765,850 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "9,767,450 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "9,769,050 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "9,770,650 examples, moving-average loss 11.87, train accuracy 0.70\n",
      "9,772,250 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "9,773,850 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "9,775,450 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,777,050 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "9,778,650 examples, moving-average loss 11.87, train accuracy 0.70\n",
      "9,780,250 examples, moving-average loss 11.90, train accuracy 0.70\n",
      "9,781,850 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "9,783,450 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "9,785,050 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "9,786,650 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,788,250 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "9,789,850 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "9,791,450 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "9,793,050 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "9,794,650 examples, moving-average loss 11.87, train accuracy 0.70\n",
      "9,796,250 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "9,797,850 examples, moving-average loss 11.81, train accuracy 0.70\n",
      "9,799,450 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "9,801,050 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "9,802,650 examples, moving-average loss 11.88, train accuracy 0.70\n",
      "9,804,250 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,805,850 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "9,807,450 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,809,050 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "9,810,650 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "9,812,250 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "9,813,850 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "9,815,450 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,817,050 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "9,818,650 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "9,820,250 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,821,850 examples, moving-average loss 11.89, train accuracy 0.70\n",
      "9,823,450 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,825,050 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "9,826,650 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "9,828,250 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "9,829,850 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "9,831,450 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "9,833,050 examples, moving-average loss 12.12, train accuracy 0.70\n",
      "9,834,650 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,836,250 examples, moving-average loss 11.90, train accuracy 0.70\n",
      "9,837,850 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "9,839,450 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,841,050 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "9,842,650 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "9,844,250 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "9,845,850 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "9,847,450 examples, moving-average loss 12.08, train accuracy 0.70\n",
      "9,849,050 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,850,650 examples, moving-average loss 11.89, train accuracy 0.70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9,852,250 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "9,853,850 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "9,855,450 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "9,857,050 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "9,858,650 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,860,250 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "9,861,850 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "9,863,450 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "9,865,050 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "9,866,650 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "9,868,250 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "9,869,850 examples, moving-average loss 12.06, train accuracy 0.70\n",
      "9,871,450 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "9,873,050 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "9,874,650 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "9,876,250 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "9,877,850 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,879,450 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,881,050 examples, moving-average loss 11.90, train accuracy 0.70\n",
      "9,882,650 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,884,250 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "9,885,850 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "9,887,450 examples, moving-average loss 12.07, train accuracy 0.70\n",
      "9,889,050 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "9,890,650 examples, moving-average loss 11.89, train accuracy 0.70\n",
      "9,892,250 examples, moving-average loss 11.86, train accuracy 0.70\n",
      "9,893,850 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "9,895,450 examples, moving-average loss 11.86, train accuracy 0.70\n",
      "9,897,050 examples, moving-average loss 12.07, train accuracy 0.70\n",
      "9,898,650 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "9,900,250 examples, moving-average loss 11.87, train accuracy 0.70\n",
      "9,901,850 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "9,903,450 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "9,905,050 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,906,650 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "9,908,250 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "9,909,850 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,911,450 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "9,913,050 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "9,914,650 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,916,250 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,917,850 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "9,919,450 examples, moving-average loss 12.06, train accuracy 0.70\n",
      "9,921,050 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "9,922,650 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,924,250 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "9,925,850 examples, moving-average loss 11.88, train accuracy 0.70\n",
      "9,927,450 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "9,929,050 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,930,650 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "9,932,250 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "9,933,850 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "9,935,450 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "9,937,050 examples, moving-average loss 11.87, train accuracy 0.70\n",
      "9,938,650 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "9,940,250 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,941,850 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "9,943,450 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "9,945,050 examples, moving-average loss 11.89, train accuracy 0.70\n",
      "9,946,650 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "9,948,250 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "9,949,850 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "9,951,450 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "9,953,050 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "9,954,650 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,956,250 examples, moving-average loss 12.05, train accuracy 0.70\n",
      "9,957,850 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,959,450 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "9,961,050 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "9,962,650 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,964,250 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "9,965,850 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,967,450 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "9,969,050 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "9,970,650 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,972,250 examples, moving-average loss 12.07, train accuracy 0.70\n",
      "9,973,850 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "9,975,450 examples, moving-average loss 12.05, train accuracy 0.70\n",
      "9,977,050 examples, moving-average loss 11.88, train accuracy 0.70\n",
      "9,978,650 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "9,980,250 examples, moving-average loss 12.05, train accuracy 0.70\n",
      "9,981,850 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "9,983,450 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "9,985,050 examples, moving-average loss 11.88, train accuracy 0.70\n",
      "9,986,650 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "9,988,250 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "9,989,850 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "9,991,450 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "9,993,050 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "9,994,650 examples, moving-average loss 11.87, train accuracy 0.70\n",
      "9,996,250 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "9,997,850 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "9,999,450 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "10,001,050 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "10,002,650 examples, moving-average loss 11.90, train accuracy 0.70\n",
      "10,004,250 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "10,005,850 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "10,007,450 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "10,009,050 examples, moving-average loss 12.06, train accuracy 0.70\n",
      "10,010,650 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "10,012,250 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "10,013,850 examples, moving-average loss 12.10, train accuracy 0.70\n",
      "10,015,450 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "10,017,050 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "10,018,650 examples, moving-average loss 11.89, train accuracy 0.70\n",
      "10,020,250 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "10,021,850 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "10,023,450 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "10,025,050 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "10,026,650 examples, moving-average loss 12.06, train accuracy 0.70\n",
      "10,028,250 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "10,029,850 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "10,031,450 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "10,033,050 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "10,034,650 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "10,036,250 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "10,037,850 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "10,039,450 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "10,041,050 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "10,042,650 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "10,044,250 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "10,045,850 examples, moving-average loss 11.97, train accuracy 0.70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10,047,450 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "10,049,050 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "10,050,650 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "10,052,250 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "10,053,850 examples, moving-average loss 12.06, train accuracy 0.70\n",
      "10,055,450 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "10,057,050 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "10,058,650 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "10,060,250 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "10,061,850 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "10,063,450 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "10,065,050 examples, moving-average loss 11.90, train accuracy 0.70\n",
      "10,066,650 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "10,068,250 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "10,069,850 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "10,071,450 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "10,073,050 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "10,074,650 examples, moving-average loss 11.86, train accuracy 0.70\n",
      "10,076,250 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "10,077,850 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "10,079,450 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "10,081,050 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "10,082,650 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "10,084,250 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "10,085,850 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "10,087,450 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "10,089,050 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "10,090,650 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "10,092,250 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "10,093,850 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "10,095,450 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "10,097,050 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "Completed 11 epoch in 0:38:59\n",
      "Train accurary:0.70390\n",
      "Validate accuracy:0.69941\n",
      "10,098,600 examples, moving-average loss 11.84, train accuracy 0.65\n",
      "10,100,200 examples, moving-average loss 11.98, train accuracy 0.68\n",
      "10,101,800 examples, moving-average loss 12.00, train accuracy 0.69\n",
      "10,103,400 examples, moving-average loss 11.99, train accuracy 0.69\n",
      "10,105,000 examples, moving-average loss 12.07, train accuracy 0.69\n",
      "10,106,600 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "10,108,200 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "10,109,800 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "10,111,400 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "10,113,000 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "10,114,600 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "10,116,200 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "10,117,800 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "10,119,400 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "10,121,000 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "10,122,600 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "10,124,200 examples, moving-average loss 12.06, train accuracy 0.70\n",
      "10,125,800 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "10,127,400 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "10,129,000 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "10,130,600 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "10,132,200 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "10,133,800 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "10,135,400 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "10,137,000 examples, moving-average loss 11.87, train accuracy 0.71\n",
      "10,138,600 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "10,140,200 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "10,141,800 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "10,143,400 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "10,145,000 examples, moving-average loss 12.05, train accuracy 0.71\n",
      "10,146,600 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "10,148,200 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "10,149,800 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "10,151,400 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "10,153,000 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "10,154,600 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "10,156,200 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "10,157,800 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "10,159,400 examples, moving-average loss 12.05, train accuracy 0.71\n",
      "10,161,000 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "10,162,600 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "10,164,200 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "10,165,800 examples, moving-average loss 11.87, train accuracy 0.71\n",
      "10,167,400 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "10,169,000 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "10,170,600 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "10,172,200 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "10,173,800 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "10,175,400 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "10,177,000 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "10,178,600 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "10,180,200 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "10,181,800 examples, moving-average loss 12.04, train accuracy 0.71\n",
      "10,183,400 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "10,185,000 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "10,186,600 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "10,188,200 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "10,189,800 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "10,191,400 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "10,193,000 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "10,194,600 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "10,196,200 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "10,197,800 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "10,199,400 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "10,201,000 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "10,202,600 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "10,204,200 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "10,205,800 examples, moving-average loss 12.05, train accuracy 0.71\n",
      "10,207,400 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "10,209,000 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "10,210,600 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "10,212,200 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "10,213,800 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "10,215,400 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "10,217,000 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "10,218,600 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "10,220,200 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "10,221,800 examples, moving-average loss 12.06, train accuracy 0.71\n",
      "10,223,400 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "10,225,000 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "10,226,600 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "10,228,200 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "10,229,800 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "10,231,400 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "10,233,000 examples, moving-average loss 12.07, train accuracy 0.70\n",
      "10,234,600 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "10,236,200 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "10,237,800 examples, moving-average loss 11.97, train accuracy 0.70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10,239,400 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "10,241,000 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "10,242,600 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "10,244,200 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "10,245,800 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "10,247,400 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "10,249,000 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "10,250,600 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "10,252,200 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "10,253,800 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "10,255,400 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "10,257,000 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "10,258,600 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "10,260,200 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "10,261,800 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "10,263,400 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "10,265,000 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "10,266,600 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "10,268,200 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "10,269,800 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "10,271,400 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "10,273,000 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "10,274,600 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "10,276,200 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "10,277,800 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "10,279,400 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "10,281,000 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "10,282,600 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "10,284,200 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "10,285,800 examples, moving-average loss 12.05, train accuracy 0.70\n",
      "10,287,400 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "10,289,000 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "10,290,600 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "10,292,200 examples, moving-average loss 11.87, train accuracy 0.70\n",
      "10,293,800 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "10,295,400 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "10,297,000 examples, moving-average loss 11.89, train accuracy 0.70\n",
      "10,298,600 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "10,300,200 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "10,301,800 examples, moving-average loss 11.89, train accuracy 0.70\n",
      "10,303,400 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "10,305,000 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "10,306,600 examples, moving-average loss 11.89, train accuracy 0.70\n",
      "10,308,200 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "10,309,800 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "10,311,400 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "10,313,000 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "10,314,600 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "10,316,200 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "10,317,800 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "10,319,400 examples, moving-average loss 11.90, train accuracy 0.70\n",
      "10,321,000 examples, moving-average loss 11.87, train accuracy 0.70\n",
      "10,322,600 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "10,324,200 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "10,325,800 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "10,327,400 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "10,329,000 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "10,330,600 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "10,332,200 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "10,333,800 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "10,335,400 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "10,337,000 examples, moving-average loss 11.88, train accuracy 0.70\n",
      "10,338,600 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "10,340,200 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "10,341,800 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "10,343,400 examples, moving-average loss 11.90, train accuracy 0.70\n",
      "10,345,000 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "10,346,600 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "10,348,200 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "10,349,800 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "10,351,400 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "10,353,000 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "10,354,600 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "10,356,200 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "10,357,800 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "10,359,400 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "10,361,000 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "10,362,600 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "10,364,200 examples, moving-average loss 11.89, train accuracy 0.70\n",
      "10,365,800 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "10,367,400 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "10,369,000 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "10,370,600 examples, moving-average loss 12.01, train accuracy 0.70\n",
      "10,372,200 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "10,373,800 examples, moving-average loss 11.85, train accuracy 0.70\n",
      "10,375,400 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "10,377,000 examples, moving-average loss 12.05, train accuracy 0.70\n",
      "10,378,600 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "10,380,200 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "10,381,800 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "10,383,400 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "10,385,000 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "10,386,600 examples, moving-average loss 11.90, train accuracy 0.70\n",
      "10,388,200 examples, moving-average loss 11.88, train accuracy 0.70\n",
      "10,389,800 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "10,391,400 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "10,393,000 examples, moving-average loss 12.02, train accuracy 0.70\n",
      "10,394,600 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "10,396,200 examples, moving-average loss 11.84, train accuracy 0.70\n",
      "10,397,800 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "10,399,400 examples, moving-average loss 11.99, train accuracy 0.70\n",
      "10,401,000 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "10,402,600 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "10,404,200 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "10,405,800 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "10,407,400 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "10,409,000 examples, moving-average loss 11.87, train accuracy 0.71\n",
      "10,410,600 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "10,412,200 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "10,413,800 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "10,415,400 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "10,417,000 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "10,418,600 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "10,420,200 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "10,421,800 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "10,423,400 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "10,425,000 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "10,426,600 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "10,428,200 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "10,429,800 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "10,431,400 examples, moving-average loss 11.93, train accuracy 0.71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10,433,000 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "10,434,600 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "10,436,200 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "10,437,800 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "10,439,400 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "10,441,000 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "10,442,600 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "10,444,200 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "10,445,800 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "10,447,400 examples, moving-average loss 11.86, train accuracy 0.71\n",
      "10,449,000 examples, moving-average loss 11.80, train accuracy 0.71\n",
      "10,450,600 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "10,452,200 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "10,453,800 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "10,455,400 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "10,457,000 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "10,458,600 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "10,460,200 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "10,461,800 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "10,463,400 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "10,465,000 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "10,466,600 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "10,468,200 examples, moving-average loss 12.05, train accuracy 0.71\n",
      "10,469,800 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "10,471,400 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "10,473,000 examples, moving-average loss 12.05, train accuracy 0.71\n",
      "10,474,600 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "10,476,200 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "10,477,800 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "10,479,400 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "10,481,000 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "10,482,600 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "10,484,200 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "10,485,800 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "10,487,400 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "10,489,000 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "10,490,600 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "10,492,200 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "10,493,800 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "10,495,400 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "10,497,000 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "10,498,600 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "10,500,200 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "10,501,800 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "10,503,400 examples, moving-average loss 12.05, train accuracy 0.71\n",
      "10,505,000 examples, moving-average loss 12.08, train accuracy 0.71\n",
      "10,506,600 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "10,508,200 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "10,509,800 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "10,511,400 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "10,513,000 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "10,514,600 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "10,516,200 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "10,517,800 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "10,519,400 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "10,521,000 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "10,522,600 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "10,524,200 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "10,525,800 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "10,527,400 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "10,529,000 examples, moving-average loss 12.05, train accuracy 0.71\n",
      "10,530,600 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "10,532,200 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "10,533,800 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "10,535,400 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "10,537,000 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "10,538,600 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "10,540,200 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "10,541,800 examples, moving-average loss 12.07, train accuracy 0.71\n",
      "10,543,400 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "10,545,000 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "10,546,600 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "10,548,200 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "10,549,800 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "10,551,400 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "10,553,000 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "10,554,600 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "10,556,200 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "10,557,800 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "10,559,400 examples, moving-average loss 12.07, train accuracy 0.71\n",
      "10,561,000 examples, moving-average loss 12.05, train accuracy 0.71\n",
      "10,562,600 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "10,564,200 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "10,565,800 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "10,567,400 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "10,569,000 examples, moving-average loss 12.05, train accuracy 0.71\n",
      "10,570,600 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "10,572,200 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "10,573,800 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "10,575,400 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "10,577,000 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "10,578,600 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "10,580,200 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "10,581,800 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "10,583,400 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "10,585,000 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "10,586,600 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "10,588,200 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "10,589,800 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "10,591,400 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "10,593,000 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "10,594,600 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "10,596,200 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "10,597,800 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "10,599,400 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "10,601,000 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "10,602,600 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "10,604,200 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "10,605,800 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "10,607,400 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "10,609,000 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "10,610,600 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "10,612,200 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "10,613,800 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "10,615,400 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "10,617,000 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "10,618,600 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "10,620,200 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "10,621,800 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "10,623,400 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "10,625,000 examples, moving-average loss 12.03, train accuracy 0.71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10,626,600 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "10,628,200 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "10,629,800 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "10,631,400 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "10,633,000 examples, moving-average loss 12.05, train accuracy 0.71\n",
      "10,634,600 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "10,636,200 examples, moving-average loss 11.87, train accuracy 0.71\n",
      "10,637,800 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "10,639,400 examples, moving-average loss 11.79, train accuracy 0.71\n",
      "10,641,000 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "10,642,600 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "10,644,200 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "10,645,800 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "10,647,400 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "10,649,000 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "10,650,600 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "10,652,200 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "10,653,800 examples, moving-average loss 12.05, train accuracy 0.71\n",
      "10,655,400 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "10,657,000 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "10,658,600 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "10,660,200 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "10,661,800 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "10,663,400 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "10,665,000 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "10,666,600 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "10,668,200 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "10,669,800 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "10,671,400 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "10,673,000 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "10,674,600 examples, moving-average loss 12.08, train accuracy 0.71\n",
      "10,676,200 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "10,677,800 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "10,679,400 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "10,681,000 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "10,682,600 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "10,684,200 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "10,685,800 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "10,687,400 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "10,689,000 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "10,690,600 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "10,692,200 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "10,693,800 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "10,695,400 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "10,697,000 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "10,698,600 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "10,700,200 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "10,701,800 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "10,703,400 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "10,705,000 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "10,706,600 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "10,708,200 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "10,709,800 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "10,711,400 examples, moving-average loss 12.05, train accuracy 0.71\n",
      "10,713,000 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "10,714,600 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "10,716,200 examples, moving-average loss 12.06, train accuracy 0.71\n",
      "10,717,800 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "10,719,400 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "10,721,000 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "10,722,600 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "10,724,200 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "10,725,800 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "10,727,400 examples, moving-average loss 12.04, train accuracy 0.71\n",
      "10,729,000 examples, moving-average loss 12.04, train accuracy 0.71\n",
      "10,730,600 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "10,732,200 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "10,733,800 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "10,735,400 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "10,737,000 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "10,738,600 examples, moving-average loss 12.07, train accuracy 0.71\n",
      "10,740,200 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "10,741,800 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "10,743,400 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "10,745,000 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "10,746,600 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "10,748,200 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "10,749,800 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "10,751,400 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "10,753,000 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "10,754,600 examples, moving-average loss 12.04, train accuracy 0.71\n",
      "10,756,200 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "10,757,800 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "10,759,400 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "10,761,000 examples, moving-average loss 12.06, train accuracy 0.71\n",
      "10,762,600 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "10,764,200 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "10,765,800 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "10,767,400 examples, moving-average loss 11.86, train accuracy 0.71\n",
      "10,769,000 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "10,770,600 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "10,772,200 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "10,773,800 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "10,775,400 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "10,777,000 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "10,778,600 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "10,780,200 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "10,781,800 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "10,783,400 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "10,785,000 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "10,786,600 examples, moving-average loss 11.86, train accuracy 0.71\n",
      "10,788,200 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "10,789,800 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "10,791,400 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "10,793,000 examples, moving-average loss 12.05, train accuracy 0.71\n",
      "10,794,600 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "10,796,200 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "10,797,800 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "10,799,400 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "10,801,000 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "10,802,600 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "10,804,200 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "10,805,800 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "10,807,400 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "10,809,000 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "10,810,600 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "10,812,200 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "10,813,800 examples, moving-average loss 12.04, train accuracy 0.71\n",
      "10,815,400 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "10,817,000 examples, moving-average loss 12.05, train accuracy 0.71\n",
      "10,818,600 examples, moving-average loss 11.88, train accuracy 0.71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10,820,200 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "10,821,800 examples, moving-average loss 12.05, train accuracy 0.71\n",
      "10,823,400 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "10,825,000 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "10,826,600 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "10,828,200 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "10,829,800 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "10,831,400 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "10,833,000 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "10,834,600 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "10,836,200 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "10,837,800 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "10,839,400 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "10,841,000 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "10,842,600 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "10,844,200 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "10,845,800 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "10,847,400 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "10,849,000 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "10,850,600 examples, moving-average loss 12.08, train accuracy 0.71\n",
      "10,852,200 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "10,853,800 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "10,855,400 examples, moving-average loss 12.09, train accuracy 0.71\n",
      "10,857,000 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "10,858,600 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "10,860,200 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "10,861,800 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "10,863,400 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "10,865,000 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "10,866,600 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "10,868,200 examples, moving-average loss 12.06, train accuracy 0.71\n",
      "10,869,800 examples, moving-average loss 11.87, train accuracy 0.71\n",
      "10,871,400 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "10,873,000 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "10,874,600 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "10,876,200 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "10,877,800 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "10,879,400 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "10,881,000 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "10,882,600 examples, moving-average loss 11.85, train accuracy 0.71\n",
      "10,884,200 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "10,885,800 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "10,887,400 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "10,889,000 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "10,890,600 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "10,892,200 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "10,893,800 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "10,895,400 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "10,897,000 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "10,898,600 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "10,900,200 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "10,901,800 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "10,903,400 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "10,905,000 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "10,906,600 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "10,908,200 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "10,909,800 examples, moving-average loss 12.04, train accuracy 0.71\n",
      "10,911,400 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "10,913,000 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "10,914,600 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "10,916,200 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "10,917,800 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "10,919,400 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "10,921,000 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "10,922,600 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "10,924,200 examples, moving-average loss 12.05, train accuracy 0.71\n",
      "10,925,800 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "10,927,400 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "10,929,000 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "10,930,600 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "10,932,200 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "10,933,800 examples, moving-average loss 12.04, train accuracy 0.71\n",
      "10,935,400 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "10,937,000 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "Completed 12 epoch in 0:38:57\n",
      "Train accurary:0.70623\n",
      "Validate accuracy:0.70101\n",
      "10,938,550 examples, moving-average loss 11.18, train accuracy 0.37\n",
      "10,940,150 examples, moving-average loss 11.85, train accuracy 0.66\n",
      "10,941,750 examples, moving-average loss 11.96, train accuracy 0.69\n",
      "10,943,350 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "10,944,950 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "10,946,550 examples, moving-average loss 12.04, train accuracy 0.70\n",
      "10,948,150 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "10,949,750 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "10,951,350 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "10,952,950 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "10,954,550 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "10,956,150 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "10,957,750 examples, moving-average loss 12.00, train accuracy 0.70\n",
      "10,959,350 examples, moving-average loss 12.03, train accuracy 0.70\n",
      "10,960,950 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "10,962,550 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "10,964,150 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "10,965,750 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "10,967,350 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "10,968,950 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "10,970,550 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "10,972,150 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "10,973,750 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "10,975,350 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "10,976,950 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "10,978,550 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "10,980,150 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "10,981,750 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "10,983,350 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "10,984,950 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "10,986,550 examples, moving-average loss 12.06, train accuracy 0.71\n",
      "10,988,150 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "10,989,750 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "10,991,350 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "10,992,950 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "10,994,550 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "10,996,150 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "10,997,750 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "10,999,350 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,000,950 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "11,002,550 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "11,004,150 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "11,005,750 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "11,007,350 examples, moving-average loss 11.87, train accuracy 0.71\n",
      "11,008,950 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "11,010,550 examples, moving-average loss 11.96, train accuracy 0.71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11,012,150 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "11,013,750 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,015,350 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "11,016,950 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "11,018,550 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "11,020,150 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "11,021,750 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "11,023,350 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "11,024,950 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "11,026,550 examples, moving-average loss 11.87, train accuracy 0.71\n",
      "11,028,150 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "11,029,750 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "11,031,350 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "11,032,950 examples, moving-average loss 12.04, train accuracy 0.71\n",
      "11,034,550 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "11,036,150 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "11,037,750 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "11,039,350 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "11,040,950 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "11,042,550 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "11,044,150 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "11,045,750 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "11,047,350 examples, moving-average loss 12.04, train accuracy 0.71\n",
      "11,048,950 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "11,050,550 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "11,052,150 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "11,053,750 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "11,055,350 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "11,056,950 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "11,058,550 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "11,060,150 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,061,750 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "11,063,350 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "11,064,950 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "11,066,550 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "11,068,150 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "11,069,750 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "11,071,350 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "11,072,950 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "11,074,550 examples, moving-average loss 12.04, train accuracy 0.71\n",
      "11,076,150 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "11,077,750 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "11,079,350 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "11,080,950 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,082,550 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "11,084,150 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,085,750 examples, moving-average loss 12.05, train accuracy 0.71\n",
      "11,087,350 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,088,950 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "11,090,550 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "11,092,150 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "11,093,750 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "11,095,350 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "11,096,950 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,098,550 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "11,100,150 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "11,101,750 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "11,103,350 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "11,104,950 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "11,106,550 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "11,108,150 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "11,109,750 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "11,111,350 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "11,112,950 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "11,114,550 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "11,116,150 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "11,117,750 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "11,119,350 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "11,120,950 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,122,550 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "11,124,150 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,125,750 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "11,127,350 examples, moving-average loss 12.04, train accuracy 0.71\n",
      "11,128,950 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "11,130,550 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "11,132,150 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "11,133,750 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "11,135,350 examples, moving-average loss 12.07, train accuracy 0.71\n",
      "11,136,950 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "11,138,550 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "11,140,150 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,141,750 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "11,143,350 examples, moving-average loss 11.87, train accuracy 0.71\n",
      "11,144,950 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "11,146,550 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "11,148,150 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "11,149,750 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "11,151,350 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "11,152,950 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "11,154,550 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "11,156,150 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "11,157,750 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "11,159,350 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "11,160,950 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "11,162,550 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "11,164,150 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,165,750 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,167,350 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "11,168,950 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "11,170,550 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "11,172,150 examples, moving-average loss 11.87, train accuracy 0.71\n",
      "11,173,750 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "11,175,350 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "11,176,950 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "11,178,550 examples, moving-average loss 11.83, train accuracy 0.71\n",
      "11,180,150 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "11,181,750 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "11,183,350 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "11,184,950 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "11,186,550 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "11,188,150 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "11,189,750 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "11,191,350 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "11,192,950 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "11,194,550 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "11,196,150 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "11,197,750 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "11,199,350 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,200,950 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "11,202,550 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "11,204,150 examples, moving-average loss 11.87, train accuracy 0.71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11,205,750 examples, moving-average loss 11.87, train accuracy 0.71\n",
      "11,207,350 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "11,208,950 examples, moving-average loss 12.04, train accuracy 0.71\n",
      "11,210,550 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "11,212,150 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "11,213,750 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "11,215,350 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "11,216,950 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "11,218,550 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "11,220,150 examples, moving-average loss 12.05, train accuracy 0.71\n",
      "11,221,750 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "11,223,350 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "11,224,950 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "11,226,550 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,228,150 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "11,229,750 examples, moving-average loss 11.87, train accuracy 0.71\n",
      "11,231,350 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "11,232,950 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "11,234,550 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "11,236,150 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,237,750 examples, moving-average loss 11.85, train accuracy 0.71\n",
      "11,239,350 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "11,240,950 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "11,242,550 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "11,244,150 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "11,245,750 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "11,247,350 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "11,248,950 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "11,250,550 examples, moving-average loss 11.86, train accuracy 0.71\n",
      "11,252,150 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "11,253,750 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "11,255,350 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "11,256,950 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "11,258,550 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "11,260,150 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "11,261,750 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,263,350 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "11,264,950 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "11,266,550 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "11,268,150 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "11,269,750 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "11,271,350 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "11,272,950 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "11,274,550 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "11,276,150 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "11,277,750 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,279,350 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "11,280,950 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "11,282,550 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "11,284,150 examples, moving-average loss 12.04, train accuracy 0.71\n",
      "11,285,750 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "11,287,350 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "11,288,950 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "11,290,550 examples, moving-average loss 11.83, train accuracy 0.71\n",
      "11,292,150 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "11,293,750 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "11,295,350 examples, moving-average loss 11.87, train accuracy 0.71\n",
      "11,296,950 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "11,298,550 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "11,300,150 examples, moving-average loss 12.07, train accuracy 0.71\n",
      "11,301,750 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "11,303,350 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "11,304,950 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "11,306,550 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "11,308,150 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "11,309,750 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "11,311,350 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "11,312,950 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "11,314,550 examples, moving-average loss 12.08, train accuracy 0.71\n",
      "11,316,150 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "11,317,750 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "11,319,350 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "11,320,950 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "11,322,550 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "11,324,150 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "11,325,750 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "11,327,350 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "11,328,950 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "11,330,550 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "11,332,150 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "11,333,750 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "11,335,350 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "11,336,950 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "11,338,550 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,340,150 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "11,341,750 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "11,343,350 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "11,344,950 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "11,346,550 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "11,348,150 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "11,349,750 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "11,351,350 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "11,352,950 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "11,354,550 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "11,356,150 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "11,357,750 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "11,359,350 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,360,950 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,362,550 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "11,364,150 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "11,365,750 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "11,367,350 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "11,368,950 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,370,550 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "11,372,150 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,373,750 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "11,375,350 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "11,376,950 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "11,378,550 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "11,380,150 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "11,381,750 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "11,383,350 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "11,384,950 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,386,550 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "11,388,150 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "11,389,750 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "11,391,350 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "11,392,950 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "11,394,550 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "11,396,150 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,397,750 examples, moving-average loss 11.96, train accuracy 0.71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11,399,350 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "11,400,950 examples, moving-average loss 12.06, train accuracy 0.71\n",
      "11,402,550 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "11,404,150 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "11,405,750 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "11,407,350 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "11,408,950 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "11,410,550 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "11,412,150 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "11,413,750 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "11,415,350 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "11,416,950 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "11,418,550 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "11,420,150 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "11,421,750 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "11,423,350 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "11,424,950 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,426,550 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "11,428,150 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "11,429,750 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "11,431,350 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "11,432,950 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "11,434,550 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "11,436,150 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "11,437,750 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "11,439,350 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "11,440,950 examples, moving-average loss 11.87, train accuracy 0.71\n",
      "11,442,550 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "11,444,150 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "11,445,750 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "11,447,350 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "11,448,950 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "11,450,550 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "11,452,150 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "11,453,750 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "11,455,350 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,456,950 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "11,458,550 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "11,460,150 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "11,461,750 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "11,463,350 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "11,464,950 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "11,466,550 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "11,468,150 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "11,469,750 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "11,471,350 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "11,472,950 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,474,550 examples, moving-average loss 12.06, train accuracy 0.71\n",
      "11,476,150 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "11,477,750 examples, moving-average loss 11.86, train accuracy 0.71\n",
      "11,479,350 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "11,480,950 examples, moving-average loss 11.80, train accuracy 0.71\n",
      "11,482,550 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "11,484,150 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "11,485,750 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "11,487,350 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "11,488,950 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,490,550 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "11,492,150 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "11,493,750 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "11,495,350 examples, moving-average loss 12.07, train accuracy 0.71\n",
      "11,496,950 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "11,498,550 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,500,150 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "11,501,750 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,503,350 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "11,504,950 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,506,550 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "11,508,150 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "11,509,750 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "11,511,350 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "11,512,950 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,514,550 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "11,516,150 examples, moving-average loss 12.06, train accuracy 0.71\n",
      "11,517,750 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "11,519,350 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "11,520,950 examples, moving-average loss 11.86, train accuracy 0.71\n",
      "11,522,550 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "11,524,150 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,525,750 examples, moving-average loss 11.86, train accuracy 0.71\n",
      "11,527,350 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "11,528,950 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "11,530,550 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "11,532,150 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,533,750 examples, moving-average loss 11.85, train accuracy 0.71\n",
      "11,535,350 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "11,536,950 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "11,538,550 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "11,540,150 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "11,541,750 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "11,543,350 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "11,544,950 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "11,546,550 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "11,548,150 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "11,549,750 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "11,551,350 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "11,552,950 examples, moving-average loss 12.04, train accuracy 0.71\n",
      "11,554,550 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,556,150 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "11,557,750 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "11,559,350 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "11,560,950 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "11,562,550 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "11,564,150 examples, moving-average loss 11.87, train accuracy 0.71\n",
      "11,565,750 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "11,567,350 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "11,568,950 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "11,570,550 examples, moving-average loss 12.08, train accuracy 0.71\n",
      "11,572,150 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "11,573,750 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "11,575,350 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "11,576,950 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "11,578,550 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "11,580,150 examples, moving-average loss 12.09, train accuracy 0.71\n",
      "11,581,750 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "11,583,350 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "11,584,950 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "11,586,550 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "11,588,150 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "11,589,750 examples, moving-average loss 11.84, train accuracy 0.71\n",
      "11,591,350 examples, moving-average loss 11.96, train accuracy 0.71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11,592,950 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "11,594,550 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "11,596,150 examples, moving-average loss 12.04, train accuracy 0.71\n",
      "11,597,750 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "11,599,350 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "11,600,950 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "11,602,550 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "11,604,150 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "11,605,750 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "11,607,350 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "11,608,950 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "11,610,550 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "11,612,150 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "11,613,750 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "11,615,350 examples, moving-average loss 12.04, train accuracy 0.71\n",
      "11,616,950 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "11,618,550 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "11,620,150 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "11,621,750 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "11,623,350 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "11,624,950 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "11,626,550 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "11,628,150 examples, moving-average loss 11.85, train accuracy 0.71\n",
      "11,629,750 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "11,631,350 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "11,632,950 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,634,550 examples, moving-average loss 12.07, train accuracy 0.71\n",
      "11,636,150 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "11,637,750 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "11,639,350 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "11,640,950 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "11,642,550 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "11,644,150 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "11,645,750 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "11,647,350 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "11,648,950 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "11,650,550 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "11,652,150 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "11,653,750 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "11,655,350 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "11,656,950 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "11,658,550 examples, moving-average loss 12.05, train accuracy 0.71\n",
      "11,660,150 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "11,661,750 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "11,663,350 examples, moving-average loss 12.05, train accuracy 0.71\n",
      "11,664,950 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "11,666,550 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "11,668,150 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "11,669,750 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "11,671,350 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "11,672,950 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,674,550 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "11,676,150 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "11,677,750 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "11,679,350 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "11,680,950 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "11,682,550 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "11,684,150 examples, moving-average loss 11.87, train accuracy 0.71\n",
      "11,685,750 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,687,350 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "11,688,950 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "11,690,550 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "11,692,150 examples, moving-average loss 12.07, train accuracy 0.71\n",
      "11,693,750 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "11,695,350 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "11,696,950 examples, moving-average loss 12.08, train accuracy 0.71\n",
      "11,698,550 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "11,700,150 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "11,701,750 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "11,703,350 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "11,704,950 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "11,706,550 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "11,708,150 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "11,709,750 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "11,711,350 examples, moving-average loss 11.84, train accuracy 0.71\n",
      "11,712,950 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "11,714,550 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "11,716,150 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "11,717,750 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "11,719,350 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "11,720,950 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "11,722,550 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "11,724,150 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "11,725,750 examples, moving-average loss 12.06, train accuracy 0.71\n",
      "11,727,350 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "11,728,950 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "11,730,550 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,732,150 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "11,733,750 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "11,735,350 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "11,736,950 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "11,738,550 examples, moving-average loss 12.04, train accuracy 0.71\n",
      "11,740,150 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "11,741,750 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "11,743,350 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "11,744,950 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "11,746,550 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "11,748,150 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "11,749,750 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "11,751,350 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "11,752,950 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "11,754,550 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "11,756,150 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "11,757,750 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "11,759,350 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "11,760,950 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "11,762,550 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "11,764,150 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "11,765,750 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "11,767,350 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,768,950 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "11,770,550 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "11,772,150 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "11,773,750 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,775,350 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "11,776,950 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "11,778,550 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "Completed 13 epoch in 0:39:19\n",
      "Train accurary:0.70860\n",
      "Validate accuracy:0.70291\n",
      "11,780,100 examples, moving-average loss 11.29, train accuracy 0.52\n",
      "11,781,700 examples, moving-average loss 11.87, train accuracy 0.67\n",
      "11,783,300 examples, moving-average loss 11.92, train accuracy 0.70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11,784,900 examples, moving-average loss 11.97, train accuracy 0.70\n",
      "11,786,500 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "11,788,100 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "11,789,700 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "11,791,300 examples, moving-average loss 11.91, train accuracy 0.70\n",
      "11,792,900 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "11,794,500 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "11,796,100 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "11,797,700 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,799,300 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "11,800,900 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "11,802,500 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "11,804,100 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "11,805,700 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "11,807,300 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "11,808,900 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "11,810,500 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "11,812,100 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "11,813,700 examples, moving-average loss 12.04, train accuracy 0.71\n",
      "11,815,300 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "11,816,900 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "11,818,500 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "11,820,100 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "11,821,700 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "11,823,300 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "11,824,900 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "11,826,500 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "11,828,100 examples, moving-average loss 12.04, train accuracy 0.71\n",
      "11,829,700 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "11,831,300 examples, moving-average loss 11.83, train accuracy 0.71\n",
      "11,832,900 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "11,834,500 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "11,836,100 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "11,837,700 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "11,839,300 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "11,840,900 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,842,500 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "11,844,100 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "11,845,700 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "11,847,300 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "11,848,900 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "11,850,500 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "11,852,100 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "11,853,700 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,855,300 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "11,856,900 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "11,858,500 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "11,860,100 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "11,861,700 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "11,863,300 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "11,864,900 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "11,866,500 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "11,868,100 examples, moving-average loss 11.86, train accuracy 0.71\n",
      "11,869,700 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "11,871,300 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "11,872,900 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "11,874,500 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "11,876,100 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "11,877,700 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "11,879,300 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "11,880,900 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "11,882,500 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "11,884,100 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "11,885,700 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "11,887,300 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "11,888,900 examples, moving-average loss 12.04, train accuracy 0.71\n",
      "11,890,500 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "11,892,100 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "11,893,700 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "11,895,300 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "11,896,900 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "11,898,500 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "11,900,100 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "11,901,700 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "11,903,300 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "11,904,900 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "11,906,500 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "11,908,100 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "11,909,700 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "11,911,300 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,912,900 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "11,914,500 examples, moving-average loss 11.86, train accuracy 0.71\n",
      "11,916,100 examples, moving-average loss 12.05, train accuracy 0.71\n",
      "11,917,700 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "11,919,300 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "11,920,900 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,922,500 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,924,100 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "11,925,700 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "11,927,300 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "11,928,900 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "11,930,500 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "11,932,100 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "11,933,700 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "11,935,300 examples, moving-average loss 11.87, train accuracy 0.71\n",
      "11,936,900 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "11,938,500 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "11,940,100 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "11,941,700 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "11,943,300 examples, moving-average loss 11.87, train accuracy 0.71\n",
      "11,944,900 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "11,946,500 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "11,948,100 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "11,949,700 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "11,951,300 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "11,952,900 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "11,954,500 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "11,956,100 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "11,957,700 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "11,959,300 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,960,900 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "11,962,500 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,964,100 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "11,965,700 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "11,967,300 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "11,968,900 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "11,970,500 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,972,100 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,973,700 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "11,975,300 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "11,976,900 examples, moving-average loss 12.04, train accuracy 0.71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11,978,500 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "11,980,100 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "11,981,700 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "11,983,300 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "11,984,900 examples, moving-average loss 11.83, train accuracy 0.71\n",
      "11,986,500 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "11,988,100 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "11,989,700 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "11,991,300 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "11,992,900 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "11,994,500 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "11,996,100 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "11,997,700 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "11,999,300 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "12,000,900 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "12,002,500 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "12,004,100 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "12,005,700 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "12,007,300 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "12,008,900 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "12,010,500 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "12,012,100 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "12,013,700 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "12,015,300 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "12,016,900 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "12,018,500 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "12,020,100 examples, moving-average loss 11.81, train accuracy 0.71\n",
      "12,021,700 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "12,023,300 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,024,900 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "12,026,500 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "12,028,100 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "12,029,700 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "12,031,300 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "12,032,900 examples, moving-average loss 11.87, train accuracy 0.71\n",
      "12,034,500 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "12,036,100 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "12,037,700 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "12,039,300 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "12,040,900 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "12,042,500 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "12,044,100 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,045,700 examples, moving-average loss 11.87, train accuracy 0.71\n",
      "12,047,300 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "12,048,900 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "12,050,500 examples, moving-average loss 12.05, train accuracy 0.71\n",
      "12,052,100 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "12,053,700 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "12,055,300 examples, moving-average loss 11.87, train accuracy 0.71\n",
      "12,056,900 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "12,058,500 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "12,060,100 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "12,061,700 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "12,063,300 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "12,064,900 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "12,066,500 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,068,100 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "12,069,700 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,071,300 examples, moving-average loss 11.85, train accuracy 0.71\n",
      "12,072,900 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "12,074,500 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,076,100 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,077,700 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,079,300 examples, moving-average loss 11.85, train accuracy 0.71\n",
      "12,080,900 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "12,082,500 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "12,084,100 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "12,085,700 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "12,087,300 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "12,088,900 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "12,090,500 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "12,092,100 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "12,093,700 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "12,095,300 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "12,096,900 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "12,098,500 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "12,100,100 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,101,700 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "12,103,300 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,104,900 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "12,106,500 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "12,108,100 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "12,109,700 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "12,111,300 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "12,112,900 examples, moving-average loss 11.87, train accuracy 0.71\n",
      "12,114,500 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "12,116,100 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "12,117,700 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "12,119,300 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "12,120,900 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,122,500 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "12,124,100 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "12,125,700 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "12,127,300 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "12,128,900 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "12,130,500 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "12,132,100 examples, moving-average loss 11.83, train accuracy 0.71\n",
      "12,133,700 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "12,135,300 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "12,136,900 examples, moving-average loss 11.85, train accuracy 0.71\n",
      "12,138,500 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "12,140,100 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "12,141,700 examples, moving-average loss 12.04, train accuracy 0.71\n",
      "12,143,300 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "12,144,900 examples, moving-average loss 11.86, train accuracy 0.71\n",
      "12,146,500 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,148,100 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "12,149,700 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "12,151,300 examples, moving-average loss 12.09, train accuracy 0.71\n",
      "12,152,900 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "12,154,500 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "12,156,100 examples, moving-average loss 12.06, train accuracy 0.71\n",
      "12,157,700 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "12,159,300 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "12,160,900 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,162,500 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "12,164,100 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "12,165,700 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "12,167,300 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "12,168,900 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "12,170,500 examples, moving-average loss 12.01, train accuracy 0.71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12,172,100 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "12,173,700 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "12,175,300 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "12,176,900 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "12,178,500 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,180,100 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "12,181,700 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "12,183,300 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "12,184,900 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "12,186,500 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "12,188,100 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "12,189,700 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "12,191,300 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,192,900 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "12,194,500 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "12,196,100 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "12,197,700 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "12,199,300 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "12,200,900 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "12,202,500 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "12,204,100 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "12,205,700 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "12,207,300 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "12,208,900 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,210,500 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "12,212,100 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "12,213,700 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "12,215,300 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,216,900 examples, moving-average loss 11.87, train accuracy 0.71\n",
      "12,218,500 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "12,220,100 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,221,700 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "12,223,300 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "12,224,900 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "12,226,500 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "12,228,100 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "12,229,700 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "12,231,300 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "12,232,900 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "12,234,500 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "12,236,100 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "12,237,700 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "12,239,300 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "12,240,900 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "12,242,500 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "12,244,100 examples, moving-average loss 12.06, train accuracy 0.71\n",
      "12,245,700 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "12,247,300 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "12,248,900 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "12,250,500 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "12,252,100 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "12,253,700 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "12,255,300 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,256,900 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "12,258,500 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "12,260,100 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,261,700 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "12,263,300 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "12,264,900 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "12,266,500 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "12,268,100 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "12,269,700 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "12,271,300 examples, moving-average loss 12.07, train accuracy 0.71\n",
      "12,272,900 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "12,274,500 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,276,100 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "12,277,700 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "12,279,300 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "12,280,900 examples, moving-average loss 11.86, train accuracy 0.71\n",
      "12,282,500 examples, moving-average loss 11.86, train accuracy 0.71\n",
      "12,284,100 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "12,285,700 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,287,300 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "12,288,900 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "12,290,500 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "12,292,100 examples, moving-average loss 12.06, train accuracy 0.71\n",
      "12,293,700 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "12,295,300 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,296,900 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "12,298,500 examples, moving-average loss 11.87, train accuracy 0.71\n",
      "12,300,100 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "12,301,700 examples, moving-average loss 11.87, train accuracy 0.71\n",
      "12,303,300 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "12,304,900 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "12,306,500 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "12,308,100 examples, moving-average loss 12.06, train accuracy 0.71\n",
      "12,309,700 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "12,311,300 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,312,900 examples, moving-average loss 12.05, train accuracy 0.71\n",
      "12,314,500 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,316,100 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "12,317,700 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "12,319,300 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "12,320,900 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "12,322,500 examples, moving-average loss 11.81, train accuracy 0.71\n",
      "12,324,100 examples, moving-average loss 11.87, train accuracy 0.71\n",
      "12,325,700 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "12,327,300 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "12,328,900 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,330,500 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "12,332,100 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "12,333,700 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "12,335,300 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "12,336,900 examples, moving-average loss 12.08, train accuracy 0.71\n",
      "12,338,500 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "12,340,100 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "12,341,700 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "12,343,300 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "12,344,900 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "12,346,500 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "12,348,100 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "12,349,700 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "12,351,300 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "12,352,900 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "12,354,500 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "12,356,100 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "12,357,700 examples, moving-average loss 12.05, train accuracy 0.71\n",
      "12,359,300 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "12,360,900 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "12,362,500 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "12,364,100 examples, moving-average loss 11.92, train accuracy 0.71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12,365,700 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "12,367,300 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "12,368,900 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "12,370,500 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "12,372,100 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "12,373,700 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "12,375,300 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "12,376,900 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "12,378,500 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "12,380,100 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "12,381,700 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,383,300 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "12,384,900 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "12,386,500 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "12,388,100 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,389,700 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "12,391,300 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "12,392,900 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "12,394,500 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "12,396,100 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "12,397,700 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "12,399,300 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "12,400,900 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "12,402,500 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "12,404,100 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "12,405,700 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "12,407,300 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "12,408,900 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "12,410,500 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "12,412,100 examples, moving-average loss 12.06, train accuracy 0.71\n",
      "12,413,700 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "12,415,300 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "12,416,900 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "12,418,500 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "12,420,100 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "12,421,700 examples, moving-average loss 12.05, train accuracy 0.71\n",
      "12,423,300 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "12,424,900 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "12,426,500 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,428,100 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "12,429,700 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,431,300 examples, moving-average loss 11.87, train accuracy 0.71\n",
      "12,432,900 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "12,434,500 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "12,436,100 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "12,437,700 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "12,439,300 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "12,440,900 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "12,442,500 examples, moving-average loss 12.04, train accuracy 0.71\n",
      "12,444,100 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "12,445,700 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "12,447,300 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "12,448,900 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "12,450,500 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "12,452,100 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "12,453,700 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "12,455,300 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "12,456,900 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "12,458,500 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "12,460,100 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "12,461,700 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "12,463,300 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "12,464,900 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "12,466,500 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "12,468,100 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "12,469,700 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "12,471,300 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "12,472,900 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "12,474,500 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,476,100 examples, moving-average loss 12.08, train accuracy 0.71\n",
      "12,477,700 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "12,479,300 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "12,480,900 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "12,482,500 examples, moving-average loss 12.05, train accuracy 0.71\n",
      "12,484,100 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "12,485,700 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "12,487,300 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "12,488,900 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "12,490,500 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "12,492,100 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "12,493,700 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "12,495,300 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,496,900 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "12,498,500 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "12,500,100 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "12,501,700 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "12,503,300 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "12,504,900 examples, moving-average loss 12.07, train accuracy 0.71\n",
      "12,506,500 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,508,100 examples, moving-average loss 11.87, train accuracy 0.71\n",
      "12,509,700 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "12,511,300 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,512,900 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "12,514,500 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "12,516,100 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "12,517,700 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "12,519,300 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "12,520,900 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "12,522,500 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "12,524,100 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "12,525,700 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "12,527,300 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "12,528,900 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "12,530,500 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "12,532,100 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,533,700 examples, moving-average loss 12.05, train accuracy 0.71\n",
      "12,535,300 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,536,900 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "12,538,500 examples, moving-average loss 12.07, train accuracy 0.71\n",
      "12,540,100 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "12,541,700 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "12,543,300 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,544,900 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "12,546,500 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "12,548,100 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "12,549,700 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "12,551,300 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "12,552,900 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "12,554,500 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "12,556,100 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "12,557,700 examples, moving-average loss 11.87, train accuracy 0.71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12,559,300 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "12,560,900 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "12,562,500 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,564,100 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,565,700 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "12,567,300 examples, moving-average loss 12.04, train accuracy 0.71\n",
      "12,568,900 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "12,570,500 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "12,572,100 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "12,573,700 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "12,575,300 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "12,576,900 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "12,578,500 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "12,580,100 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "12,581,700 examples, moving-average loss 11.87, train accuracy 0.71\n",
      "12,583,300 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "12,584,900 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "12,586,500 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "12,588,100 examples, moving-average loss 11.86, train accuracy 0.71\n",
      "12,589,700 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "12,591,300 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "12,592,900 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,594,500 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "12,596,100 examples, moving-average loss 11.87, train accuracy 0.71\n",
      "12,597,700 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "12,599,300 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "12,600,900 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "12,602,500 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "12,604,100 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "12,605,700 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "12,607,300 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,608,900 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "12,610,500 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "12,612,100 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "12,613,700 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "12,615,300 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "12,616,900 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,618,500 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "12,620,100 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "Completed 14 epoch in 0:39:06\n",
      "Train accurary:0.71072\n",
      "Validate accuracy:0.70431\n",
      "12,621,650 examples, moving-average loss 11.42, train accuracy 0.59\n",
      "12,623,250 examples, moving-average loss 11.86, train accuracy 0.68\n",
      "12,624,850 examples, moving-average loss 11.93, train accuracy 0.70\n",
      "12,626,450 examples, moving-average loss 11.98, train accuracy 0.70\n",
      "12,628,050 examples, moving-average loss 11.90, train accuracy 0.70\n",
      "12,629,650 examples, moving-average loss 11.95, train accuracy 0.70\n",
      "12,631,250 examples, moving-average loss 11.94, train accuracy 0.70\n",
      "12,632,850 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "12,634,450 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,636,050 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "12,637,650 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "12,639,250 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "12,640,850 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "12,642,450 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "12,644,050 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "12,645,650 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "12,647,250 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "12,648,850 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "12,650,450 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "12,652,050 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "12,653,650 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "12,655,250 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "12,656,850 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,658,450 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,660,050 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "12,661,650 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "12,663,250 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "12,664,850 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "12,666,450 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "12,668,050 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "12,669,650 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "12,671,250 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,672,850 examples, moving-average loss 11.82, train accuracy 0.71\n",
      "12,674,450 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "12,676,050 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "12,677,650 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "12,679,250 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "12,680,850 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "12,682,450 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "12,684,050 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "12,685,650 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "12,687,250 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "12,688,850 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "12,690,450 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "12,692,050 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "12,693,650 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,695,250 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,696,850 examples, moving-average loss 11.86, train accuracy 0.71\n",
      "12,698,450 examples, moving-average loss 11.87, train accuracy 0.71\n",
      "12,700,050 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "12,701,650 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "12,703,250 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "12,704,850 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "12,706,450 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "12,708,050 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "12,709,650 examples, moving-average loss 11.85, train accuracy 0.71\n",
      "12,711,250 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "12,712,850 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "12,714,450 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "12,716,050 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "12,717,650 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "12,719,250 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "12,720,850 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "12,722,450 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,724,050 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "12,725,650 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "12,727,250 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "12,728,850 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "12,730,450 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "12,732,050 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "12,733,650 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "12,735,250 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "12,736,850 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "12,738,450 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "12,740,050 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "12,741,650 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "12,743,250 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "12,744,850 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "12,746,450 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "12,748,050 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,749,650 examples, moving-average loss 11.94, train accuracy 0.71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12,751,250 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "12,752,850 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "12,754,450 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "12,756,050 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "12,757,650 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "12,759,250 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "12,760,850 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,762,450 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "12,764,050 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "12,765,650 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "12,767,250 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "12,768,850 examples, moving-average loss 12.05, train accuracy 0.71\n",
      "12,770,450 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "12,772,050 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "12,773,650 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "12,775,250 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "12,776,850 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "12,778,450 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "12,780,050 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "12,781,650 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "12,783,250 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "12,784,850 examples, moving-average loss 11.84, train accuracy 0.71\n",
      "12,786,450 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "12,788,050 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "12,789,650 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "12,791,250 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "12,792,850 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "12,794,450 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "12,796,050 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "12,797,650 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "12,799,250 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "12,800,850 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "12,802,450 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,804,050 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "12,805,650 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,807,250 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "12,808,850 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "12,810,450 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "12,812,050 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "12,813,650 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "12,815,250 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "12,816,850 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "12,818,450 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "12,820,050 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,821,650 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "12,823,250 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "12,824,850 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "12,826,450 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "12,828,050 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "12,829,650 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "12,831,250 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "12,832,850 examples, moving-average loss 11.86, train accuracy 0.71\n",
      "12,834,450 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "12,836,050 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "12,837,650 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "12,839,250 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "12,840,850 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "12,842,450 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "12,844,050 examples, moving-average loss 11.86, train accuracy 0.71\n",
      "12,845,650 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "12,847,250 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "12,848,850 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "12,850,450 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "12,852,050 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "12,853,650 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "12,855,250 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "12,856,850 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "12,858,450 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "12,860,050 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "12,861,650 examples, moving-average loss 11.82, train accuracy 0.71\n",
      "12,863,250 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "12,864,850 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,866,450 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "12,868,050 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "12,869,650 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "12,871,250 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "12,872,850 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "12,874,450 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "12,876,050 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,877,650 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "12,879,250 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "12,880,850 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "12,882,450 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "12,884,050 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "12,885,650 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,887,250 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "12,888,850 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "12,890,450 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "12,892,050 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "12,893,650 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "12,895,250 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "12,896,850 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "12,898,450 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "12,900,050 examples, moving-average loss 11.87, train accuracy 0.71\n",
      "12,901,650 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "12,903,250 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "12,904,850 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "12,906,450 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "12,908,050 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,909,650 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "12,911,250 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "12,912,850 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "12,914,450 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "12,916,050 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "12,917,650 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "12,919,250 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "12,920,850 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "12,922,450 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,924,050 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "12,925,650 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "12,927,250 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "12,928,850 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "12,930,450 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "12,932,050 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "12,933,650 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "12,935,250 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "12,936,850 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "12,938,450 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "12,940,050 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "12,941,650 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,943,250 examples, moving-average loss 12.01, train accuracy 0.71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12,944,850 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,946,450 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "12,948,050 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "12,949,650 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "12,951,250 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "12,952,850 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "12,954,450 examples, moving-average loss 11.86, train accuracy 0.71\n",
      "12,956,050 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "12,957,650 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "12,959,250 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "12,960,850 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "12,962,450 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "12,964,050 examples, moving-average loss 11.85, train accuracy 0.71\n",
      "12,965,650 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "12,967,250 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "12,968,850 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "12,970,450 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "12,972,050 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "12,973,650 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "12,975,250 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "12,976,850 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "12,978,450 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "12,980,050 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "12,981,650 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "12,983,250 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "12,984,850 examples, moving-average loss 11.86, train accuracy 0.71\n",
      "12,986,450 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "12,988,050 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "12,989,650 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "12,991,250 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "12,992,850 examples, moving-average loss 12.12, train accuracy 0.71\n",
      "12,994,450 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "12,996,050 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "12,997,650 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "12,999,250 examples, moving-average loss 11.86, train accuracy 0.71\n",
      "13,000,850 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "13,002,450 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "13,004,050 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "13,005,650 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "13,007,250 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "13,008,850 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "13,010,450 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "13,012,050 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "13,013,650 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "13,015,250 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "13,016,850 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "13,018,450 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "13,020,050 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "13,021,650 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "13,023,250 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "13,024,850 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "13,026,450 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "13,028,050 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "13,029,650 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "13,031,250 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "13,032,850 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "13,034,450 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "13,036,050 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "13,037,650 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "13,039,250 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,040,850 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "13,042,450 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "13,044,050 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "13,045,650 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "13,047,250 examples, moving-average loss 11.83, train accuracy 0.71\n",
      "13,048,850 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "13,050,450 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "13,052,050 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,053,650 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "13,055,250 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "13,056,850 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,058,450 examples, moving-average loss 11.82, train accuracy 0.71\n",
      "13,060,050 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "13,061,650 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "13,063,250 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "13,064,850 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "13,066,450 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "13,068,050 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,069,650 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "13,071,250 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "13,072,850 examples, moving-average loss 12.06, train accuracy 0.71\n",
      "13,074,450 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "13,076,050 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "13,077,650 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "13,079,250 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "13,080,850 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "13,082,450 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "13,084,050 examples, moving-average loss 12.05, train accuracy 0.71\n",
      "13,085,650 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "13,087,250 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "13,088,850 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "13,090,450 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "13,092,050 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,093,650 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "13,095,250 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "13,096,850 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,098,450 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "13,100,050 examples, moving-average loss 11.87, train accuracy 0.71\n",
      "13,101,650 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "13,103,250 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "13,104,850 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "13,106,450 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "13,108,050 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "13,109,650 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "13,111,250 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "13,112,850 examples, moving-average loss 12.05, train accuracy 0.71\n",
      "13,114,450 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "13,116,050 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "13,117,650 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "13,119,250 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "13,120,850 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "13,122,450 examples, moving-average loss 11.87, train accuracy 0.71\n",
      "13,124,050 examples, moving-average loss 11.87, train accuracy 0.71\n",
      "13,125,650 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "13,127,250 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "13,128,850 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "13,130,450 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "13,132,050 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "13,133,650 examples, moving-average loss 12.04, train accuracy 0.71\n",
      "13,135,250 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,136,850 examples, moving-average loss 11.95, train accuracy 0.71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13,138,450 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "13,140,050 examples, moving-average loss 11.85, train accuracy 0.71\n",
      "13,141,650 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "13,143,250 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "13,144,850 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "13,146,450 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "13,148,050 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "13,149,650 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "13,151,250 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "13,152,850 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "13,154,450 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "13,156,050 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "13,157,650 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "13,159,250 examples, moving-average loss 11.86, train accuracy 0.71\n",
      "13,160,850 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "13,162,450 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "13,164,050 examples, moving-average loss 11.82, train accuracy 0.71\n",
      "13,165,650 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "13,167,250 examples, moving-average loss 11.86, train accuracy 0.71\n",
      "13,168,850 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "13,170,450 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "13,172,050 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "13,173,650 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "13,175,250 examples, moving-average loss 12.05, train accuracy 0.71\n",
      "13,176,850 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "13,178,450 examples, moving-average loss 12.04, train accuracy 0.71\n",
      "13,180,050 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "13,181,650 examples, moving-average loss 11.85, train accuracy 0.71\n",
      "13,183,250 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "13,184,850 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "13,186,450 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "13,188,050 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "13,189,650 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,191,250 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "13,192,850 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "13,194,450 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "13,196,050 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,197,650 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "13,199,250 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "13,200,850 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "13,202,450 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "13,204,050 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,205,650 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "13,207,250 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "13,208,850 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "13,210,450 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "13,212,050 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "13,213,650 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "13,215,250 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "13,216,850 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "13,218,450 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "13,220,050 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,221,650 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "13,223,250 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "13,224,850 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "13,226,450 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "13,228,050 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "13,229,650 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "13,231,250 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "13,232,850 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "13,234,450 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "13,236,050 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "13,237,650 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "13,239,250 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "13,240,850 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,242,450 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "13,244,050 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "13,245,650 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "13,247,250 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "13,248,850 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "13,250,450 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "13,252,050 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "13,253,650 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "13,255,250 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "13,256,850 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "13,258,450 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "13,260,050 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "13,261,650 examples, moving-average loss 11.85, train accuracy 0.71\n",
      "13,263,250 examples, moving-average loss 12.04, train accuracy 0.71\n",
      "13,264,850 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "13,266,450 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,268,050 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "13,269,650 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "13,271,250 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "13,272,850 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "13,274,450 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "13,276,050 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "13,277,650 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "13,279,250 examples, moving-average loss 12.04, train accuracy 0.71\n",
      "13,280,850 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "13,282,450 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "13,284,050 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "13,285,650 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,287,250 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "13,288,850 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "13,290,450 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "13,292,050 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "13,293,650 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "13,295,250 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "13,296,850 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "13,298,450 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "13,300,050 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "13,301,650 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "13,303,250 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "13,304,850 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "13,306,450 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "13,308,050 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "13,309,650 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "13,311,250 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "13,312,850 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,314,450 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "13,316,050 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "13,317,650 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "13,319,250 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "13,320,850 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "13,322,450 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "13,324,050 examples, moving-average loss 12.08, train accuracy 0.71\n",
      "13,325,650 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "13,327,250 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "13,328,850 examples, moving-average loss 11.86, train accuracy 0.71\n",
      "13,330,450 examples, moving-average loss 11.96, train accuracy 0.71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13,332,050 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "13,333,650 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "13,335,250 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "13,336,850 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "13,338,450 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "13,340,050 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "13,341,650 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,343,250 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "13,344,850 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "13,346,450 examples, moving-average loss 12.06, train accuracy 0.71\n",
      "13,348,050 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "13,349,650 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "13,351,250 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "13,352,850 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "13,354,450 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "13,356,050 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,357,650 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "13,359,250 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "13,360,850 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "13,362,450 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "13,364,050 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "13,365,650 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "13,367,250 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "13,368,850 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "13,370,450 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "13,372,050 examples, moving-average loss 12.04, train accuracy 0.71\n",
      "13,373,650 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "13,375,250 examples, moving-average loss 12.06, train accuracy 0.71\n",
      "13,376,850 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "13,378,450 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "13,380,050 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "13,381,650 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "13,383,250 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "13,384,850 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "13,386,450 examples, moving-average loss 11.87, train accuracy 0.71\n",
      "13,388,050 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "13,389,650 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "13,391,250 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "13,392,850 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,394,450 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "13,396,050 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,397,650 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "13,399,250 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "13,400,850 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "13,402,450 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "13,404,050 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "13,405,650 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "13,407,250 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "13,408,850 examples, moving-average loss 12.04, train accuracy 0.71\n",
      "13,410,450 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "13,412,050 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "13,413,650 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "13,415,250 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "13,416,850 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "13,418,450 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "13,420,050 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "13,421,650 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "13,423,250 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "13,424,850 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "13,426,450 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "13,428,050 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "13,429,650 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "13,431,250 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "13,432,850 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "13,434,450 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "13,436,050 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "13,437,650 examples, moving-average loss 11.87, train accuracy 0.71\n",
      "13,439,250 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "13,440,850 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "13,442,450 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "13,444,050 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,445,650 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "13,447,250 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "13,448,850 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "13,450,450 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "13,452,050 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "13,453,650 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "13,455,250 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "13,456,850 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "13,458,450 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "13,460,050 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "13,461,650 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "Completed 15 epoch in 0:39:11\n",
      "Train accurary:0.71283\n",
      "Validate accuracy:0.70535\n",
      "13,463,200 examples, moving-average loss 11.57, train accuracy 0.59\n",
      "13,464,800 examples, moving-average loss 11.86, train accuracy 0.69\n",
      "13,466,400 examples, moving-average loss 11.96, train accuracy 0.70\n",
      "13,468,000 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "13,469,600 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "13,471,200 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "13,472,800 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "13,474,400 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "13,476,000 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "13,477,600 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "13,479,200 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "13,480,800 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "13,482,400 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "13,484,000 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "13,485,600 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "13,487,200 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "13,488,800 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "13,490,400 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "13,492,000 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "13,493,600 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "13,495,200 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "13,496,800 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "13,498,400 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "13,500,000 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "13,501,600 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "13,503,200 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "13,504,800 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "13,506,400 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "13,508,000 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "13,509,600 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "13,511,200 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "13,512,800 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "13,514,400 examples, moving-average loss 11.87, train accuracy 0.71\n",
      "13,516,000 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "13,517,600 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "13,519,200 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "13,520,800 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "13,522,400 examples, moving-average loss 11.95, train accuracy 0.72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13,524,000 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "13,525,600 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "13,527,200 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "13,528,800 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "13,530,400 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "13,532,000 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "13,533,600 examples, moving-average loss 11.87, train accuracy 0.72\n",
      "13,535,200 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "13,536,800 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "13,538,400 examples, moving-average loss 11.88, train accuracy 0.72\n",
      "13,540,000 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "13,541,600 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "13,543,200 examples, moving-average loss 11.85, train accuracy 0.72\n",
      "13,544,800 examples, moving-average loss 11.87, train accuracy 0.71\n",
      "13,546,400 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "13,548,000 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "13,549,600 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "13,551,200 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "13,552,800 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "13,554,400 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "13,556,000 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "13,557,600 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "13,559,200 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "13,560,800 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "13,562,400 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "13,564,000 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,565,600 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "13,567,200 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "13,568,800 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "13,570,400 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "13,572,000 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "13,573,600 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "13,575,200 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "13,576,800 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "13,578,400 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "13,580,000 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,581,600 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "13,583,200 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "13,584,800 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "13,586,400 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "13,588,000 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "13,589,600 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "13,591,200 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "13,592,800 examples, moving-average loss 11.83, train accuracy 0.71\n",
      "13,594,400 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "13,596,000 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "13,597,600 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,599,200 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,600,800 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "13,602,400 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,604,000 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "13,605,600 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "13,607,200 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "13,608,800 examples, moving-average loss 11.87, train accuracy 0.71\n",
      "13,610,400 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "13,612,000 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "13,613,600 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "13,615,200 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "13,616,800 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "13,618,400 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "13,620,000 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "13,621,600 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "13,623,200 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,624,800 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "13,626,400 examples, moving-average loss 11.86, train accuracy 0.71\n",
      "13,628,000 examples, moving-average loss 11.87, train accuracy 0.71\n",
      "13,629,600 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "13,631,200 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "13,632,800 examples, moving-average loss 11.87, train accuracy 0.71\n",
      "13,634,400 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "13,636,000 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "13,637,600 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "13,639,200 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "13,640,800 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "13,642,400 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "13,644,000 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,645,600 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "13,647,200 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "13,648,800 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,650,400 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "13,652,000 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "13,653,600 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "13,655,200 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,656,800 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "13,658,400 examples, moving-average loss 11.85, train accuracy 0.71\n",
      "13,660,000 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "13,661,600 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "13,663,200 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "13,664,800 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "13,666,400 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "13,668,000 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "13,669,600 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "13,671,200 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "13,672,800 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "13,674,400 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "13,676,000 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,677,600 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "13,679,200 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "13,680,800 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,682,400 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "13,684,000 examples, moving-average loss 11.87, train accuracy 0.71\n",
      "13,685,600 examples, moving-average loss 11.85, train accuracy 0.71\n",
      "13,687,200 examples, moving-average loss 11.86, train accuracy 0.71\n",
      "13,688,800 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "13,690,400 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "13,692,000 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "13,693,600 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "13,695,200 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "13,696,800 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "13,698,400 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "13,700,000 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "13,701,600 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "13,703,200 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "13,704,800 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "13,706,400 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "13,708,000 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,709,600 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "13,711,200 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "13,712,800 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,714,400 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "13,716,000 examples, moving-average loss 11.92, train accuracy 0.71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13,717,600 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "13,719,200 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "13,720,800 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "13,722,400 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "13,724,000 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,725,600 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "13,727,200 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "13,728,800 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "13,730,400 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "13,732,000 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "13,733,600 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "13,735,200 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "13,736,800 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "13,738,400 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "13,740,000 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "13,741,600 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "13,743,200 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,744,800 examples, moving-average loss 12.04, train accuracy 0.71\n",
      "13,746,400 examples, moving-average loss 11.85, train accuracy 0.71\n",
      "13,748,000 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "13,749,600 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "13,751,200 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "13,752,800 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,754,400 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "13,756,000 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "13,757,600 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "13,759,200 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "13,760,800 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "13,762,400 examples, moving-average loss 11.87, train accuracy 0.71\n",
      "13,764,000 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "13,765,600 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "13,767,200 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "13,768,800 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "13,770,400 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "13,772,000 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,773,600 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "13,775,200 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "13,776,800 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "13,778,400 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "13,780,000 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,781,600 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "13,783,200 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "13,784,800 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "13,786,400 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "13,788,000 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "13,789,600 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "13,791,200 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "13,792,800 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "13,794,400 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,796,000 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "13,797,600 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,799,200 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "13,800,800 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,802,400 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "13,804,000 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,805,600 examples, moving-average loss 11.81, train accuracy 0.71\n",
      "13,807,200 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "13,808,800 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "13,810,400 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "13,812,000 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "13,813,600 examples, moving-average loss 11.87, train accuracy 0.71\n",
      "13,815,200 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "13,816,800 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "13,818,400 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "13,820,000 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "13,821,600 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "13,823,200 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "13,824,800 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "13,826,400 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "13,828,000 examples, moving-average loss 11.87, train accuracy 0.71\n",
      "13,829,600 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "13,831,200 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "13,832,800 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "13,834,400 examples, moving-average loss 12.09, train accuracy 0.71\n",
      "13,836,000 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "13,837,600 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "13,839,200 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "13,840,800 examples, moving-average loss 11.86, train accuracy 0.71\n",
      "13,842,400 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "13,844,000 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "13,845,600 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,847,200 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "13,848,800 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "13,850,400 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "13,852,000 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "13,853,600 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "13,855,200 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "13,856,800 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "13,858,400 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "13,860,000 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "13,861,600 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "13,863,200 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "13,864,800 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "13,866,400 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "13,868,000 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "13,869,600 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "13,871,200 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "13,872,800 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "13,874,400 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "13,876,000 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "13,877,600 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "13,879,200 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "13,880,800 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,882,400 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "13,884,000 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,885,600 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "13,887,200 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "13,888,800 examples, moving-average loss 11.83, train accuracy 0.71\n",
      "13,890,400 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "13,892,000 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,893,600 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "13,895,200 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "13,896,800 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "13,898,400 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "13,900,000 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "13,901,600 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,903,200 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "13,904,800 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "13,906,400 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "13,908,000 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "13,909,600 examples, moving-average loss 11.92, train accuracy 0.71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13,911,200 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "13,912,800 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "13,914,400 examples, moving-average loss 12.05, train accuracy 0.71\n",
      "13,916,000 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "13,917,600 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,919,200 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "13,920,800 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "13,922,400 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "13,924,000 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "13,925,600 examples, moving-average loss 12.09, train accuracy 0.71\n",
      "13,927,200 examples, moving-average loss 12.04, train accuracy 0.71\n",
      "13,928,800 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "13,930,400 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "13,932,000 examples, moving-average loss 11.85, train accuracy 0.71\n",
      "13,933,600 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "13,935,200 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "13,936,800 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "13,938,400 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "13,940,000 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "13,941,600 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "13,943,200 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "13,944,800 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "13,946,400 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "13,948,000 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "13,949,600 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "13,951,200 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "13,952,800 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "13,954,400 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "13,956,000 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "13,957,600 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "13,959,200 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,960,800 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "13,962,400 examples, moving-average loss 11.86, train accuracy 0.71\n",
      "13,964,000 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "13,965,600 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "13,967,200 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "13,968,800 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "13,970,400 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "13,972,000 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "13,973,600 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "13,975,200 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "13,976,800 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "13,978,400 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,980,000 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "13,981,600 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "13,983,200 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "13,984,800 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "13,986,400 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "13,988,000 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "13,989,600 examples, moving-average loss 12.05, train accuracy 0.71\n",
      "13,991,200 examples, moving-average loss 12.05, train accuracy 0.71\n",
      "13,992,800 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,994,400 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "13,996,000 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "13,997,600 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "13,999,200 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "14,000,800 examples, moving-average loss 11.84, train accuracy 0.71\n",
      "14,002,400 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "14,004,000 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "14,005,600 examples, moving-average loss 11.86, train accuracy 0.71\n",
      "14,007,200 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "14,008,800 examples, moving-average loss 11.85, train accuracy 0.71\n",
      "14,010,400 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "14,012,000 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "14,013,600 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "14,015,200 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "14,016,800 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "14,018,400 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "14,020,000 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "14,021,600 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "14,023,200 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "14,024,800 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "14,026,400 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "14,028,000 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "14,029,600 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "14,031,200 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "14,032,800 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "14,034,400 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "14,036,000 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "14,037,600 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "14,039,200 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "14,040,800 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "14,042,400 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "14,044,000 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "14,045,600 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "14,047,200 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "14,048,800 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "14,050,400 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "14,052,000 examples, moving-average loss 11.86, train accuracy 0.71\n",
      "14,053,600 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "14,055,200 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "14,056,800 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "14,058,400 examples, moving-average loss 11.87, train accuracy 0.71\n",
      "14,060,000 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "14,061,600 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "14,063,200 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "14,064,800 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "14,066,400 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "14,068,000 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "14,069,600 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "14,071,200 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "14,072,800 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "14,074,400 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "14,076,000 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "14,077,600 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "14,079,200 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "14,080,800 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "14,082,400 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "14,084,000 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "14,085,600 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "14,087,200 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "14,088,800 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "14,090,400 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "14,092,000 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "14,093,600 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "14,095,200 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "14,096,800 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "14,098,400 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "14,100,000 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "14,101,600 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "14,103,200 examples, moving-average loss 11.87, train accuracy 0.71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14,104,800 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "14,106,400 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "14,108,000 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "14,109,600 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "14,111,200 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "14,112,800 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "14,114,400 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "14,116,000 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "14,117,600 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "14,119,200 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "14,120,800 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "14,122,400 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "14,124,000 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "14,125,600 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "14,127,200 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "14,128,800 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "14,130,400 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "14,132,000 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "14,133,600 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "14,135,200 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "14,136,800 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "14,138,400 examples, moving-average loss 11.86, train accuracy 0.71\n",
      "14,140,000 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "14,141,600 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "14,143,200 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "14,144,800 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "14,146,400 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "14,148,000 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "14,149,600 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "14,151,200 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "14,152,800 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "14,154,400 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "14,156,000 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "14,157,600 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "14,159,200 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "14,160,800 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "14,162,400 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "14,164,000 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "14,165,600 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "14,167,200 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "14,168,800 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "14,170,400 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "14,172,000 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "14,173,600 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "14,175,200 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "14,176,800 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "14,178,400 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "14,180,000 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "14,181,600 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "14,183,200 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "14,184,800 examples, moving-average loss 11.87, train accuracy 0.71\n",
      "14,186,400 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "14,188,000 examples, moving-average loss 12.06, train accuracy 0.71\n",
      "14,189,600 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "14,191,200 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "14,192,800 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "14,194,400 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "14,196,000 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "14,197,600 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "14,199,200 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "14,200,800 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "14,202,400 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "14,204,000 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "14,205,600 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "14,207,200 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "14,208,800 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "14,210,400 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "14,212,000 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "14,213,600 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "14,215,200 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "14,216,800 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "14,218,400 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "14,220,000 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "14,221,600 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "14,223,200 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "14,224,800 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "14,226,400 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "14,228,000 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "14,229,600 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "14,231,200 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "14,232,800 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "14,234,400 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "14,236,000 examples, moving-average loss 11.82, train accuracy 0.71\n",
      "14,237,600 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "14,239,200 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "14,240,800 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "14,242,400 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "14,244,000 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "14,245,600 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "14,247,200 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "14,248,800 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "14,250,400 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "14,252,000 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "14,253,600 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "14,255,200 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "14,256,800 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "14,258,400 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "14,260,000 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "14,261,600 examples, moving-average loss 12.03, train accuracy 0.71\n",
      "14,263,200 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "14,264,800 examples, moving-average loss 11.88, train accuracy 0.71\n",
      "14,266,400 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "14,268,000 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "14,269,600 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "14,271,200 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "14,272,800 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "14,274,400 examples, moving-average loss 11.87, train accuracy 0.71\n",
      "14,276,000 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "14,277,600 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "14,279,200 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "14,280,800 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "14,282,400 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "14,284,000 examples, moving-average loss 11.87, train accuracy 0.71\n",
      "14,285,600 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "14,287,200 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "14,288,800 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "14,290,400 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "14,292,000 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "14,293,600 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "14,295,200 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "14,296,800 examples, moving-average loss 11.99, train accuracy 0.71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14,298,400 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "14,300,000 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "14,301,600 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "14,303,200 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "Completed 16 epoch in 0:39:13\n",
      "Train accurary:0.71471\n",
      "Validate accuracy:0.70632\n",
      "14,304,750 examples, moving-average loss 11.61, train accuracy 0.62\n",
      "14,306,350 examples, moving-average loss 11.85, train accuracy 0.69\n",
      "14,307,950 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "14,309,550 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "14,311,150 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "14,312,750 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "14,314,350 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "14,315,950 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "14,317,550 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "14,319,150 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "14,320,750 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "14,322,350 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "14,323,950 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "14,325,550 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "14,327,150 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "14,328,750 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "14,330,350 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "14,331,950 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "14,333,550 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "14,335,150 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "14,336,750 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "14,338,350 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "14,339,950 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "14,341,550 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "14,343,150 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "14,344,750 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "14,346,350 examples, moving-average loss 12.01, train accuracy 0.72\n",
      "14,347,950 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "14,349,550 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "14,351,150 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "14,352,750 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "14,354,350 examples, moving-average loss 11.88, train accuracy 0.72\n",
      "14,355,950 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "14,357,550 examples, moving-average loss 11.85, train accuracy 0.72\n",
      "14,359,150 examples, moving-average loss 12.01, train accuracy 0.72\n",
      "14,360,750 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "14,362,350 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "14,363,950 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "14,365,550 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "14,367,150 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "14,368,750 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "14,370,350 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "14,371,950 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "14,373,550 examples, moving-average loss 11.87, train accuracy 0.72\n",
      "14,375,150 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "14,376,750 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "14,378,350 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "14,379,950 examples, moving-average loss 11.87, train accuracy 0.72\n",
      "14,381,550 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "14,383,150 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "14,384,750 examples, moving-average loss 11.85, train accuracy 0.72\n",
      "14,386,350 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "14,387,950 examples, moving-average loss 12.04, train accuracy 0.72\n",
      "14,389,550 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "14,391,150 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "14,392,750 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "14,394,350 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "14,395,950 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "14,397,550 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "14,399,150 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "14,400,750 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "14,402,350 examples, moving-average loss 12.02, train accuracy 0.72\n",
      "14,403,950 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "14,405,550 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "14,407,150 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "14,408,750 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "14,410,350 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "14,411,950 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "14,413,550 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "14,415,150 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "14,416,750 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "14,418,350 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "14,419,950 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "14,421,550 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "14,423,150 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "14,424,750 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "14,426,350 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "14,427,950 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "14,429,550 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "14,431,150 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "14,432,750 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "14,434,350 examples, moving-average loss 11.87, train accuracy 0.72\n",
      "14,435,950 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "14,437,550 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "14,439,150 examples, moving-average loss 12.01, train accuracy 0.72\n",
      "14,440,750 examples, moving-average loss 12.02, train accuracy 0.72\n",
      "14,442,350 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "14,443,950 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "14,445,550 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "14,447,150 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "14,448,750 examples, moving-average loss 12.01, train accuracy 0.72\n",
      "14,450,350 examples, moving-average loss 11.87, train accuracy 0.72\n",
      "14,451,950 examples, moving-average loss 12.02, train accuracy 0.72\n",
      "14,453,550 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "14,455,150 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "14,456,750 examples, moving-average loss 12.01, train accuracy 0.72\n",
      "14,458,350 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "14,459,950 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "14,461,550 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "14,463,150 examples, moving-average loss 11.87, train accuracy 0.72\n",
      "14,464,750 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "14,466,350 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "14,467,950 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "14,469,550 examples, moving-average loss 11.88, train accuracy 0.72\n",
      "14,471,150 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "14,472,750 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "14,474,350 examples, moving-average loss 11.87, train accuracy 0.72\n",
      "14,475,950 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "14,477,550 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "14,479,150 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "14,480,750 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "14,482,350 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "14,483,950 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "14,485,550 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "14,487,150 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "14,488,750 examples, moving-average loss 11.95, train accuracy 0.71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14,490,350 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "14,491,950 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "14,493,550 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "14,495,150 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "14,496,750 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "14,498,350 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "14,499,950 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "14,501,550 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "14,503,150 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "14,504,750 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "14,506,350 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "14,507,950 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "14,509,550 examples, moving-average loss 11.84, train accuracy 0.71\n",
      "14,511,150 examples, moving-average loss 11.95, train accuracy 0.71\n",
      "14,512,750 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "14,514,350 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "14,515,950 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "14,517,550 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "14,519,150 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "14,520,750 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "14,522,350 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "14,523,950 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "14,525,550 examples, moving-average loss 11.84, train accuracy 0.71\n",
      "14,527,150 examples, moving-average loss 11.85, train accuracy 0.72\n",
      "14,528,750 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "14,530,350 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "14,531,950 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "14,533,550 examples, moving-average loss 12.00, train accuracy 0.71\n",
      "14,535,150 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "14,536,750 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "14,538,350 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "14,539,950 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "14,541,550 examples, moving-average loss 12.02, train accuracy 0.71\n",
      "14,543,150 examples, moving-average loss 11.92, train accuracy 0.71\n",
      "14,544,750 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "14,546,350 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "14,547,950 examples, moving-average loss 11.87, train accuracy 0.72\n",
      "14,549,550 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "14,551,150 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "14,552,750 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "14,554,350 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "14,555,950 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "14,557,550 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "14,559,150 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "14,560,750 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "14,562,350 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "14,563,950 examples, moving-average loss 12.04, train accuracy 0.72\n",
      "14,565,550 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "14,567,150 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "14,568,750 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "14,570,350 examples, moving-average loss 11.88, train accuracy 0.72\n",
      "14,571,950 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "14,573,550 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "14,575,150 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "14,576,750 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "14,578,350 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "14,579,950 examples, moving-average loss 11.88, train accuracy 0.72\n",
      "14,581,550 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "14,583,150 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "14,584,750 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "14,586,350 examples, moving-average loss 12.03, train accuracy 0.72\n",
      "14,587,950 examples, moving-average loss 11.86, train accuracy 0.72\n",
      "14,589,550 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "14,591,150 examples, moving-average loss 11.87, train accuracy 0.72\n",
      "14,592,750 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "14,594,350 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "14,595,950 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "14,597,550 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "14,599,150 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "14,600,750 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "14,602,350 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "14,603,950 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "14,605,550 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "14,607,150 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "14,608,750 examples, moving-average loss 11.88, train accuracy 0.72\n",
      "14,610,350 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "14,611,950 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "14,613,550 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "14,615,150 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "14,616,750 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "14,618,350 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "14,619,950 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "14,621,550 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "14,623,150 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "14,624,750 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "14,626,350 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "14,627,950 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "14,629,550 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "14,631,150 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "14,632,750 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "14,634,350 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "14,635,950 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "14,637,550 examples, moving-average loss 11.85, train accuracy 0.72\n",
      "14,639,150 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "14,640,750 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "14,642,350 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "14,643,950 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "14,645,550 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "14,647,150 examples, moving-average loss 11.85, train accuracy 0.72\n",
      "14,648,750 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "14,650,350 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "14,651,950 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "14,653,550 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "14,655,150 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "14,656,750 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "14,658,350 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "14,659,950 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "14,661,550 examples, moving-average loss 11.87, train accuracy 0.72\n",
      "14,663,150 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "14,664,750 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "14,666,350 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "14,667,950 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "14,669,550 examples, moving-average loss 11.85, train accuracy 0.72\n",
      "14,671,150 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "14,672,750 examples, moving-average loss 11.88, train accuracy 0.72\n",
      "14,674,350 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "14,675,950 examples, moving-average loss 12.07, train accuracy 0.72\n",
      "14,677,550 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "14,679,150 examples, moving-average loss 12.02, train accuracy 0.72\n",
      "14,680,750 examples, moving-average loss 12.01, train accuracy 0.72\n",
      "14,682,350 examples, moving-average loss 11.89, train accuracy 0.72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14,683,950 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "14,685,550 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "14,687,150 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "14,688,750 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "14,690,350 examples, moving-average loss 11.87, train accuracy 0.72\n",
      "14,691,950 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "14,693,550 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "14,695,150 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "14,696,750 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "14,698,350 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "14,699,950 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "14,701,550 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "14,703,150 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "14,704,750 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "14,706,350 examples, moving-average loss 11.86, train accuracy 0.72\n",
      "14,707,950 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "14,709,550 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "14,711,150 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "14,712,750 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "14,714,350 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "14,715,950 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "14,717,550 examples, moving-average loss 12.03, train accuracy 0.72\n",
      "14,719,150 examples, moving-average loss 12.02, train accuracy 0.72\n",
      "14,720,750 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "14,722,350 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "14,723,950 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "14,725,550 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "14,727,150 examples, moving-average loss 12.03, train accuracy 0.72\n",
      "14,728,750 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "14,730,350 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "14,731,950 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "14,733,550 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "14,735,150 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "14,736,750 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "14,738,350 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "14,739,950 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "14,741,550 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "14,743,150 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "14,744,750 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "14,746,350 examples, moving-average loss 12.01, train accuracy 0.72\n",
      "14,747,950 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "14,749,550 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "14,751,150 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "14,752,750 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "14,754,350 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "14,755,950 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "14,757,550 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "14,759,150 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "14,760,750 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "14,762,350 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "14,763,950 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "14,765,550 examples, moving-average loss 12.02, train accuracy 0.72\n",
      "14,767,150 examples, moving-average loss 12.08, train accuracy 0.72\n",
      "14,768,750 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "14,770,350 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "14,771,950 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "14,773,550 examples, moving-average loss 11.87, train accuracy 0.72\n",
      "14,775,150 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "14,776,750 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "14,778,350 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "14,779,950 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "14,781,550 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "14,783,150 examples, moving-average loss 11.84, train accuracy 0.72\n",
      "14,784,750 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "14,786,350 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "14,787,950 examples, moving-average loss 12.02, train accuracy 0.72\n",
      "14,789,550 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "14,791,150 examples, moving-average loss 12.02, train accuracy 0.72\n",
      "14,792,750 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "14,794,350 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "14,795,950 examples, moving-average loss 12.01, train accuracy 0.72\n",
      "14,797,550 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "14,799,150 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "14,800,750 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "14,802,350 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "14,803,950 examples, moving-average loss 11.88, train accuracy 0.72\n",
      "14,805,550 examples, moving-average loss 11.88, train accuracy 0.72\n",
      "14,807,150 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "14,808,750 examples, moving-average loss 11.88, train accuracy 0.72\n",
      "14,810,350 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "14,811,950 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "14,813,550 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "14,815,150 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "14,816,750 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "14,818,350 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "14,819,950 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "14,821,550 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "14,823,150 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "14,824,750 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "14,826,350 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "14,827,950 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "14,829,550 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "14,831,150 examples, moving-average loss 12.05, train accuracy 0.72\n",
      "14,832,750 examples, moving-average loss 12.02, train accuracy 0.72\n",
      "14,834,350 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "14,835,950 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "14,837,550 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "14,839,150 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "14,840,750 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "14,842,350 examples, moving-average loss 11.81, train accuracy 0.72\n",
      "14,843,950 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "14,845,550 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "14,847,150 examples, moving-average loss 11.88, train accuracy 0.72\n",
      "14,848,750 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "14,850,350 examples, moving-average loss 11.85, train accuracy 0.72\n",
      "14,851,950 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "14,853,550 examples, moving-average loss 12.01, train accuracy 0.72\n",
      "14,855,150 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "14,856,750 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "14,858,350 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "14,859,950 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "14,861,550 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "14,863,150 examples, moving-average loss 11.88, train accuracy 0.72\n",
      "14,864,750 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "14,866,350 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "14,867,950 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "14,869,550 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "14,871,150 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "14,872,750 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "14,874,350 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "14,875,950 examples, moving-average loss 11.96, train accuracy 0.72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14,877,550 examples, moving-average loss 11.86, train accuracy 0.72\n",
      "14,879,150 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "14,880,750 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "14,882,350 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "14,883,950 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "14,885,550 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "14,887,150 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "14,888,750 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "14,890,350 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "14,891,950 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "14,893,550 examples, moving-average loss 11.84, train accuracy 0.72\n",
      "14,895,150 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "14,896,750 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "14,898,350 examples, moving-average loss 11.86, train accuracy 0.72\n",
      "14,899,950 examples, moving-average loss 11.88, train accuracy 0.72\n",
      "14,901,550 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "14,903,150 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "14,904,750 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "14,906,350 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "14,907,950 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "14,909,550 examples, moving-average loss 11.83, train accuracy 0.72\n",
      "14,911,150 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "14,912,750 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "14,914,350 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "14,915,950 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "14,917,550 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "14,919,150 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "14,920,750 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "14,922,350 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "14,923,950 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "14,925,550 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "14,927,150 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "14,928,750 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "14,930,350 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "14,931,950 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "14,933,550 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "14,935,150 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "14,936,750 examples, moving-average loss 12.03, train accuracy 0.72\n",
      "14,938,350 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "14,939,950 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "14,941,550 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "14,943,150 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "14,944,750 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "14,946,350 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "14,947,950 examples, moving-average loss 12.02, train accuracy 0.72\n",
      "14,949,550 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "14,951,150 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "14,952,750 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "14,954,350 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "14,955,950 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "14,957,550 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "14,959,150 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "14,960,750 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "14,962,350 examples, moving-average loss 12.04, train accuracy 0.72\n",
      "14,963,950 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "14,965,550 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "14,967,150 examples, moving-average loss 12.01, train accuracy 0.72\n",
      "14,968,750 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "14,970,350 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "14,971,950 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "14,973,550 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "14,975,150 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "14,976,750 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "14,978,350 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "14,979,950 examples, moving-average loss 11.87, train accuracy 0.72\n",
      "14,981,550 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "14,983,150 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "14,984,750 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "14,986,350 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "14,987,950 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "14,989,550 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "14,991,150 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "14,992,750 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "14,994,350 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "14,995,950 examples, moving-average loss 12.02, train accuracy 0.72\n",
      "14,997,550 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "14,999,150 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,000,750 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "15,002,350 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "15,003,950 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "15,005,550 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "15,007,150 examples, moving-average loss 12.02, train accuracy 0.72\n",
      "15,008,750 examples, moving-average loss 12.02, train accuracy 0.72\n",
      "15,010,350 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "15,011,950 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "15,013,550 examples, moving-average loss 12.06, train accuracy 0.72\n",
      "15,015,150 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "15,016,750 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "15,018,350 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "15,019,950 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,021,550 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "15,023,150 examples, moving-average loss 12.02, train accuracy 0.72\n",
      "15,024,750 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "15,026,350 examples, moving-average loss 11.87, train accuracy 0.72\n",
      "15,027,950 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "15,029,550 examples, moving-average loss 12.06, train accuracy 0.72\n",
      "15,031,150 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "15,032,750 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "15,034,350 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "15,035,950 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "15,037,550 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "15,039,150 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,040,750 examples, moving-average loss 12.04, train accuracy 0.72\n",
      "15,042,350 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,043,950 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "15,045,550 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "15,047,150 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,048,750 examples, moving-average loss 11.88, train accuracy 0.72\n",
      "15,050,350 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "15,051,950 examples, moving-average loss 12.02, train accuracy 0.72\n",
      "15,053,550 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,055,150 examples, moving-average loss 12.03, train accuracy 0.72\n",
      "15,056,750 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "15,058,350 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "15,059,950 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "15,061,550 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "15,063,150 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "15,064,750 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "15,066,350 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "15,067,950 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "15,069,550 examples, moving-average loss 11.88, train accuracy 0.72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15,071,150 examples, moving-average loss 11.85, train accuracy 0.72\n",
      "15,072,750 examples, moving-average loss 11.88, train accuracy 0.72\n",
      "15,074,350 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "15,075,950 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "15,077,550 examples, moving-average loss 11.86, train accuracy 0.72\n",
      "15,079,150 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "15,080,750 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,082,350 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "15,083,950 examples, moving-average loss 11.86, train accuracy 0.72\n",
      "15,085,550 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "15,087,150 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "15,088,750 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,090,350 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "15,091,950 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "15,093,550 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "15,095,150 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "15,096,750 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "15,098,350 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,099,950 examples, moving-average loss 12.01, train accuracy 0.72\n",
      "15,101,550 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "15,103,150 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "15,104,750 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "15,106,350 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "15,107,950 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "15,109,550 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "15,111,150 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "15,112,750 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "15,114,350 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "15,115,950 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "15,117,550 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "15,119,150 examples, moving-average loss 11.88, train accuracy 0.72\n",
      "15,120,750 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "15,122,350 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "15,123,950 examples, moving-average loss 12.01, train accuracy 0.72\n",
      "15,125,550 examples, moving-average loss 11.85, train accuracy 0.72\n",
      "15,127,150 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "15,128,750 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "15,130,350 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "15,131,950 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "15,133,550 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "15,135,150 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "15,136,750 examples, moving-average loss 11.86, train accuracy 0.72\n",
      "15,138,350 examples, moving-average loss 12.02, train accuracy 0.72\n",
      "15,139,950 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "15,141,550 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "15,143,150 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "15,144,750 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "Completed 17 epoch in 0:39:05\n",
      "Train accurary:0.71650\n",
      "Validate accuracy:0.70724\n",
      "15,146,300 examples, moving-average loss 11.70, train accuracy 0.63\n",
      "15,147,900 examples, moving-average loss 11.87, train accuracy 0.69\n",
      "15,149,500 examples, moving-average loss 11.98, train accuracy 0.71\n",
      "15,151,100 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "15,152,700 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "15,154,300 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "15,155,900 examples, moving-average loss 11.94, train accuracy 0.71\n",
      "15,157,500 examples, moving-average loss 11.89, train accuracy 0.71\n",
      "15,159,100 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "15,160,700 examples, moving-average loss 11.88, train accuracy 0.72\n",
      "15,162,300 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "15,163,900 examples, moving-average loss 11.96, train accuracy 0.71\n",
      "15,165,500 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "15,167,100 examples, moving-average loss 12.01, train accuracy 0.71\n",
      "15,168,700 examples, moving-average loss 11.90, train accuracy 0.71\n",
      "15,170,300 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "15,171,900 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "15,173,500 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "15,175,100 examples, moving-average loss 12.02, train accuracy 0.72\n",
      "15,176,700 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "15,178,300 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "15,179,900 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,181,500 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,183,100 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "15,184,700 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "15,186,300 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,187,900 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "15,189,500 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "15,191,100 examples, moving-average loss 11.87, train accuracy 0.72\n",
      "15,192,700 examples, moving-average loss 12.02, train accuracy 0.72\n",
      "15,194,300 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "15,195,900 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "15,197,500 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "15,199,100 examples, moving-average loss 11.85, train accuracy 0.72\n",
      "15,200,700 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "15,202,300 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,203,900 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "15,205,500 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "15,207,100 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,208,700 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,210,300 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "15,211,900 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "15,213,500 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "15,215,100 examples, moving-average loss 11.87, train accuracy 0.72\n",
      "15,216,700 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "15,218,300 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "15,219,900 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,221,500 examples, moving-average loss 11.84, train accuracy 0.72\n",
      "15,223,100 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "15,224,700 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "15,226,300 examples, moving-average loss 11.86, train accuracy 0.72\n",
      "15,227,900 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "15,229,500 examples, moving-average loss 12.02, train accuracy 0.72\n",
      "15,231,100 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "15,232,700 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "15,234,300 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "15,235,900 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "15,237,500 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,239,100 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "15,240,700 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "15,242,300 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "15,243,900 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "15,245,500 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "15,247,100 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "15,248,700 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "15,250,300 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "15,251,900 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "15,253,500 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "15,255,100 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "15,256,700 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "15,258,300 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "15,259,900 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "15,261,500 examples, moving-average loss 11.92, train accuracy 0.72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15,263,100 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "15,264,700 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "15,266,300 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "15,267,900 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "15,269,500 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "15,271,100 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,272,700 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "15,274,300 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "15,275,900 examples, moving-average loss 11.86, train accuracy 0.72\n",
      "15,277,500 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,279,100 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "15,280,700 examples, moving-average loss 12.01, train accuracy 0.72\n",
      "15,282,300 examples, moving-average loss 12.04, train accuracy 0.72\n",
      "15,283,900 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "15,285,500 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "15,287,100 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "15,288,700 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "15,290,300 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "15,291,900 examples, moving-average loss 11.86, train accuracy 0.72\n",
      "15,293,500 examples, moving-average loss 12.03, train accuracy 0.72\n",
      "15,295,100 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "15,296,700 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "15,298,300 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "15,299,900 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "15,301,500 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "15,303,100 examples, moving-average loss 11.88, train accuracy 0.72\n",
      "15,304,700 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,306,300 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "15,307,900 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "15,309,500 examples, moving-average loss 11.86, train accuracy 0.72\n",
      "15,311,100 examples, moving-average loss 11.85, train accuracy 0.72\n",
      "15,312,700 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "15,314,300 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "15,315,900 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "15,317,500 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "15,319,100 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "15,320,700 examples, moving-average loss 12.02, train accuracy 0.72\n",
      "15,322,300 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "15,323,900 examples, moving-average loss 12.05, train accuracy 0.72\n",
      "15,325,500 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "15,327,100 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "15,328,700 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "15,330,300 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "15,331,900 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "15,333,500 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "15,335,100 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "15,336,700 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "15,338,300 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "15,339,900 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "15,341,500 examples, moving-average loss 11.87, train accuracy 0.72\n",
      "15,343,100 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "15,344,700 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "15,346,300 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "15,347,900 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "15,349,500 examples, moving-average loss 12.03, train accuracy 0.72\n",
      "15,351,100 examples, moving-average loss 11.81, train accuracy 0.72\n",
      "15,352,700 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "15,354,300 examples, moving-average loss 11.84, train accuracy 0.72\n",
      "15,355,900 examples, moving-average loss 12.02, train accuracy 0.72\n",
      "15,357,500 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "15,359,100 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "15,360,700 examples, moving-average loss 12.01, train accuracy 0.72\n",
      "15,362,300 examples, moving-average loss 12.03, train accuracy 0.72\n",
      "15,363,900 examples, moving-average loss 12.01, train accuracy 0.72\n",
      "15,365,500 examples, moving-average loss 11.87, train accuracy 0.72\n",
      "15,367,100 examples, moving-average loss 11.80, train accuracy 0.72\n",
      "15,368,700 examples, moving-average loss 11.84, train accuracy 0.72\n",
      "15,370,300 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "15,371,900 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "15,373,500 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "15,375,100 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "15,376,700 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "15,378,300 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "15,379,900 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "15,381,500 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "15,383,100 examples, moving-average loss 12.01, train accuracy 0.72\n",
      "15,384,700 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,386,300 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,387,900 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "15,389,500 examples, moving-average loss 11.88, train accuracy 0.72\n",
      "15,391,100 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "15,392,700 examples, moving-average loss 11.86, train accuracy 0.72\n",
      "15,394,300 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,395,900 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "15,397,500 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "15,399,100 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,400,700 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "15,402,300 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,403,900 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "15,405,500 examples, moving-average loss 12.02, train accuracy 0.72\n",
      "15,407,100 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "15,408,700 examples, moving-average loss 11.85, train accuracy 0.72\n",
      "15,410,300 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,411,900 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "15,413,500 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,415,100 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "15,416,700 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,418,300 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "15,419,900 examples, moving-average loss 12.03, train accuracy 0.72\n",
      "15,421,500 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "15,423,100 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "15,424,700 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "15,426,300 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "15,427,900 examples, moving-average loss 12.03, train accuracy 0.72\n",
      "15,429,500 examples, moving-average loss 11.87, train accuracy 0.72\n",
      "15,431,100 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "15,432,700 examples, moving-average loss 11.86, train accuracy 0.72\n",
      "15,434,300 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "15,435,900 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,437,500 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,439,100 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "15,440,700 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "15,442,300 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "15,443,900 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "15,445,500 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "15,447,100 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "15,448,700 examples, moving-average loss 12.01, train accuracy 0.72\n",
      "15,450,300 examples, moving-average loss 11.86, train accuracy 0.72\n",
      "15,451,900 examples, moving-average loss 11.88, train accuracy 0.72\n",
      "15,453,500 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "15,455,100 examples, moving-average loss 11.91, train accuracy 0.72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15,456,700 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "15,458,300 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "15,459,900 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "15,461,500 examples, moving-average loss 11.88, train accuracy 0.72\n",
      "15,463,100 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "15,464,700 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "15,466,300 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "15,467,900 examples, moving-average loss 12.02, train accuracy 0.72\n",
      "15,469,500 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "15,471,100 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "15,472,700 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "15,474,300 examples, moving-average loss 11.88, train accuracy 0.72\n",
      "15,475,900 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "15,477,500 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "15,479,100 examples, moving-average loss 11.84, train accuracy 0.72\n",
      "15,480,700 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "15,482,300 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,483,900 examples, moving-average loss 11.88, train accuracy 0.72\n",
      "15,485,500 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "15,487,100 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "15,488,700 examples, moving-average loss 11.84, train accuracy 0.72\n",
      "15,490,300 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,491,900 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "15,493,500 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "15,495,100 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "15,496,700 examples, moving-average loss 11.86, train accuracy 0.72\n",
      "15,498,300 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "15,499,900 examples, moving-average loss 12.01, train accuracy 0.72\n",
      "15,501,500 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "15,503,100 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "15,504,700 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "15,506,300 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "15,507,900 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "15,509,500 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "15,511,100 examples, moving-average loss 11.83, train accuracy 0.72\n",
      "15,512,700 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "15,514,300 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "15,515,900 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "15,517,500 examples, moving-average loss 12.08, train accuracy 0.72\n",
      "15,519,100 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "15,520,700 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "15,522,300 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "15,523,900 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "15,525,500 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "15,527,100 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "15,528,700 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "15,530,300 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "15,531,900 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "15,533,500 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "15,535,100 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "15,536,700 examples, moving-average loss 12.03, train accuracy 0.72\n",
      "15,538,300 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "15,539,900 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,541,500 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "15,543,100 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "15,544,700 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "15,546,300 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "15,547,900 examples, moving-average loss 11.88, train accuracy 0.72\n",
      "15,549,500 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "15,551,100 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "15,552,700 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "15,554,300 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "15,555,900 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "15,557,500 examples, moving-average loss 12.02, train accuracy 0.72\n",
      "15,559,100 examples, moving-average loss 12.03, train accuracy 0.72\n",
      "15,560,700 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "15,562,300 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,563,900 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,565,500 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "15,567,100 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "15,568,700 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "15,570,300 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "15,571,900 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "15,573,500 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "15,575,100 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "15,576,700 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "15,578,300 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "15,579,900 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "15,581,500 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "15,583,100 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "15,584,700 examples, moving-average loss 11.88, train accuracy 0.72\n",
      "15,586,300 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "15,587,900 examples, moving-average loss 12.03, train accuracy 0.72\n",
      "15,589,500 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "15,591,100 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "15,592,700 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,594,300 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,595,900 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "15,597,500 examples, moving-average loss 12.01, train accuracy 0.72\n",
      "15,599,100 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "15,600,700 examples, moving-average loss 12.01, train accuracy 0.72\n",
      "15,602,300 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "15,603,900 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "15,605,500 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "15,607,100 examples, moving-average loss 12.06, train accuracy 0.72\n",
      "15,608,700 examples, moving-average loss 12.01, train accuracy 0.72\n",
      "15,610,300 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,611,900 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "15,613,500 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "15,615,100 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "15,616,700 examples, moving-average loss 12.01, train accuracy 0.72\n",
      "15,618,300 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "15,619,900 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "15,621,500 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "15,623,100 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "15,624,700 examples, moving-average loss 11.87, train accuracy 0.72\n",
      "15,626,300 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "15,627,900 examples, moving-average loss 11.88, train accuracy 0.72\n",
      "15,629,500 examples, moving-average loss 12.01, train accuracy 0.72\n",
      "15,631,100 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "15,632,700 examples, moving-average loss 12.01, train accuracy 0.72\n",
      "15,634,300 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "15,635,900 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "15,637,500 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "15,639,100 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "15,640,700 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "15,642,300 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "15,643,900 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "15,645,500 examples, moving-average loss 11.86, train accuracy 0.72\n",
      "15,647,100 examples, moving-average loss 11.84, train accuracy 0.72\n",
      "15,648,700 examples, moving-average loss 11.95, train accuracy 0.72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15,650,300 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "15,651,900 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "15,653,500 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "15,655,100 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "15,656,700 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "15,658,300 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "15,659,900 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "15,661,500 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "15,663,100 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,664,700 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "15,666,300 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "15,667,900 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "15,669,500 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "15,671,100 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "15,672,700 examples, moving-average loss 12.01, train accuracy 0.72\n",
      "15,674,300 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "15,675,900 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "15,677,500 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "15,679,100 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "15,680,700 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "15,682,300 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "15,683,900 examples, moving-average loss 11.86, train accuracy 0.72\n",
      "15,685,500 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "15,687,100 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "15,688,700 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "15,690,300 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "15,691,900 examples, moving-average loss 11.83, train accuracy 0.72\n",
      "15,693,500 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "15,695,100 examples, moving-average loss 12.01, train accuracy 0.72\n",
      "15,696,700 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "15,698,300 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,699,900 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "15,701,500 examples, moving-average loss 12.01, train accuracy 0.72\n",
      "15,703,100 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "15,704,700 examples, moving-average loss 11.86, train accuracy 0.72\n",
      "15,706,300 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "15,707,900 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "15,709,500 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "15,711,100 examples, moving-average loss 11.88, train accuracy 0.72\n",
      "15,712,700 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "15,714,300 examples, moving-average loss 11.86, train accuracy 0.72\n",
      "15,715,900 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "15,717,500 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "15,719,100 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "15,720,700 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "15,722,300 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "15,723,900 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "15,725,500 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "15,727,100 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "15,728,700 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,730,300 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "15,731,900 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "15,733,500 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "15,735,100 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "15,736,700 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,738,300 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "15,739,900 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "15,741,500 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "15,743,100 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "15,744,700 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "15,746,300 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "15,747,900 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "15,749,500 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "15,751,100 examples, moving-average loss 11.80, train accuracy 0.72\n",
      "15,752,700 examples, moving-average loss 11.88, train accuracy 0.72\n",
      "15,754,300 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "15,755,900 examples, moving-average loss 11.86, train accuracy 0.72\n",
      "15,757,500 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "15,759,100 examples, moving-average loss 12.02, train accuracy 0.72\n",
      "15,760,700 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "15,762,300 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "15,763,900 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "15,765,500 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "15,767,100 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "15,768,700 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "15,770,300 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "15,771,900 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,773,500 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "15,775,100 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "15,776,700 examples, moving-average loss 12.02, train accuracy 0.72\n",
      "15,778,300 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "15,779,900 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "15,781,500 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "15,783,100 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "15,784,700 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "15,786,300 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "15,787,900 examples, moving-average loss 12.01, train accuracy 0.72\n",
      "15,789,500 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "15,791,100 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "15,792,700 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "15,794,300 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "15,795,900 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,797,500 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "15,799,100 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,800,700 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "15,802,300 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "15,803,900 examples, moving-average loss 12.01, train accuracy 0.72\n",
      "15,805,500 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,807,100 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "15,808,700 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "15,810,300 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "15,811,900 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "15,813,500 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,815,100 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,816,700 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "15,818,300 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "15,819,900 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "15,821,500 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "15,823,100 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "15,824,700 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "15,826,300 examples, moving-average loss 11.88, train accuracy 0.72\n",
      "15,827,900 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "15,829,500 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "15,831,100 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "15,832,700 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,834,300 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "15,835,900 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "15,837,500 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "15,839,100 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,840,700 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "15,842,300 examples, moving-average loss 11.92, train accuracy 0.72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15,843,900 examples, moving-average loss 11.88, train accuracy 0.72\n",
      "15,845,500 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "15,847,100 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "15,848,700 examples, moving-average loss 12.01, train accuracy 0.72\n",
      "15,850,300 examples, moving-average loss 12.01, train accuracy 0.72\n",
      "15,851,900 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "15,853,500 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "15,855,100 examples, moving-average loss 12.05, train accuracy 0.72\n",
      "15,856,700 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "15,858,300 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "15,859,900 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "15,861,500 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "15,863,100 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,864,700 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "15,866,300 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "15,867,900 examples, moving-average loss 11.84, train accuracy 0.72\n",
      "15,869,500 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "15,871,100 examples, moving-average loss 12.05, train accuracy 0.72\n",
      "15,872,700 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "15,874,300 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "15,875,900 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "15,877,500 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "15,879,100 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "15,880,700 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "15,882,300 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "15,883,900 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "15,885,500 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "15,887,100 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "15,888,700 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "15,890,300 examples, moving-average loss 11.87, train accuracy 0.72\n",
      "15,891,900 examples, moving-average loss 11.88, train accuracy 0.72\n",
      "15,893,500 examples, moving-average loss 12.05, train accuracy 0.72\n",
      "15,895,100 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "15,896,700 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "15,898,300 examples, moving-average loss 12.01, train accuracy 0.72\n",
      "15,899,900 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "15,901,500 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,903,100 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "15,904,700 examples, moving-average loss 12.02, train accuracy 0.72\n",
      "15,906,300 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "15,907,900 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "15,909,500 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,911,100 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "15,912,700 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "15,914,300 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "15,915,900 examples, moving-average loss 12.01, train accuracy 0.72\n",
      "15,917,500 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "15,919,100 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "15,920,700 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "15,922,300 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "15,923,900 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "15,925,500 examples, moving-average loss 11.88, train accuracy 0.72\n",
      "15,927,100 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "15,928,700 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "15,930,300 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "15,931,900 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "15,933,500 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "15,935,100 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "15,936,700 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "15,938,300 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "15,939,900 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "15,941,500 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "15,943,100 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "15,944,700 examples, moving-average loss 12.01, train accuracy 0.72\n",
      "15,946,300 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "15,947,900 examples, moving-average loss 11.87, train accuracy 0.72\n",
      "15,949,500 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "15,951,100 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "15,952,700 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "15,954,300 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "15,955,900 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "15,957,500 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "15,959,100 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "15,960,700 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "15,962,300 examples, moving-average loss 11.88, train accuracy 0.72\n",
      "15,963,900 examples, moving-average loss 12.02, train accuracy 0.72\n",
      "15,965,500 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "15,967,100 examples, moving-average loss 11.81, train accuracy 0.72\n",
      "15,968,700 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "15,970,300 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "15,971,900 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,973,500 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "15,975,100 examples, moving-average loss 11.88, train accuracy 0.72\n",
      "15,976,700 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "15,978,300 examples, moving-average loss 11.87, train accuracy 0.72\n",
      "15,979,900 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "15,981,500 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "15,983,100 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "15,984,700 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "15,986,300 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "Completed 18 epoch in 0:39:19\n",
      "Train accurary:0.71828\n",
      "Validate accuracy:0.70755\n",
      "15,987,850 examples, moving-average loss 11.78, train accuracy 0.64\n",
      "15,989,450 examples, moving-average loss 11.92, train accuracy 0.70\n",
      "15,991,050 examples, moving-average loss 11.99, train accuracy 0.71\n",
      "15,992,650 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "15,994,250 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "15,995,850 examples, moving-average loss 11.97, train accuracy 0.71\n",
      "15,997,450 examples, moving-average loss 11.93, train accuracy 0.71\n",
      "15,999,050 examples, moving-average loss 11.91, train accuracy 0.71\n",
      "16,000,650 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "16,002,250 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "16,003,850 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "16,005,450 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "16,007,050 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "16,008,650 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "16,010,250 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "16,011,850 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "16,013,450 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "16,015,050 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "16,016,650 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "16,018,250 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "16,019,850 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "16,021,450 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "16,023,050 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "16,024,650 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "16,026,250 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "16,027,850 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "16,029,450 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "16,031,050 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "16,032,650 examples, moving-average loss 11.83, train accuracy 0.72\n",
      "16,034,250 examples, moving-average loss 12.03, train accuracy 0.72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16,035,850 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "16,037,450 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "16,039,050 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "16,040,650 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "16,042,250 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "16,043,850 examples, moving-average loss 11.86, train accuracy 0.72\n",
      "16,045,450 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "16,047,050 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "16,048,650 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "16,050,250 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "16,051,850 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "16,053,450 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "16,055,050 examples, moving-average loss 11.87, train accuracy 0.72\n",
      "16,056,650 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "16,058,250 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "16,059,850 examples, moving-average loss 11.87, train accuracy 0.72\n",
      "16,061,450 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "16,063,050 examples, moving-average loss 11.87, train accuracy 0.72\n",
      "16,064,650 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "16,066,250 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "16,067,850 examples, moving-average loss 11.88, train accuracy 0.72\n",
      "16,069,450 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "16,071,050 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "16,072,650 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "16,074,250 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "16,075,850 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "16,077,450 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "16,079,050 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "16,080,650 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "16,082,250 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "16,083,850 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "16,085,450 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "16,087,050 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "16,088,650 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "16,090,250 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "16,091,850 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "16,093,450 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "16,095,050 examples, moving-average loss 12.01, train accuracy 0.72\n",
      "16,096,650 examples, moving-average loss 12.01, train accuracy 0.72\n",
      "16,098,250 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "16,099,850 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "16,101,450 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "16,103,050 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "16,104,650 examples, moving-average loss 11.87, train accuracy 0.72\n",
      "16,106,250 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "16,107,850 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "16,109,450 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "16,111,050 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "16,112,650 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "16,114,250 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "16,115,850 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "16,117,450 examples, moving-average loss 11.87, train accuracy 0.72\n",
      "16,119,050 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "16,120,650 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "16,122,250 examples, moving-average loss 12.05, train accuracy 0.72\n",
      "16,123,850 examples, moving-average loss 12.02, train accuracy 0.72\n",
      "16,125,450 examples, moving-average loss 12.02, train accuracy 0.72\n",
      "16,127,050 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "16,128,650 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "16,130,250 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "16,131,850 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "16,133,450 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "16,135,050 examples, moving-average loss 12.02, train accuracy 0.72\n",
      "16,136,650 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "16,138,250 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "16,139,850 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "16,141,450 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "16,143,050 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "16,144,650 examples, moving-average loss 11.87, train accuracy 0.72\n",
      "16,146,250 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "16,147,850 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "16,149,450 examples, moving-average loss 11.88, train accuracy 0.72\n",
      "16,151,050 examples, moving-average loss 11.88, train accuracy 0.72\n",
      "16,152,650 examples, moving-average loss 11.87, train accuracy 0.72\n",
      "16,154,250 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "16,155,850 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "16,157,450 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "16,159,050 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "16,160,650 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "16,162,250 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "16,163,850 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "16,165,450 examples, moving-average loss 12.03, train accuracy 0.72\n",
      "16,167,050 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "16,168,650 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "16,170,250 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "16,171,850 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "16,173,450 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "16,175,050 examples, moving-average loss 12.01, train accuracy 0.72\n",
      "16,176,650 examples, moving-average loss 11.85, train accuracy 0.72\n",
      "16,178,250 examples, moving-average loss 12.01, train accuracy 0.72\n",
      "16,179,850 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "16,181,450 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "16,183,050 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "16,184,650 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "16,186,250 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "16,187,850 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "16,189,450 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "16,191,050 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "16,192,650 examples, moving-average loss 11.83, train accuracy 0.72\n",
      "16,194,250 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "16,195,850 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "16,197,450 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "16,199,050 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "16,200,650 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "16,202,250 examples, moving-average loss 12.01, train accuracy 0.72\n",
      "16,203,850 examples, moving-average loss 12.04, train accuracy 0.72\n",
      "16,205,450 examples, moving-average loss 12.04, train accuracy 0.72\n",
      "16,207,050 examples, moving-average loss 11.86, train accuracy 0.72\n",
      "16,208,650 examples, moving-average loss 11.86, train accuracy 0.72\n",
      "16,210,250 examples, moving-average loss 11.79, train accuracy 0.72\n",
      "16,211,850 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "16,213,450 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "16,215,050 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "16,216,650 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "16,218,250 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "16,219,850 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "16,221,450 examples, moving-average loss 11.85, train accuracy 0.72\n",
      "16,223,050 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "16,224,650 examples, moving-average loss 12.03, train accuracy 0.72\n",
      "16,226,250 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "16,227,850 examples, moving-average loss 11.93, train accuracy 0.72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16,229,450 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "16,231,050 examples, moving-average loss 11.86, train accuracy 0.72\n",
      "16,232,650 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "16,234,250 examples, moving-average loss 11.86, train accuracy 0.72\n",
      "16,235,850 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "16,237,450 examples, moving-average loss 12.05, train accuracy 0.72\n",
      "16,239,050 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "16,240,650 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "16,242,250 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "16,243,850 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "16,245,450 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "16,247,050 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "16,248,650 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "16,250,250 examples, moving-average loss 11.88, train accuracy 0.72\n",
      "16,251,850 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "16,253,450 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "16,255,050 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "16,256,650 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "16,258,250 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "16,259,850 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "16,261,450 examples, moving-average loss 12.02, train accuracy 0.72\n",
      "16,263,050 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "16,264,650 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "16,266,250 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "16,267,850 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "16,269,450 examples, moving-average loss 12.03, train accuracy 0.72\n",
      "16,271,050 examples, moving-average loss 11.88, train accuracy 0.72\n",
      "16,272,650 examples, moving-average loss 11.84, train accuracy 0.72\n",
      "16,274,250 examples, moving-average loss 11.86, train accuracy 0.72\n",
      "16,275,850 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "16,277,450 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "16,279,050 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "16,280,650 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "16,282,250 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "16,283,850 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "16,285,450 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "16,287,050 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "16,288,650 examples, moving-average loss 11.87, train accuracy 0.72\n",
      "16,290,250 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "16,291,850 examples, moving-average loss 11.88, train accuracy 0.72\n",
      "16,293,450 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "16,295,050 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "16,296,650 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "16,298,250 examples, moving-average loss 11.81, train accuracy 0.72\n",
      "16,299,850 examples, moving-average loss 11.87, train accuracy 0.72\n",
      "16,301,450 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "16,303,050 examples, moving-average loss 11.88, train accuracy 0.72\n",
      "16,304,650 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "16,306,250 examples, moving-average loss 11.86, train accuracy 0.72\n",
      "16,307,850 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "16,309,450 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "16,311,050 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "16,312,650 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "16,314,250 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "16,315,850 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "16,317,450 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "16,319,050 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "16,320,650 examples, moving-average loss 11.87, train accuracy 0.72\n",
      "16,322,250 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "16,323,850 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "16,325,450 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "16,327,050 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "16,328,650 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "16,330,250 examples, moving-average loss 11.85, train accuracy 0.72\n",
      "16,331,850 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "16,333,450 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "16,335,050 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "16,336,650 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "16,338,250 examples, moving-average loss 11.85, train accuracy 0.72\n",
      "16,339,850 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "16,341,450 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "16,343,050 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "16,344,650 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "16,346,250 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "16,347,850 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "16,349,450 examples, moving-average loss 12.01, train accuracy 0.72\n",
      "16,351,050 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "16,352,650 examples, moving-average loss 11.85, train accuracy 0.72\n",
      "16,354,250 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "16,355,850 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "16,357,450 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "16,359,050 examples, moving-average loss 12.06, train accuracy 0.72\n",
      "16,360,650 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "16,362,250 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "16,363,850 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "16,365,450 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "16,367,050 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "16,368,650 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "16,370,250 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "16,371,850 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "16,373,450 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "16,375,050 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "16,376,650 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "16,378,250 examples, moving-average loss 12.02, train accuracy 0.72\n",
      "16,379,850 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "16,381,450 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "16,383,050 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "16,384,650 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "16,386,250 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "16,387,850 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "16,389,450 examples, moving-average loss 11.88, train accuracy 0.72\n",
      "16,391,050 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "16,392,650 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "16,394,250 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "16,395,850 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "16,397,450 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "16,399,050 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "16,400,650 examples, moving-average loss 12.05, train accuracy 0.72\n",
      "16,402,250 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "16,403,850 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "16,405,450 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "16,407,050 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "16,408,650 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "16,410,250 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "16,411,850 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "16,413,450 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "16,415,050 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "16,416,650 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "16,418,250 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "16,419,850 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "16,421,450 examples, moving-average loss 11.95, train accuracy 0.72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16,423,050 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "16,424,650 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "16,426,250 examples, moving-average loss 11.87, train accuracy 0.72\n",
      "16,427,850 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "16,429,450 examples, moving-average loss 12.01, train accuracy 0.72\n",
      "16,431,050 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "16,432,650 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "16,434,250 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "16,435,850 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "16,437,450 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "16,439,050 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "16,440,650 examples, moving-average loss 11.87, train accuracy 0.72\n",
      "16,442,250 examples, moving-average loss 12.01, train accuracy 0.72\n",
      "16,443,850 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "16,445,450 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "16,447,050 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "16,448,650 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "16,450,250 examples, moving-average loss 12.01, train accuracy 0.72\n",
      "16,451,850 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "16,453,450 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "16,455,050 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "16,456,650 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "16,458,250 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "16,459,850 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "16,461,450 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "16,463,050 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "16,464,650 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "16,466,250 examples, moving-average loss 11.85, train accuracy 0.72\n",
      "16,467,850 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "16,469,450 examples, moving-average loss 11.86, train accuracy 0.72\n",
      "16,471,050 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "16,472,650 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "16,474,250 examples, moving-average loss 12.01, train accuracy 0.72\n",
      "16,475,850 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "16,477,450 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "16,479,050 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "16,480,650 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "16,482,250 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "16,483,850 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "16,485,450 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "16,487,050 examples, moving-average loss 11.87, train accuracy 0.72\n",
      "16,488,650 examples, moving-average loss 11.83, train accuracy 0.72\n",
      "16,490,250 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "16,491,850 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "16,493,450 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "16,495,050 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "16,496,650 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "16,498,250 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "16,499,850 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "16,501,450 examples, moving-average loss 11.88, train accuracy 0.72\n",
      "16,503,050 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "16,504,650 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "16,506,250 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "16,507,850 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "16,509,450 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "16,511,050 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "16,512,650 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "16,514,250 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "16,515,850 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "16,517,450 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "16,519,050 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "16,520,650 examples, moving-average loss 12.02, train accuracy 0.72\n",
      "16,522,250 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "16,523,850 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "16,525,450 examples, moving-average loss 11.85, train accuracy 0.72\n",
      "16,527,050 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "16,528,650 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "16,530,250 examples, moving-average loss 11.87, train accuracy 0.72\n",
      "16,531,850 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "16,533,450 examples, moving-average loss 11.86, train accuracy 0.72\n",
      "16,535,050 examples, moving-average loss 12.01, train accuracy 0.72\n",
      "16,536,650 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "16,538,250 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "16,539,850 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "16,541,450 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "16,543,050 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "16,544,650 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "16,546,250 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "16,547,850 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "16,549,450 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "16,551,050 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "16,552,650 examples, moving-average loss 11.84, train accuracy 0.72\n",
      "16,554,250 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "16,555,850 examples, moving-average loss 11.85, train accuracy 0.72\n",
      "16,557,450 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "16,559,050 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "16,560,650 examples, moving-average loss 11.88, train accuracy 0.72\n",
      "16,562,250 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "16,563,850 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "16,565,450 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "16,567,050 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "16,568,650 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "16,570,250 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "16,571,850 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "16,573,450 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "16,575,050 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "16,576,650 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "16,578,250 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "16,579,850 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "16,581,450 examples, moving-average loss 11.86, train accuracy 0.72\n",
      "16,583,050 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "16,584,650 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "16,586,250 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "16,587,850 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "16,589,450 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "16,591,050 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "16,592,650 examples, moving-average loss 11.80, train accuracy 0.72\n",
      "16,594,250 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "16,595,850 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "16,597,450 examples, moving-average loss 11.84, train accuracy 0.72\n",
      "16,599,050 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "16,600,650 examples, moving-average loss 12.04, train accuracy 0.72\n",
      "16,602,250 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "16,603,850 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "16,605,450 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "16,607,050 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "16,608,650 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "16,610,250 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "16,611,850 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "16,613,450 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "16,615,050 examples, moving-average loss 11.97, train accuracy 0.72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16,616,650 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "16,618,250 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "16,619,850 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "16,621,450 examples, moving-average loss 11.83, train accuracy 0.72\n",
      "16,623,050 examples, moving-average loss 11.86, train accuracy 0.72\n",
      "16,624,650 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "16,626,250 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "16,627,850 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "16,629,450 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "16,631,050 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "16,632,650 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "16,634,250 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "16,635,850 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "16,637,450 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "16,639,050 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "16,640,650 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "16,642,250 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "16,643,850 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "16,645,450 examples, moving-average loss 12.03, train accuracy 0.72\n",
      "16,647,050 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "16,648,650 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "16,650,250 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "16,651,850 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "16,653,450 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "16,655,050 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "16,656,650 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "16,658,250 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "16,659,850 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "16,661,450 examples, moving-average loss 11.86, train accuracy 0.72\n",
      "16,663,050 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "16,664,650 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "16,666,250 examples, moving-average loss 12.01, train accuracy 0.72\n",
      "16,667,850 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "16,669,450 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "16,671,050 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "16,672,650 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "16,674,250 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "16,675,850 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "16,677,450 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "16,679,050 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "16,680,650 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "16,682,250 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "16,683,850 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "16,685,450 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "16,687,050 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "16,688,650 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "16,690,250 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "16,691,850 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "16,693,450 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "16,695,050 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "16,696,650 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "16,698,250 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "16,699,850 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "16,701,450 examples, moving-average loss 12.00, train accuracy 0.72\n",
      "16,703,050 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "16,704,650 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "16,706,250 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "16,707,850 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "16,709,450 examples, moving-average loss 11.85, train accuracy 0.72\n",
      "16,711,050 examples, moving-average loss 12.02, train accuracy 0.72\n",
      "16,712,650 examples, moving-average loss 12.08, train accuracy 0.72\n",
      "16,714,250 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "16,715,850 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "16,717,450 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "16,719,050 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "16,720,650 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "16,722,250 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "16,723,850 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "16,725,450 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "16,727,050 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "16,728,650 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "16,730,250 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "16,731,850 examples, moving-average loss 11.87, train accuracy 0.72\n",
      "16,733,450 examples, moving-average loss 11.84, train accuracy 0.72\n",
      "16,735,050 examples, moving-average loss 12.03, train accuracy 0.72\n",
      "16,736,650 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "16,738,250 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "16,739,850 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "16,741,450 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "16,743,050 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "16,744,650 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "16,746,250 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "16,747,850 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "16,749,450 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "16,751,050 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "16,752,650 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "16,754,250 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "16,755,850 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "16,757,450 examples, moving-average loss 12.01, train accuracy 0.72\n",
      "16,759,050 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "16,760,650 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "16,762,250 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "16,763,850 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "16,765,450 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "16,767,050 examples, moving-average loss 11.86, train accuracy 0.72\n",
      "16,768,650 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "16,770,250 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "16,771,850 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "16,773,450 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "16,775,050 examples, moving-average loss 12.02, train accuracy 0.72\n",
      "16,776,650 examples, moving-average loss 11.98, train accuracy 0.72\n",
      "16,778,250 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "16,779,850 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "16,781,450 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "16,783,050 examples, moving-average loss 12.02, train accuracy 0.72\n",
      "16,784,650 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "16,786,250 examples, moving-average loss 12.04, train accuracy 0.72\n",
      "16,787,850 examples, moving-average loss 12.01, train accuracy 0.72\n",
      "16,789,450 examples, moving-average loss 11.88, train accuracy 0.72\n",
      "16,791,050 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "16,792,650 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "16,794,250 examples, moving-average loss 11.94, train accuracy 0.72\n",
      "16,795,850 examples, moving-average loss 11.89, train accuracy 0.72\n",
      "16,797,450 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "16,799,050 examples, moving-average loss 11.97, train accuracy 0.72\n",
      "16,800,650 examples, moving-average loss 11.87, train accuracy 0.72\n",
      "16,802,250 examples, moving-average loss 11.88, train accuracy 0.72\n",
      "16,803,850 examples, moving-average loss 11.83, train accuracy 0.72\n",
      "16,805,450 examples, moving-average loss 12.01, train accuracy 0.72\n",
      "16,807,050 examples, moving-average loss 12.02, train accuracy 0.72\n",
      "16,808,650 examples, moving-average loss 11.87, train accuracy 0.72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16,810,250 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "16,811,850 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "16,813,450 examples, moving-average loss 11.99, train accuracy 0.72\n",
      "16,815,050 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "16,816,650 examples, moving-average loss 11.88, train accuracy 0.72\n",
      "16,818,250 examples, moving-average loss 11.96, train accuracy 0.72\n",
      "16,819,850 examples, moving-average loss 11.93, train accuracy 0.72\n",
      "16,821,450 examples, moving-average loss 12.04, train accuracy 0.72\n",
      "16,823,050 examples, moving-average loss 11.91, train accuracy 0.72\n",
      "16,824,650 examples, moving-average loss 11.92, train accuracy 0.72\n",
      "16,826,250 examples, moving-average loss 11.90, train accuracy 0.72\n",
      "16,827,850 examples, moving-average loss 11.95, train accuracy 0.72\n",
      "Completed 19 epoch in 0:39:33\n",
      "Train accurary:0.71986\n",
      "Validate accuracy:0.70797\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# start session\n",
    "sess = tf.Session()\n",
    "graph = tf.get_default_graph()\n",
    "\n",
    "# Tensorboard - Visualize graph \n",
    "merged = tf.summary.merge_all()\n",
    "train_writer = tf.summary.FileWriter(summary_params['chkpt_dir'] + '/train', sess.graph)\n",
    "test_writer = tf.summary.FileWriter(summary_params['chkpt_dir'] + '/test')\n",
    "\n",
    "print(\"tensorboard --logdir={}/train\".format(summary_params['chkpt_dir']))\n",
    "print(\"tensorboard --logdir={}/test\".format(summary_params['chkpt_dir']))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "init_l = tf.local_variables_initializer()\n",
    "\n",
    "# Run the initializer\n",
    "sess.run(init)\n",
    "sess.run(init_l)\n",
    "\n",
    "total_batches = 0\n",
    "total_examples = 0\n",
    "total_loss = 0\n",
    "loss_ema = np.log(2)  # track exponential-moving-average of loss\n",
    "ema_decay = np.exp(-1/10)  # decay parameter for moving average = np.exp(-1/history_length)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(train_params['total_epochs']):\n",
    "    t0 = time.time()\n",
    "\n",
    "    train_batches = 1\n",
    "    train_accuracy = 0.0\n",
    "    \n",
    "    for (bx, by) in utils.multi_batch_generator(train_params['batch_size'], \\\n",
    "                                        ds.padded_train_features, ds.train_labels):\n",
    "\n",
    "        summary, batch_loss, _, batch_accuracy = sess.run(\n",
    "            [merged, regularized_loss_, train_op_, accuracy_], feed_dict={X: bx, Y: by})\n",
    "        \n",
    "        train_batches +=1\n",
    "        train_accuracy += batch_accuracy\n",
    "        \n",
    "        # Compute some statistics\n",
    "        total_batches += 1\n",
    "        total_examples += len(bx)\n",
    "        total_loss += batch_loss * len(bx)  # re-scale, since batch loss is mean\n",
    "\n",
    "        # Compute moving average to smooth out noisy per-batch loss\n",
    "        loss_ema = ema_decay * loss_ema + (1 - ema_decay) * batch_loss\n",
    "        \n",
    "        if (total_batches % 25 == 0):\n",
    "            print(\"{:5,} examples, moving-average loss {:.2f}, train accuracy {:.2f}\"\\\n",
    "                  .format(total_examples, loss_ema, train_accuracy/train_batches))    \n",
    "            \n",
    "        train_writer.add_summary(summary, total_batches)\n",
    "\n",
    "    print(\"Completed {} epoch in {:s}\".format(i, utils.pretty_timedelta(since=t0)))\n",
    "    \n",
    "    train_accuracy = train_accuracy/train_batches\n",
    "    print(\"Train accurary:{:.5f}\".format(train_accuracy))\n",
    "    \n",
    "    validate_batches = 1\n",
    "    validate_accuracy = 0.0\n",
    "    for (vx, vy) in utils.multi_batch_generator(train_params['batch_size'], \\\n",
    "                                            ds.padded_validate_features, ds.validate_labels):\n",
    "\n",
    "        summary, batch_accuracy = sess.run([merged, accuracy_], feed_dict={X: vx, Y: vy})\n",
    "\n",
    "        validate_batches +=1\n",
    "        validate_accuracy += batch_accuracy\n",
    "\n",
    "        test_writer.add_summary(summary, total_batches + validate_batches)\n",
    "\n",
    "    validate_accuracy = validate_accuracy/validate_batches\n",
    "    print(\"Validate accuracy:{:.5f}\".format(validate_accuracy))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:0.7057087912192711\n"
     ]
    }
   ],
   "source": [
    "test_batches = 1\n",
    "test_accuracy = 0.0\n",
    "test_pred_y = []\n",
    "\n",
    "for (tx, ty) in utils.multi_batch_generator(train_params['batch_size'], \\\n",
    "                                        ds.padded_test_features, ds.test_labels):\n",
    "\n",
    "    batch_accuracy, pred_max = sess.run([accuracy_, pred_max_], feed_dict={X: tx, Y: ty})\n",
    "\n",
    "    test_batches +=1\n",
    "    test_accuracy += batch_accuracy\n",
    "    test_pred_y.append(pred_max.tolist())\n",
    "\n",
    "test_accuracy = test_accuracy/test_batches\n",
    "print(\"Test accuracy:{}\".format(test_accuracy))\n",
    "\n",
    "pred_y = [y for x in test_pred_y for y in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_path = saver.save(sess, \"./tmp/model_bow_test.ckpt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8909,  1529,   403,   115],\n",
       "       [ 3007,  5506,  4034,   484],\n",
       "       [  591,  2195, 16346,  9545],\n",
       "       [  216,   267,  8140, 42592]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(ds.test_labels, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#op = sess.graph.get_operations()\n",
    "#[m.values() for m in op]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Implement Integrated Gradients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_gradients(sess, graph, review):\n",
    "    \n",
    "    with graph.as_default():\n",
    "\n",
    "        # get prediction \n",
    "        pred_prob_ = graph.get_tensor_by_name('Prediction/pred_proba:0')\n",
    "        pred_prob = sess.run([pred_prob_], feed_dict={X:[review], Y:[0]})\n",
    "        \n",
    "        # get gradient     \n",
    "        input_y_ = graph.get_tensor_by_name('input_y:0')[0]\n",
    "        embed_x_ = graph.get_tensor_by_name('Embedding_Layer/embed_x:0')\n",
    "        label_prediction_ = graph.get_tensor_by_name('Prediction/pred_proba:0')[:, input_y_]\n",
    "        grads_ = tf.gradients(label_prediction_, embed_x_)[0]\n",
    "        \n",
    "        embed_x, grads = sess.run([embed_x_, grads_], feed_dict={X:[review], Y:[np.argmax(pred_prob)]})\n",
    "        return grads * embed_x\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_integrated_gradients_new(sess, graph, review, steps = 50):\n",
    "\n",
    "    empty_review = np.zeros(input_length)\n",
    "    \n",
    "    with graph.as_default():\n",
    "\n",
    "        # get embedding and prediction \n",
    "        embed_x_ = graph.get_tensor_by_name('Embedding_Layer/embed_x:0')\n",
    "        pred_prob_ = graph.get_tensor_by_name('Prediction/pred_proba:0')\n",
    "        embed_x, pred_y, pred_prob = sess.run([embed_x_, pred_max_, pred_prob_], feed_dict={X:[review], Y:[4]})\n",
    "          \n",
    "        # empty embedding \n",
    "        empty_embed_x, empty_pred_prob = sess.run([embed_x_, pred_prob_], feed_dict={X:[empty_review], Y:[4]})\n",
    "            \n",
    "            \n",
    "        # get integrated gradient \n",
    "        input_y_ = graph.get_tensor_by_name('input_y:0')[0]\n",
    "        label_prediction_ = graph.get_tensor_by_name('Prediction/pred_proba:0')[:, input_y_]\n",
    "        grads_ = tf.gradients(label_prediction_, embed_x_)[0]\n",
    "\n",
    "        \n",
    "        all_grads = []\n",
    "        for i in range(0, steps + 1):\n",
    "            _, grads = sess.run([label_prediction_, grads_], feed_dict={embed_x_:(empty_embed_x + (embed_x - empty_embed_x)*(float(i)/steps)), Y:pred_y})\n",
    "            all_grads.append(grads)\n",
    "        \n",
    "        integrated_grads = np.average(all_grads[:-1], axis=0) * embed_x\n",
    "        return integrated_grads, pred_y[0], pred_prob, empty_pred_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Supporting class to save attributions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class AttributionResult(object):\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.html_text = \"<html><body>\"\n",
    "    \n",
    "    def append(self, text):\n",
    "        self.html_text += text\n",
    "    \n",
    "    def write(self, index):\n",
    "        self.html_text += \"</body></html>\"\n",
    "        \n",
    "        with open(\"result/{}_{}.html\".format(self.filename, index), \"w\") as the_file:\n",
    "            the_file.write(self.html_text)\n",
    "            \n",
    "        self.html_text = \"<html><body>\"\n",
    "        \n",
    "class AttributionCount(object):\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.word_count = []\n",
    "        \n",
    "    def append(self, token):\n",
    "        self.word_count.append(token)\n",
    "    \n",
    "    def write(self, index):\n",
    "        df = pd.DataFrame.from_records(self.word_count)\n",
    "        df.columns = ['pred', 'target', 'vocab', 'attr']\n",
    "        df.attr.round(5)\n",
    "        df.to_csv(\"result/{}_{}.csv\".format(self.filename, index))\n",
    "    \n",
    "        self.word_count = []\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Visualize the attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(visualization)\n",
    "\n",
    "file_suffix = \"cnn_glovec_d{}_h1024_64_epoch{}\".format(model_params['embed_dim'], \\\n",
    "                                   train_params['total_epochs'])\n",
    "\n",
    "corrHigh = AttributionResult(\"CorrHigh_{}\".format(file_suffix))\n",
    "corrLow = AttributionResult(\"CorrLow_{}\".format(file_suffix))\n",
    "incorrHigh = AttributionResult(\"InCorrHigh_{}\".format(file_suffix))\n",
    "incorrLow = AttributionResult(\"InCorrLow_{}\".format(file_suffix))\n",
    "word_counts = AttributionCount(\"wordcounts_{}\".format(file_suffix))\n",
    "\n",
    "\n",
    "for i in range(0, len(ds.test_labels)):\n",
    "    gradients = get_gradients(sess, sess.graph, ds.padded_test_features[i])\n",
    "    #integrated_gradients, pred_y, pred_proba = get_integrated_gradients(sess, sess.graph, ds.padded_test_features[i])\n",
    "    integrated_gradients, pred_y, pred_proba, empty_pred_proba = get_integrated_gradients_new(sess, sess.graph, ds.padded_test_features[i])\n",
    "   \n",
    "    \n",
    "    #print(np.matrix(gradients).sum())\n",
    "    print(np.matrix(integrated_gradients).sum())\n",
    "    print(pred_proba[0][pred_y])\n",
    "    print(empty_pred_proba[0][pred_y])\n",
    "\n",
    "    pred_text = \"predicted = {}, actual = {}\".format(pred_y+2, ds.test_labels[i]+2)\n",
    "    print(\"{}, {}\".format(i, pred_text))\n",
    "\n",
    "    #visualization.visualize_token_attrs(ds.vocab.ids_to_words(ds.test_features[i])[:input_length], np.matrix(gradients).sum(axis=1))\n",
    "    html_text = visualization.visualize_token_attrs(\n",
    "            ds.vocab.ids_to_words(ds.test_features[i])[:input_length], \n",
    "            np.matrix(integrated_gradients).sum(axis=1), \n",
    "            pred_y+2, ds.test_labels[i]+2, word_counts)\n",
    "\n",
    "    text = \"</br>\" + pred_text + \"</br>\" + html_text\n",
    "    \n",
    "    if (pred_y == ds.test_labels[i]):\n",
    "        if (pred_y >= 2):\n",
    "            corrHigh.append(text)\n",
    "        else:\n",
    "            corrLow.append(text)\n",
    "    else:\n",
    "        if (ds.test_labels[i] >= 2):\n",
    "            incorrHigh.append(text)\n",
    "        else:\n",
    "            incorrLow.append(text)\n",
    "    \n",
    "    if (i % 1000) == 0:\n",
    "        corrHigh.write(i)\n",
    "        corrLow.write(i)\n",
    "        incorrHigh.write(i)\n",
    "        incorrLow.write(i)\n",
    "        \n",
    "        word_counts.write(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
